{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype:uint8\n",
      "shape:uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a3eb5a860>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image=cv2.imread('wheel.png',cv2.IMREAD_GRAYSCALE)\n",
    "print('dtype:'+str(input_image.dtype))\n",
    "print('shape:'+str(input_image.dtype))\n",
    "plt.imshow(input_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a3ebb72b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddepth=cv2.CV_64F\n",
    "dx=1\n",
    "dy=0\n",
    "sobelx=cv2.Sobel(input_image,ddepth,dx,dy)\n",
    "\n",
    "plt.imshow(sobelx,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a3ec9b668>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sobelx=cv2.Sobel(input_image,cv2.CV_64F,1,0)\n",
    "sobely=cv2.Sobel(input_image,cv2.CV_64F,0,1)\n",
    "sobel=cv2.sqrt(cv2.addWeighted(cv2.pow(sobelx,2.0),1.0,cv2.pow(sobely,2.0),1.0,0.0))\n",
    "\n",
    "plt.figure(figsize=(6,6));\n",
    "plt.subplot(2,2,1);\n",
    "plt.title('Input image');\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(input_image,cmap='gray');\n",
    "plt.subplot(2,2,2);\n",
    "plt.title('Sobel x operation');\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(cv2.absdiff(sobelx,0.0),cmap='gray')\n",
    "plt.subplot(2,2,3);\n",
    "plt.title('Sobel y operation');\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(cv2.absdiff(sobely,0.0),cmap='gray')\n",
    "plt.subplot(2,2,4);\n",
    "plt.title('Sobel  intensity');\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(sobel,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a3ed1f2e8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGcJJREFUeJztnV/sJlV5xz9PqXKhJIAGsi5rQbNNSnqBZENJNMZeVIGbxQsNXtRNY7JeQKNJe4F6UW560Ua9MDUkGEmXxkJJ1LA3TUViYm9EV4L8cYOsSmTdDZsGo9gmKvD04p0Xhvl7ZubMzJmZ7yf55X1/886888yZc77neZ5z5rzm7gghRJ4/mtsAIUR6SBiEECUkDEKIEhIGIUQJCYMQooSEQQhRYjRhMLObzOwZMztjZneOdR4hRHxsjHkMZnYR8BPgr4CzwA+Aj7n7j6OfTAgRnbE8hhuAM+7+M3f/PfAAcHSkcwkhIvPHI33vQeD53P9ngb+o29nMNP1SiAlwdwvZbyxhqDr5Gxq/mR0Hjo90fiHEAMYShrPAodz/VwHn8ju4+z3APSCPQYjUGCvH8APgsJldY2ZvBm4DTo50LiFEZEbxGNz9ZTO7A/gv4CLgXnd/eoxzCSHiM8pwZWcjFEoIMQmhyUfNfBRClJAwCCFKSBiEECUkDEKIEhIGIUQJCYMQooSEQQhRQsIghCghYRBClJAwCCFKSBiEECUkDEKIEhIGMSru/tpfcbtIl7EWahHiNcyCHugTCSFhEKOyFwV5CMtCwiAmoeg1SCjSRjkGMSpV+QWRPvIYxGi4u/ILC0UegxCihIRBCFFCwiBmQSFG2kgYhBAlJAxCiBISBjEaCheWi4RBzILmNqSNhEHMgryJtJEwCCFKaOaj2ARtoYs8mDcySBjM7DngJeAV4GV3P2JmlwP/AVwNPAd81N1/NcxMsUTmnhK9FwMz62RH/ritEiOU+Et3v87dj2T/3wk84u6HgUey/4WYlL0o9Wnc++O2/ADYGDmGo8CJ7P0J4NYRziFEifxqUTF6e3kM/XHgW2b2QzM7nm270t3PA2SvV1QdaGbHzeyUmZ0aaIPYOHkx6Osl1JFfaGZL3oMNuVgze4e7nzOzK4CHgb8FTrr7pbl9fuXul7V8z3ZKfENMlWOY8jywbE/C3YOMH+QxuPu57PUC8E3gBuAFMzsAkL1eGHIOIZqYMsG5pWXqeguDmb3FzC7Zvwc+CDwFnASOZbsdAx4aaqQQRWLmErqwlcRk71DCzN7FzkuA3bDnv7v7P5rZ24AHgXcCvwA+4u4vtnzXekt4w9Q13BgNOv8d+/dTC8USQ4vQUGJQjiEWEoZ1MpUwxPrOWLakzCQ5BiHmotgQ52yYe29lTUgYxOKoaoQpNMwUbIiFhEGICOSTkmtAwiAWxRLi+TWIg4RBrIJUxGItcx302PVIFCtGKhV3KpbQs49FcRh1iUgYRqQ4nFbcJkSqSBhGoKqnWLogdFnoZOludCzyycil3X8Jw8Sk7l7WNeo2m/PHyVN6naWOVEgYBDC8AdcdV3yuYIhApC6qdSzRZgnDBOQr9JzTdvdU2RAzYdaWeK3K3C+x8XRhaZ6ThGFEUqsMIXaMsfJRnVCkUi5TsLSQQsIwMikshjq3HU3nLj4l2XTMHE9QxmYp9ksYRmKuCtBnZeSqnmzqxU/qzrmUhhTCkq5DwrASqsKWth64KdSZ43cYqkKOJQ/51bEEsZMwjETdjR+jUtQ1nLYG31UshtgW8p1FUcsv8Lq2FZNSFwct1DICcy2C2qVRp9ALh04br/OGUm5YRYrXMGOoGXRSeQwLpc8KRqG9d4zOIuYISF1jGmMlqLHIez1d8j9zIY9hBJoq29CK2OYltP2f31bc3nbeEELyFUM8mqHeQ5fvHYOqUZiJ16nUmo8pMkQYQnrMNlGCbtOb9/QVkKF5jJB1I2N8X9fvicUMC9gqlFgTbY21rVKHft60TwhNk5uKE5u6hDZVoxP5/2OFP3l3fyzGCIliI49hYrpWgtCkVZ33kD92iB2xaQpxQjyEqoYVs8efsnwmPlfQibSCU8K0icK+dys2mqYk1xQ9Ygh1XkPfocm6GZTFfUK+Z2/LVJ3m3PeiCoUSidNW2eumDhdJYXiySF2OoMqlL86QLM7wjNWg98fXlftY5ZeCWOdRKDExoRWgKWSA6lg+NJRIqRL2GVWpO77u/X6/riHcWCNLdd8Jk4yKKJRYKkWxbuu1mipqXYiRClU9flOiser4/ed177sQun/sDjWlewLyGEajb4/TVsFDhiv3FN3iJdJlWLKq7Ma6/qV9b+7743gMZnavmV0ws6dy2y43s4fN7Nns9bJsu5nZl8zsjJk9YWbX97+E7dFWKYq9f5OXsAZRgOp8Q1VnVhyZKB4/hPzxKXSkUxASSvwrcFNh253AI+5+GHgk+x/gZuBw9nccuDuOmdukaxKxKARLF4U9TdfUFGLEbtBTiEIq96xVGNz9u0DxZ+yPAiey9yeAW3Pb7/Md3wMuNbMDsYxdM1VDjvn3beP0+X3W2Ku1eQ7FEY38+2Leoomq8st/9xQNN4X71zf5eKW7nwfIXq/Ith8Ens/tdzbbJgLpkmXPi8caPYUiobmGIcOXay27rsQelagq1cq7YmbHzeyUmZ2KbMPiaBp1aGrwVe7y2it2WxnkGSPfsBX6CsML+xAhe72QbT8LHMrtdxVwruoL3P0edz/i7kd62rAa6lzUpjH4Kjd57aKwpxgy1SUdoTopuQRxmNvGvsJwEjiWvT8GPJTb/vFsdOJG4Nf7kEOE0WX8fQvhQx1VYUXILMUllFMSNuYnvlT9AfcD54E/sPMIPgG8jd1oxLPZ6+XZvgZ8Gfgp8CRwpO37s+N8bX++u7BOn+237wnZt+1ca/8rlkNIubeVV0h5jl3mY31/SHt0d01wGosm176YWa9LqtV9x5bChhDqyrPq89DvgzSfSh2Ka0p0+rRV6LpjxI66vEF+tCbk2CJLbvixkDAkRohQqOLuqEq65hO5VXMbQoW1rYzzyc+xmLMTkDAkQr4iqjcLpylcK5ZjURz6NLytlL+EISHyFXUrFTAWVcO5UM4XFF+HnnOtoZ2EYSTGqDSh3zeFm5sSdR5AnVhUhRgpMqd9EobEGFoRmjLqWyXlxp8qEoYZKeYVYrm5WxOF1Hv+JSJhmIkxKvLSx9iHEjL7cUi5zyE+c4mehGEG+jTetkavHrMeeRTdkTAkxpAef8vewhysWWy0fPxIdHXrl5BXaGsIcwpT27nrvIZQm+vu51rFWMIwEUuO/0NHOrY0IrL28ETCEJm6yrLExrIXs1DbQ1dYmpOYNqV4fbFQjiESrz2uOtG6gCnTZU0JkSYShoHkZxlOmVMYm6GNOvXrE81IGHpQFIMpvIQpY9pYnk+fpxqnIlW7qphDZDcvDF2fK0g5fk6ZscurawPX/Wtmc8nHuplxIQ2+rygsbURiSbZOwdLuXww24zFUuf51C3wUVwMqHhvbplDGqpxLcKeh3s58WLDGBqwp0SPQ5xHkquXJxyCVsfCYzxOMTd39DJljsUbRGIvVCkNx+LBrpeh7XF5M+jSwtmOmaLQxBSvW0GWT19a3wYeKxRYFZZU5hrl7hyUmKKtWjxpajjHvQ53AFMPBrt+5t3HuOpMaq/MY5naD855GX1vm8BqKHtLQRhLLxr3n1zY83PV8Rc9OovBGViUMS5x5mO8J8xW0bWr1lCFFn0aXF8ehDa94T4se2ZoXdZ1LtFYlDEumi0s8ZUUpNvAm6kRgqCgUz931KccleARVZTun97vKHENKdLm5XcVhygof0juP9Vhy1bmH5BZSpO4a5rq2VQlDahWkj6tbNarRVGmm7g1DzzVWDN8UUtTZ0fWY/HFTlG+Kaz0olJiAvg9XhQrL3AnXImONysRqPDFDnaG0Tdqai1ZhMLN7zeyCmT2V23aXmf3SzB7P/m7JffYZMztjZs+Y2YfGMnzthDauqSp1fnSgGPMXt8cYNag6f9fvm7txhZKapwu0/9q1mb0f+C1wn7v/ebbtLuC37v75wr7XAvcDNwDvAL4N/Km7v9JyjmXcwYmpGqWoq0Rjzjno891jzuUIsadqn9Bt+e1zJC7HPKfH+rVrd/8u8GLgeY8CD7j779z958AZdiIxKX2G2FKlSwOLfc19G/fYohCyT8xzT1WfYgztxmJIjuEOM3siCzUuy7YdBJ7P7XM221bCzI6b2SkzOzXAhkqmHOsfkypvoelZgfznXa+9a1Kx7rOQuRh9aApT6s4/5Fx5b6HLkG3f86U2B6evMNwNvBu4DjgPfCHbXnVVlSXp7ve4+xF3P9LThkZSKeCh1CXKmiZA9bn20Apf53YXK3bMSt7FA2kSjaHEFrzijM6U6CUM7v6Cu7/i7q8CX+H1cOEscCi361XAuWEm9ic/5LdkitcR2kCmcIHH7uliiELd511zDjG9ofx1pSYK0FMYzOxA7t8PA/sRi5PAbWZ2sZldAxwGvj/MxHCKmfKq90ulS1iRPyZUIPpWzjEFIVR0Qu/vEKFs8ob6zlNJURD2tE5wMrP7gQ8Abzezs8A/AB8ws+vYhQnPAZ8EcPenzexB4MfAy8DtbSMSY5NvGH0mukxB17g432BC4uqiOIT2knOUTZ9ka6idoWLa9X5UeaZ1w7Up1LcQWocrJzEi0nBl0dUrCkHTsNSc9BEGKM8CHJJAnLMM2hpV0zFdrrmubtTtO6Ru9LmmKQgdrlzVlOg8xRsb2ktOTR87quLcqlCj7fgQO0YeU+/kUnfNs1Qdtz927OtNoW4NYVNTouu8ozm8phhDa1WNKnbmPGYCNz+U2vfa+8bmdSLQ9ZitsFqPAdp7zbzLOBVjxJr5a8g3nFTi2qF2DD2+Ln+SQhidKqvKMUD703TFrH5o3BnDrrwdU5+n7/U1udxFYl7b3KKWSqgZm9Acw+pDiTpXe/9+ygo45Tnq4uq6rHzXDmLvmeT/YhHrngydx5FCpzkXq/MYoH3iSt1ElbqKGLOiTt0LNdkeOnIztm17Uuqh+yY6U2fzoxJF8qFD0WsIOTaWDVMTKoBTjkrMHSY0USynFDrOOdiMMMRg7h52CHmBKE6QCknSFr8nhLpGlXKZpWzblKxSGMa6uVPnJMagz4hFzNGApTF0otNSWX3yMY8mrrzOWq5DjMNqhWGq2HDJMWibOCz52sQwVisMoRQrf8gQ1xbcyxSvL8Ywqwhj88JQpM9zC2usnKleV164pxCvFAVyClYrDEMqdttkoOL3p9qI1kZxMlXVXJVYbP3ernJUIgaxH0YS41HViIf28nWisxXvYbUeA9Tf3C6Nfas9xlIoTlqLPT17rO9MnVULA7Q/7FOcsJQXjzZ3UuHEfMR4bL0rW7rHqxcGqHY16xp6MX5VJjxN8jM3hz4s1ZUt3P/VC0NojzL0MeK1VZalZOOrnu4c815sJfe0emEo0nUOQn7/oueR/56lx6Ep294lNzRFg817K2tlM8JQdxNDcwTFylknBGuuLHPTRcynYq33exPCEGvoakhYIvqRckiz5rBiE8IA9Ss31e1T91mbZ7EFN3MuQsq0+Hj52KQqWkPZjDBU0bXidH1UWeIwnK6L6vTZdyhrvNebEobigiN9EoZdJ0ktscKk4r63DUWGPuw2BWsTh00Jw9CbFxKO1O0vuhMi3CndgzXd700Jw56hyr6mnmEpLGWZuLXUjVZhMLNDZvYdMzttZk+b2aey7Zeb2cNm9mz2elm23czsS2Z2xsyeMLPrx76ILsQYoQhNRIbuI5qp8xxCynbqss/PcVkyIR7Dy8DfufufATcCt5vZtcCdwCPufhh4JPsf4GbgcPZ3HLg7utUDSa2XEcPo83DcmKyhfrUKg7ufd/fHsvcvAaeBg8BR4ES22wng1uz9UeA+3/E94FIzOxDd8plZ02O4qTSoPqT6TMvS60WnHIOZXQ28B3gUuNLdz8NOPIArst0OAs/nDjubbUuKoe5e1QNZdT3XkibCpDIi0YViaNc2O3UqlnC/6wheqMXM3gp8Hfi0u/+mocCrPiiVkJkdZxdqzMIYsX9bJVxCg1uCjXWsyYubmyCPwczexE4Uvubu38g2v7APEbLXC9n2s8Ch3OFXAeeK3+nu97j7EXc/0tf4lCjOkVhqb7HUxFnfeSmimpBRCQO+Cpx29y/mPjoJHMveHwMeym3/eDY6cSPw633IkRpNDbjrKk9LFYN86LDEMEKMQ+uP2prZ+4D/Bp4EXs02f5ZdnuFB4J3AL4CPuPuLmZD8C3AT8H/A37j7qZZzzNaiio2h6hHr0OOL70OOn5sq+yUQ68UDf9R2lb923ZXQxl3VYKr23x+zBHGoEwGJwzBSLb9QYdjkzMcqqhpx0ZPIvxbfVx2TYsUQIgQJA+GPW1c90ts0Iy8Fb6wrS7Q5NVL1Frqg35XIaIqt89tDRKRtv1QJvU6xfuQxFGgapViqFyBEVyQMOepmKBbHyCUOYu0olCjQNh9hySMQdUjo4rGG/AJouDIKS68MS7dfhKPhyoF0nfm4ZJZufyqk0MnGQsLQwJputBiXtdUVCUMNSjSKUJacX6pDyccGYtxoxe/rZY2CsEfCEIGQWZCxK48EZx6Ko1FrRaFEAH2WKC8eM8aiMApzpiWVlaGmQMIQQN/VoKuezhTLYz/jdQuCsEfCEEjXClHcf6wKJbEZl60Jwh4JQwfaVntq8hr2n8dEnsi4bLlcJQwdqVuDoW1thqbjh7DF3mxMUlplek4kDB1o66FDRWOMnmjLvVsMtphHaELPSvSk63BhyDJxU9sktoeelZiALT1PsTa0vkYzEoaeDE38jSEUmtsQRj5kkGBXI2EYQNeKVWy4YzRiiUM1bet0ijciYYhA14bYNLwZA4nDG5EgdEfCEInQeFWVczrkJfRHD1FFoGu+YYpfeyp6DVtqGBp2HI48hoh0ceGnqLRbaxwaZYiHPIbIdPUGphKINaNwIT4ShhGIFSrEDAXWOPlJgjAeraGEmR0ys++Y2Wkze9rMPpVtv8vMfmlmj2d/t+SO+YyZnTGzZ8zsQ2NeQMrEcG23Fg6EIlEYl9Yp0WZ2ADjg7o+Z2SXAD4FbgY8Cv3X3zxf2vxa4H7gBeAfwbeBP3f2VhnOsOjDsUonHThgu2XOQGAwn2pRodz/v7o9l718CTgMHGw45Cjzg7r9z958DZ9iJxGYJefiq+BDPWJV/6Y1q6fYvhU6jEmZ2NfAe4NFs0x1m9oSZ3Wtml2XbDgLP5w47S4WQmNlxMztlZqc6W71A9o29bo6+QoZ68qIppiFYGMzsrcDXgU+7+2+Au4F3A9cB54Ev7HetOLzUVbr7Pe5+xN2PdLZ6wVR5BHNU+CUM62ldhPkIEgYzexM7Ufiau38DwN1fcPdX3P1V4Cu8Hi6cBQ7lDr8KOBfPZLEFliBcayZkVMKArwKn3f2Lue0Hcrt9GHgqe38SuM3MLjaza4DDwPfjmSxikGIPXJVrEfMQMo/hvcBfA0+a2ePZts8CHzOz69iFCc8BnwRw96fN7EHgx8DLwO1NIxJiPlLK8iuHkBZawUnM2ii3+jzHXIQOV2rmo5iFlLwVUUbCICZ52nOPBGEZ6OlK8Rpjh5USheUgYRBvILY46HcalomEQQDjNFp5CMtFOQbxBmI0Yo00LB8JgyjRt6eXh7AeFEqIEn1+M0OisC4kDKKS0AaulZjXiUIJUUt+cdt8o1cOYf1IGEQj+TUk8tvEupEwiFYkBNtDOQYhRAkJgxCihIRBCFFCwiCEKCFhEEKUkDAIIUpIGIQQJSQMQogSEgYhRAkJgxCihIRBCFFCwiCEKCFhEEKUkDAIIUpIGIQQJSQMQogSEgYhRIlUVnD6H+B/s9dUeDtp2QPp2SR72knJpj8J3dHG/r3CUMzslLsfmduOPanZA+nZJHvaSdGmEBRKCCFKSBiEECVSEoZ75jagQGr2QHo2yZ52UrSplWRyDEKIdEjJYxBCJMLswmBmN5nZM2Z2xszunNGO58zsSTN73MxOZdsuN7OHzezZ7PWyEc9/r5ldMLOnctsqz287vpSV2RNmdv2ENt1lZr/MyulxM7sl99lnMpueMbMPjWDPITP7jpmdNrOnzexT2fZZyqnBntnKKBr7nx+b4w+4CPgp8C7gzcCPgGtnsuU54O2Fbf8M3Jm9vxP4pxHP/37geuCptvMDtwD/CRhwI/DohDbdBfx9xb7XZvfvYuCa7L5eFNmeA8D12ftLgJ9k552lnBrsma2MYv3N7THcAJxx95+5+++BB4CjM9uU5yhwInt/Arh1rBO5+3eBFwPPfxS4z3d8D7jUzA5MZFMdR4EH3P137v5z4Ay7+xvTnvPu/lj2/iXgNHCQmcqpwZ46Ri+jWMwtDAeB53P/n6W5YMfEgW+Z2Q/N7Hi27Up3Pw+7SgBcMbFNdeefu9zuyFzze3Ph1aQ2mdnVwHuAR0mgnAr2QAJlNIS5haHq11LnGiZ5r7tfD9wM3G5m75/JjhDmLLe7gXcD1wHngS9MbZOZvRX4OvBpd/9N065T2FRhz+xlNJS5heEscCj3/1XAuTkMcfdz2esF4JvsXLwX9q5n9nphYrPqzj9bubn7C+7+iru/CnyF113hSWwyszexa4Rfc/dvZJtnK6cqe+YuoxjMLQw/AA6b2TVm9mbgNuDk1EaY2VvM7JL9e+CDwFOZLcey3Y4BD01sWt35TwIfz7LuNwK/3rvSY1OI0T/Mrpz2Nt1mZheb2TXAYeD7kc9twFeB0+7+xdxHs5RTnT1zllE05s5+sssc/4RdhvZzM9nwLnbZ4h8BT+/tAN4GPAI8m71ePqIN97NzO//Armf5RN352bmkX87K7EngyIQ2/Vt2zifYVfQDuf0/l9n0DHDzCPa8j53r/QTwePZ3y1zl1GDPbGUU608zH4UQJeYOJYQQCSJhEEKUkDAIIUpIGIQQJSQMQogSEgYhRAkJgxCihIRBCFHi/wHK1xgdsI4mfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cannay edge detection\n",
    "threshold1=100\n",
    "threshold2=200\n",
    "canny=cv2.Canny(input_image,threshold1,threshold2)\n",
    "\n",
    "plt.imshow(canny,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a3ed9ec88>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#open and show images\n",
    "img1=cv2.imread('box.png')\n",
    "img2=cv2.imread('box_in_scene.png')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.cvtColor(img2,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-501775447bb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#SIFT feature extracting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgray1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgray2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "#SIFT feature extracting\n",
    "sift=cv2.xfeatures2d.SIFT_create()\n",
    "gray1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "gray2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "start_time=time.time()\n",
    "kp1,des1=sift.detectAndCompute(gray1,None)\n",
    "kp2,des2=sift.detectAndCompute(gray2,None)\n",
    "print('Elapsed time:%.6fs'%(time.time()-start_time))\n",
    "\n",
    "print('Image 1=%d feature detected'%des1.shape[0])\n",
    "print('Image 2=%d feature detected'%des2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-8f1127fc77da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##Apply ratio test as in David row's paper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgood_matches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgood_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "##Apply ratio test as in David row's paper\n",
    "good_matches=[]\n",
    "for m,n in matches:\n",
    "    if m.distance<0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "print('%d matches'%len(good_matches))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1ce7cc16e648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Display images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawMatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgood_matches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kp1' is not defined"
     ]
    }
   ],
   "source": [
    "#Display images\n",
    "img3=cv2.drawMatches(img1,kp1,img2,kp2,good_matches,None)\n",
    "plt.imshow(cv2.cvtColor(img3,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'des1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-d817e83d7f0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#BFMatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBFMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNORM_L2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdes2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d matches'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'des1' is not defined"
     ]
    }
   ],
   "source": [
    "#BFMatcher\n",
    "bf=cv2.BFMatcher(cv2.NORM_L2)\n",
    "matches=bf.match(des1,des2,k=2)\n",
    "print('%d matches'%len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-460eb3b7c355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#inspect matcher results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "#inspect matcher results\n",
    "print(type(matches))\n",
    "print(len(matches))\n",
    "print(type(matches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package cv2.cv2 in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.cv2 - Python wrapper for OpenCV.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cv2\n",
      "    data (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        cv2.error\n",
      "    builtins.object\n",
      "        cv2.Algorithm\n",
      "            cv2.AlignExposures\n",
      "                cv2.AlignMTB\n",
      "            cv2.BackgroundSubtractor\n",
      "                cv2.BackgroundSubtractorKNN\n",
      "                cv2.BackgroundSubtractorMOG2\n",
      "            cv2.BaseCascadeClassifier\n",
      "            cv2.CLAHE\n",
      "            cv2.CalibrateCRF\n",
      "                cv2.CalibrateDebevec\n",
      "                cv2.CalibrateRobertson\n",
      "            cv2.DenseOpticalFlow\n",
      "                cv2.DISOpticalFlow\n",
      "                cv2.FarnebackOpticalFlow\n",
      "                cv2.VariationalRefinement\n",
      "            cv2.DescriptorMatcher\n",
      "                cv2.BFMatcher\n",
      "                cv2.FlannBasedMatcher\n",
      "            cv2.GeneralizedHough\n",
      "                cv2.GeneralizedHoughBallard\n",
      "                cv2.GeneralizedHoughGuil\n",
      "            cv2.LineSegmentDetector\n",
      "            cv2.MergeExposures\n",
      "                cv2.MergeDebevec\n",
      "                cv2.MergeMertens\n",
      "                cv2.MergeRobertson\n",
      "            cv2.SparseOpticalFlow\n",
      "                cv2.SparsePyrLKOpticalFlow\n",
      "            cv2.StereoMatcher\n",
      "                cv2.StereoBM\n",
      "                cv2.StereoSGBM\n",
      "            cv2.Tonemap\n",
      "                cv2.TonemapDrago\n",
      "                cv2.TonemapMantiuk\n",
      "                cv2.TonemapReinhard\n",
      "            cv2.dnn_Layer\n",
      "            cv2.ml_StatModel\n",
      "                cv2.ml_ANN_MLP\n",
      "                cv2.ml_DTrees\n",
      "                    cv2.ml_Boost\n",
      "                    cv2.ml_RTrees\n",
      "                cv2.ml_EM\n",
      "                cv2.ml_KNearest\n",
      "                cv2.ml_LogisticRegression\n",
      "                cv2.ml_NormalBayesClassifier\n",
      "                cv2.ml_SVM\n",
      "                cv2.ml_SVMSGD\n",
      "        cv2.BOWImgDescriptorExtractor\n",
      "        cv2.BOWTrainer\n",
      "            cv2.BOWKMeansTrainer\n",
      "        cv2.CascadeClassifier\n",
      "        cv2.CirclesGridFinderParameters\n",
      "        cv2.DMatch\n",
      "        cv2.Feature2D\n",
      "            cv2.AKAZE\n",
      "            cv2.AgastFeatureDetector\n",
      "            cv2.BRISK\n",
      "            cv2.FastFeatureDetector\n",
      "            cv2.GFTTDetector\n",
      "            cv2.KAZE\n",
      "            cv2.MSER\n",
      "            cv2.ORB\n",
      "            cv2.SimpleBlobDetector\n",
      "        cv2.FileNode\n",
      "        cv2.FileStorage\n",
      "        cv2.HOGDescriptor\n",
      "        cv2.KalmanFilter\n",
      "        cv2.KeyPoint\n",
      "        cv2.PyRotationWarper\n",
      "        cv2.QRCodeDetector\n",
      "        cv2.SimpleBlobDetector_Params\n",
      "        cv2.Stitcher\n",
      "        cv2.Subdiv2D\n",
      "        cv2.TickMeter\n",
      "        cv2.UMat\n",
      "        cv2.VideoCapture\n",
      "        cv2.VideoWriter\n",
      "        cv2.WarperCreator\n",
      "        cv2.cuda_BufferPool\n",
      "        cv2.cuda_DeviceInfo\n",
      "        cv2.cuda_Event\n",
      "        cv2.cuda_GpuMat\n",
      "        cv2.cuda_GpuMat_Allocator\n",
      "        cv2.cuda_HostMem\n",
      "        cv2.cuda_Stream\n",
      "        cv2.cuda_TargetArchs\n",
      "        cv2.detail_Blender\n",
      "            cv2.detail_FeatherBlender\n",
      "            cv2.detail_MultiBandBlender\n",
      "        cv2.detail_CameraParams\n",
      "        cv2.detail_Estimator\n",
      "            cv2.detail_AffineBasedEstimator\n",
      "            cv2.detail_BundleAdjusterBase\n",
      "                cv2.detail_BundleAdjusterAffine\n",
      "                cv2.detail_BundleAdjusterAffinePartial\n",
      "                cv2.detail_BundleAdjusterRay\n",
      "                cv2.detail_BundleAdjusterReproj\n",
      "                cv2.detail_NoBundleAdjuster\n",
      "            cv2.detail_HomographyBasedEstimator\n",
      "        cv2.detail_ExposureCompensator\n",
      "            cv2.detail_BlocksCompensator\n",
      "                cv2.detail_BlocksChannelsCompensator\n",
      "                cv2.detail_BlocksGainCompensator\n",
      "            cv2.detail_ChannelsCompensator\n",
      "            cv2.detail_GainCompensator\n",
      "            cv2.detail_NoExposureCompensator\n",
      "        cv2.detail_FeaturesMatcher\n",
      "            cv2.detail_BestOf2NearestMatcher\n",
      "                cv2.detail_AffineBestOf2NearestMatcher\n",
      "                cv2.detail_BestOf2NearestRangeMatcher\n",
      "        cv2.detail_GraphCutSeamFinder\n",
      "        cv2.detail_ImageFeatures\n",
      "        cv2.detail_MatchesInfo\n",
      "        cv2.detail_ProjectorBase\n",
      "            cv2.detail_SphericalProjector\n",
      "        cv2.detail_SeamFinder\n",
      "            cv2.detail_DpSeamFinder\n",
      "            cv2.detail_NoSeamFinder\n",
      "            cv2.detail_PairwiseSeamFinder\n",
      "                cv2.detail_VoronoiSeamFinder\n",
      "        cv2.detail_Timelapser\n",
      "            cv2.detail_TimelapserCrop\n",
      "        cv2.dnn_DictValue\n",
      "        cv2.dnn_Net\n",
      "        cv2.flann_Index\n",
      "        cv2.ml_ParamGrid\n",
      "        cv2.ml_TrainData\n",
      "        cv2.ocl_Device\n",
      "    \n",
      "    class AKAZE(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      AKAZE\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorChannels(...)\n",
      "     |      getDescriptorChannels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorSize(...)\n",
      "     |      getDescriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorType(...)\n",
      "     |      getDescriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDiffusivity(...)\n",
      "     |      getDiffusivity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaveLayers(...)\n",
      "     |      getNOctaveLayers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaves(...)\n",
      "     |      getNOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorChannels(...)\n",
      "     |      setDescriptorChannels(dch) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorSize(...)\n",
      "     |      setDescriptorSize(dsize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorType(...)\n",
      "     |      setDescriptorType(dtype) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDiffusivity(...)\n",
      "     |      setDiffusivity(diff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaveLayers(...)\n",
      "     |      setNOctaveLayers(octaveLayers) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaves(...)\n",
      "     |      setNOctaves(octaves) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, descriptor_type[, descriptor_size[, descriptor_channels[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]]) -> retval\n",
      "     |      .   @brief The AKAZE constructor\n",
      "     |      .   \n",
      "     |      .   @param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,\n",
      "     |      .   DESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.\n",
      "     |      .   @param descriptor_size Size of the descriptor in bits. 0 -\\> Full size\n",
      "     |      .   @param descriptor_channels Number of channels in the descriptor (1, 2, 3)\n",
      "     |      .   @param threshold Detector response threshold to accept point\n",
      "     |      .   @param nOctaves Maximum octave evolution of the image\n",
      "     |      .   @param nOctaveLayers Default number of sublevels per scale level\n",
      "     |      .   @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "     |      .   DIFF_CHARBONNIER\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class AgastFeatureDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      AgastFeatureDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNonmaxSuppression(...)\n",
      "     |      getNonmaxSuppression() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNonmaxSuppression(...)\n",
      "     |      setNonmaxSuppression(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class Algorithm(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class AlignExposures(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      AlignExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, dst, times, response) -> None\n",
      "     |      .   @brief Aligns images\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst vector of aligned images\n",
      "     |      .   @param times vector of exposure time values for each image\n",
      "     |      .   @param response 256x1 matrix with inverse camera response function for each pixel value, it should\n",
      "     |      .   have the same number of channels as images.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class AlignMTB(AlignExposures)\n",
      "     |  Method resolution order:\n",
      "     |      AlignMTB\n",
      "     |      AlignExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calculateShift(...)\n",
      "     |      calculateShift(img0, img1) -> retval\n",
      "     |      .   @brief Calculates shift between two images, i. e. how to shift the second image to correspond it with the\n",
      "     |      .   first.\n",
      "     |      .   \n",
      "     |      .   @param img0 first image\n",
      "     |      .   @param img1 second image\n",
      "     |  \n",
      "     |  computeBitmaps(...)\n",
      "     |      computeBitmaps(img[, tb[, eb]]) -> tb, eb\n",
      "     |      .   @brief Computes median threshold and exclude bitmaps of given image.\n",
      "     |      .   \n",
      "     |      .   @param img input image\n",
      "     |      .   @param tb median threshold bitmap\n",
      "     |      .   @param eb exclude bitmap\n",
      "     |  \n",
      "     |  getCut(...)\n",
      "     |      getCut() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExcludeRange(...)\n",
      "     |      getExcludeRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBits(...)\n",
      "     |      getMaxBits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, dst, times, response) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, dst) -> None\n",
      "     |      .   @brief Short version of process, that doesn't take extra arguments.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst vector of aligned images\n",
      "     |  \n",
      "     |  setCut(...)\n",
      "     |      setCut(value) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExcludeRange(...)\n",
      "     |      setExcludeRange(exclude_range) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBits(...)\n",
      "     |      setMaxBits(max_bits) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  shiftMat(...)\n",
      "     |      shiftMat(src, shift[, dst]) -> dst\n",
      "     |      .   @brief Helper function, that shift Mat filling new regions with zeros.\n",
      "     |      .   \n",
      "     |      .   @param src input image\n",
      "     |      .   @param dst result image\n",
      "     |      .   @param shift shift value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class BFMatcher(DescriptorMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      BFMatcher\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, normType[, crossCheck]]) -> retval\n",
      "     |      .   @brief Brute-force matcher create method.\n",
      "     |      .   @param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are\n",
      "     |      .   preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "     |      .   BRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor\n",
      "     |      .   description).\n",
      "     |      .   @param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k\n",
      "     |      .   nearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with\n",
      "     |      .   k=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the\n",
      "     |      .   matcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent\n",
      "     |      .   pairs. Such technique usually produces best results with minimal number of outliers when there are\n",
      "     |      .   enough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DescriptorMatcher:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .   collection.\n",
      "     |      .   \n",
      "     |      .   If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .   train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .   @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .   that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .   object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .   These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .   descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .   for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .   second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .   used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .   matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .   mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .   query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .   returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .   Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .   train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .   have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .   example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class BOWImgDescriptorExtractor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, imgDescriptor]) -> imgDescriptor\n",
      "     |      .   @overload\n",
      "     |      .   @param keypointDescriptors Computed descriptors to match with vocabulary.\n",
      "     |      .   @param imgDescriptor Computed output image descriptor.\n",
      "     |      .   @param pointIdxsOfClusters Indices of keypoints that belong to the cluster. This means that\n",
      "     |      .   pointIdxsOfClusters[i] are keypoint indices that belong to the i -th cluster (word of vocabulary)\n",
      "     |      .   returned if it is non-zero.\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .   @brief Returns an image descriptor size if the vocabulary is set. Otherwise, it returns 0.\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .   @brief Returns an image descriptor type.\n",
      "     |  \n",
      "     |  getVocabulary(...)\n",
      "     |      getVocabulary() -> retval\n",
      "     |      .   @brief Returns the set vocabulary.\n",
      "     |  \n",
      "     |  setVocabulary(...)\n",
      "     |      setVocabulary(vocabulary) -> None\n",
      "     |      .   @brief Sets a visual vocabulary.\n",
      "     |      .   \n",
      "     |      .   @param vocabulary Vocabulary (can be trained using the inheritor of BOWTrainer ). Each row of the\n",
      "     |      .   vocabulary is a visual word (cluster center).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BOWKMeansTrainer(BOWTrainer)\n",
      "     |  Method resolution order:\n",
      "     |      BOWKMeansTrainer\n",
      "     |      BOWTrainer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  cluster(...)\n",
      "     |      cluster() -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      cluster(descriptors) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BOWTrainer:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to a training set.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a\n",
      "     |      .   descriptor.\n",
      "     |      .   \n",
      "     |      .   The training set is clustered using clustermethod to construct the vocabulary.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorsCount(...)\n",
      "     |      descriptorsCount() -> retval\n",
      "     |      .   @brief Returns the count of all descriptors stored in the training set.\n",
      "     |  \n",
      "     |  getDescriptors(...)\n",
      "     |      getDescriptors() -> retval\n",
      "     |      .   @brief Returns a training set of descriptors.\n",
      "    \n",
      "    class BOWTrainer(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to a training set.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a\n",
      "     |      .   descriptor.\n",
      "     |      .   \n",
      "     |      .   The training set is clustered using clustermethod to construct the vocabulary.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  cluster(...)\n",
      "     |      cluster() -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      cluster(descriptors) -> retval\n",
      "     |      .   @brief Clusters train descriptors.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to cluster. Each row of the descriptors matrix is a descriptor.\n",
      "     |      .   Descriptors are not added to the inner train descriptor set.\n",
      "     |      .   \n",
      "     |      .   The vocabulary consists of cluster centers. So, this method returns the vocabulary. In the first\n",
      "     |      .   variant of the method, train descriptors stored in the object are clustered. In the second variant,\n",
      "     |      .   input descriptors are clustered.\n",
      "     |  \n",
      "     |  descriptorsCount(...)\n",
      "     |      descriptorsCount() -> retval\n",
      "     |      .   @brief Returns the count of all descriptors stored in the training set.\n",
      "     |  \n",
      "     |  getDescriptors(...)\n",
      "     |      getDescriptors() -> retval\n",
      "     |      .   @brief Returns a training set of descriptors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BRISK(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      BRISK\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getOctaves(...)\n",
      "     |      getOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setOctaves(...)\n",
      "     |      setOctaves(octaves) -> None\n",
      "     |      .   @brief Set detection octaves.\n",
      "     |      .   @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .   @brief Set detection threshold.\n",
      "     |      .   @param threshold AGAST detection threshold score.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, thresh[, octaves[, patternScale]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor\n",
      "     |      .   \n",
      "     |      .   @param thresh AGAST detection threshold score.\n",
      "     |      .   @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |      .   @param patternScale apply this scale to the pattern used for sampling the neighbourhood of a\n",
      "     |      .   keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor for a custom pattern\n",
      "     |      .   \n",
      "     |      .   @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "     |      .   keypoint scale 1).\n",
      "     |      .   @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "     |      .   size as radiusList..\n",
      "     |      .   @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "     |      .   scale 1).\n",
      "     |      .   @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "     |      .   keypoint scale 1).\n",
      "     |      .   @param indexChange index remapping of the bits.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(thresh, octaves, radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor for a custom pattern, detection threshold and octaves\n",
      "     |      .   \n",
      "     |      .   @param thresh AGAST detection threshold score.\n",
      "     |      .   @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |      .   @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "     |      .   keypoint scale 1).\n",
      "     |      .   @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "     |      .   size as radiusList..\n",
      "     |      .   @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "     |      .   scale 1).\n",
      "     |      .   @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "     |      .   keypoint scale 1).\n",
      "     |      .   @param indexChange index remapping of the bits.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class BackgroundSubtractor(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .   @param image Next video frame.\n",
      "     |      .   @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .   @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .   learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .   rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .   is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .   @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .   @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .   statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class BackgroundSubtractorKNN(BackgroundSubtractor)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractorKNN\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDetectShadows(...)\n",
      "     |      getDetectShadows() -> retval\n",
      "     |      .   @brief Returns the shadow detection flag\n",
      "     |      .   \n",
      "     |      .   If true, the algorithm detects shadows and marks them. See createBackgroundSubtractorKNN for\n",
      "     |      .   details.\n",
      "     |  \n",
      "     |  getDist2Threshold(...)\n",
      "     |      getDist2Threshold() -> retval\n",
      "     |      .   @brief Returns the threshold on the squared distance between the pixel and the sample\n",
      "     |      .   \n",
      "     |      .   The threshold on the squared distance between the pixel and the sample to decide whether a pixel is\n",
      "     |      .   close to a data sample.\n",
      "     |  \n",
      "     |  getHistory(...)\n",
      "     |      getHistory() -> retval\n",
      "     |      .   @brief Returns the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  getNSamples(...)\n",
      "     |      getNSamples() -> retval\n",
      "     |      .   @brief Returns the number of data samples in the background model\n",
      "     |  \n",
      "     |  getShadowThreshold(...)\n",
      "     |      getShadowThreshold() -> retval\n",
      "     |      .   @brief Returns the shadow threshold\n",
      "     |      .   \n",
      "     |      .   A shadow is detected if pixel is a darker version of the background. The shadow threshold (Tau in\n",
      "     |      .   the paper) is a threshold defining how much darker the shadow can be. Tau= 0.5 means that if a pixel\n",
      "     |      .   is more than twice darker then it is not shadow. See Prati, Mikic, Trivedi and Cucchiara,\n",
      "     |      .   *Detecting Moving Shadows...*, IEEE PAMI,2003.\n",
      "     |  \n",
      "     |  getShadowValue(...)\n",
      "     |      getShadowValue() -> retval\n",
      "     |      .   @brief Returns the shadow value\n",
      "     |      .   \n",
      "     |      .   Shadow value is the value used to mark shadows in the foreground mask. Default value is 127. Value 0\n",
      "     |      .   in the mask always means background, 255 means foreground.\n",
      "     |  \n",
      "     |  getkNNSamples(...)\n",
      "     |      getkNNSamples() -> retval\n",
      "     |      .   @brief Returns the number of neighbours, the k in the kNN.\n",
      "     |      .   \n",
      "     |      .   K is the number of samples that need to be within dist2Threshold in order to decide that that\n",
      "     |      .   pixel is matching the kNN background model.\n",
      "     |  \n",
      "     |  setDetectShadows(...)\n",
      "     |      setDetectShadows(detectShadows) -> None\n",
      "     |      .   @brief Enables or disables shadow detection\n",
      "     |  \n",
      "     |  setDist2Threshold(...)\n",
      "     |      setDist2Threshold(_dist2Threshold) -> None\n",
      "     |      .   @brief Sets the threshold on the squared distance\n",
      "     |  \n",
      "     |  setHistory(...)\n",
      "     |      setHistory(history) -> None\n",
      "     |      .   @brief Sets the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  setNSamples(...)\n",
      "     |      setNSamples(_nN) -> None\n",
      "     |      .   @brief Sets the number of data samples in the background model.\n",
      "     |      .   \n",
      "     |      .   The model needs to be reinitalized to reserve memory.\n",
      "     |  \n",
      "     |  setShadowThreshold(...)\n",
      "     |      setShadowThreshold(threshold) -> None\n",
      "     |      .   @brief Sets the shadow threshold\n",
      "     |  \n",
      "     |  setShadowValue(...)\n",
      "     |      setShadowValue(value) -> None\n",
      "     |      .   @brief Sets the shadow value\n",
      "     |  \n",
      "     |  setkNNSamples(...)\n",
      "     |      setkNNSamples(_nkNN) -> None\n",
      "     |      .   @brief Sets the k in the kNN. How many nearest neighbours need to match.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BackgroundSubtractor:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .   @param image Next video frame.\n",
      "     |      .   @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .   @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .   learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .   rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .   is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .   @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .   @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .   statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class BackgroundSubtractorMOG2(BackgroundSubtractor)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractorMOG2\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .   @param image Next video frame. Floating point frame will be used without scaling and should be in range \\f$[0,255]\\f$.\n",
      "     |      .   @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .   @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .   learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .   rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .   is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundRatio(...)\n",
      "     |      getBackgroundRatio() -> retval\n",
      "     |      .   @brief Returns the \"background ratio\" parameter of the algorithm\n",
      "     |      .   \n",
      "     |      .   If a foreground pixel keeps semi-constant value for about backgroundRatio\\*history frames, it's\n",
      "     |      .   considered background and added to the model as a center of a new component. It corresponds to TB\n",
      "     |      .   parameter in the paper.\n",
      "     |  \n",
      "     |  getComplexityReductionThreshold(...)\n",
      "     |      getComplexityReductionThreshold() -> retval\n",
      "     |      .   @brief Returns the complexity reduction threshold\n",
      "     |      .   \n",
      "     |      .   This parameter defines the number of samples needed to accept to prove the component exists. CT=0.05\n",
      "     |      .   is a default value for all the samples. By setting CT=0 you get an algorithm very similar to the\n",
      "     |      .   standard Stauffer&Grimson algorithm.\n",
      "     |  \n",
      "     |  getDetectShadows(...)\n",
      "     |      getDetectShadows() -> retval\n",
      "     |      .   @brief Returns the shadow detection flag\n",
      "     |      .   \n",
      "     |      .   If true, the algorithm detects shadows and marks them. See createBackgroundSubtractorMOG2 for\n",
      "     |      .   details.\n",
      "     |  \n",
      "     |  getHistory(...)\n",
      "     |      getHistory() -> retval\n",
      "     |      .   @brief Returns the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  getNMixtures(...)\n",
      "     |      getNMixtures() -> retval\n",
      "     |      .   @brief Returns the number of gaussian components in the background model\n",
      "     |  \n",
      "     |  getShadowThreshold(...)\n",
      "     |      getShadowThreshold() -> retval\n",
      "     |      .   @brief Returns the shadow threshold\n",
      "     |      .   \n",
      "     |      .   A shadow is detected if pixel is a darker version of the background. The shadow threshold (Tau in\n",
      "     |      .   the paper) is a threshold defining how much darker the shadow can be. Tau= 0.5 means that if a pixel\n",
      "     |      .   is more than twice darker then it is not shadow. See Prati, Mikic, Trivedi and Cucchiara,\n",
      "     |      .   *Detecting Moving Shadows...*, IEEE PAMI,2003.\n",
      "     |  \n",
      "     |  getShadowValue(...)\n",
      "     |      getShadowValue() -> retval\n",
      "     |      .   @brief Returns the shadow value\n",
      "     |      .   \n",
      "     |      .   Shadow value is the value used to mark shadows in the foreground mask. Default value is 127. Value 0\n",
      "     |      .   in the mask always means background, 255 means foreground.\n",
      "     |  \n",
      "     |  getVarInit(...)\n",
      "     |      getVarInit() -> retval\n",
      "     |      .   @brief Returns the initial variance of each gaussian component\n",
      "     |  \n",
      "     |  getVarMax(...)\n",
      "     |      getVarMax() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarMin(...)\n",
      "     |      getVarMin() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarThreshold(...)\n",
      "     |      getVarThreshold() -> retval\n",
      "     |      .   @brief Returns the variance threshold for the pixel-model match\n",
      "     |      .   \n",
      "     |      .   The main threshold on the squared Mahalanobis distance to decide if the sample is well described by\n",
      "     |      .   the background model or not. Related to Cthr from the paper.\n",
      "     |  \n",
      "     |  getVarThresholdGen(...)\n",
      "     |      getVarThresholdGen() -> retval\n",
      "     |      .   @brief Returns the variance threshold for the pixel-model match used for new mixture component generation\n",
      "     |      .   \n",
      "     |      .   Threshold for the squared Mahalanobis distance that helps decide when a sample is close to the\n",
      "     |      .   existing components (corresponds to Tg in the paper). If a pixel is not close to any component, it\n",
      "     |      .   is considered foreground or added as a new component. 3 sigma =\\> Tg=3\\*3=9 is default. A smaller Tg\n",
      "     |      .   value generates more components. A higher Tg value may result in a small number of components but\n",
      "     |      .   they can grow too large.\n",
      "     |  \n",
      "     |  setBackgroundRatio(...)\n",
      "     |      setBackgroundRatio(ratio) -> None\n",
      "     |      .   @brief Sets the \"background ratio\" parameter of the algorithm\n",
      "     |  \n",
      "     |  setComplexityReductionThreshold(...)\n",
      "     |      setComplexityReductionThreshold(ct) -> None\n",
      "     |      .   @brief Sets the complexity reduction threshold\n",
      "     |  \n",
      "     |  setDetectShadows(...)\n",
      "     |      setDetectShadows(detectShadows) -> None\n",
      "     |      .   @brief Enables or disables shadow detection\n",
      "     |  \n",
      "     |  setHistory(...)\n",
      "     |      setHistory(history) -> None\n",
      "     |      .   @brief Sets the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  setNMixtures(...)\n",
      "     |      setNMixtures(nmixtures) -> None\n",
      "     |      .   @brief Sets the number of gaussian components in the background model.\n",
      "     |      .   \n",
      "     |      .   The model needs to be reinitalized to reserve memory.\n",
      "     |  \n",
      "     |  setShadowThreshold(...)\n",
      "     |      setShadowThreshold(threshold) -> None\n",
      "     |      .   @brief Sets the shadow threshold\n",
      "     |  \n",
      "     |  setShadowValue(...)\n",
      "     |      setShadowValue(value) -> None\n",
      "     |      .   @brief Sets the shadow value\n",
      "     |  \n",
      "     |  setVarInit(...)\n",
      "     |      setVarInit(varInit) -> None\n",
      "     |      .   @brief Sets the initial variance of each gaussian component\n",
      "     |  \n",
      "     |  setVarMax(...)\n",
      "     |      setVarMax(varMax) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVarMin(...)\n",
      "     |      setVarMin(varMin) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVarThreshold(...)\n",
      "     |      setVarThreshold(varThreshold) -> None\n",
      "     |      .   @brief Sets the variance threshold for the pixel-model match\n",
      "     |  \n",
      "     |  setVarThresholdGen(...)\n",
      "     |      setVarThresholdGen(varThresholdGen) -> None\n",
      "     |      .   @brief Sets the variance threshold for the pixel-model match used for new mixture component generation\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BackgroundSubtractor:\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .   @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .   @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .   statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class BaseCascadeClassifier(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      BaseCascadeClassifier\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class CLAHE(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      CLAHE\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(src[, dst]) -> dst\n",
      "     |      .   @brief Equalizes the histogram of a grayscale image using Contrast Limited Adaptive Histogram Equalization.\n",
      "     |      .   \n",
      "     |      .   @param src Source image of type CV_8UC1 or CV_16UC1.\n",
      "     |      .   @param dst Destination image.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getClipLimit(...)\n",
      "     |      getClipLimit() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTilesGridSize(...)\n",
      "     |      getTilesGridSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setClipLimit(...)\n",
      "     |      setClipLimit(clipLimit) -> None\n",
      "     |      .   @brief Sets threshold for contrast limiting.\n",
      "     |      .   \n",
      "     |      .   @param clipLimit threshold value.\n",
      "     |  \n",
      "     |  setTilesGridSize(...)\n",
      "     |      setTilesGridSize(tileGridSize) -> None\n",
      "     |      .   @brief Sets size of grid for histogram equalization. Input image will be divided into\n",
      "     |      .   equally sized rectangular tiles.\n",
      "     |      .   \n",
      "     |      .   @param tileGridSize defines the number of tiles in row and column.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class CalibrateCRF(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .   @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class CalibrateDebevec(CalibrateCRF)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateDebevec\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getLambda(...)\n",
      "     |      getLambda() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRandom(...)\n",
      "     |      getRandom() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSamples(...)\n",
      "     |      getSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLambda(...)\n",
      "     |      setLambda(lambda) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRandom(...)\n",
      "     |      setRandom(random) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSamples(...)\n",
      "     |      setSamples(samples) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CalibrateCRF:\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .   @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class CalibrateRobertson(CalibrateCRF)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateRobertson\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getMaxIter(...)\n",
      "     |      getMaxIter() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRadiance(...)\n",
      "     |      getRadiance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxIter(...)\n",
      "     |      setMaxIter(max_iter) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CalibrateCRF:\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .   @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class CascadeClassifier(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detectMultiScale(...)\n",
      "     |      detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects\n",
      "     |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "     |      .   of rectangles.\n",
      "     |      .   \n",
      "     |      .   @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "     |      .   @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "     |      .   rectangles may be partially outside the original image.\n",
      "     |      .   @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "     |      .   @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "     |      .   to retain it.\n",
      "     |      .   @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "     |      .   cvHaarDetectObjects. It is not used for a new cascade.\n",
      "     |      .   @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "     |      .   @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .   @note\n",
      "     |      .   -   (Python) A face detection example using cascade classifiers can be found at\n",
      "     |      .   opencv_source_code/samples/python/facedetect.py\n",
      "     |  \n",
      "     |  detectMultiScale2(...)\n",
      "     |      detectMultiScale2(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects, numDetections\n",
      "     |      .   @overload\n",
      "     |      .   @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "     |      .   @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "     |      .   rectangles may be partially outside the original image.\n",
      "     |      .   @param numDetections Vector of detection numbers for the corresponding objects. An object's number\n",
      "     |      .   of detections is the number of neighboring positively classified rectangles that were joined\n",
      "     |      .   together to form the object.\n",
      "     |      .   @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "     |      .   @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "     |      .   to retain it.\n",
      "     |      .   @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "     |      .   cvHaarDetectObjects. It is not used for a new cascade.\n",
      "     |      .   @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "     |      .   @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "     |  \n",
      "     |  detectMultiScale3(...)\n",
      "     |      detectMultiScale3(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize[, outputRejectLevels]]]]]]) -> objects, rejectLevels, levelWeights\n",
      "     |      .   @overload\n",
      "     |      .   This function allows you to retrieve the final stage decision certainty of classification.\n",
      "     |      .   For this, one needs to set `outputRejectLevels` on true and provide the `rejectLevels` and `levelWeights` parameter.\n",
      "     |      .   For each resulting detection, `levelWeights` will then contain the certainty of classification at the final stage.\n",
      "     |      .   This value can then be used to separate strong from weaker classifications.\n",
      "     |      .   \n",
      "     |      .   A code sample on how to use it efficiently can be found below:\n",
      "     |      .   @code\n",
      "     |      .   Mat img;\n",
      "     |      .   vector<double> weights;\n",
      "     |      .   vector<int> levels;\n",
      "     |      .   vector<Rect> detections;\n",
      "     |      .   CascadeClassifier model(\"/path/to/your/model.xml\");\n",
      "     |      .   model.detectMultiScale(img, detections, levels, weights, 1.1, 3, 0, Size(), Size(), true);\n",
      "     |      .   cerr << \"Detection \" << detections[0] << \" with weight \" << weights[0] << endl;\n",
      "     |      .   @endcode\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Checks whether the classifier has been loaded.\n",
      "     |  \n",
      "     |  getFeatureType(...)\n",
      "     |      getFeatureType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getOriginalWindowSize(...)\n",
      "     |      getOriginalWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isOldFormatCascade(...)\n",
      "     |      isOldFormatCascade() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filename) -> retval\n",
      "     |      .   @brief Loads a classifier from a file.\n",
      "     |      .   \n",
      "     |      .   @param filename Name of the file from which the classifier is loaded. The file may contain an old\n",
      "     |      .   HAAR classifier trained by the haartraining application or a new cascade classifier trained by the\n",
      "     |      .   traincascade application.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(node) -> retval\n",
      "     |      .   @brief Reads a classifier from a FileStorage node.\n",
      "     |      .   \n",
      "     |      .   @note The file may contain a new cascade classifier (trained traincascade application) only.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  convert(...)\n",
      "     |      convert(oldcascade, newcascade) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class CirclesGridFinderParameters(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  convexHullFactor\n",
      "     |      convexHullFactor\n",
      "     |  \n",
      "     |  densityNeighborhoodSize\n",
      "     |      densityNeighborhoodSize\n",
      "     |  \n",
      "     |  edgeGain\n",
      "     |      edgeGain\n",
      "     |  \n",
      "     |  edgePenalty\n",
      "     |      edgePenalty\n",
      "     |  \n",
      "     |  existingVertexGain\n",
      "     |      existingVertexGain\n",
      "     |  \n",
      "     |  keypointScale\n",
      "     |      keypointScale\n",
      "     |  \n",
      "     |  kmeansAttempts\n",
      "     |      kmeansAttempts\n",
      "     |  \n",
      "     |  maxRectifiedDistance\n",
      "     |      maxRectifiedDistance\n",
      "     |  \n",
      "     |  minDensity\n",
      "     |      minDensity\n",
      "     |  \n",
      "     |  minDistanceToAddKeypoint\n",
      "     |      minDistanceToAddKeypoint\n",
      "     |  \n",
      "     |  minGraphConfidence\n",
      "     |      minGraphConfidence\n",
      "     |  \n",
      "     |  minRNGEdgeSwitchDist\n",
      "     |      minRNGEdgeSwitchDist\n",
      "     |  \n",
      "     |  squareSize\n",
      "     |      squareSize\n",
      "     |  \n",
      "     |  vertexGain\n",
      "     |      vertexGain\n",
      "     |  \n",
      "     |  vertexPenalty\n",
      "     |      vertexPenalty\n",
      "    \n",
      "    class DISOpticalFlow(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      DISOpticalFlow\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFinestScale(...)\n",
      "     |      getFinestScale() -> retval\n",
      "     |      .   @brief Finest level of the Gaussian pyramid on which the flow is computed (zero level\n",
      "     |      .   corresponds to the original image resolution). The final flow is obtained by bilinear upscaling.\n",
      "     |      .   @see setFinestScale\n",
      "     |  \n",
      "     |  getGradientDescentIterations(...)\n",
      "     |      getGradientDescentIterations() -> retval\n",
      "     |      .   @brief Maximum number of gradient descent iterations in the patch inverse search stage. Higher values\n",
      "     |      .   may improve quality in some cases.\n",
      "     |      .   @see setGradientDescentIterations\n",
      "     |  \n",
      "     |  getPatchSize(...)\n",
      "     |      getPatchSize() -> retval\n",
      "     |      .   @brief Size of an image patch for matching (in pixels). Normally, default 8x8 patches work well\n",
      "     |      .   enough in most cases.\n",
      "     |      .   @see setPatchSize\n",
      "     |  \n",
      "     |  getPatchStride(...)\n",
      "     |      getPatchStride() -> retval\n",
      "     |      .   @brief Stride between neighbor patches. Must be less than patch size. Lower values correspond\n",
      "     |      .   to higher flow quality.\n",
      "     |      .   @see setPatchStride\n",
      "     |  \n",
      "     |  getUseMeanNormalization(...)\n",
      "     |      getUseMeanNormalization() -> retval\n",
      "     |      .   @brief Whether to use mean-normalization of patches when computing patch distance. It is turned on\n",
      "     |      .   by default as it typically provides a noticeable quality boost because of increased robustness to\n",
      "     |      .   illumination variations. Turn it off if you are certain that your sequence doesn't contain any changes\n",
      "     |      .   in illumination.\n",
      "     |      .   @see setUseMeanNormalization\n",
      "     |  \n",
      "     |  getUseSpatialPropagation(...)\n",
      "     |      getUseSpatialPropagation() -> retval\n",
      "     |      .   @brief Whether to use spatial propagation of good optical flow vectors. This option is turned on by\n",
      "     |      .   default, as it tends to work better on average and can sometimes help recover from major errors\n",
      "     |      .   introduced by the coarse-to-fine scheme employed by the DIS optical flow algorithm. Turning this\n",
      "     |      .   option off can make the output flow field a bit smoother, however.\n",
      "     |      .   @see setUseSpatialPropagation\n",
      "     |  \n",
      "     |  getVariationalRefinementAlpha(...)\n",
      "     |      getVariationalRefinementAlpha() -> retval\n",
      "     |      .   @brief Weight of the smoothness term\n",
      "     |      .   @see setVariationalRefinementAlpha\n",
      "     |  \n",
      "     |  getVariationalRefinementDelta(...)\n",
      "     |      getVariationalRefinementDelta() -> retval\n",
      "     |      .   @brief Weight of the color constancy term\n",
      "     |      .   @see setVariationalRefinementDelta\n",
      "     |  \n",
      "     |  getVariationalRefinementGamma(...)\n",
      "     |      getVariationalRefinementGamma() -> retval\n",
      "     |      .   @brief Weight of the gradient constancy term\n",
      "     |      .   @see setVariationalRefinementGamma\n",
      "     |  \n",
      "     |  getVariationalRefinementIterations(...)\n",
      "     |      getVariationalRefinementIterations() -> retval\n",
      "     |      .   @brief Number of fixed point iterations of variational refinement per scale. Set to zero to\n",
      "     |      .   disable variational refinement completely. Higher values will typically result in more smooth and\n",
      "     |      .   high-quality flow.\n",
      "     |      .   @see setGradientDescentIterations\n",
      "     |  \n",
      "     |  setFinestScale(...)\n",
      "     |      setFinestScale(val) -> None\n",
      "     |      .   @copybrief getFinestScale @see getFinestScale\n",
      "     |  \n",
      "     |  setGradientDescentIterations(...)\n",
      "     |      setGradientDescentIterations(val) -> None\n",
      "     |      .   @copybrief getGradientDescentIterations @see getGradientDescentIterations\n",
      "     |  \n",
      "     |  setPatchSize(...)\n",
      "     |      setPatchSize(val) -> None\n",
      "     |      .   @copybrief getPatchSize @see getPatchSize\n",
      "     |  \n",
      "     |  setPatchStride(...)\n",
      "     |      setPatchStride(val) -> None\n",
      "     |      .   @copybrief getPatchStride @see getPatchStride\n",
      "     |  \n",
      "     |  setUseMeanNormalization(...)\n",
      "     |      setUseMeanNormalization(val) -> None\n",
      "     |      .   @copybrief getUseMeanNormalization @see getUseMeanNormalization\n",
      "     |  \n",
      "     |  setUseSpatialPropagation(...)\n",
      "     |      setUseSpatialPropagation(val) -> None\n",
      "     |      .   @copybrief getUseSpatialPropagation @see getUseSpatialPropagation\n",
      "     |  \n",
      "     |  setVariationalRefinementAlpha(...)\n",
      "     |      setVariationalRefinementAlpha(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementAlpha @see getVariationalRefinementAlpha\n",
      "     |  \n",
      "     |  setVariationalRefinementDelta(...)\n",
      "     |      setVariationalRefinementDelta(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementDelta @see getVariationalRefinementDelta\n",
      "     |  \n",
      "     |  setVariationalRefinementGamma(...)\n",
      "     |      setVariationalRefinementGamma(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementGamma @see getVariationalRefinementGamma\n",
      "     |  \n",
      "     |  setVariationalRefinementIterations(...)\n",
      "     |      setVariationalRefinementIterations(val) -> None\n",
      "     |      .   @copybrief getGradientDescentIterations @see getGradientDescentIterations\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, preset]) -> retval\n",
      "     |      .   @brief Creates an instance of DISOpticalFlow\n",
      "     |      .   \n",
      "     |      .   @param preset one of PRESET_ULTRAFAST, PRESET_FAST and PRESET_MEDIUM\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .   @param I0 first 8-bit single-channel input image.\n",
      "     |      .   @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class DMatch(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  distance\n",
      "     |      distance\n",
      "     |  \n",
      "     |  imgIdx\n",
      "     |      imgIdx\n",
      "     |  \n",
      "     |  queryIdx\n",
      "     |      queryIdx\n",
      "     |  \n",
      "     |  trainIdx\n",
      "     |      trainIdx\n",
      "    \n",
      "    class DenseOpticalFlow(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .   @param I0 first 8-bit single-channel input image.\n",
      "     |      .   @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class DescriptorMatcher(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .   collection.\n",
      "     |      .   \n",
      "     |      .   If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .   train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .   @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .   that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .   object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .   These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .   descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .   for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .   second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .   used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .   matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .   mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .   query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .   returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .   Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .   train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .   have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .   example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(descriptorMatcherType) -> retval\n",
      "     |      .   @brief Creates a descriptor matcher of a given type with the default parameters (using default\n",
      "     |      .   constructor).\n",
      "     |      .   \n",
      "     |      .   @param descriptorMatcherType Descriptor matcher type. Now the following matcher types are\n",
      "     |      .   supported:\n",
      "     |      .   -   `BruteForce` (it uses L2 )\n",
      "     |      .   -   `BruteForce-L1`\n",
      "     |      .   -   `BruteForce-Hamming`\n",
      "     |      .   -   `BruteForce-Hamming(2)`\n",
      "     |      .   -   `FlannBased`\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(matcherType) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class FarnebackOpticalFlow(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      FarnebackOpticalFlow\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFastPyramids(...)\n",
      "     |      getFastPyramids() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFlags(...)\n",
      "     |      getFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumIters(...)\n",
      "     |      getNumIters() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumLevels(...)\n",
      "     |      getNumLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPolyN(...)\n",
      "     |      getPolyN() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPolySigma(...)\n",
      "     |      getPolySigma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPyrScale(...)\n",
      "     |      getPyrScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWinSize(...)\n",
      "     |      getWinSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFastPyramids(...)\n",
      "     |      setFastPyramids(fastPyramids) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFlags(...)\n",
      "     |      setFlags(flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumIters(...)\n",
      "     |      setNumIters(numIters) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumLevels(...)\n",
      "     |      setNumLevels(numLevels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPolyN(...)\n",
      "     |      setPolyN(polyN) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPolySigma(...)\n",
      "     |      setPolySigma(polySigma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPyrScale(...)\n",
      "     |      setPyrScale(pyrScale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWinSize(...)\n",
      "     |      setWinSize(winSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .   @param I0 first 8-bit single-channel input image.\n",
      "     |      .   @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class FastFeatureDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      FastFeatureDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNonmaxSuppression(...)\n",
      "     |      getNonmaxSuppression() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNonmaxSuppression(...)\n",
      "     |      setNonmaxSuppression(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class Feature2D(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FileNode(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  at(...)\n",
      "     |      at(i) -> retval\n",
      "     |      .   @overload\n",
      "     |      .   @param i Index of an element in the sequence node.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNode(...)\n",
      "     |      getNode(nodename) -> retval\n",
      "     |      .   @overload\n",
      "     |      .   @param nodename Name of an element in the mapping node.\n",
      "     |  \n",
      "     |  isInt(...)\n",
      "     |      isInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isMap(...)\n",
      "     |      isMap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNamed(...)\n",
      "     |      isNamed() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNone(...)\n",
      "     |      isNone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isReal(...)\n",
      "     |      isReal() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isSeq(...)\n",
      "     |      isSeq() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isString(...)\n",
      "     |      isString() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      keys() -> retval\n",
      "     |      .   @brief Returns keys of a mapping node.\n",
      "     |      .   @returns Keys of a mapping node.\n",
      "     |  \n",
      "     |  mat(...)\n",
      "     |      mat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  rawSize(...)\n",
      "     |      rawSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> retval\n",
      "     |      .   Internal method used when reading FileStorage.\n",
      "     |      .   Sets the type (int, real or string) and value of the previously created node.\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  string(...)\n",
      "     |      string() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .   @brief Returns type of the node.\n",
      "     |      .   @returns Type of the node. See FileNode::Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FileStorage(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFirstTopLevelNode(...)\n",
      "     |      getFirstTopLevelNode() -> retval\n",
      "     |      .   @brief Returns the first element of the top-level mapping.\n",
      "     |      .   @returns The first element of the top-level mapping.\n",
      "     |  \n",
      "     |  getFormat(...)\n",
      "     |      getFormat() -> retval\n",
      "     |      .   @brief Returns the current format.\n",
      "     |      .   * @returns The current format, see FileStorage::Mode\n",
      "     |  \n",
      "     |  getNode(...)\n",
      "     |      getNode(nodename) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Checks whether the file is opened.\n",
      "     |      .   \n",
      "     |      .   @returns true if the object is associated with the current file and false otherwise. It is a\n",
      "     |      .   good practice to call this method after you tried to open a file.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename, flags[, encoding]) -> retval\n",
      "     |      .   @brief Opens a file.\n",
      "     |      .   \n",
      "     |      .   See description of parameters in FileStorage::FileStorage. The method calls FileStorage::release\n",
      "     |      .   before opening the file.\n",
      "     |      .   @param filename Name of the file to open or the text string to read the data from.\n",
      "     |      .   Extension of the file (.xml, .yml/.yaml or .json) determines its format (XML, YAML or JSON\n",
      "     |      .   respectively). Also you can append .gz to work with compressed files, for example myHugeMatrix.xml.gz. If both\n",
      "     |      .   FileStorage::WRITE and FileStorage::MEMORY flags are specified, source is used just to specify\n",
      "     |      .   the output file format (e.g. mydata.xml, .yml etc.). A file name can also contain parameters.\n",
      "     |      .   You can use this format, \"*?base64\" (e.g. \"file.json?base64\" (case sensitive)), as an alternative to\n",
      "     |      .   FileStorage::BASE64 flag.\n",
      "     |      .   @param flags Mode of operation. One of FileStorage::Mode\n",
      "     |      .   @param encoding Encoding of the file. Note that UTF-16 XML encoding is not supported currently and\n",
      "     |      .   you should use 8-bit encoding instead of it.\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes the file and releases all the memory buffers.\n",
      "     |      .   \n",
      "     |      .   Call this method after all I/O operations with the storage are finished.\n",
      "     |  \n",
      "     |  releaseAndGetString(...)\n",
      "     |      releaseAndGetString() -> retval\n",
      "     |      .   @brief Closes the file and releases all the memory buffers.\n",
      "     |      .   \n",
      "     |      .   Call this method after all I/O operations with the storage are finished. If the storage was\n",
      "     |      .   opened for writing data and FileStorage::WRITE was specified\n",
      "     |  \n",
      "     |  root(...)\n",
      "     |      root([, streamidx]) -> retval\n",
      "     |      .   @brief Returns the top-level mapping\n",
      "     |      .   @param streamidx Zero-based index of the stream. In most cases there is only one stream in the file.\n",
      "     |      .   However, YAML supports multiple streams and so there can be several.\n",
      "     |      .   @returns The top-level mapping.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(name, val) -> None\n",
      "     |      .   * @brief Simplified writing API to use with bindings.\n",
      "     |      .   * @param name Name of the written object\n",
      "     |      .   * @param val Value of the written object\n",
      "     |  \n",
      "     |  writeComment(...)\n",
      "     |      writeComment(comment[, append]) -> None\n",
      "     |      .   @brief Writes a comment.\n",
      "     |      .   \n",
      "     |      .   The function writes a comment into file storage. The comments are skipped when the storage is read.\n",
      "     |      .   @param comment The written comment, single-line or multi-line\n",
      "     |      .   @param append If true, the function tries to put the comment at the end of current line.\n",
      "     |      .   Else if the comment is multi-line, or if it does not fit at the end of the current\n",
      "     |      .   line, the comment starts a new line.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FlannBasedMatcher(DescriptorMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      FlannBasedMatcher\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DescriptorMatcher:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .   collection.\n",
      "     |      .   \n",
      "     |      .   If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .   @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .   train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .   @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .   that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .   object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .   These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .   descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .   for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .   @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .   less than k possible matches in total.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .   second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .   used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .   matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .   mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .   descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .   collection stored in the class object.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .   descriptors.\n",
      "     |      .   \n",
      "     |      .   For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .   query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .   returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .   @param queryDescriptors Query set of descriptors.\n",
      "     |      .   @param matches Found matches.\n",
      "     |      .   @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .   metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .   in Pixels)!\n",
      "     |      .   @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .   descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .   @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .   false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .   the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .   Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .   train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .   have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .   example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class GFTTDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      GFTTDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getHarrisDetector(...)\n",
      "     |      getHarrisDetector() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getK(...)\n",
      "     |      getK() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxFeatures(...)\n",
      "     |      getMaxFeatures() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDistance(...)\n",
      "     |      getMinDistance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getQualityLevel(...)\n",
      "     |      getQualityLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setHarrisDetector(...)\n",
      "     |      setHarrisDetector(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setK(...)\n",
      "     |      setK(k) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxFeatures(...)\n",
      "     |      setMaxFeatures(maxFeatures) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDistance(...)\n",
      "     |      setMinDistance(minDistance) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setQualityLevel(...)\n",
      "     |      setQualityLevel(qlevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, k]]]]]]) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(maxCorners, qualityLevel, minDistance, blockSize, gradiantSize[, useHarrisDetector[, k]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class GeneralizedHough(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class GeneralizedHoughBallard(GeneralizedHough)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHoughBallard\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getLevels(...)\n",
      "     |      getLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVotesThreshold(...)\n",
      "     |      getVotesThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLevels(...)\n",
      "     |      setLevels(levels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVotesThreshold(...)\n",
      "     |      setVotesThreshold(votesThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GeneralizedHough:\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class GeneralizedHoughGuil(GeneralizedHough)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHoughGuil\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GeneralizedHough:\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class HOGDescriptor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  checkDetectorSize(...)\n",
      "     |      checkDetectorSize() -> retval\n",
      "     |      .   @brief Checks if detector size equal to descriptor size.\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
      "     |      .   @brief Computes HOG descriptors of given image.\n",
      "     |      .   @param img Matrix of the type CV_8U containing an image where HOG features will be calculated.\n",
      "     |      .   @param descriptors Matrix of the type CV_32F\n",
      "     |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .   @param padding Padding\n",
      "     |      .   @param locations Vector of Point\n",
      "     |  \n",
      "     |  computeGradient(...)\n",
      "     |      computeGradient(img, grad, angleOfs[, paddingTL[, paddingBR]]) -> grad, angleOfs\n",
      "     |      .   @brief  Computes gradients and quantized gradient orientations.\n",
      "     |      .   @param img Matrix contains the image to be computed\n",
      "     |      .   @param grad Matrix of type CV_32FC2 contains computed gradients\n",
      "     |      .   @param angleOfs Matrix of type CV_8UC2 contains quantized gradient orientations\n",
      "     |      .   @param paddingTL Padding from top-left\n",
      "     |      .   @param paddingBR Padding from bottom-right\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights\n",
      "     |      .   @brief Performs object detection without a multi-scale window.\n",
      "     |      .   @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      "     |      .   @param foundLocations Vector of point where each point contains left-top corner point of detected object boundaries.\n",
      "     |      .   @param weights Vector that will contain confidence values for each detected object.\n",
      "     |      .   @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      "     |      .   Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      "     |      .   But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      "     |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .   @param padding Padding\n",
      "     |      .   @param searchLocations Vector of Point includes set of requested locations to be evaluated.\n",
      "     |  \n",
      "     |  detectMultiScale(...)\n",
      "     |      detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, finalThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights\n",
      "     |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "     |      .   of rectangles.\n",
      "     |      .   @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      "     |      .   @param foundLocations Vector of rectangles where each rectangle contains the detected object.\n",
      "     |      .   @param foundWeights Vector that will contain confidence values for each detected object.\n",
      "     |      .   @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      "     |      .   Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      "     |      .   But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      "     |      .   @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .   @param padding Padding\n",
      "     |      .   @param scale Coefficient of the detection window increase.\n",
      "     |      .   @param finalThreshold Final threshold\n",
      "     |      .   @param useMeanshiftGrouping indicates grouping algorithm\n",
      "     |  \n",
      "     |  getDescriptorSize(...)\n",
      "     |      getDescriptorSize() -> retval\n",
      "     |      .   @brief Returns the number of coefficients required for the classification.\n",
      "     |  \n",
      "     |  getWinSigma(...)\n",
      "     |      getWinSigma() -> retval\n",
      "     |      .   @brief Returns winSigma value\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filename[, objname]) -> retval\n",
      "     |      .   @brief loads HOGDescriptor parameters and coefficients for the linear SVM classifier from a file.\n",
      "     |      .   @param filename Path of the file to read.\n",
      "     |      .   @param objname The optional name of the node to read (if empty, the first top-level node will be used).\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename[, objname]) -> None\n",
      "     |      .   @brief saves HOGDescriptor parameters and coefficients for the linear SVM classifier to a file\n",
      "     |      .   @param filename File name\n",
      "     |      .   @param objname Object name\n",
      "     |  \n",
      "     |  setSVMDetector(...)\n",
      "     |      setSVMDetector(svmdetector) -> None\n",
      "     |      .   @brief Sets coefficients for the linear SVM classifier.\n",
      "     |      .   @param svmdetector coefficients for the linear SVM classifier.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  getDaimlerPeopleDetector(...)\n",
      "     |      getDaimlerPeopleDetector() -> retval\n",
      "     |      .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      "     |  \n",
      "     |  getDefaultPeopleDetector(...)\n",
      "     |      getDefaultPeopleDetector() -> retval\n",
      "     |      .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  L2HysThreshold\n",
      "     |      L2HysThreshold\n",
      "     |  \n",
      "     |  blockSize\n",
      "     |      blockSize\n",
      "     |  \n",
      "     |  blockStride\n",
      "     |      blockStride\n",
      "     |  \n",
      "     |  cellSize\n",
      "     |      cellSize\n",
      "     |  \n",
      "     |  derivAperture\n",
      "     |      derivAperture\n",
      "     |  \n",
      "     |  gammaCorrection\n",
      "     |      gammaCorrection\n",
      "     |  \n",
      "     |  histogramNormType\n",
      "     |      histogramNormType\n",
      "     |  \n",
      "     |  nbins\n",
      "     |      nbins\n",
      "     |  \n",
      "     |  nlevels\n",
      "     |      nlevels\n",
      "     |  \n",
      "     |  signedGradient\n",
      "     |      signedGradient\n",
      "     |  \n",
      "     |  svmDetector\n",
      "     |      svmDetector\n",
      "     |  \n",
      "     |  winSigma\n",
      "     |      winSigma\n",
      "     |  \n",
      "     |  winSize\n",
      "     |      winSize\n",
      "    \n",
      "    class KAZE(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      KAZE\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDiffusivity(...)\n",
      "     |      getDiffusivity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExtended(...)\n",
      "     |      getExtended() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaveLayers(...)\n",
      "     |      getNOctaveLayers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaves(...)\n",
      "     |      getNOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUpright(...)\n",
      "     |      getUpright() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDiffusivity(...)\n",
      "     |      setDiffusivity(diff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExtended(...)\n",
      "     |      setExtended(extended) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaveLayers(...)\n",
      "     |      setNOctaveLayers(octaveLayers) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaves(...)\n",
      "     |      setNOctaves(octaves) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpright(...)\n",
      "     |      setUpright(upright) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, extended[, upright[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]) -> retval\n",
      "     |      .   @brief The KAZE constructor\n",
      "     |      .   \n",
      "     |      .   @param extended Set to enable extraction of extended (128-byte) descriptor.\n",
      "     |      .   @param upright Set to enable use of upright descriptors (non rotation-invariant).\n",
      "     |      .   @param threshold Detector response threshold to accept point\n",
      "     |      .   @param nOctaves Maximum octave evolution of the image\n",
      "     |      .   @param nOctaveLayers Default number of sublevels per scale level\n",
      "     |      .   @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "     |      .   DIFF_CHARBONNIER\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class KalmanFilter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  correct(...)\n",
      "     |      correct(measurement) -> retval\n",
      "     |      .   @brief Updates the predicted state from the measurement.\n",
      "     |      .   \n",
      "     |      .   @param measurement The measured system parameters\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict([, control]) -> retval\n",
      "     |      .   @brief Computes a predicted state.\n",
      "     |      .   \n",
      "     |      .   @param control The optional input control\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  controlMatrix\n",
      "     |      controlMatrix\n",
      "     |  \n",
      "     |  errorCovPost\n",
      "     |      errorCovPost\n",
      "     |  \n",
      "     |  errorCovPre\n",
      "     |      errorCovPre\n",
      "     |  \n",
      "     |  gain\n",
      "     |      gain\n",
      "     |  \n",
      "     |  measurementMatrix\n",
      "     |      measurementMatrix\n",
      "     |  \n",
      "     |  measurementNoiseCov\n",
      "     |      measurementNoiseCov\n",
      "     |  \n",
      "     |  processNoiseCov\n",
      "     |      processNoiseCov\n",
      "     |  \n",
      "     |  statePost\n",
      "     |      statePost\n",
      "     |  \n",
      "     |  statePre\n",
      "     |      statePre\n",
      "     |  \n",
      "     |  transitionMatrix\n",
      "     |      transitionMatrix\n",
      "    \n",
      "    class KeyPoint(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  convert(...)\n",
      "     |      convert(keypoints[, keypointIndexes]) -> points2f\n",
      "     |      .   This method converts vector of keypoints to vector of points or the reverse, where each keypoint is\n",
      "     |      .   assigned the same size and the same orientation.\n",
      "     |      .   \n",
      "     |      .   @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "     |      .   @param points2f Array of (x,y) coordinates of each keypoint\n",
      "     |      .   @param keypointIndexes Array of indexes of keypoints to be converted to points. (Acts like a mask to\n",
      "     |      .   convert only specified keypoints)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convert(points2f[, size[, response[, octave[, class_id]]]]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param points2f Array of (x,y) coordinates of each keypoint\n",
      "     |      .   @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "     |      .   @param size keypoint diameter\n",
      "     |      .   @param response keypoint detector response on the keypoint (that is, strength of the keypoint)\n",
      "     |      .   @param octave pyramid octave in which the keypoint has been detected\n",
      "     |      .   @param class_id object id\n",
      "     |  \n",
      "     |  overlap(...)\n",
      "     |      overlap(kp1, kp2) -> retval\n",
      "     |      .   This method computes overlap for pair of keypoints. Overlap is the ratio between area of keypoint\n",
      "     |      .   regions' intersection and area of keypoint regions' union (considering keypoint region as circle).\n",
      "     |      .   If they don't overlap, we get zero. If they coincide at same location with same size, we get 1.\n",
      "     |      .   @param kp1 First keypoint\n",
      "     |      .   @param kp2 Second keypoint\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  angle\n",
      "     |      angle\n",
      "     |  \n",
      "     |  class_id\n",
      "     |      class_id\n",
      "     |  \n",
      "     |  octave\n",
      "     |      octave\n",
      "     |  \n",
      "     |  pt\n",
      "     |      pt\n",
      "     |  \n",
      "     |  response\n",
      "     |      response\n",
      "     |  \n",
      "     |  size\n",
      "     |      size\n",
      "    \n",
      "    class LineSegmentDetector(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      LineSegmentDetector\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compareSegments(...)\n",
      "     |      compareSegments(size, lines1, lines2[, _image]) -> retval, _image\n",
      "     |      .   @brief Draws two groups of lines in blue and red, counting the non overlapping (mismatching) pixels.\n",
      "     |      .   \n",
      "     |      .   @param size The size of the image, where lines1 and lines2 were found.\n",
      "     |      .   @param lines1 The first group of lines that needs to be drawn. It is visualized in blue color.\n",
      "     |      .   @param lines2 The second group of lines. They visualized in red color.\n",
      "     |      .   @param _image Optional image, where the lines will be drawn. The image should be color(3-channel)\n",
      "     |      .   in order for lines1 and lines2 to be drawn in the above mentioned colors.\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(_image[, _lines[, width[, prec[, nfa]]]]) -> _lines, width, prec, nfa\n",
      "     |      .   @brief Finds lines in the input image.\n",
      "     |      .   \n",
      "     |      .   This is the output of the default parameters of the algorithm on the above shown image.\n",
      "     |      .   \n",
      "     |      .   ![image](pics/building_lsd.png)\n",
      "     |      .   \n",
      "     |      .   @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be selected, use:\n",
      "     |      .   `lsd_ptr-\\>detect(image(roi), lines, ...); lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\n",
      "     |      .   @param _lines A vector of Vec4i or Vec4f elements specifying the beginning and ending point of a line. Where\n",
      "     |      .   Vec4i/Vec4f is (x1, y1, x2, y2), point 1 is the start, point 2 - end. Returned lines are strictly\n",
      "     |      .   oriented depending on the gradient.\n",
      "     |      .   @param width Vector of widths of the regions, where the lines are found. E.g. Width of line.\n",
      "     |      .   @param prec Vector of precisions with which the lines are found.\n",
      "     |      .   @param nfa Vector containing number of false alarms in the line region, with precision of 10%. The\n",
      "     |      .   bigger the value, logarithmically better the detection.\n",
      "     |      .   - -1 corresponds to 10 mean false alarms\n",
      "     |      .   - 0 corresponds to 1 mean false alarm\n",
      "     |      .   - 1 corresponds to 0.1 mean false alarms\n",
      "     |      .   This vector will be calculated only when the objects type is #LSD_REFINE_ADV.\n",
      "     |  \n",
      "     |  drawSegments(...)\n",
      "     |      drawSegments(_image, lines) -> _image\n",
      "     |      .   @brief Draws the line segments on a given image.\n",
      "     |      .   @param _image The image, where the lines will be drawn. Should be bigger or equal to the image,\n",
      "     |      .   where the lines were found.\n",
      "     |      .   @param lines A vector of the lines that needed to be drawn.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class MSER(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      MSER\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detectRegions(...)\n",
      "     |      detectRegions(image) -> msers, bboxes\n",
      "     |      .   @brief Detect %MSER regions\n",
      "     |      .   \n",
      "     |      .   @param image input image (8UC1, 8UC3 or 8UC4, must be greater or equal than 3x3)\n",
      "     |      .   @param msers resulting list of point sets\n",
      "     |      .   @param bboxes resulting bounding boxes\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDelta(...)\n",
      "     |      getDelta() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxArea(...)\n",
      "     |      getMaxArea() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinArea(...)\n",
      "     |      getMinArea() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPass2Only(...)\n",
      "     |      getPass2Only() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDelta(...)\n",
      "     |      setDelta(delta) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxArea(...)\n",
      "     |      setMaxArea(maxArea) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinArea(...)\n",
      "     |      setMinArea(minArea) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPass2Only(...)\n",
      "     |      setPass2Only(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, _delta[, _min_area[, _max_area[, _max_variation[, _min_diversity[, _max_evolution[, _area_threshold[, _min_margin[, _edge_blur_size]]]]]]]]]) -> retval\n",
      "     |      .   @brief Full consturctor for %MSER detector\n",
      "     |      .   \n",
      "     |      .   @param _delta it compares \\f$(size_{i}-size_{i-delta})/size_{i-delta}\\f$\n",
      "     |      .   @param _min_area prune the area which smaller than minArea\n",
      "     |      .   @param _max_area prune the area which bigger than maxArea\n",
      "     |      .   @param _max_variation prune the area have similar size to its children\n",
      "     |      .   @param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity\n",
      "     |      .   @param _max_evolution  for color image, the evolution steps\n",
      "     |      .   @param _area_threshold for color image, the area threshold to cause re-initialize\n",
      "     |      .   @param _min_margin for color image, ignore too small margin\n",
      "     |      .   @param _edge_blur_size for color image, the aperture size for edge blur\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class MergeDebevec(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeDebevec\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class MergeExposures(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   @brief Merges images.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst result image\n",
      "     |      .   @param times vector of exposure time values for each image\n",
      "     |      .   @param response 256x1 matrix with inverse camera response function for each pixel value, it should\n",
      "     |      .   have the same number of channels as images.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class MergeMertens(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeMertens\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getContrastWeight(...)\n",
      "     |      getContrastWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExposureWeight(...)\n",
      "     |      getExposureWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSaturationWeight(...)\n",
      "     |      getSaturationWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Short version of process, that doesn't take extra arguments.\n",
      "     |      .   \n",
      "     |      .   @param src vector of input images\n",
      "     |      .   @param dst result image\n",
      "     |  \n",
      "     |  setContrastWeight(...)\n",
      "     |      setContrastWeight(contrast_weiht) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExposureWeight(...)\n",
      "     |      setExposureWeight(exposure_weight) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturationWeight(...)\n",
      "     |      setSaturationWeight(saturation_weight) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class MergeRobertson(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeRobertson\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ORB(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      ORB\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getEdgeThreshold(...)\n",
      "     |      getEdgeThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFastThreshold(...)\n",
      "     |      getFastThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFirstLevel(...)\n",
      "     |      getFirstLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxFeatures(...)\n",
      "     |      getMaxFeatures() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNLevels(...)\n",
      "     |      getNLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPatchSize(...)\n",
      "     |      getPatchSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScaleFactor(...)\n",
      "     |      getScaleFactor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScoreType(...)\n",
      "     |      getScoreType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWTA_K(...)\n",
      "     |      getWTA_K() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setEdgeThreshold(...)\n",
      "     |      setEdgeThreshold(edgeThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFastThreshold(...)\n",
      "     |      setFastThreshold(fastThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFirstLevel(...)\n",
      "     |      setFirstLevel(firstLevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxFeatures(...)\n",
      "     |      setMaxFeatures(maxFeatures) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNLevels(...)\n",
      "     |      setNLevels(nlevels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPatchSize(...)\n",
      "     |      setPatchSize(patchSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScaleFactor(...)\n",
      "     |      setScaleFactor(scaleFactor) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScoreType(...)\n",
      "     |      setScoreType(scoreType) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWTA_K(...)\n",
      "     |      setWTA_K(wta_k) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold]]]]]]]]]) -> retval\n",
      "     |      .   @brief The ORB constructor\n",
      "     |      .   \n",
      "     |      .   @param nfeatures The maximum number of features to retain.\n",
      "     |      .   @param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical\n",
      "     |      .   pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor\n",
      "     |      .   will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor\n",
      "     |      .   will mean that to cover certain scale range you will need more pyramid levels and so the speed\n",
      "     |      .   will suffer.\n",
      "     |      .   @param nlevels The number of pyramid levels. The smallest level will have linear size equal to\n",
      "     |      .   input_image_linear_size/pow(scaleFactor, nlevels - firstLevel).\n",
      "     |      .   @param edgeThreshold This is size of the border where the features are not detected. It should\n",
      "     |      .   roughly match the patchSize parameter.\n",
      "     |      .   @param firstLevel The level of pyramid to put source image to. Previous layers are filled\n",
      "     |      .   with upscaled source image.\n",
      "     |      .   @param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The\n",
      "     |      .   default value 2 means the BRIEF where we take a random point pair and compare their brightnesses,\n",
      "     |      .   so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3\n",
      "     |      .   random points (of course, those point coordinates are random, but they are generated from the\n",
      "     |      .   pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel\n",
      "     |      .   rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such\n",
      "     |      .   output will occupy 2 bits, and therefore it will need a special variant of Hamming distance,\n",
      "     |      .   denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each\n",
      "     |      .   bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).\n",
      "     |      .   @param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features\n",
      "     |      .   (the score is written to KeyPoint::score and is used to retain best nfeatures features);\n",
      "     |      .   FAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,\n",
      "     |      .   but it is a little faster to compute.\n",
      "     |      .   @param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller\n",
      "     |      .   pyramid layers the perceived image area covered by a feature will be larger.\n",
      "     |      .   @param fastThreshold\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class PyRotationWarper(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  buildMaps(...)\n",
      "     |      buildMaps(src_size, K, R[, xmap[, ymap]]) -> retval, xmap, ymap\n",
      "     |      .   @brief Builds the projection maps according to the given camera data.\n",
      "     |      .   \n",
      "     |      .   @param src_size Source image size\n",
      "     |      .   @param K Camera intrinsic parameters\n",
      "     |      .   @param R Camera rotation matrix\n",
      "     |      .   @param xmap Projection map for the x axis\n",
      "     |      .   @param ymap Projection map for the y axis\n",
      "     |      .   @return Projected image minimum bounding box\n",
      "     |  \n",
      "     |  getScale(...)\n",
      "     |      getScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScale(...)\n",
      "     |      setScale(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  warp(...)\n",
      "     |      warp(src, K, R, interp_mode, border_mode[, dst]) -> retval, dst\n",
      "     |      .   @brief Projects the image.\n",
      "     |      .   \n",
      "     |      .   @param src Source image\n",
      "     |      .   @param K Camera intrinsic parameters\n",
      "     |      .   @param R Camera rotation matrix\n",
      "     |      .   @param interp_mode Interpolation mode\n",
      "     |      .   @param border_mode Border extrapolation mode\n",
      "     |      .   @param dst Projected image\n",
      "     |      .   @return Project image top-left corner\n",
      "     |  \n",
      "     |  warpBackward(...)\n",
      "     |      warpBackward(src, K, R, interp_mode, border_mode, dst_size[, dst]) -> dst\n",
      "     |      .   @brief Projects the image backward.\n",
      "     |      .   \n",
      "     |      .   @param src Projected image\n",
      "     |      .   @param K Camera intrinsic parameters\n",
      "     |      .   @param R Camera rotation matrix\n",
      "     |      .   @param interp_mode Interpolation mode\n",
      "     |      .   @param border_mode Border extrapolation mode\n",
      "     |      .   @param dst_size Backward-projected image size\n",
      "     |      .   @param dst Backward-projected image\n",
      "     |  \n",
      "     |  warpPoint(...)\n",
      "     |      warpPoint(pt, K, R) -> retval\n",
      "     |      .   @brief Projects the image point.\n",
      "     |      .   \n",
      "     |      .   @param pt Source point\n",
      "     |      .   @param K Camera intrinsic parameters\n",
      "     |      .   @param R Camera rotation matrix\n",
      "     |      .   @return Projected point\n",
      "     |  \n",
      "     |  warpRoi(...)\n",
      "     |      warpRoi(src_size, K, R) -> retval\n",
      "     |      .   @param src_size Source image bounding box\n",
      "     |      .   @param K Camera intrinsic parameters\n",
      "     |      .   @param R Camera rotation matrix\n",
      "     |      .   @return Projected image minimum bounding box\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class QRCodeDetector(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  decode(...)\n",
      "     |      decode(img, points[, straight_qrcode]) -> retval, straight_qrcode\n",
      "     |      .   @brief Decodes QR code in image once it's found by the detect() method.\n",
      "     |      .   Returns UTF8-encoded output string or empty string if the code cannot be decoded.\n",
      "     |      .   \n",
      "     |      .   @param img grayscale or color (BGR) image containing QR code.\n",
      "     |      .   @param points Quadrangle vertices found by detect() method (or some other algorithm).\n",
      "     |      .   @param straight_qrcode The optional output image containing rectified and binarized QR code\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(img[, points]) -> retval, points\n",
      "     |      .   @brief Detects QR code in image and returns the quadrangle containing the code.\n",
      "     |      .   @param img grayscale or color (BGR) image containing (or not) QR code.\n",
      "     |      .   @param points Output vector of vertices of the minimum-area quadrangle containing the code.\n",
      "     |  \n",
      "     |  detectAndDecode(...)\n",
      "     |      detectAndDecode(img[, points[, straight_qrcode]]) -> retval, points, straight_qrcode\n",
      "     |      .   @brief Both detects and decodes QR code\n",
      "     |      .   \n",
      "     |      .   @param img grayscale or color (BGR) image containing QR code.\n",
      "     |      .   @param points opiotnal output array of vertices of the found QR code quadrangle. Will be empty if not found.\n",
      "     |      .   @param straight_qrcode The optional output image containing rectified and binarized QR code\n",
      "     |  \n",
      "     |  setEpsX(...)\n",
      "     |      setEpsX(epsX) -> None\n",
      "     |      .   @brief sets the epsilon used during the horizontal scan of QR code stop marker detection.\n",
      "     |      .   @param epsX Epsilon neighborhood, which allows you to determine the horizontal pattern\n",
      "     |      .   of the scheme 1:1:3:1:1 according to QR code standard.\n",
      "     |  \n",
      "     |  setEpsY(...)\n",
      "     |      setEpsY(epsY) -> None\n",
      "     |      .   @brief sets the epsilon used during the vertical scan of QR code stop marker detection.\n",
      "     |      .   @param epsY Epsilon neighborhood, which allows you to determine the vertical pattern\n",
      "     |      .   of the scheme 1:1:3:1:1 according to QR code standard.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SimpleBlobDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      SimpleBlobDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, parameters]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .   (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .   computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .   with several dominant orientations (for each orientation).\n",
      "     |      .   @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .   descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .   descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .   @param image Image.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .   matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .   @param images Image set.\n",
      "     |      .   @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .   of keypoints detected in images[i] .\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class SimpleBlobDetector_Params(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  blobColor\n",
      "     |      blobColor\n",
      "     |  \n",
      "     |  filterByArea\n",
      "     |      filterByArea\n",
      "     |  \n",
      "     |  filterByCircularity\n",
      "     |      filterByCircularity\n",
      "     |  \n",
      "     |  filterByColor\n",
      "     |      filterByColor\n",
      "     |  \n",
      "     |  filterByConvexity\n",
      "     |      filterByConvexity\n",
      "     |  \n",
      "     |  filterByInertia\n",
      "     |      filterByInertia\n",
      "     |  \n",
      "     |  maxArea\n",
      "     |      maxArea\n",
      "     |  \n",
      "     |  maxCircularity\n",
      "     |      maxCircularity\n",
      "     |  \n",
      "     |  maxConvexity\n",
      "     |      maxConvexity\n",
      "     |  \n",
      "     |  maxInertiaRatio\n",
      "     |      maxInertiaRatio\n",
      "     |  \n",
      "     |  maxThreshold\n",
      "     |      maxThreshold\n",
      "     |  \n",
      "     |  minArea\n",
      "     |      minArea\n",
      "     |  \n",
      "     |  minCircularity\n",
      "     |      minCircularity\n",
      "     |  \n",
      "     |  minConvexity\n",
      "     |      minConvexity\n",
      "     |  \n",
      "     |  minDistBetweenBlobs\n",
      "     |      minDistBetweenBlobs\n",
      "     |  \n",
      "     |  minInertiaRatio\n",
      "     |      minInertiaRatio\n",
      "     |  \n",
      "     |  minRepeatability\n",
      "     |      minRepeatability\n",
      "     |  \n",
      "     |  minThreshold\n",
      "     |      minThreshold\n",
      "     |  \n",
      "     |  thresholdStep\n",
      "     |      thresholdStep\n",
      "    \n",
      "    class SparseOpticalFlow(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      SparseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(prevImg, nextImg, prevPts, nextPts[, status[, err]]) -> nextPts, status, err\n",
      "     |      .   @brief Calculates a sparse optical flow.\n",
      "     |      .   \n",
      "     |      .   @param prevImg First input image.\n",
      "     |      .   @param nextImg Second input image of the same size and the same type as prevImg.\n",
      "     |      .   @param prevPts Vector of 2D points for which the flow needs to be found.\n",
      "     |      .   @param nextPts Output vector of 2D points containing the calculated new positions of input features in the second image.\n",
      "     |      .   @param status Output status vector. Each element of the vector is set to 1 if the\n",
      "     |      .   flow for the corresponding features has been found. Otherwise, it is set to 0.\n",
      "     |      .   @param err Optional output vector that contains error response for each point (inverse confidence).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class SparsePyrLKOpticalFlow(SparseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      SparsePyrLKOpticalFlow\n",
      "     |      SparseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFlags(...)\n",
      "     |      getFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxLevel(...)\n",
      "     |      getMaxLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinEigThreshold(...)\n",
      "     |      getMinEigThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWinSize(...)\n",
      "     |      getWinSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFlags(...)\n",
      "     |      setFlags(flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxLevel(...)\n",
      "     |      setMaxLevel(maxLevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinEigThreshold(...)\n",
      "     |      setMinEigThreshold(minEigThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(crit) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWinSize(...)\n",
      "     |      setWinSize(winSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, winSize[, maxLevel[, crit[, flags[, minEigThreshold]]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SparseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(prevImg, nextImg, prevPts, nextPts[, status[, err]]) -> nextPts, status, err\n",
      "     |      .   @brief Calculates a sparse optical flow.\n",
      "     |      .   \n",
      "     |      .   @param prevImg First input image.\n",
      "     |      .   @param nextImg Second input image of the same size and the same type as prevImg.\n",
      "     |      .   @param prevPts Vector of 2D points for which the flow needs to be found.\n",
      "     |      .   @param nextPts Output vector of 2D points containing the calculated new positions of input features in the second image.\n",
      "     |      .   @param status Output status vector. Each element of the vector is set to 1 if the\n",
      "     |      .   flow for the corresponding features has been found. Otherwise, it is set to 0.\n",
      "     |      .   @param err Optional output vector that contains error response for each point (inverse confidence).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class StereoBM(StereoMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      StereoBM\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getPreFilterCap(...)\n",
      "     |      getPreFilterCap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterSize(...)\n",
      "     |      getPreFilterSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterType(...)\n",
      "     |      getPreFilterType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getROI1(...)\n",
      "     |      getROI1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getROI2(...)\n",
      "     |      getROI2() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSmallerBlockSize(...)\n",
      "     |      getSmallerBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTextureThreshold(...)\n",
      "     |      getTextureThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUniquenessRatio(...)\n",
      "     |      getUniquenessRatio() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterCap(...)\n",
      "     |      setPreFilterCap(preFilterCap) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterSize(...)\n",
      "     |      setPreFilterSize(preFilterSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterType(...)\n",
      "     |      setPreFilterType(preFilterType) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setROI1(...)\n",
      "     |      setROI1(roi1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setROI2(...)\n",
      "     |      setROI2(roi2) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSmallerBlockSize(...)\n",
      "     |      setSmallerBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTextureThreshold(...)\n",
      "     |      setTextureThreshold(textureThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUniquenessRatio(...)\n",
      "     |      setUniquenessRatio(uniquenessRatio) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, numDisparities[, blockSize]]) -> retval\n",
      "     |      .   @brief Creates StereoBM object\n",
      "     |      .   \n",
      "     |      .   @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "     |      .   disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "     |      .   shifted by changing the minimum disparity.\n",
      "     |      .   @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "     |      .   (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "     |      .   accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "     |      .   chance for algorithm to find a wrong correspondence.\n",
      "     |      .   \n",
      "     |      .   The function create StereoBM object. You can then call StereoBM::compute() to compute disparity for\n",
      "     |      .   a specific stereo pair.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatcher:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .   @param left Left 8-bit single-channel image.\n",
      "     |      .   @param right Right image of the same size and the same type as the left one.\n",
      "     |      .   @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .   like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .   has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class StereoMatcher(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .   @param left Left 8-bit single-channel image.\n",
      "     |      .   @param right Right image of the same size and the same type as the left one.\n",
      "     |      .   @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .   like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .   has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class StereoSGBM(StereoMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      StereoSGBM\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getMode(...)\n",
      "     |      getMode() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getP1(...)\n",
      "     |      getP1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getP2(...)\n",
      "     |      getP2() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterCap(...)\n",
      "     |      getPreFilterCap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUniquenessRatio(...)\n",
      "     |      getUniquenessRatio() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMode(...)\n",
      "     |      setMode(mode) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setP1(...)\n",
      "     |      setP1(P1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setP2(...)\n",
      "     |      setP2(P2) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterCap(...)\n",
      "     |      setPreFilterCap(preFilterCap) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUniquenessRatio(...)\n",
      "     |      setUniquenessRatio(uniquenessRatio) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, minDisparity[, numDisparities[, blockSize[, P1[, P2[, disp12MaxDiff[, preFilterCap[, uniquenessRatio[, speckleWindowSize[, speckleRange[, mode]]]]]]]]]]]) -> retval\n",
      "     |      .   @brief Creates StereoSGBM object\n",
      "     |      .   \n",
      "     |      .   @param minDisparity Minimum possible disparity value. Normally, it is zero but sometimes\n",
      "     |      .   rectification algorithms can shift images, so this parameter needs to be adjusted accordingly.\n",
      "     |      .   @param numDisparities Maximum disparity minus minimum disparity. The value is always greater than\n",
      "     |      .   zero. In the current implementation, this parameter must be divisible by 16.\n",
      "     |      .   @param blockSize Matched block size. It must be an odd number \\>=1 . Normally, it should be\n",
      "     |      .   somewhere in the 3..11 range.\n",
      "     |      .   @param P1 The first parameter controlling the disparity smoothness. See below.\n",
      "     |      .   @param P2 The second parameter controlling the disparity smoothness. The larger the values are,\n",
      "     |      .   the smoother the disparity is. P1 is the penalty on the disparity change by plus or minus 1\n",
      "     |      .   between neighbor pixels. P2 is the penalty on the disparity change by more than 1 between neighbor\n",
      "     |      .   pixels. The algorithm requires P2 \\> P1 . See stereo_match.cpp sample where some reasonably good\n",
      "     |      .   P1 and P2 values are shown (like 8\\*number_of_image_channels\\*SADWindowSize\\*SADWindowSize and\n",
      "     |      .   32\\*number_of_image_channels\\*SADWindowSize\\*SADWindowSize , respectively).\n",
      "     |      .   @param disp12MaxDiff Maximum allowed difference (in integer pixel units) in the left-right\n",
      "     |      .   disparity check. Set it to a non-positive value to disable the check.\n",
      "     |      .   @param preFilterCap Truncation value for the prefiltered image pixels. The algorithm first\n",
      "     |      .   computes x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap] interval.\n",
      "     |      .   The result values are passed to the Birchfield-Tomasi pixel cost function.\n",
      "     |      .   @param uniquenessRatio Margin in percentage by which the best (minimum) computed cost function\n",
      "     |      .   value should \"win\" the second best value to consider the found match correct. Normally, a value\n",
      "     |      .   within the 5-15 range is good enough.\n",
      "     |      .   @param speckleWindowSize Maximum size of smooth disparity regions to consider their noise speckles\n",
      "     |      .   and invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the\n",
      "     |      .   50-200 range.\n",
      "     |      .   @param speckleRange Maximum disparity variation within each connected component. If you do speckle\n",
      "     |      .   filtering, set the parameter to a positive value, it will be implicitly multiplied by 16.\n",
      "     |      .   Normally, 1 or 2 is good enough.\n",
      "     |      .   @param mode Set it to StereoSGBM::MODE_HH to run the full-scale two-pass dynamic programming\n",
      "     |      .   algorithm. It will consume O(W\\*H\\*numDisparities) bytes, which is large for 640x480 stereo and\n",
      "     |      .   huge for HD-size pictures. By default, it is set to false .\n",
      "     |      .   \n",
      "     |      .   The first constructor initializes StereoSGBM with all the default parameters. So, you only have to\n",
      "     |      .   set StereoSGBM::numDisparities at minimum. The second constructor enables you to set each parameter\n",
      "     |      .   to a custom value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatcher:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .   @param left Left 8-bit single-channel image.\n",
      "     |      .   @param right Right image of the same size and the same type as the left one.\n",
      "     |      .   @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .   like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .   has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class Stitcher(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  composePanorama(...)\n",
      "     |      composePanorama([, pano]) -> retval, pano\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  compositingResol(...)\n",
      "     |      compositingResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  estimateTransform(...)\n",
      "     |      estimateTransform(images[, masks]) -> retval\n",
      "     |      .   @brief These functions try to match the given images and to estimate rotations of each camera.\n",
      "     |      .   \n",
      "     |      .   @note Use the functions only if you're aware of the stitching pipeline, otherwise use\n",
      "     |      .   Stitcher::stitch.\n",
      "     |      .   \n",
      "     |      .   @param images Input images.\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   @return Status code.\n",
      "     |  \n",
      "     |  interpolationFlags(...)\n",
      "     |      interpolationFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  panoConfidenceThresh(...)\n",
      "     |      panoConfidenceThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  registrationResol(...)\n",
      "     |      registrationResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  seamEstimationResol(...)\n",
      "     |      seamEstimationResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCompositingResol(...)\n",
      "     |      setCompositingResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setInterpolationFlags(...)\n",
      "     |      setInterpolationFlags(interp_flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPanoConfidenceThresh(...)\n",
      "     |      setPanoConfidenceThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRegistrationResol(...)\n",
      "     |      setRegistrationResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSeamEstimationResol(...)\n",
      "     |      setSeamEstimationResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWaveCorrection(...)\n",
      "     |      setWaveCorrection(flag) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  stitch(...)\n",
      "     |      stitch(images[, pano]) -> retval, pano\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      stitch(images, masks[, pano]) -> retval, pano\n",
      "     |      .   @brief These functions try to stitch the given images.\n",
      "     |      .   \n",
      "     |      .   @param images Input images.\n",
      "     |      .   @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .   @param pano Final pano.\n",
      "     |      .   @return Status code.\n",
      "     |  \n",
      "     |  waveCorrection(...)\n",
      "     |      waveCorrection() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  workScale(...)\n",
      "     |      workScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, mode]) -> retval\n",
      "     |      .   @brief Creates a Stitcher configured in one of the stitching modes.\n",
      "     |      .   \n",
      "     |      .   @param mode Scenario for stitcher operation. This is usually determined by source of images\n",
      "     |      .   to stitch and their transformation. Default parameters will be chosen for operation in given\n",
      "     |      .   scenario.\n",
      "     |      .   @return Stitcher class instance.\n",
      "    \n",
      "    class Subdiv2D(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  edgeDst(...)\n",
      "     |      edgeDst(edge) -> retval, dstpt\n",
      "     |      .   @brief Returns the edge destination.\n",
      "     |      .   \n",
      "     |      .   @param edge Subdivision edge ID.\n",
      "     |      .   @param dstpt Output vertex location.\n",
      "     |      .   \n",
      "     |      .   @returns vertex ID.\n",
      "     |  \n",
      "     |  edgeOrg(...)\n",
      "     |      edgeOrg(edge) -> retval, orgpt\n",
      "     |      .   @brief Returns the edge origin.\n",
      "     |      .   \n",
      "     |      .   @param edge Subdivision edge ID.\n",
      "     |      .   @param orgpt Output vertex location.\n",
      "     |      .   \n",
      "     |      .   @returns vertex ID.\n",
      "     |  \n",
      "     |  findNearest(...)\n",
      "     |      findNearest(pt) -> retval, nearestPt\n",
      "     |      .   @brief Finds the subdivision vertex closest to the given point.\n",
      "     |      .   \n",
      "     |      .   @param pt Input point.\n",
      "     |      .   @param nearestPt Output subdivision vertex point.\n",
      "     |      .   \n",
      "     |      .   The function is another function that locates the input point within the subdivision. It finds the\n",
      "     |      .   subdivision vertex that is the closest to the input point. It is not necessarily one of vertices\n",
      "     |      .   of the facet containing the input point, though the facet (located using locate() ) is used as a\n",
      "     |      .   starting point.\n",
      "     |      .   \n",
      "     |      .   @returns vertex ID.\n",
      "     |  \n",
      "     |  getEdge(...)\n",
      "     |      getEdge(edge, nextEdgeType) -> retval\n",
      "     |      .   @brief Returns one of the edges related to the given edge.\n",
      "     |      .   \n",
      "     |      .   @param edge Subdivision edge ID.\n",
      "     |      .   @param nextEdgeType Parameter specifying which of the related edges to return.\n",
      "     |      .   The following values are possible:\n",
      "     |      .   -   NEXT_AROUND_ORG next around the edge origin ( eOnext on the picture below if e is the input edge)\n",
      "     |      .   -   NEXT_AROUND_DST next around the edge vertex ( eDnext )\n",
      "     |      .   -   PREV_AROUND_ORG previous around the edge origin (reversed eRnext )\n",
      "     |      .   -   PREV_AROUND_DST previous around the edge destination (reversed eLnext )\n",
      "     |      .   -   NEXT_AROUND_LEFT next around the left facet ( eLnext )\n",
      "     |      .   -   NEXT_AROUND_RIGHT next around the right facet ( eRnext )\n",
      "     |      .   -   PREV_AROUND_LEFT previous around the left facet (reversed eOnext )\n",
      "     |      .   -   PREV_AROUND_RIGHT previous around the right facet (reversed eDnext )\n",
      "     |      .   \n",
      "     |      .   ![sample output](pics/quadedge.png)\n",
      "     |      .   \n",
      "     |      .   @returns edge ID related to the input edge.\n",
      "     |  \n",
      "     |  getEdgeList(...)\n",
      "     |      getEdgeList() -> edgeList\n",
      "     |      .   @brief Returns a list of all edges.\n",
      "     |      .   \n",
      "     |      .   @param edgeList Output vector.\n",
      "     |      .   \n",
      "     |      .   The function gives each edge as a 4 numbers vector, where each two are one of the edge\n",
      "     |      .   vertices. i.e. org_x = v[0], org_y = v[1], dst_x = v[2], dst_y = v[3].\n",
      "     |  \n",
      "     |  getLeadingEdgeList(...)\n",
      "     |      getLeadingEdgeList() -> leadingEdgeList\n",
      "     |      .   @brief Returns a list of the leading edge ID connected to each triangle.\n",
      "     |      .   \n",
      "     |      .   @param leadingEdgeList Output vector.\n",
      "     |      .   \n",
      "     |      .   The function gives one edge ID for each triangle.\n",
      "     |  \n",
      "     |  getTriangleList(...)\n",
      "     |      getTriangleList() -> triangleList\n",
      "     |      .   @brief Returns a list of all triangles.\n",
      "     |      .   \n",
      "     |      .   @param triangleList Output vector.\n",
      "     |      .   \n",
      "     |      .   The function gives each triangle as a 6 numbers vector, where each two are one of the triangle\n",
      "     |      .   vertices. i.e. p1_x = v[0], p1_y = v[1], p2_x = v[2], p2_y = v[3], p3_x = v[4], p3_y = v[5].\n",
      "     |  \n",
      "     |  getVertex(...)\n",
      "     |      getVertex(vertex) -> retval, firstEdge\n",
      "     |      .   @brief Returns vertex location from vertex ID.\n",
      "     |      .   \n",
      "     |      .   @param vertex vertex ID.\n",
      "     |      .   @param firstEdge Optional. The first edge ID which is connected to the vertex.\n",
      "     |      .   @returns vertex (x,y)\n",
      "     |  \n",
      "     |  getVoronoiFacetList(...)\n",
      "     |      getVoronoiFacetList(idx) -> facetList, facetCenters\n",
      "     |      .   @brief Returns a list of all Voroni facets.\n",
      "     |      .   \n",
      "     |      .   @param idx Vector of vertices IDs to consider. For all vertices you can pass empty vector.\n",
      "     |      .   @param facetList Output vector of the Voroni facets.\n",
      "     |      .   @param facetCenters Output vector of the Voroni facets center points.\n",
      "     |  \n",
      "     |  initDelaunay(...)\n",
      "     |      initDelaunay(rect) -> None\n",
      "     |      .   @brief Creates a new empty Delaunay subdivision\n",
      "     |      .   \n",
      "     |      .   @param rect Rectangle that includes all of the 2D points that are to be added to the subdivision.\n",
      "     |  \n",
      "     |  insert(...)\n",
      "     |      insert(pt) -> retval\n",
      "     |      .   @brief Insert a single point into a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .   @param pt Point to insert.\n",
      "     |      .   \n",
      "     |      .   The function inserts a single point into a subdivision and modifies the subdivision topology\n",
      "     |      .   appropriately. If a point with the same coordinates exists already, no new point is added.\n",
      "     |      .   @returns the ID of the point.\n",
      "     |      .   \n",
      "     |      .   @note If the point is outside of the triangulation specified rect a runtime error is raised.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      insert(ptvec) -> None\n",
      "     |      .   @brief Insert multiple points into a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .   @param ptvec Points to insert.\n",
      "     |      .   \n",
      "     |      .   The function inserts a vector of points into a subdivision and modifies the subdivision topology\n",
      "     |      .   appropriately.\n",
      "     |  \n",
      "     |  locate(...)\n",
      "     |      locate(pt) -> retval, edge, vertex\n",
      "     |      .   @brief Returns the location of a point within a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .   @param pt Point to locate.\n",
      "     |      .   @param edge Output edge that the point belongs to or is located to the right of it.\n",
      "     |      .   @param vertex Optional output vertex the input point coincides with.\n",
      "     |      .   \n",
      "     |      .   The function locates the input point within the subdivision and gives one of the triangle edges\n",
      "     |      .   or vertices.\n",
      "     |      .   \n",
      "     |      .   @returns an integer which specify one of the following five cases for point location:\n",
      "     |      .   -  The point falls into some facet. The function returns #PTLOC_INSIDE and edge will contain one of\n",
      "     |      .   edges of the facet.\n",
      "     |      .   -  The point falls onto the edge. The function returns #PTLOC_ON_EDGE and edge will contain this edge.\n",
      "     |      .   -  The point coincides with one of the subdivision vertices. The function returns #PTLOC_VERTEX and\n",
      "     |      .   vertex will contain a pointer to the vertex.\n",
      "     |      .   -  The point is outside the subdivision reference rectangle. The function returns #PTLOC_OUTSIDE_RECT\n",
      "     |      .   and no pointers are filled.\n",
      "     |      .   -  One of input arguments is invalid. A runtime error is raised or, if silent or \"parent\" error\n",
      "     |      .   processing mode is selected, #PTLOC_ERROR is returned.\n",
      "     |  \n",
      "     |  nextEdge(...)\n",
      "     |      nextEdge(edge) -> retval\n",
      "     |      .   @brief Returns next edge around the edge origin.\n",
      "     |      .   \n",
      "     |      .   @param edge Subdivision edge ID.\n",
      "     |      .   \n",
      "     |      .   @returns an integer which is next edge ID around the edge origin: eOnext on the\n",
      "     |      .   picture above if e is the input edge).\n",
      "     |  \n",
      "     |  rotateEdge(...)\n",
      "     |      rotateEdge(edge, rotate) -> retval\n",
      "     |      .   @brief Returns another edge of the same quad-edge.\n",
      "     |      .   \n",
      "     |      .   @param edge Subdivision edge ID.\n",
      "     |      .   @param rotate Parameter specifying which of the edges of the same quad-edge as the input\n",
      "     |      .   one to return. The following values are possible:\n",
      "     |      .   -   0 - the input edge ( e on the picture below if e is the input edge)\n",
      "     |      .   -   1 - the rotated edge ( eRot )\n",
      "     |      .   -   2 - the reversed edge (reversed e (in green))\n",
      "     |      .   -   3 - the reversed rotated edge (reversed eRot (in green))\n",
      "     |      .   \n",
      "     |      .   @returns one of the edges ID of the same quad-edge as the input edge.\n",
      "     |  \n",
      "     |  symEdge(...)\n",
      "     |      symEdge(edge) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TickMeter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getCounter(...)\n",
      "     |      getCounter() -> retval\n",
      "     |      .   returns internal counter value.\n",
      "     |  \n",
      "     |  getTimeMicro(...)\n",
      "     |      getTimeMicro() -> retval\n",
      "     |      .   returns passed time in microseconds.\n",
      "     |  \n",
      "     |  getTimeMilli(...)\n",
      "     |      getTimeMilli() -> retval\n",
      "     |      .   returns passed time in milliseconds.\n",
      "     |  \n",
      "     |  getTimeSec(...)\n",
      "     |      getTimeSec() -> retval\n",
      "     |      .   returns passed time in seconds.\n",
      "     |  \n",
      "     |  getTimeTicks(...)\n",
      "     |      getTimeTicks() -> retval\n",
      "     |      .   returns counted ticks.\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      reset() -> None\n",
      "     |      .   resets internal values.\n",
      "     |  \n",
      "     |  start(...)\n",
      "     |      start() -> None\n",
      "     |      .   starts counting ticks.\n",
      "     |  \n",
      "     |  stop(...)\n",
      "     |      stop() -> None\n",
      "     |      .   stops counting ticks.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Tonemap(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .   @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .   @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class TonemapDrago(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapDrago\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBias(...)\n",
      "     |      getBias() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSaturation(...)\n",
      "     |      getSaturation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBias(...)\n",
      "     |      setBias(bias) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturation(...)\n",
      "     |      setSaturation(saturation) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .   @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .   @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class TonemapMantiuk(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapMantiuk\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getSaturation(...)\n",
      "     |      getSaturation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScale(...)\n",
      "     |      getScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturation(...)\n",
      "     |      setSaturation(saturation) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScale(...)\n",
      "     |      setScale(scale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .   @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .   @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class TonemapReinhard(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapReinhard\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getColorAdaptation(...)\n",
      "     |      getColorAdaptation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getIntensity(...)\n",
      "     |      getIntensity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLightAdaptation(...)\n",
      "     |      getLightAdaptation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setColorAdaptation(...)\n",
      "     |      setColorAdaptation(color_adapt) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setIntensity(...)\n",
      "     |      setIntensity(intensity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLightAdaptation(...)\n",
      "     |      setLightAdaptation(light_adapt) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .   @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .   @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class UMat(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  handle(...)\n",
      "     |      handle(accessFlags) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isSubmatrix(...)\n",
      "     |      isSubmatrix() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  context(...)\n",
      "     |      context() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  queue(...)\n",
      "     |      queue() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |      offset\n",
      "    \n",
      "    class VariationalRefinement(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      VariationalRefinement\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calcUV(...)\n",
      "     |      calcUV(I0, I1, flow_u, flow_v) -> flow_u, flow_v\n",
      "     |      .   @brief @ref calc function overload to handle separate horizontal (u) and vertical (v) flow components\n",
      "     |      .   (to avoid extra splits/merges)\n",
      "     |  \n",
      "     |  getAlpha(...)\n",
      "     |      getAlpha() -> retval\n",
      "     |      .   @brief Weight of the smoothness term\n",
      "     |      .   @see setAlpha\n",
      "     |  \n",
      "     |  getDelta(...)\n",
      "     |      getDelta() -> retval\n",
      "     |      .   @brief Weight of the color constancy term\n",
      "     |      .   @see setDelta\n",
      "     |  \n",
      "     |  getFixedPointIterations(...)\n",
      "     |      getFixedPointIterations() -> retval\n",
      "     |      .   @brief Number of outer (fixed-point) iterations in the minimization procedure.\n",
      "     |      .   @see setFixedPointIterations\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .   @brief Weight of the gradient constancy term\n",
      "     |      .   @see setGamma\n",
      "     |  \n",
      "     |  getOmega(...)\n",
      "     |      getOmega() -> retval\n",
      "     |      .   @brief Relaxation factor in SOR\n",
      "     |      .   @see setOmega\n",
      "     |  \n",
      "     |  getSorIterations(...)\n",
      "     |      getSorIterations() -> retval\n",
      "     |      .   @brief Number of inner successive over-relaxation (SOR) iterations\n",
      "     |      .   in the minimization procedure to solve the respective linear system.\n",
      "     |      .   @see setSorIterations\n",
      "     |  \n",
      "     |  setAlpha(...)\n",
      "     |      setAlpha(val) -> None\n",
      "     |      .   @copybrief getAlpha @see getAlpha\n",
      "     |  \n",
      "     |  setDelta(...)\n",
      "     |      setDelta(val) -> None\n",
      "     |      .   @copybrief getDelta @see getDelta\n",
      "     |  \n",
      "     |  setFixedPointIterations(...)\n",
      "     |      setFixedPointIterations(val) -> None\n",
      "     |      .   @copybrief getFixedPointIterations @see getFixedPointIterations\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(val) -> None\n",
      "     |      .   @copybrief getGamma @see getGamma\n",
      "     |  \n",
      "     |  setOmega(...)\n",
      "     |      setOmega(val) -> None\n",
      "     |      .   @copybrief getOmega @see getOmega\n",
      "     |  \n",
      "     |  setSorIterations(...)\n",
      "     |      setSorIterations(val) -> None\n",
      "     |      .   @copybrief getSorIterations @see getSorIterations\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates an instance of VariationalRefinement\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .   @param I0 first 8-bit single-channel input image.\n",
      "     |      .   @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class VideoCapture(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get(propId) -> retval\n",
      "     |      .   @brief Returns the specified VideoCapture property\n",
      "     |      .   \n",
      "     |      .   @param propId Property identifier from cv::VideoCaptureProperties (eg. cv::CAP_PROP_POS_MSEC, cv::CAP_PROP_POS_FRAMES, ...)\n",
      "     |      .   or one from @ref videoio_flags_others\n",
      "     |      .   @return Value for the specified property. Value 0 is returned when querying a property that is\n",
      "     |      .   not supported by the backend used by the VideoCapture instance.\n",
      "     |      .   \n",
      "     |      .   @note Reading / writing properties involves many layers. Some unexpected result might happens\n",
      "     |      .   along this chain.\n",
      "     |      .   @code {.txt}\n",
      "     |      .   `VideoCapture -> API Backend -> Operating System -> Device Driver -> Device Hardware`\n",
      "     |      .   @endcode\n",
      "     |      .   The returned value might be different from what really used by the device or it could be encoded\n",
      "     |      .   using device dependent rules (eg. steps or percentage). Effective behaviour depends from device\n",
      "     |      .   driver and API Backend\n",
      "     |  \n",
      "     |  getBackendName(...)\n",
      "     |      getBackendName() -> retval\n",
      "     |      .   @brief Returns used backend API name\n",
      "     |      .   \n",
      "     |      .   @note Stream should be opened.\n",
      "     |  \n",
      "     |  grab(...)\n",
      "     |      grab() -> retval\n",
      "     |      .   @brief Grabs the next frame from video file or capturing device.\n",
      "     |      .   \n",
      "     |      .   @return `true` (non-zero) in the case of success.\n",
      "     |      .   \n",
      "     |      .   The method/function grabs the next frame from video file or camera and returns true (non-zero) in\n",
      "     |      .   the case of success.\n",
      "     |      .   \n",
      "     |      .   The primary use of the function is in multi-camera environments, especially when the cameras do not\n",
      "     |      .   have hardware synchronization. That is, you call VideoCapture::grab() for each camera and after that\n",
      "     |      .   call the slower method VideoCapture::retrieve() to decode and get frame from each camera. This way\n",
      "     |      .   the overhead on demosaicing or motion jpeg decompression etc. is eliminated and the retrieved frames\n",
      "     |      .   from different cameras will be closer in time.\n",
      "     |      .   \n",
      "     |      .   Also, when a connected camera is multi-head (for example, a stereo camera or a Kinect device), the\n",
      "     |      .   correct way of retrieving data from it is to call VideoCapture::grab() first and then call\n",
      "     |      .   VideoCapture::retrieve() one or more times with different values of the channel parameter.\n",
      "     |      .   \n",
      "     |      .   @ref tutorial_kinect_openni\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Returns true if video capturing has been initialized already.\n",
      "     |      .   \n",
      "     |      .   If the previous call to VideoCapture constructor or VideoCapture::open() succeeded, the method returns\n",
      "     |      .   true.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename[, apiPreference]) -> retval\n",
      "     |      .   @brief  Opens a video file or a capturing device or an IP video stream for video capturing.\n",
      "     |      .   \n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   Parameters are same as the constructor VideoCapture(const String& filename, int apiPreference = CAP_ANY)\n",
      "     |      .   @return `true` if the file has been successfully opened\n",
      "     |      .   \n",
      "     |      .   The method first calls VideoCapture::release to close the already opened file or camera.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(index[, apiPreference]) -> retval\n",
      "     |      .   @brief  Opens a camera for video capturing\n",
      "     |      .   \n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .   Parameters are same as the constructor VideoCapture(int index, int apiPreference = CAP_ANY)\n",
      "     |      .   @return `true` if the camera has been successfully opened.\n",
      "     |      .   \n",
      "     |      .   The method first calls VideoCapture::release to close the already opened file or camera.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read([, image]) -> retval, image\n",
      "     |      .   @brief Grabs, decodes and returns the next video frame.\n",
      "     |      .   \n",
      "     |      .   @param [out] image the video frame is returned here. If no frames has been grabbed the image will be empty.\n",
      "     |      .   @return `false` if no frames has been grabbed\n",
      "     |      .   \n",
      "     |      .   The method/function combines VideoCapture::grab() and VideoCapture::retrieve() in one call. This is the\n",
      "     |      .   most convenient method for reading video files or capturing data from decode and returns the just\n",
      "     |      .   grabbed frame. If no frames has been grabbed (camera has been disconnected, or there are no more\n",
      "     |      .   frames in video file), the method returns false and the function returns empty image (with %cv::Mat, test it with Mat::empty()).\n",
      "     |      .   \n",
      "     |      .   @note In @ref videoio_c \"C API\", functions cvRetrieveFrame() and cv.RetrieveFrame() return image stored inside the video\n",
      "     |      .   capturing structure. It is not allowed to modify or release the image! You can copy the frame using\n",
      "     |      .   cvCloneImage and then do whatever you want with the copy.\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes video file or capturing device.\n",
      "     |      .   \n",
      "     |      .   The method is automatically called by subsequent VideoCapture::open and by VideoCapture\n",
      "     |      .   destructor.\n",
      "     |      .   \n",
      "     |      .   The C function also deallocates memory and clears \\*capture pointer.\n",
      "     |  \n",
      "     |  retrieve(...)\n",
      "     |      retrieve([, image[, flag]]) -> retval, image\n",
      "     |      .   @brief Decodes and returns the grabbed video frame.\n",
      "     |      .   \n",
      "     |      .   @param [out] image the video frame is returned here. If no frames has been grabbed the image will be empty.\n",
      "     |      .   @param flag it could be a frame index or a driver specific flag\n",
      "     |      .   @return `false` if no frames has been grabbed\n",
      "     |      .   \n",
      "     |      .   The method decodes and returns the just grabbed frame. If no frames has been grabbed\n",
      "     |      .   (camera has been disconnected, or there are no more frames in video file), the method returns false\n",
      "     |      .   and the function returns an empty image (with %cv::Mat, test it with Mat::empty()).\n",
      "     |      .   \n",
      "     |      .   @sa read()\n",
      "     |      .   \n",
      "     |      .   @note In @ref videoio_c \"C API\", functions cvRetrieveFrame() and cv.RetrieveFrame() return image stored inside the video\n",
      "     |      .   capturing structure. It is not allowed to modify or release the image! You can copy the frame using\n",
      "     |      .   cvCloneImage and then do whatever you want with the copy.\n",
      "     |  \n",
      "     |  set(...)\n",
      "     |      set(propId, value) -> retval\n",
      "     |      .   @brief Sets a property in the VideoCapture.\n",
      "     |      .   \n",
      "     |      .   @param propId Property identifier from cv::VideoCaptureProperties (eg. cv::CAP_PROP_POS_MSEC, cv::CAP_PROP_POS_FRAMES, ...)\n",
      "     |      .   or one from @ref videoio_flags_others\n",
      "     |      .   @param value Value of the property.\n",
      "     |      .   @return `true` if the property is supported by backend used by the VideoCapture instance.\n",
      "     |      .   @note Even if it returns `true` this doesn't ensure that the property\n",
      "     |      .   value has been accepted by the capture device. See note in VideoCapture::get()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class VideoWriter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get(propId) -> retval\n",
      "     |      .   @brief Returns the specified VideoWriter property\n",
      "     |      .   \n",
      "     |      .   @param propId Property identifier from cv::VideoWriterProperties (eg. cv::VIDEOWRITER_PROP_QUALITY)\n",
      "     |      .   or one of @ref videoio_flags_others\n",
      "     |      .   \n",
      "     |      .   @return Value for the specified property. Value 0 is returned when querying a property that is\n",
      "     |      .   not supported by the backend used by the VideoWriter instance.\n",
      "     |  \n",
      "     |  getBackendName(...)\n",
      "     |      getBackendName() -> retval\n",
      "     |      .   @brief Returns used backend API name\n",
      "     |      .   \n",
      "     |      .   @note Stream should be opened.\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Returns true if video writer has been successfully initialized.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename, fourcc, fps, frameSize[, isColor]) -> retval\n",
      "     |      .   @brief Initializes or reinitializes video writer.\n",
      "     |      .   \n",
      "     |      .   The method opens video writer. Parameters are the same as in the constructor\n",
      "     |      .   VideoWriter::VideoWriter.\n",
      "     |      .   @return `true` if video writer has been successfully initialized\n",
      "     |      .   \n",
      "     |      .   The method first calls VideoWriter::release to close the already opened file.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(filename, apiPreference, fourcc, fps, frameSize[, isColor]) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes the video writer.\n",
      "     |      .   \n",
      "     |      .   The method is automatically called by subsequent VideoWriter::open and by the VideoWriter\n",
      "     |      .   destructor.\n",
      "     |  \n",
      "     |  set(...)\n",
      "     |      set(propId, value) -> retval\n",
      "     |      .   @brief Sets a property in the VideoWriter.\n",
      "     |      .   \n",
      "     |      .   @param propId Property identifier from cv::VideoWriterProperties (eg. cv::VIDEOWRITER_PROP_QUALITY)\n",
      "     |      .   or one of @ref videoio_flags_others\n",
      "     |      .   \n",
      "     |      .   @param value Value of the property.\n",
      "     |      .   @return  `true` if the property is supported by the backend used by the VideoWriter instance.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(image) -> None\n",
      "     |      .   @brief Writes the next video frame\n",
      "     |      .   \n",
      "     |      .   @param image The written frame. In general, color images are expected in BGR format.\n",
      "     |      .   \n",
      "     |      .   The function/method writes the specified image to video file. It must have the same size as has\n",
      "     |      .   been specified when opening the video writer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  fourcc(...)\n",
      "     |      fourcc(c1, c2, c3, c4) -> retval\n",
      "     |      .   @brief Concatenates 4 chars to a fourcc code\n",
      "     |      .   \n",
      "     |      .   @return a fourcc code\n",
      "     |      .   \n",
      "     |      .   This static method constructs the fourcc code of the codec to be used in the constructor\n",
      "     |      .   VideoWriter::VideoWriter or VideoWriter::open.\n",
      "    \n",
      "    class WarperCreator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_BufferPool(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAllocator(...)\n",
      "     |      getAllocator() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBuffer(...)\n",
      "     |      getBuffer(rows, cols, type) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getBuffer(size, type) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_DeviceInfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  ECCEnabled(...)\n",
      "     |      ECCEnabled() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  asyncEngineCount(...)\n",
      "     |      asyncEngineCount() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  canMapHostMemory(...)\n",
      "     |      canMapHostMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clockRate(...)\n",
      "     |      clockRate() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  computeMode(...)\n",
      "     |      computeMode() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  concurrentKernels(...)\n",
      "     |      concurrentKernels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceID(...)\n",
      "     |      deviceID() -> retval\n",
      "     |      .   @brief Returns system index of the CUDA device starting with 0.\n",
      "     |  \n",
      "     |  freeMemory(...)\n",
      "     |      freeMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  integrated(...)\n",
      "     |      integrated() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isCompatible(...)\n",
      "     |      isCompatible() -> retval\n",
      "     |      .   @brief Checks the CUDA module and device compatibility.\n",
      "     |      .   \n",
      "     |      .   This function returns true if the CUDA module can be run on the specified device. Otherwise, it\n",
      "     |      .   returns false .\n",
      "     |  \n",
      "     |  kernelExecTimeoutEnabled(...)\n",
      "     |      kernelExecTimeoutEnabled() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  l2CacheSize(...)\n",
      "     |      l2CacheSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  majorVersion(...)\n",
      "     |      majorVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxGridSize(...)\n",
      "     |      maxGridSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface1D(...)\n",
      "     |      maxSurface1D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface1DLayered(...)\n",
      "     |      maxSurface1DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface2D(...)\n",
      "     |      maxSurface2D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface2DLayered(...)\n",
      "     |      maxSurface2DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface3D(...)\n",
      "     |      maxSurface3D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurfaceCubemap(...)\n",
      "     |      maxSurfaceCubemap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurfaceCubemapLayered(...)\n",
      "     |      maxSurfaceCubemapLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1D(...)\n",
      "     |      maxTexture1D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DLayered(...)\n",
      "     |      maxTexture1DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DLinear(...)\n",
      "     |      maxTexture1DLinear() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DMipmap(...)\n",
      "     |      maxTexture1DMipmap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2D(...)\n",
      "     |      maxTexture2D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DGather(...)\n",
      "     |      maxTexture2DGather() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DLayered(...)\n",
      "     |      maxTexture2DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DLinear(...)\n",
      "     |      maxTexture2DLinear() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DMipmap(...)\n",
      "     |      maxTexture2DMipmap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture3D(...)\n",
      "     |      maxTexture3D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTextureCubemap(...)\n",
      "     |      maxTextureCubemap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTextureCubemapLayered(...)\n",
      "     |      maxTextureCubemapLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsDim(...)\n",
      "     |      maxThreadsDim() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsPerBlock(...)\n",
      "     |      maxThreadsPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsPerMultiProcessor(...)\n",
      "     |      maxThreadsPerMultiProcessor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memPitch(...)\n",
      "     |      memPitch() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memoryBusWidth(...)\n",
      "     |      memoryBusWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memoryClockRate(...)\n",
      "     |      memoryClockRate() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  minorVersion(...)\n",
      "     |      minorVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  multiProcessorCount(...)\n",
      "     |      multiProcessorCount() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciBusID(...)\n",
      "     |      pciBusID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciDeviceID(...)\n",
      "     |      pciDeviceID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciDomainID(...)\n",
      "     |      pciDomainID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  queryMemory(...)\n",
      "     |      queryMemory(totalMemory, freeMemory) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  regsPerBlock(...)\n",
      "     |      regsPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  sharedMemPerBlock(...)\n",
      "     |      sharedMemPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  surfaceAlignment(...)\n",
      "     |      surfaceAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  tccDriver(...)\n",
      "     |      tccDriver() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  textureAlignment(...)\n",
      "     |      textureAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  texturePitchAlignment(...)\n",
      "     |      texturePitchAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalConstMem(...)\n",
      "     |      totalConstMem() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalGlobalMem(...)\n",
      "     |      totalGlobalMem() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalMemory(...)\n",
      "     |      totalMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  unifiedAddressing(...)\n",
      "     |      unifiedAddressing() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  warpSize(...)\n",
      "     |      warpSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_Event(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  queryIfComplete(...)\n",
      "     |      queryIfComplete() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  record(...)\n",
      "     |      record([, stream]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  waitForCompletion(...)\n",
      "     |      waitForCompletion() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  elapsedTime(...)\n",
      "     |      elapsedTime(start, end) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class cuda_GpuMat(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  adjustROI(...)\n",
      "     |      adjustROI(dtop, dbottom, dleft, dright) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  assignTo(...)\n",
      "     |      assignTo(m[, type]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  channels(...)\n",
      "     |      channels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  col(...)\n",
      "     |      col(x) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  colRange(...)\n",
      "     |      colRange(startcol, endcol) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      colRange(r) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  convertTo(...)\n",
      "     |      convertTo(rtype[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha[, dst[, beta]]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha, stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha, beta, stream[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  copyTo(...)\n",
      "     |      copyTo([, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(mask[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(mask, stream[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(rows, cols, type) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(size, type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  depth(...)\n",
      "     |      depth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  download(...)\n",
      "     |      download([, dst]) -> dst\n",
      "     |      .   @brief Performs data download from GpuMat (Blocking call)\n",
      "     |      .   \n",
      "     |      .   This function copies data from device memory to host memory. As being a blocking call, it is\n",
      "     |      .   guaranteed that the copy operation is finished when this function returns.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      download(stream[, dst]) -> dst\n",
      "     |      .   @brief Performs data download from GpuMat (Non-Blocking call)\n",
      "     |      .   \n",
      "     |      .   This function copies data from device memory to host memory. As being a non-blocking call, this\n",
      "     |      .   function may return even if the copy operation is not finished.\n",
      "     |      .   \n",
      "     |      .   The copy operation may be overlapped with operations in other non-default streams if \\p stream is\n",
      "     |      .   not the default stream and \\p dst is HostMem allocated with HostMem::PAGE_LOCKED option.\n",
      "     |  \n",
      "     |  elemSize(...)\n",
      "     |      elemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize1(...)\n",
      "     |      elemSize1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  locateROI(...)\n",
      "     |      locateROI(wholeSize, ofs) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(cn[, rows]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  row(...)\n",
      "     |      row(y) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  rowRange(...)\n",
      "     |      rowRange(startrow, endrow) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      rowRange(r) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTo(...)\n",
      "     |      setTo(s) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, stream) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, mask) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, mask, stream) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  step1(...)\n",
      "     |      step1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  swap(...)\n",
      "     |      swap(mat) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  updateContinuityFlag(...)\n",
      "     |      updateContinuityFlag() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  upload(...)\n",
      "     |      upload(arr) -> None\n",
      "     |      .   @brief Performs data upload to GpuMat (Blocking call)\n",
      "     |      .   \n",
      "     |      .   This function copies data from host memory to device memory. As being a blocking call, it is\n",
      "     |      .   guaranteed that the copy operation is finished when this function returns.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      upload(arr, stream) -> None\n",
      "     |      .   @brief Performs data upload to GpuMat (Non-Blocking call)\n",
      "     |      .   \n",
      "     |      .   This function copies data from host memory to device memory. As being a non-blocking call, this\n",
      "     |      .   function may return even if the copy operation is not finished.\n",
      "     |      .   \n",
      "     |      .   The copy operation may be overlapped with operations in other non-default streams if \\p stream is\n",
      "     |      .   not the default stream and \\p dst is HostMem allocated with HostMem::PAGE_LOCKED option.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  defaultAllocator(...)\n",
      "     |      defaultAllocator() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDefaultAllocator(...)\n",
      "     |      setDefaultAllocator(allocator) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  step\n",
      "     |      step\n",
      "    \n",
      "    class cuda_GpuMat_Allocator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_HostMem(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  channels(...)\n",
      "     |      channels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(rows, cols, type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  createMatHeader(...)\n",
      "     |      createMatHeader() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  depth(...)\n",
      "     |      depth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize(...)\n",
      "     |      elemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize1(...)\n",
      "     |      elemSize1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .   @brief Maps CPU memory to GPU address space and creates the cuda::GpuMat header without reference counting\n",
      "     |      .   for it.\n",
      "     |      .   \n",
      "     |      .   This can be done only if memory was allocated with the SHARED flag and if it is supported by the\n",
      "     |      .   hardware. Laptops often share video and CPU memory, so address spaces can be mapped, which\n",
      "     |      .   eliminates an extra copy.\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(cn[, rows]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  step1(...)\n",
      "     |      step1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  swap(...)\n",
      "     |      swap(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  step\n",
      "     |      step\n",
      "    \n",
      "    class cuda_Stream(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  queryIfComplete(...)\n",
      "     |      queryIfComplete() -> retval\n",
      "     |      .   @brief Returns true if the current stream queue is finished. Otherwise, it returns false.\n",
      "     |  \n",
      "     |  waitEvent(...)\n",
      "     |      waitEvent(event) -> None\n",
      "     |      .   @brief Makes a compute stream wait on an event.\n",
      "     |  \n",
      "     |  waitForCompletion(...)\n",
      "     |      waitForCompletion() -> None\n",
      "     |      .   @brief Blocks the current CPU thread until all operations in the stream are complete.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  Null(...)\n",
      "     |      Null() -> retval\n",
      "     |      .   @brief Adds a callback to be called on the host after all currently enqueued items in the stream have\n",
      "     |      .   completed.\n",
      "     |      .   \n",
      "     |      .   @note Callbacks must not make any CUDA API calls. Callbacks must not perform any synchronization\n",
      "     |      .   that may depend on outstanding device work or other callbacks that are not mandated to run earlier.\n",
      "     |      .   Callbacks without a mandated order (in independent streams) execute in undefined order and may be\n",
      "     |      .   serialized.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_TargetArchs(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  has(...)\n",
      "     |      has(major, minor) -> retval\n",
      "     |      .   @brief There is a set of methods to check whether the module contains intermediate (PTX) or binary CUDA\n",
      "     |      .   code for the given architecture(s):\n",
      "     |      .   \n",
      "     |      .   @param major Major compute capability version.\n",
      "     |      .   @param minor Minor compute capability version.\n",
      "     |  \n",
      "     |  hasBin(...)\n",
      "     |      hasBin(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreater(...)\n",
      "     |      hasEqualOrGreater(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreaterBin(...)\n",
      "     |      hasEqualOrGreaterBin(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreaterPtx(...)\n",
      "     |      hasEqualOrGreaterPtx(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrLessPtx(...)\n",
      "     |      hasEqualOrLessPtx(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasPtx(...)\n",
      "     |      hasPtx(major, minor) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_AffineBasedEstimator(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_AffineBasedEstimator\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_AffineBestOf2NearestMatcher(detail_BestOf2NearestMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_AffineBestOf2NearestMatcher\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .   @param features1 First image features\n",
      "     |      .   @param features2 Second image features\n",
      "     |      .   @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .   @param features Features of the source images\n",
      "     |      .   @param pairwise_matches Found pairwise matches\n",
      "     |      .   @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .   @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_BestOf2NearestMatcher(detail_FeaturesMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .   @param features1 First image features\n",
      "     |      .   @param features2 Second image features\n",
      "     |      .   @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .   @param features Features of the source images\n",
      "     |      .   @param pairwise_matches Found pairwise matches\n",
      "     |      .   @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .   @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_BestOf2NearestRangeMatcher(detail_BestOf2NearestMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BestOf2NearestRangeMatcher\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .   @param features1 First image features\n",
      "     |      .   @param features2 Second image features\n",
      "     |      .   @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .   @param features Features of the source images\n",
      "     |      .   @param pairwise_matches Found pairwise matches\n",
      "     |      .   @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .   @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_Blender(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .   @brief Blends and returns the final pano.\n",
      "     |      .   \n",
      "     |      .   @param dst Final pano\n",
      "     |      .   @param dst_mask Final pano mask\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .   @brief Processes the image.\n",
      "     |      .   \n",
      "     |      .   @param img Source image\n",
      "     |      .   @param mask Source image mask\n",
      "     |      .   @param tl Source image top-left corners\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(corners, sizes) -> None\n",
      "     |      .   @brief Prepares the blender for blending.\n",
      "     |      .   \n",
      "     |      .   @param corners Source images top-left corners\n",
      "     |      .   @param sizes Source image sizes\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksChannelsCompensator(detail_BlocksCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksChannelsCompensator\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BlocksCompensator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksGainCompensator(detail_BlocksCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksGainCompensator\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BlocksCompensator:\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BundleAdjusterAffine(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterAffine\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterAffinePartial(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterAffinePartial\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterBase(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterRay(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterRay\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterReproj(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterReproj\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_CameraParams(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  K(...)\n",
      "     |      K() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  R\n",
      "     |      R\n",
      "     |  \n",
      "     |  aspect\n",
      "     |      aspect\n",
      "     |  \n",
      "     |  focal\n",
      "     |      focal\n",
      "     |  \n",
      "     |  ppx\n",
      "     |      ppx\n",
      "     |  \n",
      "     |  ppy\n",
      "     |      ppy\n",
      "     |  \n",
      "     |  t\n",
      "     |      t\n",
      "    \n",
      "    class detail_ChannelsCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_ChannelsCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_DpSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_DpSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  setCostFunction(...)\n",
      "     |      setCostFunction(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .   @brief Estimates seams.\n",
      "     |      .   \n",
      "     |      .   @param src Source images\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param masks Source image masks to update\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_Estimator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_ExposureCompensator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .   @brief Compensate exposure in the specified image.\n",
      "     |      .   \n",
      "     |      .   @param index Image index\n",
      "     |      .   @param corner Image top-left corner\n",
      "     |      .   @param image Image to process\n",
      "     |      .   @param mask Image mask\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, arg1]) -> arg1\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_FeatherBlender(detail_Blender)\n",
      "     |  Method resolution order:\n",
      "     |      detail_FeatherBlender\n",
      "     |      detail_Blender\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .\n",
      "     |  \n",
      "     |  createWeightMaps(...)\n",
      "     |      createWeightMaps(masks, corners, weight_maps) -> retval, weight_maps\n",
      "     |      .\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSharpness(...)\n",
      "     |      setSharpness(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  sharpness(...)\n",
      "     |      sharpness() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Blender:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_FeaturesMatcher(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .   @param features1 First image features\n",
      "     |      .   @param features2 Second image features\n",
      "     |      .   @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .   @param features Features of the source images\n",
      "     |      .   @param pairwise_matches Found pairwise matches\n",
      "     |      .   @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .   @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Frees unused memory allocated before if there is any.\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_GainCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_GainCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_GraphCutSeamFinder(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_HomographyBasedEstimator(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_HomographyBasedEstimator\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_ImageFeatures(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getKeypoints(...)\n",
      "     |      getKeypoints() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  descriptors\n",
      "     |      descriptors\n",
      "     |  \n",
      "     |  img_idx\n",
      "     |      img_idx\n",
      "     |  \n",
      "     |  img_size\n",
      "     |      img_size\n",
      "    \n",
      "    class detail_MatchesInfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getInliers(...)\n",
      "     |      getInliers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatches(...)\n",
      "     |      getMatches() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  H\n",
      "     |      H\n",
      "     |  \n",
      "     |  confidence\n",
      "     |      confidence\n",
      "     |  \n",
      "     |  dst_img_idx\n",
      "     |      dst_img_idx\n",
      "     |  \n",
      "     |  num_inliers\n",
      "     |      num_inliers\n",
      "     |  \n",
      "     |  src_img_idx\n",
      "     |      src_img_idx\n",
      "    \n",
      "    class detail_MultiBandBlender(detail_Blender)\n",
      "     |  Method resolution order:\n",
      "     |      detail_MultiBandBlender\n",
      "     |      detail_Blender\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  numBands(...)\n",
      "     |      numBands() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumBands(...)\n",
      "     |      setNumBands(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Blender:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_NoBundleAdjuster(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoBundleAdjuster\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .   @param features Features of images\n",
      "     |      .   @param pairwise_matches Pairwise matches of images\n",
      "     |      .   @param cameras Estimated camera parameters\n",
      "     |      .   @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_NoExposureCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoExposureCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(arg1, arg2, arg3, arg4) -> arg3\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param images Source images\n",
      "     |      .   @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .   to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_NoSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(arg1, arg2, arg3) -> arg3\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_PairwiseSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_PairwiseSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_ProjectorBase(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_SeamFinder(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .   @brief Estimates seams.\n",
      "     |      .   \n",
      "     |      .   @param src Source images\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .   @param masks Source image masks to update\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_SphericalProjector(detail_ProjectorBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_SphericalProjector\n",
      "     |      detail_ProjectorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  mapBackward(...)\n",
      "     |      mapBackward(u, v, x, y) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  mapForward(...)\n",
      "     |      mapForward(x, y, u, v) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_Timelapser(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDst(...)\n",
      "     |      getDst() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  initialize(...)\n",
      "     |      initialize(corners, sizes) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_TimelapserCrop(detail_Timelapser)\n",
      "     |  Method resolution order:\n",
      "     |      detail_TimelapserCrop\n",
      "     |      detail_Timelapser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Timelapser:\n",
      "     |  \n",
      "     |  getDst(...)\n",
      "     |      getDst() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  initialize(...)\n",
      "     |      initialize(corners, sizes) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Timelapser:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_VoronoiSeamFinder(detail_PairwiseSeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_VoronoiSeamFinder\n",
      "     |      detail_PairwiseSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class dnn_DictValue(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getIntValue(...)\n",
      "     |      getIntValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRealValue(...)\n",
      "     |      getRealValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getStringValue(...)\n",
      "     |      getStringValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isInt(...)\n",
      "     |      isInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isReal(...)\n",
      "     |      isReal() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isString(...)\n",
      "     |      isString() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class dnn_Layer(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_Layer\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  finalize(...)\n",
      "     |      finalize(inputs[, outputs]) -> outputs\n",
      "     |      .   @brief Computes and sets internal parameters according to inputs, outputs and blobs.\n",
      "     |      .   *  @param[in]  inputs  vector of already allocated input blobs\n",
      "     |      .   *  @param[out] outputs vector of already allocated output blobs\n",
      "     |      .   *\n",
      "     |      .   * If this method is called after network has allocated all memory for input and output blobs\n",
      "     |      .   * and before inferencing.\n",
      "     |  \n",
      "     |  outputNameToIndex(...)\n",
      "     |      outputNameToIndex(outputName) -> retval\n",
      "     |      .   @brief Returns index of output blob in output array.\n",
      "     |      .   *  @see inputNameToIndex()\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(inputs, internals[, outputs]) -> outputs, internals\n",
      "     |      .   @brief Allocates layer and computes output.\n",
      "     |      .   *  @deprecated This method will be removed in the future release.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  blobs\n",
      "     |      blobs\n",
      "     |  \n",
      "     |  name\n",
      "     |      name\n",
      "     |  \n",
      "     |  preferableTarget\n",
      "     |      preferableTarget\n",
      "     |  \n",
      "     |  type\n",
      "     |      type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class dnn_Net(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .   *  @param outPin descriptor of the first layer output.\n",
      "     |      .   *  @param inpPin descriptor of the second layer input.\n",
      "     |      .   *\n",
      "     |      .   * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .   * - the first part of the template <DFN>layer_name</DFN> is sting name of the added layer.\n",
      "     |      .   *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .   * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .   *   is either number of the layer input, either label one.\n",
      "     |      .   *   If this part is omitted then the first layer input will be used.\n",
      "     |      .   *\n",
      "     |      .   *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .   * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .   *  @param outputName name for layer which output is needed to get\n",
      "     |      .   *  @return blob for first output of specified layer.\n",
      "     |      .   *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .   *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .   *  @param outputName name for layer which output is needed to get\n",
      "     |      .   *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .   *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .   *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .   *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .   *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .   * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .   * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .   *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .   * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .   * @param layerType type.\n",
      "     |      .   * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .   *  preliminary inferencing isn't necessary.\n",
      "     |      .   *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .   *  @param layersIds output parameter for layer IDs.\n",
      "     |      .   *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .   * order is the same as in layersIds\n",
      "     |      .   *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .   * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .   *  @param layer name or id of the layer.\n",
      "     |      .   *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .   *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .   * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .   * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .   * @param timings vector for tick timings for all layers.\n",
      "     |      .   * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .   * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .   * @see setPreferableBackend\n",
      "     |      .   *\n",
      "     |      .   * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .   * specific target. For layers that not represented in scheduling file\n",
      "     |      .   * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .   *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .   *  @param name        A name of input layer.\n",
      "     |      .   *  @param scalefactor An optional normalization scale.\n",
      "     |      .   *  @param mean        An optional mean subtraction values.\n",
      "     |      .   *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .   *\n",
      "     |      .   *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .   *  as:\n",
      "     |      .   * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .   *\n",
      "     |      .   * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .   * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .   * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .   * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .   *  @param layer name or id of the layer.\n",
      "     |      .   *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .   *  @param blob the new value.\n",
      "     |      .   *  @see Layer::blobs\n",
      "     |      .   *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .   *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .   * @param[in] backendId backend identifier.\n",
      "     |      .   * @see Backend\n",
      "     |      .   *\n",
      "     |      .   * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .   * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .   * @param[in] targetId target identifier.\n",
      "     |      .   * @see Target\n",
      "     |      .   *\n",
      "     |      .   * List of supported combinations backend / target:\n",
      "     |      .   * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |\n",
      "     |      .   * |------------------------|--------------------|------------------------------|--------------------|\n",
      "     |      .   * | DNN_TARGET_CPU         |                  + |                            + |                  + |\n",
      "     |      .   * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |\n",
      "     |      .   * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |\n",
      "     |      .   * | DNN_TARGET_MYRIAD      |                    |                            + |                    |\n",
      "     |      .   * | DNN_TARGET_FPGA        |                    |                            + |                    |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation.\n",
      "     |      .   *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .   *  @param[in] bin Binary file with trained weights.\n",
      "     |      .   *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .   *  backend.\n",
      "    \n",
      "    class error(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  code = None\n",
      "     |  \n",
      "     |  err = None\n",
      "     |  \n",
      "     |  file = None\n",
      "     |  \n",
      "     |  func = None\n",
      "     |  \n",
      "     |  line = None\n",
      "     |  \n",
      "     |  msg = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class flann_Index(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  build(...)\n",
      "     |      build(features, params[, distType]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getAlgorithm(...)\n",
      "     |      getAlgorithm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDistance(...)\n",
      "     |      getDistance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  knnSearch(...)\n",
      "     |      knnSearch(query, knn[, indices[, dists[, params]]]) -> indices, dists\n",
      "     |      .\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(features, filename) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  radiusSearch(...)\n",
      "     |      radiusSearch(query, radius, maxResults[, indices[, dists[, params]]]) -> retval, indices, dists\n",
      "     |      .\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ml_ANN_MLP(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_ANN_MLP\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAnnealCoolingRatio(...)\n",
      "     |      getAnnealCoolingRatio() -> retval\n",
      "     |      .   @see setAnnealCoolingRatio\n",
      "     |  \n",
      "     |  getAnnealFinalT(...)\n",
      "     |      getAnnealFinalT() -> retval\n",
      "     |      .   @see setAnnealFinalT\n",
      "     |  \n",
      "     |  getAnnealInitialT(...)\n",
      "     |      getAnnealInitialT() -> retval\n",
      "     |      .   @see setAnnealInitialT\n",
      "     |  \n",
      "     |  getAnnealItePerStep(...)\n",
      "     |      getAnnealItePerStep() -> retval\n",
      "     |      .   @see setAnnealItePerStep\n",
      "     |  \n",
      "     |  getBackpropMomentumScale(...)\n",
      "     |      getBackpropMomentumScale() -> retval\n",
      "     |      .   @see setBackpropMomentumScale\n",
      "     |  \n",
      "     |  getBackpropWeightScale(...)\n",
      "     |      getBackpropWeightScale() -> retval\n",
      "     |      .   @see setBackpropWeightScale\n",
      "     |  \n",
      "     |  getLayerSizes(...)\n",
      "     |      getLayerSizes() -> retval\n",
      "     |      .   Integer vector specifying the number of neurons in each layer including the input and output layers.\n",
      "     |      .   The very first element specifies the number of elements in the input layer.\n",
      "     |      .   The last element - number of elements in the output layer.\n",
      "     |      .   @sa setLayerSizes\n",
      "     |  \n",
      "     |  getRpropDW0(...)\n",
      "     |      getRpropDW0() -> retval\n",
      "     |      .   @see setRpropDW0\n",
      "     |  \n",
      "     |  getRpropDWMax(...)\n",
      "     |      getRpropDWMax() -> retval\n",
      "     |      .   @see setRpropDWMax\n",
      "     |  \n",
      "     |  getRpropDWMin(...)\n",
      "     |      getRpropDWMin() -> retval\n",
      "     |      .   @see setRpropDWMin\n",
      "     |  \n",
      "     |  getRpropDWMinus(...)\n",
      "     |      getRpropDWMinus() -> retval\n",
      "     |      .   @see setRpropDWMinus\n",
      "     |  \n",
      "     |  getRpropDWPlus(...)\n",
      "     |      getRpropDWPlus() -> retval\n",
      "     |      .   @see setRpropDWPlus\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getTrainMethod(...)\n",
      "     |      getTrainMethod() -> retval\n",
      "     |      .   Returns current training method\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights(layerIdx) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setActivationFunction(...)\n",
      "     |      setActivationFunction(type[, param1[, param2]]) -> None\n",
      "     |      .   Initialize the activation function for each neuron.\n",
      "     |      .   Currently the default and the only fully supported activation function is ANN_MLP::SIGMOID_SYM.\n",
      "     |      .   @param type The type of activation function. See ANN_MLP::ActivationFunctions.\n",
      "     |      .   @param param1 The first parameter of the activation function, \\f$\\alpha\\f$. Default value is 0.\n",
      "     |      .   @param param2 The second parameter of the activation function, \\f$\\beta\\f$. Default value is 0.\n",
      "     |  \n",
      "     |  setAnnealCoolingRatio(...)\n",
      "     |      setAnnealCoolingRatio(val) -> None\n",
      "     |      .   @copybrief getAnnealCoolingRatio @see getAnnealCoolingRatio\n",
      "     |  \n",
      "     |  setAnnealFinalT(...)\n",
      "     |      setAnnealFinalT(val) -> None\n",
      "     |      .   @copybrief getAnnealFinalT @see getAnnealFinalT\n",
      "     |  \n",
      "     |  setAnnealInitialT(...)\n",
      "     |      setAnnealInitialT(val) -> None\n",
      "     |      .   @copybrief getAnnealInitialT @see getAnnealInitialT\n",
      "     |  \n",
      "     |  setAnnealItePerStep(...)\n",
      "     |      setAnnealItePerStep(val) -> None\n",
      "     |      .   @copybrief getAnnealItePerStep @see getAnnealItePerStep\n",
      "     |  \n",
      "     |  setBackpropMomentumScale(...)\n",
      "     |      setBackpropMomentumScale(val) -> None\n",
      "     |      .   @copybrief getBackpropMomentumScale @see getBackpropMomentumScale\n",
      "     |  \n",
      "     |  setBackpropWeightScale(...)\n",
      "     |      setBackpropWeightScale(val) -> None\n",
      "     |      .   @copybrief getBackpropWeightScale @see getBackpropWeightScale\n",
      "     |  \n",
      "     |  setLayerSizes(...)\n",
      "     |      setLayerSizes(_layer_sizes) -> None\n",
      "     |      .   Integer vector specifying the number of neurons in each layer including the input and output layers.\n",
      "     |      .   The very first element specifies the number of elements in the input layer.\n",
      "     |      .   The last element - number of elements in the output layer. Default value is empty Mat.\n",
      "     |      .   @sa getLayerSizes\n",
      "     |  \n",
      "     |  setRpropDW0(...)\n",
      "     |      setRpropDW0(val) -> None\n",
      "     |      .   @copybrief getRpropDW0 @see getRpropDW0\n",
      "     |  \n",
      "     |  setRpropDWMax(...)\n",
      "     |      setRpropDWMax(val) -> None\n",
      "     |      .   @copybrief getRpropDWMax @see getRpropDWMax\n",
      "     |  \n",
      "     |  setRpropDWMin(...)\n",
      "     |      setRpropDWMin(val) -> None\n",
      "     |      .   @copybrief getRpropDWMin @see getRpropDWMin\n",
      "     |  \n",
      "     |  setRpropDWMinus(...)\n",
      "     |      setRpropDWMinus(val) -> None\n",
      "     |      .   @copybrief getRpropDWMinus @see getRpropDWMinus\n",
      "     |  \n",
      "     |  setRpropDWPlus(...)\n",
      "     |      setRpropDWPlus(val) -> None\n",
      "     |      .   @copybrief getRpropDWPlus @see getRpropDWPlus\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setTrainMethod(...)\n",
      "     |      setTrainMethod(method[, param1[, param2]]) -> None\n",
      "     |      .   Sets training method and common parameters.\n",
      "     |      .   @param method Default value is ANN_MLP::RPROP. See ANN_MLP::TrainingMethods.\n",
      "     |      .   @param param1 passed to setRpropDW0 for ANN_MLP::RPROP and to setBackpropWeightScale for ANN_MLP::BACKPROP and to initialT for ANN_MLP::ANNEAL.\n",
      "     |      .   @param param2 passed to setRpropDWMin for ANN_MLP::RPROP and to setBackpropMomentumScale for ANN_MLP::BACKPROP and to finalT for ANN_MLP::ANNEAL.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model\n",
      "     |      .   \n",
      "     |      .   Use StatModel::train to train the model, Algorithm::load\\<ANN_MLP\\>(filename) to load the pre-trained model.\n",
      "     |      .   Note that the train method has optional flags: ANN_MLP::TrainFlags.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath) -> retval\n",
      "     |      .   @brief Loads and creates a serialized ANN from a file\n",
      "     |      .   *\n",
      "     |      .   * Use ANN::save to serialize and store an ANN to disk.\n",
      "     |      .   * Load the ANN from this file again, by calling this function with the path to the file.\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized ANN\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_Boost(ml_DTrees)\n",
      "     |  Method resolution order:\n",
      "     |      ml_Boost\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBoostType(...)\n",
      "     |      getBoostType() -> retval\n",
      "     |      .   @see setBoostType\n",
      "     |  \n",
      "     |  getWeakCount(...)\n",
      "     |      getWeakCount() -> retval\n",
      "     |      .   @see setWeakCount\n",
      "     |  \n",
      "     |  getWeightTrimRate(...)\n",
      "     |      getWeightTrimRate() -> retval\n",
      "     |      .   @see setWeightTrimRate\n",
      "     |  \n",
      "     |  setBoostType(...)\n",
      "     |      setBoostType(val) -> None\n",
      "     |      .   @copybrief getBoostType @see getBoostType\n",
      "     |  \n",
      "     |  setWeakCount(...)\n",
      "     |      setWeakCount(val) -> None\n",
      "     |      .   @copybrief getWeakCount @see getWeakCount\n",
      "     |  \n",
      "     |  setWeightTrimRate(...)\n",
      "     |      setWeightTrimRate(val) -> None\n",
      "     |      .   @copybrief getWeightTrimRate @see getWeightTrimRate\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates the empty model.\n",
      "     |      .   Use StatModel::train to train the model, Algorithm::load\\<Boost\\>(filename) to load the pre-trained model.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized Boost from a file\n",
      "     |      .   *\n",
      "     |      .   * Use Boost::save to serialize and store an RTree to disk.\n",
      "     |      .   * Load the Boost from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized Boost\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_DTrees:\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_DTrees(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates the empty model\n",
      "     |      .   \n",
      "     |      .   The static method creates empty decision tree with the specified parameters. It should be then\n",
      "     |      .   trained using train method (see StatModel::train). Alternatively, you can load the model from\n",
      "     |      .   file using Algorithm::load\\<DTrees\\>(filename).\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized DTrees from a file\n",
      "     |      .   *\n",
      "     |      .   * Use DTree::save to serialize and store an DTree to disk.\n",
      "     |      .   * Load the DTree from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized DTree\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_EM(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_EM\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getClustersNumber(...)\n",
      "     |      getClustersNumber() -> retval\n",
      "     |      .   @see setClustersNumber\n",
      "     |  \n",
      "     |  getCovarianceMatrixType(...)\n",
      "     |      getCovarianceMatrixType() -> retval\n",
      "     |      .   @see setCovarianceMatrixType\n",
      "     |  \n",
      "     |  getCovs(...)\n",
      "     |      getCovs([, covs]) -> covs\n",
      "     |      .   @brief Returns covariation matrices\n",
      "     |      .   \n",
      "     |      .   Returns vector of covariation matrices. Number of matrices is the number of gaussian mixtures,\n",
      "     |      .   each matrix is a square floating-point matrix NxN, where N is the space dimensionality.\n",
      "     |  \n",
      "     |  getMeans(...)\n",
      "     |      getMeans() -> retval\n",
      "     |      .   @brief Returns the cluster centers (means of the Gaussian mixture)\n",
      "     |      .   \n",
      "     |      .   Returns matrix with the number of rows equal to the number of mixtures and number of columns\n",
      "     |      .   equal to the space dimensionality.\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights() -> retval\n",
      "     |      .   @brief Returns weights of the mixtures\n",
      "     |      .   \n",
      "     |      .   Returns vector with the number of elements equal to the number of mixtures.\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Returns posterior probabilities for the provided samples\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output \\f$ nSamples \\times nClusters\\f$ matrix of results. It contains\n",
      "     |      .   posterior probabilities for each sample from the input\n",
      "     |      .   @param flags This parameter will be ignored\n",
      "     |  \n",
      "     |  predict2(...)\n",
      "     |      predict2(sample[, probs]) -> retval, probs\n",
      "     |      .   @brief Returns a likelihood logarithm value and an index of the most probable mixture component\n",
      "     |      .   for the given sample.\n",
      "     |      .   \n",
      "     |      .   @param sample A sample for classification. It should be a one-channel matrix of\n",
      "     |      .   \\f$1 \\times dims\\f$ or \\f$dims \\times 1\\f$ size.\n",
      "     |      .   @param probs Optional output matrix that contains posterior probabilities of each component\n",
      "     |      .   given the sample. It has \\f$1 \\times nclusters\\f$ size and CV_64FC1 type.\n",
      "     |      .   \n",
      "     |      .   The method returns a two-element double vector. Zero element is a likelihood logarithm value for\n",
      "     |      .   the sample. First element is an index of the most probable mixture component for the given\n",
      "     |      .   sample.\n",
      "     |  \n",
      "     |  setClustersNumber(...)\n",
      "     |      setClustersNumber(val) -> None\n",
      "     |      .   @copybrief getClustersNumber @see getClustersNumber\n",
      "     |  \n",
      "     |  setCovarianceMatrixType(...)\n",
      "     |      setCovarianceMatrixType(val) -> None\n",
      "     |      .   @copybrief getCovarianceMatrixType @see getCovarianceMatrixType\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  trainE(...)\n",
      "     |      trainE(samples, means0[, covs0[, weights0[, logLikelihoods[, labels[, probs]]]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .   This variation starts with Expectation step. You need to provide initial means \\f$a_k\\f$ of\n",
      "     |      .   mixture components. Optionally you can pass initial weights \\f$\\pi_k\\f$ and covariance matrices\n",
      "     |      .   \\f$S_k\\f$ of mixture components.\n",
      "     |      .   \n",
      "     |      .   @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .   one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .   it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .   @param means0 Initial means \\f$a_k\\f$ of mixture components. It is a one-channel matrix of\n",
      "     |      .   \\f$nclusters \\times dims\\f$ size. If the matrix does not have CV_64F type it will be\n",
      "     |      .   converted to the inner matrix of such type for the further computing.\n",
      "     |      .   @param covs0 The vector of initial covariance matrices \\f$S_k\\f$ of mixture components. Each of\n",
      "     |      .   covariance matrices is a one-channel matrix of \\f$dims \\times dims\\f$ size. If the matrices\n",
      "     |      .   do not have CV_64F type they will be converted to the inner matrices of such type for the\n",
      "     |      .   further computing.\n",
      "     |      .   @param weights0 Initial weights \\f$\\pi_k\\f$ of mixture components. It should be a one-channel\n",
      "     |      .   floating-point matrix with \\f$1 \\times nclusters\\f$ or \\f$nclusters \\times 1\\f$ size.\n",
      "     |      .   @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .   each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .   @param labels The optional output \"class label\" for each sample:\n",
      "     |      .   \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .   mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .   @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .   mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .   CV_64FC1 type.\n",
      "     |  \n",
      "     |  trainEM(...)\n",
      "     |      trainEM(samples[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .   This variation starts with Expectation step. Initial values of the model parameters will be\n",
      "     |      .   estimated by the k-means algorithm.\n",
      "     |      .   \n",
      "     |      .   Unlike many of the ML models, %EM is an unsupervised learning algorithm and it does not take\n",
      "     |      .   responses (class labels or function values) as input. Instead, it computes the *Maximum\n",
      "     |      .   Likelihood Estimate* of the Gaussian mixture parameters from an input sample set, stores all the\n",
      "     |      .   parameters inside the structure: \\f$p_{i,k}\\f$ in probs, \\f$a_k\\f$ in means , \\f$S_k\\f$ in\n",
      "     |      .   covs[k], \\f$\\pi_k\\f$ in weights , and optionally computes the output \"class label\" for each\n",
      "     |      .   sample: \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most\n",
      "     |      .   probable mixture component for each sample).\n",
      "     |      .   \n",
      "     |      .   The trained model can be used further for prediction, just like any other classifier. The\n",
      "     |      .   trained model is similar to the NormalBayesClassifier.\n",
      "     |      .   \n",
      "     |      .   @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .   one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .   it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .   @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .   each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .   @param labels The optional output \"class label\" for each sample:\n",
      "     |      .   \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .   mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .   @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .   mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .   CV_64FC1 type.\n",
      "     |  \n",
      "     |  trainM(...)\n",
      "     |      trainM(samples, probs0[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .   This variation starts with Maximization step. You need to provide initial probabilities\n",
      "     |      .   \\f$p_{i,k}\\f$ to use this option.\n",
      "     |      .   \n",
      "     |      .   @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .   one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .   it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .   @param probs0\n",
      "     |      .   @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .   each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .   @param labels The optional output \"class label\" for each sample:\n",
      "     |      .   \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .   mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .   @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .   mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .   CV_64FC1 type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty %EM model.\n",
      "     |      .   The model should be trained then using StatModel::train(traindata, flags) method. Alternatively, you\n",
      "     |      .   can use one of the EM::train\\* methods or load it from file using Algorithm::load\\<EM\\>(filename).\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized EM from a file\n",
      "     |      .   *\n",
      "     |      .   * Use EM::save to serialize and store an EM to disk.\n",
      "     |      .   * Load the EM from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized EM\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_KNearest(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_KNearest\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  findNearest(...)\n",
      "     |      findNearest(samples, k[, results[, neighborResponses[, dist]]]) -> retval, results, neighborResponses, dist\n",
      "     |      .   @brief Finds the neighbors and predicts responses for input vectors.\n",
      "     |      .   \n",
      "     |      .   @param samples Input samples stored by rows. It is a single-precision floating-point matrix of\n",
      "     |      .   `<number_of_samples> * k` size.\n",
      "     |      .   @param k Number of used nearest neighbors. Should be greater than 1.\n",
      "     |      .   @param results Vector with results of prediction (regression or classification) for each input\n",
      "     |      .   sample. It is a single-precision floating-point vector with `<number_of_samples>` elements.\n",
      "     |      .   @param neighborResponses Optional output values for corresponding neighbors. It is a single-\n",
      "     |      .   precision floating-point matrix of `<number_of_samples> * k` size.\n",
      "     |      .   @param dist Optional output distances from the input vectors to the corresponding neighbors. It\n",
      "     |      .   is a single-precision floating-point matrix of `<number_of_samples> * k` size.\n",
      "     |      .   \n",
      "     |      .   For each input vector (a row of the matrix samples), the method finds the k nearest neighbors.\n",
      "     |      .   In case of regression, the predicted result is a mean value of the particular vector's neighbor\n",
      "     |      .   responses. In case of classification, the class is determined by voting.\n",
      "     |      .   \n",
      "     |      .   For each input vector, the neighbors are sorted by their distances to the vector.\n",
      "     |      .   \n",
      "     |      .   In case of C++ interface you can use output pointers to empty matrices and the function will\n",
      "     |      .   allocate memory itself.\n",
      "     |      .   \n",
      "     |      .   If only a single input vector is passed, all output matrices are optional and the predicted\n",
      "     |      .   value is returned by the method.\n",
      "     |      .   \n",
      "     |      .   The function is parallelized with the TBB library.\n",
      "     |  \n",
      "     |  getAlgorithmType(...)\n",
      "     |      getAlgorithmType() -> retval\n",
      "     |      .   @see setAlgorithmType\n",
      "     |  \n",
      "     |  getDefaultK(...)\n",
      "     |      getDefaultK() -> retval\n",
      "     |      .   @see setDefaultK\n",
      "     |  \n",
      "     |  getEmax(...)\n",
      "     |      getEmax() -> retval\n",
      "     |      .   @see setEmax\n",
      "     |  \n",
      "     |  getIsClassifier(...)\n",
      "     |      getIsClassifier() -> retval\n",
      "     |      .   @see setIsClassifier\n",
      "     |  \n",
      "     |  setAlgorithmType(...)\n",
      "     |      setAlgorithmType(val) -> None\n",
      "     |      .   @copybrief getAlgorithmType @see getAlgorithmType\n",
      "     |  \n",
      "     |  setDefaultK(...)\n",
      "     |      setDefaultK(val) -> None\n",
      "     |      .   @copybrief getDefaultK @see getDefaultK\n",
      "     |  \n",
      "     |  setEmax(...)\n",
      "     |      setEmax(val) -> None\n",
      "     |      .   @copybrief getEmax @see getEmax\n",
      "     |  \n",
      "     |  setIsClassifier(...)\n",
      "     |      setIsClassifier(val) -> None\n",
      "     |      .   @copybrief getIsClassifier @see getIsClassifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates the empty model\n",
      "     |      .   \n",
      "     |      .   The static method creates empty %KNearest classifier. It should be then trained using StatModel::train method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_LogisticRegression(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_LogisticRegression\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getIterations(...)\n",
      "     |      getIterations() -> retval\n",
      "     |      .   @see setIterations\n",
      "     |  \n",
      "     |  getLearningRate(...)\n",
      "     |      getLearningRate() -> retval\n",
      "     |      .   @see setLearningRate\n",
      "     |  \n",
      "     |  getMiniBatchSize(...)\n",
      "     |      getMiniBatchSize() -> retval\n",
      "     |      .   @see setMiniBatchSize\n",
      "     |  \n",
      "     |  getRegularization(...)\n",
      "     |      getRegularization() -> retval\n",
      "     |      .   @see setRegularization\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getTrainMethod(...)\n",
      "     |      getTrainMethod() -> retval\n",
      "     |      .   @see setTrainMethod\n",
      "     |  \n",
      "     |  get_learnt_thetas(...)\n",
      "     |      get_learnt_thetas() -> retval\n",
      "     |      .   @brief This function returns the trained parameters arranged across rows.\n",
      "     |      .   \n",
      "     |      .   For a two class classifcation problem, it returns a row matrix. It returns learnt parameters of\n",
      "     |      .   the Logistic Regression as a matrix of type CV_32F.\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts responses for input samples and returns a float type.\n",
      "     |      .   \n",
      "     |      .   @param samples The input data for the prediction algorithm. Matrix [m x n], where each row\n",
      "     |      .   contains variables (features) of one object being classified. Should have data type CV_32F.\n",
      "     |      .   @param results Predicted labels as a column matrix of type CV_32S.\n",
      "     |      .   @param flags Not used.\n",
      "     |  \n",
      "     |  setIterations(...)\n",
      "     |      setIterations(val) -> None\n",
      "     |      .   @copybrief getIterations @see getIterations\n",
      "     |  \n",
      "     |  setLearningRate(...)\n",
      "     |      setLearningRate(val) -> None\n",
      "     |      .   @copybrief getLearningRate @see getLearningRate\n",
      "     |  \n",
      "     |  setMiniBatchSize(...)\n",
      "     |      setMiniBatchSize(val) -> None\n",
      "     |      .   @copybrief getMiniBatchSize @see getMiniBatchSize\n",
      "     |  \n",
      "     |  setRegularization(...)\n",
      "     |      setRegularization(val) -> None\n",
      "     |      .   @copybrief getRegularization @see getRegularization\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setTrainMethod(...)\n",
      "     |      setTrainMethod(val) -> None\n",
      "     |      .   @copybrief getTrainMethod @see getTrainMethod\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model.\n",
      "     |      .   \n",
      "     |      .   Creates Logistic Regression model with parameters given.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized LogisticRegression from a file\n",
      "     |      .   *\n",
      "     |      .   * Use LogisticRegression::save to serialize and store an LogisticRegression to disk.\n",
      "     |      .   * Load the LogisticRegression from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized LogisticRegression\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_NormalBayesClassifier(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_NormalBayesClassifier\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  predictProb(...)\n",
      "     |      predictProb(inputs[, outputs[, outputProbs[, flags]]]) -> retval, outputs, outputProbs\n",
      "     |      .   @brief Predicts the response for sample(s).\n",
      "     |      .   \n",
      "     |      .   The method estimates the most probable classes for input vectors. Input vectors (one or more)\n",
      "     |      .   are stored as rows of the matrix inputs. In case of multiple input vectors, there should be one\n",
      "     |      .   output vector outputs. The predicted class for a single input vector is returned by the method.\n",
      "     |      .   The vector outputProbs contains the output probabilities corresponding to each element of\n",
      "     |      .   result.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty model\n",
      "     |      .   Use StatModel::train to train the model after creation.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized NormalBayesClassifier from a file\n",
      "     |      .   *\n",
      "     |      .   * Use NormalBayesClassifier::save to serialize and store an NormalBayesClassifier to disk.\n",
      "     |      .   * Load the NormalBayesClassifier from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized NormalBayesClassifier\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_ParamGrid(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, minVal[, maxVal[, logstep]]]) -> retval\n",
      "     |      .   @brief Creates a ParamGrid Ptr that can be given to the %SVM::trainAuto method\n",
      "     |      .   \n",
      "     |      .   @param minVal minimum value of the parameter grid\n",
      "     |      .   @param maxVal maximum value of the parameter grid\n",
      "     |      .   @param logstep Logarithmic step for iterating the statmodel parameter\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  logStep\n",
      "     |      logStep\n",
      "     |  \n",
      "     |  maxVal\n",
      "     |      maxVal\n",
      "     |  \n",
      "     |  minVal\n",
      "     |      minVal\n",
      "    \n",
      "    class ml_RTrees(ml_DTrees)\n",
      "     |  Method resolution order:\n",
      "     |      ml_RTrees\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getActiveVarCount(...)\n",
      "     |      getActiveVarCount() -> retval\n",
      "     |      .   @see setActiveVarCount\n",
      "     |  \n",
      "     |  getCalculateVarImportance(...)\n",
      "     |      getCalculateVarImportance() -> retval\n",
      "     |      .   @see setCalculateVarImportance\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getVarImportance(...)\n",
      "     |      getVarImportance() -> retval\n",
      "     |      .   Returns the variable importance array.\n",
      "     |      .   The method returns the variable importance vector, computed at the training stage when\n",
      "     |      .   CalculateVarImportance is set to true. If this flag was set to false, the empty matrix is\n",
      "     |      .   returned.\n",
      "     |  \n",
      "     |  getVotes(...)\n",
      "     |      getVotes(samples, flags[, results]) -> results\n",
      "     |      .   Returns the result of each individual tree in the forest.\n",
      "     |      .   In case the model is a regression problem, the method will return each of the trees'\n",
      "     |      .   results for each of the sample cases. If the model is a classifier, it will return\n",
      "     |      .   a Mat with samples + 1 rows, where the first row gives the class number and the\n",
      "     |      .   following rows return the votes each class had for each sample.\n",
      "     |      .   @param samples Array containing the samples for which votes will be calculated.\n",
      "     |      .   @param results Array where the result of the calculation will be written.\n",
      "     |      .   @param flags Flags for defining the type of RTrees.\n",
      "     |  \n",
      "     |  setActiveVarCount(...)\n",
      "     |      setActiveVarCount(val) -> None\n",
      "     |      .   @copybrief getActiveVarCount @see getActiveVarCount\n",
      "     |  \n",
      "     |  setCalculateVarImportance(...)\n",
      "     |      setCalculateVarImportance(val) -> None\n",
      "     |      .   @copybrief getCalculateVarImportance @see getCalculateVarImportance\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates the empty model.\n",
      "     |      .   Use StatModel::train to train the model, StatModel::train to create and train the model,\n",
      "     |      .   Algorithm::load to load the pre-trained model.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized RTree from a file\n",
      "     |      .   *\n",
      "     |      .   * Use RTree::save to serialize and store an RTree to disk.\n",
      "     |      .   * Load the RTree from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized RTree\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_DTrees:\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_SVM(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_SVM\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getC(...)\n",
      "     |      getC() -> retval\n",
      "     |      .   @see setC\n",
      "     |  \n",
      "     |  getClassWeights(...)\n",
      "     |      getClassWeights() -> retval\n",
      "     |      .   @see setClassWeights\n",
      "     |  \n",
      "     |  getCoef0(...)\n",
      "     |      getCoef0() -> retval\n",
      "     |      .   @see setCoef0\n",
      "     |  \n",
      "     |  getDecisionFunction(...)\n",
      "     |      getDecisionFunction(i[, alpha[, svidx]]) -> retval, alpha, svidx\n",
      "     |      .   @brief Retrieves the decision function\n",
      "     |      .   \n",
      "     |      .   @param i the index of the decision function. If the problem solved is regression, 1-class or\n",
      "     |      .   2-class classification, then there will be just one decision function and the index should\n",
      "     |      .   always be 0. Otherwise, in the case of N-class classification, there will be \\f$N(N-1)/2\\f$\n",
      "     |      .   decision functions.\n",
      "     |      .   @param alpha the optional output vector for weights, corresponding to different support vectors.\n",
      "     |      .   In the case of linear %SVM all the alpha's will be 1's.\n",
      "     |      .   @param svidx the optional output vector of indices of support vectors within the matrix of\n",
      "     |      .   support vectors (which can be retrieved by SVM::getSupportVectors). In the case of linear\n",
      "     |      .   %SVM each decision function consists of a single \"compressed\" support vector.\n",
      "     |      .   \n",
      "     |      .   The method returns rho parameter of the decision function, a scalar subtracted from the weighted\n",
      "     |      .   sum of kernel responses.\n",
      "     |  \n",
      "     |  getDegree(...)\n",
      "     |      getDegree() -> retval\n",
      "     |      .   @see setDegree\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .   @see setGamma\n",
      "     |  \n",
      "     |  getKernelType(...)\n",
      "     |      getKernelType() -> retval\n",
      "     |      .   Type of a %SVM kernel.\n",
      "     |      .   See SVM::KernelTypes. Default value is SVM::RBF.\n",
      "     |  \n",
      "     |  getNu(...)\n",
      "     |      getNu() -> retval\n",
      "     |      .   @see setNu\n",
      "     |  \n",
      "     |  getP(...)\n",
      "     |      getP() -> retval\n",
      "     |      .   @see setP\n",
      "     |  \n",
      "     |  getSupportVectors(...)\n",
      "     |      getSupportVectors() -> retval\n",
      "     |      .   @brief Retrieves all the support vectors\n",
      "     |      .   \n",
      "     |      .   The method returns all the support vectors as a floating-point matrix, where support vectors are\n",
      "     |      .   stored as matrix rows.\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .   @see setType\n",
      "     |  \n",
      "     |  getUncompressedSupportVectors(...)\n",
      "     |      getUncompressedSupportVectors() -> retval\n",
      "     |      .   @brief Retrieves all the uncompressed support vectors of a linear %SVM\n",
      "     |      .   \n",
      "     |      .   The method returns all the uncompressed support vectors of a linear %SVM that the compressed\n",
      "     |      .   support vector, used for prediction, was derived from. They are returned in a floating-point\n",
      "     |      .   matrix, where the support vectors are stored as matrix rows.\n",
      "     |  \n",
      "     |  setC(...)\n",
      "     |      setC(val) -> None\n",
      "     |      .   @copybrief getC @see getC\n",
      "     |  \n",
      "     |  setClassWeights(...)\n",
      "     |      setClassWeights(val) -> None\n",
      "     |      .   @copybrief getClassWeights @see getClassWeights\n",
      "     |  \n",
      "     |  setCoef0(...)\n",
      "     |      setCoef0(val) -> None\n",
      "     |      .   @copybrief getCoef0 @see getCoef0\n",
      "     |  \n",
      "     |  setDegree(...)\n",
      "     |      setDegree(val) -> None\n",
      "     |      .   @copybrief getDegree @see getDegree\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(val) -> None\n",
      "     |      .   @copybrief getGamma @see getGamma\n",
      "     |  \n",
      "     |  setKernel(...)\n",
      "     |      setKernel(kernelType) -> None\n",
      "     |      .   Initialize with one of predefined kernels.\n",
      "     |      .   See SVM::KernelTypes.\n",
      "     |  \n",
      "     |  setNu(...)\n",
      "     |      setNu(val) -> None\n",
      "     |      .   @copybrief getNu @see getNu\n",
      "     |  \n",
      "     |  setP(...)\n",
      "     |      setP(val) -> None\n",
      "     |      .   @copybrief getP @see getP\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(val) -> None\n",
      "     |      .   @copybrief getType @see getType\n",
      "     |  \n",
      "     |  trainAuto(...)\n",
      "     |      trainAuto(samples, layout, responses[, kFold[, Cgrid[, gammaGrid[, pGrid[, nuGrid[, coeffGrid[, degreeGrid[, balanced]]]]]]]]) -> retval\n",
      "     |      .   @brief Trains an %SVM with optimal parameters\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |      .   @param kFold Cross-validation parameter. The training set is divided into kFold subsets. One\n",
      "     |      .   subset is used to test the model, the others form the train set. So, the %SVM algorithm is\n",
      "     |      .   @param Cgrid grid for C\n",
      "     |      .   @param gammaGrid grid for gamma\n",
      "     |      .   @param pGrid grid for p\n",
      "     |      .   @param nuGrid grid for nu\n",
      "     |      .   @param coeffGrid grid for coeff\n",
      "     |      .   @param degreeGrid grid for degree\n",
      "     |      .   @param balanced If true and the problem is 2-class classification then the method creates more\n",
      "     |      .   balanced cross-validation subsets that is proportions between classes in subsets are close\n",
      "     |      .   to such proportion in the whole train dataset.\n",
      "     |      .   \n",
      "     |      .   The method trains the %SVM model automatically by choosing the optimal parameters C, gamma, p,\n",
      "     |      .   nu, coef0, degree. Parameters are considered optimal when the cross-validation\n",
      "     |      .   estimate of the test set error is minimal.\n",
      "     |      .   \n",
      "     |      .   This function only makes use of SVM::getDefaultGrid for parameter optimization and thus only\n",
      "     |      .   offers rudimentary parameter options.\n",
      "     |      .   \n",
      "     |      .   This function works for the classification (SVM::C_SVC or SVM::NU_SVC) as well as for the\n",
      "     |      .   regression (SVM::EPS_SVR or SVM::NU_SVR). If it is SVM::ONE_CLASS, no optimization is made and\n",
      "     |      .   the usual %SVM with parameters specified in params is executed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty model.\n",
      "     |      .   Use StatModel::train to train the model. Since %SVM has several parameters, you may want to\n",
      "     |      .   find the best parameters for your problem, it can be done with SVM::trainAuto.\n",
      "     |  \n",
      "     |  getDefaultGridPtr(...)\n",
      "     |      getDefaultGridPtr(param_id) -> retval\n",
      "     |      .   @brief Generates a grid for %SVM parameters.\n",
      "     |      .   \n",
      "     |      .   @param param_id %SVM parameters IDs that must be one of the SVM::ParamTypes. The grid is\n",
      "     |      .   generated for the parameter with this ID.\n",
      "     |      .   \n",
      "     |      .   The function generates a grid pointer for the specified parameter of the %SVM algorithm.\n",
      "     |      .   The grid may be passed to the function SVM::trainAuto.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath) -> retval\n",
      "     |      .   @brief Loads and creates a serialized svm from a file\n",
      "     |      .   *\n",
      "     |      .   * Use SVM::save to serialize and store an SVM to disk.\n",
      "     |      .   * Load the SVM from this file again, by calling this function with the path to the file.\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized svm\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_SVMSGD(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_SVMSGD\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getInitialStepSize(...)\n",
      "     |      getInitialStepSize() -> retval\n",
      "     |      .   @see setInitialStepSize\n",
      "     |  \n",
      "     |  getMarginRegularization(...)\n",
      "     |      getMarginRegularization() -> retval\n",
      "     |      .   @see setMarginRegularization\n",
      "     |  \n",
      "     |  getMarginType(...)\n",
      "     |      getMarginType() -> retval\n",
      "     |      .   @see setMarginType\n",
      "     |  \n",
      "     |  getShift(...)\n",
      "     |      getShift() -> retval\n",
      "     |      .   * @return the shift of the trained model (decision function f(x) = weights * x + shift).\n",
      "     |  \n",
      "     |  getStepDecreasingPower(...)\n",
      "     |      getStepDecreasingPower() -> retval\n",
      "     |      .   @see setStepDecreasingPower\n",
      "     |  \n",
      "     |  getSvmsgdType(...)\n",
      "     |      getSvmsgdType() -> retval\n",
      "     |      .   @see setSvmsgdType\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights() -> retval\n",
      "     |      .   * @return the weights of the trained model (decision function f(x) = weights * x + shift).\n",
      "     |  \n",
      "     |  setInitialStepSize(...)\n",
      "     |      setInitialStepSize(InitialStepSize) -> None\n",
      "     |      .   @copybrief getInitialStepSize @see getInitialStepSize\n",
      "     |  \n",
      "     |  setMarginRegularization(...)\n",
      "     |      setMarginRegularization(marginRegularization) -> None\n",
      "     |      .   @copybrief getMarginRegularization @see getMarginRegularization\n",
      "     |  \n",
      "     |  setMarginType(...)\n",
      "     |      setMarginType(marginType) -> None\n",
      "     |      .   @copybrief getMarginType @see getMarginType\n",
      "     |  \n",
      "     |  setOptimalParameters(...)\n",
      "     |      setOptimalParameters([, svmsgdType[, marginType]]) -> None\n",
      "     |      .   @brief Function sets optimal parameters values for chosen SVM SGD model.\n",
      "     |      .   * @param svmsgdType is the type of SVMSGD classifier.\n",
      "     |      .   * @param marginType is the type of margin constraint.\n",
      "     |  \n",
      "     |  setStepDecreasingPower(...)\n",
      "     |      setStepDecreasingPower(stepDecreasingPower) -> None\n",
      "     |      .   @copybrief getStepDecreasingPower @see getStepDecreasingPower\n",
      "     |  \n",
      "     |  setSvmsgdType(...)\n",
      "     |      setSvmsgdType(svmsgdType) -> None\n",
      "     |      .   @copybrief getSvmsgdType @see getSvmsgdType\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model.\n",
      "     |      .   * Use StatModel::train to train the model. Since %SVMSGD has several parameters, you may want to\n",
      "     |      .   * find the best parameters for your problem or use setOptimalParameters() to set some default parameters.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized SVMSGD from a file\n",
      "     |      .   *\n",
      "     |      .   * Use SVMSGD::save to serialize and store an SVMSGD to disk.\n",
      "     |      .   * Load the SVMSGD from this file again, by calling this function with the path to the file.\n",
      "     |      .   * Optionally specify the node for the file containing the classifier\n",
      "     |      .   *\n",
      "     |      .   * @param filepath path to serialized SVMSGD\n",
      "     |      .   * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_StatModel(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .   @param data the training data\n",
      "     |      .   @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .   computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .   different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .   the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .   that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .   @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .   The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .   computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .   @param samples The input samples, floating-point matrix\n",
      "     |      .   @param results The optional output matrix of results.\n",
      "     |      .   @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .   created with TrainData::create.\n",
      "     |      .   @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .   new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .   @param samples training samples\n",
      "     |      .   @param layout See ml::SampleTypes.\n",
      "     |      .   @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .   * @overload\n",
      "    \n",
      "    class ml_TrainData(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getCatCount(...)\n",
      "     |      getCatCount(vi) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCatMap(...)\n",
      "     |      getCatMap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCatOfs(...)\n",
      "     |      getCatOfs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getClassLabels(...)\n",
      "     |      getClassLabels() -> retval\n",
      "     |      .   @brief Returns the vector of class labels\n",
      "     |      .   \n",
      "     |      .   The function returns vector of unique labels occurred in the responses.\n",
      "     |  \n",
      "     |  getDefaultSubstValues(...)\n",
      "     |      getDefaultSubstValues() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayout(...)\n",
      "     |      getLayout() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMissing(...)\n",
      "     |      getMissing() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNAllVars(...)\n",
      "     |      getNAllVars() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNSamples(...)\n",
      "     |      getNSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNTestSamples(...)\n",
      "     |      getNTestSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNTrainSamples(...)\n",
      "     |      getNTrainSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNVars(...)\n",
      "     |      getNVars() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNames(...)\n",
      "     |      getNames(names) -> None\n",
      "     |      .   @brief Returns vector of symbolic names captured in loadFromCSV()\n",
      "     |  \n",
      "     |  getNormCatResponses(...)\n",
      "     |      getNormCatResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getResponseType(...)\n",
      "     |      getResponseType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getResponses(...)\n",
      "     |      getResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSample(...)\n",
      "     |      getSample(varIdx, sidx, buf) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSampleWeights(...)\n",
      "     |      getSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSamples(...)\n",
      "     |      getSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestNormCatResponses(...)\n",
      "     |      getTestNormCatResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestResponses(...)\n",
      "     |      getTestResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSampleIdx(...)\n",
      "     |      getTestSampleIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSampleWeights(...)\n",
      "     |      getTestSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSamples(...)\n",
      "     |      getTestSamples() -> retval\n",
      "     |      .   @brief Returns matrix of test samples\n",
      "     |  \n",
      "     |  getTrainNormCatResponses(...)\n",
      "     |      getTrainNormCatResponses() -> retval\n",
      "     |      .   @brief Returns the vector of normalized categorical responses\n",
      "     |      .   \n",
      "     |      .   The function returns vector of responses. Each response is integer from `0` to `<number of\n",
      "     |      .   classes>-1`. The actual label value can be retrieved then from the class label vector, see\n",
      "     |      .   TrainData::getClassLabels.\n",
      "     |  \n",
      "     |  getTrainResponses(...)\n",
      "     |      getTrainResponses() -> retval\n",
      "     |      .   @brief Returns the vector of responses\n",
      "     |      .   \n",
      "     |      .   The function returns ordered or the original categorical responses. Usually it's used in\n",
      "     |      .   regression algorithms.\n",
      "     |  \n",
      "     |  getTrainSampleIdx(...)\n",
      "     |      getTrainSampleIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTrainSampleWeights(...)\n",
      "     |      getTrainSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTrainSamples(...)\n",
      "     |      getTrainSamples([, layout[, compressSamples[, compressVars]]]) -> retval\n",
      "     |      .   @brief Returns matrix of train samples\n",
      "     |      .   \n",
      "     |      .   @param layout The requested layout. If it's different from the initial one, the matrix is\n",
      "     |      .   transposed. See ml::SampleTypes.\n",
      "     |      .   @param compressSamples if true, the function returns only the training samples (specified by\n",
      "     |      .   sampleIdx)\n",
      "     |      .   @param compressVars if true, the function returns the shorter training samples, containing only\n",
      "     |      .   the active variables.\n",
      "     |      .   \n",
      "     |      .   In current implementation the function tries to avoid physical data copying and returns the\n",
      "     |      .   matrix stored inside TrainData (unless the transposition or compression is needed).\n",
      "     |  \n",
      "     |  getValues(...)\n",
      "     |      getValues(vi, sidx, values) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarIdx(...)\n",
      "     |      getVarIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarSymbolFlags(...)\n",
      "     |      getVarSymbolFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarType(...)\n",
      "     |      getVarType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTrainTestSplit(...)\n",
      "     |      setTrainTestSplit(count[, shuffle]) -> None\n",
      "     |      .   @brief Splits the training data into the training and test parts\n",
      "     |      .   @sa TrainData::setTrainTestSplitRatio\n",
      "     |  \n",
      "     |  setTrainTestSplitRatio(...)\n",
      "     |      setTrainTestSplitRatio(ratio[, shuffle]) -> None\n",
      "     |      .   @brief Splits the training data into the training and test parts\n",
      "     |      .   \n",
      "     |      .   The function selects a subset of specified relative size and then returns it as the training\n",
      "     |      .   set. If the function is not called, all the data is used for training. Please, note that for\n",
      "     |      .   each of TrainData::getTrain\\* there is corresponding TrainData::getTest\\*, so that the test\n",
      "     |      .   subset can be retrieved and processed as well.\n",
      "     |      .   @sa TrainData::setTrainTestSplit\n",
      "     |  \n",
      "     |  shuffleTrainTest(...)\n",
      "     |      shuffleTrainTest() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(samples, layout, responses[, varIdx[, sampleIdx[, sampleWeights[, varType]]]]) -> retval\n",
      "     |      .   @brief Creates training data from in-memory arrays.\n",
      "     |      .   \n",
      "     |      .   @param samples matrix of samples. It should have CV_32F type.\n",
      "     |      .   @param layout see ml::SampleTypes.\n",
      "     |      .   @param responses matrix of responses. If the responses are scalar, they should be stored as a\n",
      "     |      .   single row or as a single column. The matrix should have type CV_32F or CV_32S (in the\n",
      "     |      .   former case the responses are considered as ordered by default; in the latter case - as\n",
      "     |      .   categorical)\n",
      "     |      .   @param varIdx vector specifying which variables to use for training. It can be an integer vector\n",
      "     |      .   (CV_32S) containing 0-based variable indices or byte vector (CV_8U) containing a mask of\n",
      "     |      .   active variables.\n",
      "     |      .   @param sampleIdx vector specifying which samples to use for training. It can be an integer\n",
      "     |      .   vector (CV_32S) containing 0-based sample indices or byte vector (CV_8U) containing a mask\n",
      "     |      .   of training samples.\n",
      "     |      .   @param sampleWeights optional vector with weights for each sample. It should have CV_32F type.\n",
      "     |      .   @param varType optional vector of type CV_8U and size `<number_of_variables_in_samples> +\n",
      "     |      .   <number_of_variables_in_responses>`, containing types of each input and output variable. See\n",
      "     |      .   ml::VariableTypes.\n",
      "     |  \n",
      "     |  getSubMatrix(...)\n",
      "     |      getSubMatrix(matrix, idx, layout) -> retval\n",
      "     |      .   @brief Extract from matrix rows/cols specified by passed indexes.\n",
      "     |      .   @param matrix input matrix (supported types: CV_32S, CV_32F, CV_64F)\n",
      "     |      .   @param idx 1D index vector\n",
      "     |      .   @param layout specifies to extract rows (cv::ml::ROW_SAMPLES) or to extract columns (cv::ml::COL_SAMPLES)\n",
      "     |  \n",
      "     |  getSubVector(...)\n",
      "     |      getSubVector(vec, idx) -> retval\n",
      "     |      .   @brief Extract from 1D vector elements specified by passed indexes.\n",
      "     |      .   @param vec input vector (supported types: CV_32S, CV_32F, CV_64F)\n",
      "     |      .   @param idx 1D index vector\n",
      "    \n",
      "    class ocl_Device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  OpenCLVersion(...)\n",
      "     |      OpenCLVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  OpenCL_C_Version(...)\n",
      "     |      OpenCL_C_Version() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  addressBits(...)\n",
      "     |      addressBits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  available(...)\n",
      "     |      available() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  compilerAvailable(...)\n",
      "     |      compilerAvailable() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceVersionMajor(...)\n",
      "     |      deviceVersionMajor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceVersionMinor(...)\n",
      "     |      deviceVersionMinor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  doubleFPConfig(...)\n",
      "     |      doubleFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  driverVersion(...)\n",
      "     |      driverVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  endianLittle(...)\n",
      "     |      endianLittle() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  errorCorrectionSupport(...)\n",
      "     |      errorCorrectionSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  executionCapabilities(...)\n",
      "     |      executionCapabilities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  extensions(...)\n",
      "     |      extensions() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheLineSize(...)\n",
      "     |      globalMemCacheLineSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheSize(...)\n",
      "     |      globalMemCacheSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheType(...)\n",
      "     |      globalMemCacheType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemSize(...)\n",
      "     |      globalMemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  halfFPConfig(...)\n",
      "     |      halfFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hostUnifiedMemory(...)\n",
      "     |      hostUnifiedMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image2DMaxHeight(...)\n",
      "     |      image2DMaxHeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image2DMaxWidth(...)\n",
      "     |      image2DMaxWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxDepth(...)\n",
      "     |      image3DMaxDepth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxHeight(...)\n",
      "     |      image3DMaxHeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxWidth(...)\n",
      "     |      image3DMaxWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageFromBufferSupport(...)\n",
      "     |      imageFromBufferSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageMaxArraySize(...)\n",
      "     |      imageMaxArraySize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageMaxBufferSize(...)\n",
      "     |      imageMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageSupport(...)\n",
      "     |      imageSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  intelSubgroupsSupport(...)\n",
      "     |      intelSubgroupsSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isAMD(...)\n",
      "     |      isAMD() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isExtensionSupported(...)\n",
      "     |      isExtensionSupported(extensionName) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isIntel(...)\n",
      "     |      isIntel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNVidia(...)\n",
      "     |      isNVidia() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  linkerAvailable(...)\n",
      "     |      linkerAvailable() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  localMemSize(...)\n",
      "     |      localMemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  localMemType(...)\n",
      "     |      localMemType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxClockFrequency(...)\n",
      "     |      maxClockFrequency() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxComputeUnits(...)\n",
      "     |      maxComputeUnits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxConstantArgs(...)\n",
      "     |      maxConstantArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxConstantBufferSize(...)\n",
      "     |      maxConstantBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxMemAllocSize(...)\n",
      "     |      maxMemAllocSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxParameterSize(...)\n",
      "     |      maxParameterSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxReadImageArgs(...)\n",
      "     |      maxReadImageArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSamplers(...)\n",
      "     |      maxSamplers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWorkGroupSize(...)\n",
      "     |      maxWorkGroupSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWorkItemDims(...)\n",
      "     |      maxWorkItemDims() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWriteImageArgs(...)\n",
      "     |      maxWriteImageArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memBaseAddrAlign(...)\n",
      "     |      memBaseAddrAlign() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthChar(...)\n",
      "     |      nativeVectorWidthChar() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthDouble(...)\n",
      "     |      nativeVectorWidthDouble() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthFloat(...)\n",
      "     |      nativeVectorWidthFloat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthHalf(...)\n",
      "     |      nativeVectorWidthHalf() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthInt(...)\n",
      "     |      nativeVectorWidthInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthLong(...)\n",
      "     |      nativeVectorWidthLong() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthShort(...)\n",
      "     |      nativeVectorWidthShort() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthChar(...)\n",
      "     |      preferredVectorWidthChar() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthDouble(...)\n",
      "     |      preferredVectorWidthDouble() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthFloat(...)\n",
      "     |      preferredVectorWidthFloat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthHalf(...)\n",
      "     |      preferredVectorWidthHalf() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthInt(...)\n",
      "     |      preferredVectorWidthInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthLong(...)\n",
      "     |      preferredVectorWidthLong() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthShort(...)\n",
      "     |      preferredVectorWidthShort() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  printfBufferSize(...)\n",
      "     |      printfBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  profilingTimerResolution(...)\n",
      "     |      profilingTimerResolution() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  singleFPConfig(...)\n",
      "     |      singleFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  vendorID(...)\n",
      "     |      vendorID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  vendorName(...)\n",
      "     |      vendorName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  version(...)\n",
      "     |      version() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  getDefault(...)\n",
      "     |      getDefault() -> retval\n",
      "     |      .\n",
      "\n",
      "FUNCTIONS\n",
      "    AKAZE_create(...)\n",
      "        AKAZE_create([, descriptor_type[, descriptor_size[, descriptor_channels[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]]) -> retval\n",
      "        .   @brief The AKAZE constructor\n",
      "        .   \n",
      "        .   @param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,\n",
      "        .   DESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.\n",
      "        .   @param descriptor_size Size of the descriptor in bits. 0 -\\> Full size\n",
      "        .   @param descriptor_channels Number of channels in the descriptor (1, 2, 3)\n",
      "        .   @param threshold Detector response threshold to accept point\n",
      "        .   @param nOctaves Maximum octave evolution of the image\n",
      "        .   @param nOctaveLayers Default number of sublevels per scale level\n",
      "        .   @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "        .   DIFF_CHARBONNIER\n",
      "    \n",
      "    AgastFeatureDetector_create(...)\n",
      "        AgastFeatureDetector_create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    BFMatcher_create(...)\n",
      "        BFMatcher_create([, normType[, crossCheck]]) -> retval\n",
      "        .   @brief Brute-force matcher create method.\n",
      "        .   @param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are\n",
      "        .   preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "        .   BRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor\n",
      "        .   description).\n",
      "        .   @param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k\n",
      "        .   nearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with\n",
      "        .   k=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the\n",
      "        .   matcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent\n",
      "        .   pairs. Such technique usually produces best results with minimal number of outliers when there are\n",
      "        .   enough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper.\n",
      "    \n",
      "    BRISK_create(...)\n",
      "        BRISK_create([, thresh[, octaves[, patternScale]]]) -> retval\n",
      "        .   @brief The BRISK constructor\n",
      "        .   \n",
      "        .   @param thresh AGAST detection threshold score.\n",
      "        .   @param octaves detection octaves. Use 0 to do single scale.\n",
      "        .   @param patternScale apply this scale to the pattern used for sampling the neighbourhood of a\n",
      "        .   keypoint.\n",
      "        \n",
      "        \n",
      "        \n",
      "        BRISK_create(radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "        .   @brief The BRISK constructor for a custom pattern\n",
      "        .   \n",
      "        .   @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "        .   keypoint scale 1).\n",
      "        .   @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "        .   size as radiusList..\n",
      "        .   @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "        .   scale 1).\n",
      "        .   @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "        .   keypoint scale 1).\n",
      "        .   @param indexChange index remapping of the bits.\n",
      "        \n",
      "        \n",
      "        \n",
      "        BRISK_create(thresh, octaves, radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "        .   @brief The BRISK constructor for a custom pattern, detection threshold and octaves\n",
      "        .   \n",
      "        .   @param thresh AGAST detection threshold score.\n",
      "        .   @param octaves detection octaves. Use 0 to do single scale.\n",
      "        .   @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "        .   keypoint scale 1).\n",
      "        .   @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "        .   size as radiusList..\n",
      "        .   @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "        .   scale 1).\n",
      "        .   @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "        .   keypoint scale 1).\n",
      "        .   @param indexChange index remapping of the bits.\n",
      "    \n",
      "    CamShift(...)\n",
      "        CamShift(probImage, window, criteria) -> retval, window\n",
      "        .   @brief Finds an object center, size, and orientation.\n",
      "        .   \n",
      "        .   @param probImage Back projection of the object histogram. See calcBackProject.\n",
      "        .   @param window Initial search window.\n",
      "        .   @param criteria Stop criteria for the underlying meanShift.\n",
      "        .   returns\n",
      "        .   (in old interfaces) Number of iterations CAMSHIFT took to converge\n",
      "        .   The function implements the CAMSHIFT object tracking algorithm @cite Bradski98 . First, it finds an\n",
      "        .   object center using meanShift and then adjusts the window size and finds the optimal rotation. The\n",
      "        .   function returns the rotated rectangle structure that includes the object position, size, and\n",
      "        .   orientation. The next position of the search window can be obtained with RotatedRect::boundingRect()\n",
      "        .   \n",
      "        .   See the OpenCV sample camshiftdemo.c that tracks colored objects.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   (Python) A sample explaining the camshift tracking algorithm can be found at\n",
      "        .   opencv_source_code/samples/python/camshift.py\n",
      "    \n",
      "    Canny(...)\n",
      "        Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
      "        .   @brief Finds edges in an image using the Canny algorithm @cite Canny86 .\n",
      "        .   \n",
      "        .   The function finds edges in the input image and marks them in the output map edges using the\n",
      "        .   Canny algorithm. The smallest value between threshold1 and threshold2 is used for edge linking. The\n",
      "        .   largest value is used to find initial segments of strong edges. See\n",
      "        .   <http://en.wikipedia.org/wiki/Canny_edge_detector>\n",
      "        .   \n",
      "        .   @param image 8-bit input image.\n",
      "        .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "        .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "        .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "        .   @param apertureSize aperture size for the Sobel operator.\n",
      "        .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "        .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "        .   L2gradient=false ).\n",
      "        \n",
      "        \n",
      "        \n",
      "        Canny(dx, dy, threshold1, threshold2[, edges[, L2gradient]]) -> edges\n",
      "        .   \\overload\n",
      "        .   \n",
      "        .   Finds edges in an image using the Canny algorithm with custom image gradient.\n",
      "        .   \n",
      "        .   @param dx 16-bit x derivative of input image (CV_16SC1 or CV_16SC3).\n",
      "        .   @param dy 16-bit y derivative of input image (same type as dx).\n",
      "        .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "        .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "        .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "        .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "        .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "        .   L2gradient=false ).\n",
      "    \n",
      "    CascadeClassifier_convert(...)\n",
      "        CascadeClassifier_convert(oldcascade, newcascade) -> retval\n",
      "        .\n",
      "    \n",
      "    DISOpticalFlow_create(...)\n",
      "        DISOpticalFlow_create([, preset]) -> retval\n",
      "        .   @brief Creates an instance of DISOpticalFlow\n",
      "        .   \n",
      "        .   @param preset one of PRESET_ULTRAFAST, PRESET_FAST and PRESET_MEDIUM\n",
      "    \n",
      "    DescriptorMatcher_create(...)\n",
      "        DescriptorMatcher_create(descriptorMatcherType) -> retval\n",
      "        .   @brief Creates a descriptor matcher of a given type with the default parameters (using default\n",
      "        .   constructor).\n",
      "        .   \n",
      "        .   @param descriptorMatcherType Descriptor matcher type. Now the following matcher types are\n",
      "        .   supported:\n",
      "        .   -   `BruteForce` (it uses L2 )\n",
      "        .   -   `BruteForce-L1`\n",
      "        .   -   `BruteForce-Hamming`\n",
      "        .   -   `BruteForce-Hamming(2)`\n",
      "        .   -   `FlannBased`\n",
      "        \n",
      "        \n",
      "        \n",
      "        DescriptorMatcher_create(matcherType) -> retval\n",
      "        .\n",
      "    \n",
      "    EMD(...)\n",
      "        EMD(signature1, signature2, distType[, cost[, lowerBound[, flow]]]) -> retval, lowerBound, flow\n",
      "        .   @brief Computes the \"minimal work\" distance between two weighted point configurations.\n",
      "        .   \n",
      "        .   The function computes the earth mover distance and/or a lower boundary of the distance between the\n",
      "        .   two weighted point configurations. One of the applications described in @cite RubnerSept98,\n",
      "        .   @cite Rubner2000 is multi-dimensional histogram comparison for image retrieval. EMD is a transportation\n",
      "        .   problem that is solved using some modification of a simplex algorithm, thus the complexity is\n",
      "        .   exponential in the worst case, though, on average it is much faster. In the case of a real metric\n",
      "        .   the lower boundary can be calculated even faster (using linear-time algorithm) and it can be used\n",
      "        .   to determine roughly whether the two signatures are far enough so that they cannot relate to the\n",
      "        .   same object.\n",
      "        .   \n",
      "        .   @param signature1 First signature, a \\f$\\texttt{size1}\\times \\texttt{dims}+1\\f$ floating-point matrix.\n",
      "        .   Each row stores the point weight followed by the point coordinates. The matrix is allowed to have\n",
      "        .   a single column (weights only) if the user-defined cost matrix is used. The weights must be\n",
      "        .   non-negative and have at least one non-zero value.\n",
      "        .   @param signature2 Second signature of the same format as signature1 , though the number of rows\n",
      "        .   may be different. The total weights may be different. In this case an extra \"dummy\" point is added\n",
      "        .   to either signature1 or signature2. The weights must be non-negative and have at least one non-zero\n",
      "        .   value.\n",
      "        .   @param distType Used metric. See #DistanceTypes.\n",
      "        .   @param cost User-defined \\f$\\texttt{size1}\\times \\texttt{size2}\\f$ cost matrix. Also, if a cost matrix\n",
      "        .   is used, lower boundary lowerBound cannot be calculated because it needs a metric function.\n",
      "        .   @param lowerBound Optional input/output parameter: lower boundary of a distance between the two\n",
      "        .   signatures that is a distance between mass centers. The lower boundary may not be calculated if\n",
      "        .   the user-defined cost matrix is used, the total weights of point configurations are not equal, or\n",
      "        .   if the signatures consist of weights only (the signature matrices have a single column). You\n",
      "        .   **must** initialize \\*lowerBound . If the calculated distance between mass centers is greater or\n",
      "        .   equal to \\*lowerBound (it means that the signatures are far enough), the function does not\n",
      "        .   calculate EMD. In any case \\*lowerBound is set to the calculated distance between mass centers on\n",
      "        .   return. Thus, if you want to calculate both distance between mass centers and EMD, \\*lowerBound\n",
      "        .   should be set to 0.\n",
      "        .   @param flow Resultant \\f$\\texttt{size1} \\times \\texttt{size2}\\f$ flow matrix: \\f$\\texttt{flow}_{i,j}\\f$ is\n",
      "        .   a flow from \\f$i\\f$ -th point of signature1 to \\f$j\\f$ -th point of signature2 .\n",
      "    \n",
      "    FarnebackOpticalFlow_create(...)\n",
      "        FarnebackOpticalFlow_create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FastFeatureDetector_create(...)\n",
      "        FastFeatureDetector_create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FlannBasedMatcher_create(...)\n",
      "        FlannBasedMatcher_create() -> retval\n",
      "        .\n",
      "    \n",
      "    GFTTDetector_create(...)\n",
      "        GFTTDetector_create([, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, k]]]]]]) -> retval\n",
      "        .   \n",
      "        \n",
      "        \n",
      "        \n",
      "        GFTTDetector_create(maxCorners, qualityLevel, minDistance, blockSize, gradiantSize[, useHarrisDetector[, k]]) -> retval\n",
      "        .\n",
      "    \n",
      "    GaussianBlur(...)\n",
      "        GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image using a Gaussian filter.\n",
      "        .   \n",
      "        .   The function convolves the source image with the specified Gaussian kernel. In-place filtering is\n",
      "        .   supported.\n",
      "        .   \n",
      "        .   @param src input image; the image can have any number of channels, which are processed\n",
      "        .   independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ksize Gaussian kernel size. ksize.width and ksize.height can differ but they both must be\n",
      "        .   positive and odd. Or, they can be zero's and then they are computed from sigma.\n",
      "        .   @param sigmaX Gaussian kernel standard deviation in X direction.\n",
      "        .   @param sigmaY Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be\n",
      "        .   equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height,\n",
      "        .   respectively (see #getGaussianKernel for details); to fully control the result regardless of\n",
      "        .   possible future modifications of all this semantics, it is recommended to specify all of ksize,\n",
      "        .   sigmaX, and sigmaY.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   \n",
      "        .   @sa  sepFilter2D, filter2D, blur, boxFilter, bilateralFilter, medianBlur\n",
      "    \n",
      "    HOGDescriptor_getDaimlerPeopleDetector(...)\n",
      "        HOGDescriptor_getDaimlerPeopleDetector() -> retval\n",
      "        .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      "    \n",
      "    HOGDescriptor_getDefaultPeopleDetector(...)\n",
      "        HOGDescriptor_getDefaultPeopleDetector() -> retval\n",
      "        .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      "    \n",
      "    HoughCircles(...)\n",
      "        HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
      "        .   @brief Finds circles in a grayscale image using the Hough transform.\n",
      "        .   \n",
      "        .   The function finds circles in a grayscale image using a modification of the Hough transform.\n",
      "        .   \n",
      "        .   Example: :\n",
      "        .   @include snippets/imgproc_HoughLinesCircles.cpp\n",
      "        .   \n",
      "        .   @note Usually the function detects the centers of circles well. However, it may fail to find correct\n",
      "        .   radii. You can assist to the function by specifying the radius range ( minRadius and maxRadius ) if\n",
      "        .   you know it. Or, you may set maxRadius to a negative number to return centers only without radius\n",
      "        .   search, and find the correct radius using an additional procedure.\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel, grayscale input image.\n",
      "        .   @param circles Output vector of found circles. Each vector is encoded as  3 or 4 element\n",
      "        .   floating-point vector \\f$(x, y, radius)\\f$ or \\f$(x, y, radius, votes)\\f$ .\n",
      "        .   @param method Detection method, see #HoughModes. Currently, the only implemented method is #HOUGH_GRADIENT\n",
      "        .   @param dp Inverse ratio of the accumulator resolution to the image resolution. For example, if\n",
      "        .   dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has\n",
      "        .   half as big width and height.\n",
      "        .   @param minDist Minimum distance between the centers of the detected circles. If the parameter is\n",
      "        .   too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is\n",
      "        .   too large, some circles may be missed.\n",
      "        .   @param param1 First method-specific parameter. In case of #HOUGH_GRADIENT , it is the higher\n",
      "        .   threshold of the two passed to the Canny edge detector (the lower one is twice smaller).\n",
      "        .   @param param2 Second method-specific parameter. In case of #HOUGH_GRADIENT , it is the\n",
      "        .   accumulator threshold for the circle centers at the detection stage. The smaller it is, the more\n",
      "        .   false circles may be detected. Circles, corresponding to the larger accumulator values, will be\n",
      "        .   returned first.\n",
      "        .   @param minRadius Minimum circle radius.\n",
      "        .   @param maxRadius Maximum circle radius. If <= 0, uses the maximum image dimension. If < 0, returns\n",
      "        .   centers without finding the radius.\n",
      "        .   \n",
      "        .   @sa fitEllipse, minEnclosingCircle\n",
      "    \n",
      "    HoughLines(...)\n",
      "        HoughLines(image, rho, theta, threshold[, lines[, srn[, stn[, min_theta[, max_theta]]]]]) -> lines\n",
      "        .   @brief Finds lines in a binary image using the standard Hough transform.\n",
      "        .   \n",
      "        .   The function implements the standard or standard multi-scale Hough transform algorithm for line\n",
      "        .   detection. See <http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm> for a good explanation of Hough\n",
      "        .   transform.\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel binary source image. The image may be modified by the function.\n",
      "        .   @param lines Output vector of lines. Each line is represented by a 2 or 3 element vector\n",
      "        .   \\f$(\\rho, \\theta)\\f$ or \\f$(\\rho, \\theta, \\textrm{votes})\\f$ . \\f$\\rho\\f$ is the distance from the coordinate origin \\f$(0,0)\\f$ (top-left corner of\n",
      "        .   the image). \\f$\\theta\\f$ is the line rotation angle in radians (\n",
      "        .   \\f$0 \\sim \\textrm{vertical line}, \\pi/2 \\sim \\textrm{horizontal line}\\f$ ).\n",
      "        .   \\f$\\textrm{votes}\\f$ is the value of accumulator.\n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param srn For the multi-scale Hough transform, it is a divisor for the distance resolution rho .\n",
      "        .   The coarse accumulator distance resolution is rho and the accurate accumulator resolution is\n",
      "        .   rho/srn . If both srn=0 and stn=0 , the classical Hough transform is used. Otherwise, both these\n",
      "        .   parameters should be positive.\n",
      "        .   @param stn For the multi-scale Hough transform, it is a divisor for the distance resolution theta.\n",
      "        .   @param min_theta For standard and multi-scale Hough transform, minimum angle to check for lines.\n",
      "        .   Must fall between 0 and max_theta.\n",
      "        .   @param max_theta For standard and multi-scale Hough transform, maximum angle to check for lines.\n",
      "        .   Must fall between min_theta and CV_PI.\n",
      "    \n",
      "    HoughLinesP(...)\n",
      "        HoughLinesP(image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]) -> lines\n",
      "        .   @brief Finds line segments in a binary image using the probabilistic Hough transform.\n",
      "        .   \n",
      "        .   The function implements the probabilistic Hough transform algorithm for line detection, described\n",
      "        .   in @cite Matas00\n",
      "        .   \n",
      "        .   See the line detection example below:\n",
      "        .   @include snippets/imgproc_HoughLinesP.cpp\n",
      "        .   This is a sample picture the function parameters have been tuned for:\n",
      "        .   \n",
      "        .   ![image](pics/building.jpg)\n",
      "        .   \n",
      "        .   And this is the output of the above program in case of the probabilistic Hough transform:\n",
      "        .   \n",
      "        .   ![image](pics/houghp.png)\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel binary source image. The image may be modified by the function.\n",
      "        .   @param lines Output vector of lines. Each line is represented by a 4-element vector\n",
      "        .   \\f$(x_1, y_1, x_2, y_2)\\f$ , where \\f$(x_1,y_1)\\f$ and \\f$(x_2, y_2)\\f$ are the ending points of each detected\n",
      "        .   line segment.\n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param minLineLength Minimum line length. Line segments shorter than that are rejected.\n",
      "        .   @param maxLineGap Maximum allowed gap between points on the same line to link them.\n",
      "        .   \n",
      "        .   @sa LineSegmentDetector\n",
      "    \n",
      "    HoughLinesPointSet(...)\n",
      "        HoughLinesPointSet(_point, lines_max, threshold, min_rho, max_rho, rho_step, min_theta, max_theta, theta_step[, _lines]) -> _lines\n",
      "        .   @brief Finds lines in a set of points using the standard Hough transform.\n",
      "        .   \n",
      "        .   The function finds lines in a set of points using a modification of the Hough transform.\n",
      "        .   @include snippets/imgproc_HoughLinesPointSet.cpp\n",
      "        .   @param _point Input vector of points. Each vector must be encoded as a Point vector \\f$(x,y)\\f$. Type must be CV_32FC2 or CV_32SC2.\n",
      "        .   @param _lines Output vector of found lines. Each vector is encoded as a vector<Vec3d> \\f$(votes, rho, theta)\\f$.\n",
      "        .   The larger the value of 'votes', the higher the reliability of the Hough line.\n",
      "        .   @param lines_max Max count of hough lines.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ )\n",
      "        .   @param min_rho Minimum Distance value of the accumulator in pixels.\n",
      "        .   @param max_rho Maximum Distance value of the accumulator in pixels.\n",
      "        .   @param rho_step Distance resolution of the accumulator in pixels.\n",
      "        .   @param min_theta Minimum angle value of the accumulator in radians.\n",
      "        .   @param max_theta Maximum angle value of the accumulator in radians.\n",
      "        .   @param theta_step Angle resolution of the accumulator in radians.\n",
      "    \n",
      "    HuMoments(...)\n",
      "        HuMoments(m[, hu]) -> hu\n",
      "        .   @overload\n",
      "    \n",
      "    KAZE_create(...)\n",
      "        KAZE_create([, extended[, upright[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]) -> retval\n",
      "        .   @brief The KAZE constructor\n",
      "        .   \n",
      "        .   @param extended Set to enable extraction of extended (128-byte) descriptor.\n",
      "        .   @param upright Set to enable use of upright descriptors (non rotation-invariant).\n",
      "        .   @param threshold Detector response threshold to accept point\n",
      "        .   @param nOctaves Maximum octave evolution of the image\n",
      "        .   @param nOctaveLayers Default number of sublevels per scale level\n",
      "        .   @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "        .   DIFF_CHARBONNIER\n",
      "    \n",
      "    KeyPoint_convert(...)\n",
      "        KeyPoint_convert(keypoints[, keypointIndexes]) -> points2f\n",
      "        .   This method converts vector of keypoints to vector of points or the reverse, where each keypoint is\n",
      "        .   assigned the same size and the same orientation.\n",
      "        .   \n",
      "        .   @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "        .   @param points2f Array of (x,y) coordinates of each keypoint\n",
      "        .   @param keypointIndexes Array of indexes of keypoints to be converted to points. (Acts like a mask to\n",
      "        .   convert only specified keypoints)\n",
      "        \n",
      "        \n",
      "        \n",
      "        KeyPoint_convert(points2f[, size[, response[, octave[, class_id]]]]) -> keypoints\n",
      "        .   @overload\n",
      "        .   @param points2f Array of (x,y) coordinates of each keypoint\n",
      "        .   @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "        .   @param size keypoint diameter\n",
      "        .   @param response keypoint detector response on the keypoint (that is, strength of the keypoint)\n",
      "        .   @param octave pyramid octave in which the keypoint has been detected\n",
      "        .   @param class_id object id\n",
      "    \n",
      "    KeyPoint_overlap(...)\n",
      "        KeyPoint_overlap(kp1, kp2) -> retval\n",
      "        .   This method computes overlap for pair of keypoints. Overlap is the ratio between area of keypoint\n",
      "        .   regions' intersection and area of keypoint regions' union (considering keypoint region as circle).\n",
      "        .   If they don't overlap, we get zero. If they coincide at same location with same size, we get 1.\n",
      "        .   @param kp1 First keypoint\n",
      "        .   @param kp2 Second keypoint\n",
      "    \n",
      "    LUT(...)\n",
      "        LUT(src, lut[, dst]) -> dst\n",
      "        .   @brief Performs a look-up table transform of an array.\n",
      "        .   \n",
      "        .   The function LUT fills the output array with values from the look-up table. Indices of the entries\n",
      "        .   are taken from the input array. That is, the function processes each element of src as follows:\n",
      "        .   \\f[\\texttt{dst} (I)  \\leftarrow \\texttt{lut(src(I) + d)}\\f]\n",
      "        .   where\n",
      "        .   \\f[d =  \\fork{0}{if \\(\\texttt{src}\\) has depth \\(\\texttt{CV_8U}\\)}{128}{if \\(\\texttt{src}\\) has depth \\(\\texttt{CV_8S}\\)}\\f]\n",
      "        .   @param src input array of 8-bit elements.\n",
      "        .   @param lut look-up table of 256 elements; in case of multi-channel input array, the table should\n",
      "        .   either have a single channel (in this case the same table is used for all channels) or the same\n",
      "        .   number of channels as in the input array.\n",
      "        .   @param dst output array of the same size and number of channels as src, and the same depth as lut.\n",
      "        .   @sa  convertScaleAbs, Mat::convertTo\n",
      "    \n",
      "    Laplacian(...)\n",
      "        Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
      "        .   @brief Calculates the Laplacian of an image.\n",
      "        .   \n",
      "        .   The function calculates the Laplacian of the source image by adding up the second x and y\n",
      "        .   derivatives calculated using the Sobel operator:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\Delta \\texttt{src} =  \\frac{\\partial^2 \\texttt{src}}{\\partial x^2} +  \\frac{\\partial^2 \\texttt{src}}{\\partial y^2}\\f]\n",
      "        .   \n",
      "        .   This is done when `ksize > 1`. When `ksize == 1`, the Laplacian is computed by filtering the image\n",
      "        .   with the following \\f$3 \\times 3\\f$ aperture:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree {0}{1}{0}{1}{-4}{1}{0}{1}{0}\\f]\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth Desired depth of the destination image.\n",
      "        .   @param ksize Aperture size used to compute the second-derivative filters. See #getDerivKernels for\n",
      "        .   details. The size must be positive and odd.\n",
      "        .   @param scale Optional scale factor for the computed Laplacian values. By default, no scaling is\n",
      "        .   applied. See #getDerivKernels for details.\n",
      "        .   @param delta Optional delta value that is added to the results prior to storing them in dst .\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes\n",
      "        .   @sa  Sobel, Scharr\n",
      "    \n",
      "    MSER_create(...)\n",
      "        MSER_create([, _delta[, _min_area[, _max_area[, _max_variation[, _min_diversity[, _max_evolution[, _area_threshold[, _min_margin[, _edge_blur_size]]]]]]]]]) -> retval\n",
      "        .   @brief Full consturctor for %MSER detector\n",
      "        .   \n",
      "        .   @param _delta it compares \\f$(size_{i}-size_{i-delta})/size_{i-delta}\\f$\n",
      "        .   @param _min_area prune the area which smaller than minArea\n",
      "        .   @param _max_area prune the area which bigger than maxArea\n",
      "        .   @param _max_variation prune the area have similar size to its children\n",
      "        .   @param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity\n",
      "        .   @param _max_evolution  for color image, the evolution steps\n",
      "        .   @param _area_threshold for color image, the area threshold to cause re-initialize\n",
      "        .   @param _min_margin for color image, ignore too small margin\n",
      "        .   @param _edge_blur_size for color image, the aperture size for edge blur\n",
      "    \n",
      "    Mahalanobis(...)\n",
      "        Mahalanobis(v1, v2, icovar) -> retval\n",
      "        .   @brief Calculates the Mahalanobis distance between two vectors.\n",
      "        .   \n",
      "        .   The function cv::Mahalanobis calculates and returns the weighted distance between two vectors:\n",
      "        .   \\f[d( \\texttt{vec1} , \\texttt{vec2} )= \\sqrt{\\sum_{i,j}{\\texttt{icovar(i,j)}\\cdot(\\texttt{vec1}(I)-\\texttt{vec2}(I))\\cdot(\\texttt{vec1(j)}-\\texttt{vec2(j)})} }\\f]\n",
      "        .   The covariance matrix may be calculated using the #calcCovarMatrix function and then inverted using\n",
      "        .   the invert function (preferably using the #DECOMP_SVD method, as the most accurate).\n",
      "        .   @param v1 first 1D input vector.\n",
      "        .   @param v2 second 1D input vector.\n",
      "        .   @param icovar inverse covariance matrix.\n",
      "    \n",
      "    ORB_create(...)\n",
      "        ORB_create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold]]]]]]]]]) -> retval\n",
      "        .   @brief The ORB constructor\n",
      "        .   \n",
      "        .   @param nfeatures The maximum number of features to retain.\n",
      "        .   @param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical\n",
      "        .   pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor\n",
      "        .   will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor\n",
      "        .   will mean that to cover certain scale range you will need more pyramid levels and so the speed\n",
      "        .   will suffer.\n",
      "        .   @param nlevels The number of pyramid levels. The smallest level will have linear size equal to\n",
      "        .   input_image_linear_size/pow(scaleFactor, nlevels - firstLevel).\n",
      "        .   @param edgeThreshold This is size of the border where the features are not detected. It should\n",
      "        .   roughly match the patchSize parameter.\n",
      "        .   @param firstLevel The level of pyramid to put source image to. Previous layers are filled\n",
      "        .   with upscaled source image.\n",
      "        .   @param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The\n",
      "        .   default value 2 means the BRIEF where we take a random point pair and compare their brightnesses,\n",
      "        .   so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3\n",
      "        .   random points (of course, those point coordinates are random, but they are generated from the\n",
      "        .   pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel\n",
      "        .   rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such\n",
      "        .   output will occupy 2 bits, and therefore it will need a special variant of Hamming distance,\n",
      "        .   denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each\n",
      "        .   bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).\n",
      "        .   @param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features\n",
      "        .   (the score is written to KeyPoint::score and is used to retain best nfeatures features);\n",
      "        .   FAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,\n",
      "        .   but it is a little faster to compute.\n",
      "        .   @param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller\n",
      "        .   pyramid layers the perceived image area covered by a feature will be larger.\n",
      "        .   @param fastThreshold\n",
      "    \n",
      "    PCABackProject(...)\n",
      "        PCABackProject(data, mean, eigenvectors[, result]) -> result\n",
      "        .   wrap PCA::backProject\n",
      "    \n",
      "    PCACompute(...)\n",
      "        PCACompute(data, mean[, eigenvectors[, maxComponents]]) -> mean, eigenvectors\n",
      "        .   wrap PCA::operator()\n",
      "        \n",
      "        \n",
      "        \n",
      "        PCACompute(data, mean, retainedVariance[, eigenvectors]) -> mean, eigenvectors\n",
      "        .   wrap PCA::operator()\n",
      "    \n",
      "    PCACompute2(...)\n",
      "        PCACompute2(data, mean[, eigenvectors[, eigenvalues[, maxComponents]]]) -> mean, eigenvectors, eigenvalues\n",
      "        .   wrap PCA::operator() and add eigenvalues output parameter\n",
      "        \n",
      "        \n",
      "        \n",
      "        PCACompute2(data, mean, retainedVariance[, eigenvectors[, eigenvalues]]) -> mean, eigenvectors, eigenvalues\n",
      "        .   wrap PCA::operator() and add eigenvalues output parameter\n",
      "    \n",
      "    PCAProject(...)\n",
      "        PCAProject(data, mean, eigenvectors[, result]) -> result\n",
      "        .   wrap PCA::project\n",
      "    \n",
      "    PSNR(...)\n",
      "        PSNR(src1, src2[, R]) -> retval\n",
      "        .   @brief Computes the Peak Signal-to-Noise Ratio (PSNR) image quality metric.\n",
      "        .   \n",
      "        .   This function calculates the Peak Signal-to-Noise Ratio (PSNR) image quality metric in decibels (dB),\n",
      "        .   between two input arrays src1 and src2. The arrays must have the same type.\n",
      "        .   \n",
      "        .   The PSNR is calculated as follows:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .   \\texttt{PSNR} = 10 \\cdot \\log_{10}{\\left( \\frac{R^2}{MSE} \\right) }\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where R is the maximum integer value of depth (e.g. 255 in the case of CV_8U data)\n",
      "        .   and MSE is the mean squared error between the two arrays.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size as src1.\n",
      "        .   @param R the maximum pixel value (255 by default)\n",
      "    \n",
      "    RQDecomp3x3(...)\n",
      "        RQDecomp3x3(src[, mtxR[, mtxQ[, Qx[, Qy[, Qz]]]]]) -> retval, mtxR, mtxQ, Qx, Qy, Qz\n",
      "        .   @brief Computes an RQ decomposition of 3x3 matrices.\n",
      "        .   \n",
      "        .   @param src 3x3 input matrix.\n",
      "        .   @param mtxR Output 3x3 upper-triangular matrix.\n",
      "        .   @param mtxQ Output 3x3 orthogonal matrix.\n",
      "        .   @param Qx Optional output 3x3 rotation matrix around x-axis.\n",
      "        .   @param Qy Optional output 3x3 rotation matrix around y-axis.\n",
      "        .   @param Qz Optional output 3x3 rotation matrix around z-axis.\n",
      "        .   \n",
      "        .   The function computes a RQ decomposition using the given rotations. This function is used in\n",
      "        .   decomposeProjectionMatrix to decompose the left 3x3 submatrix of a projection matrix into a camera\n",
      "        .   and a rotation matrix.\n",
      "        .   \n",
      "        .   It optionally returns three rotation matrices, one for each axis, and the three Euler angles in\n",
      "        .   degrees (as the return value) that could be used in OpenGL. Note, there is always more than one\n",
      "        .   sequence of rotations about the three principal axes that results in the same orientation of an\n",
      "        .   object, e.g. see @cite Slabaugh . Returned tree rotation matrices and corresponding three Euler angles\n",
      "        .   are only one of the possible solutions.\n",
      "    \n",
      "    Rodrigues(...)\n",
      "        Rodrigues(src[, dst[, jacobian]]) -> dst, jacobian\n",
      "        .   @brief Converts a rotation matrix to a rotation vector or vice versa.\n",
      "        .   \n",
      "        .   @param src Input rotation vector (3x1 or 1x3) or rotation matrix (3x3).\n",
      "        .   @param dst Output rotation matrix (3x3) or rotation vector (3x1 or 1x3), respectively.\n",
      "        .   @param jacobian Optional output Jacobian matrix, 3x9 or 9x3, which is a matrix of partial\n",
      "        .   derivatives of the output array components with respect to the input array components.\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\theta \\leftarrow norm(r) \\\\ r  \\leftarrow r/ \\theta \\\\ R =  \\cos{\\theta} I + (1- \\cos{\\theta} ) r r^T +  \\sin{\\theta} \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} \\end{array}\\f]\n",
      "        .   \n",
      "        .   Inverse transformation can be also done easily, since\n",
      "        .   \n",
      "        .   \\f[\\sin ( \\theta ) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} = \\frac{R - R^T}{2}\\f]\n",
      "        .   \n",
      "        .   A rotation vector is a convenient and most compact representation of a rotation matrix (since any\n",
      "        .   rotation matrix has just 3 degrees of freedom). The representation is used in the global 3D geometry\n",
      "        .   optimization procedures like calibrateCamera, stereoCalibrate, or solvePnP .\n",
      "    \n",
      "    SVBackSubst(...)\n",
      "        SVBackSubst(w, u, vt, rhs[, dst]) -> dst\n",
      "        .   wrap SVD::backSubst\n",
      "    \n",
      "    SVDecomp(...)\n",
      "        SVDecomp(src[, w[, u[, vt[, flags]]]]) -> w, u, vt\n",
      "        .   wrap SVD::compute\n",
      "    \n",
      "    Scharr(...)\n",
      "        Scharr(src, ddepth, dx, dy[, dst[, scale[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Calculates the first x- or y- image derivative using Scharr operator.\n",
      "        .   \n",
      "        .   The function computes the first x- or y- spatial image derivative using the Scharr operator. The\n",
      "        .   call\n",
      "        .   \n",
      "        .   \\f[\\texttt{Scharr(src, dst, ddepth, dx, dy, scale, delta, borderType)}\\f]\n",
      "        .   \n",
      "        .   is equivalent to\n",
      "        .   \n",
      "        .   \\f[\\texttt{Sobel(src, dst, ddepth, dx, dy, FILTER_SCHARR, scale, delta, borderType)} .\\f]\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src.\n",
      "        .   @param ddepth output image depth, see @ref filter_depths \"combinations\"\n",
      "        .   @param dx order of the derivative x.\n",
      "        .   @param dy order of the derivative y.\n",
      "        .   @param scale optional scale factor for the computed derivative values; by default, no scaling is\n",
      "        .   applied (see #getDerivKernels for details).\n",
      "        .   @param delta optional delta value that is added to the results prior to storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   @sa  cartToPolar\n",
      "    \n",
      "    SimpleBlobDetector_create(...)\n",
      "        SimpleBlobDetector_create([, parameters]) -> retval\n",
      "        .\n",
      "    \n",
      "    Sobel(...)\n",
      "        Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
      "        .   @brief Calculates the first, second, third, or mixed image derivatives using an extended Sobel operator.\n",
      "        .   \n",
      "        .   In all cases except one, the \\f$\\texttt{ksize} \\times \\texttt{ksize}\\f$ separable kernel is used to\n",
      "        .   calculate the derivative. When \\f$\\texttt{ksize = 1}\\f$, the \\f$3 \\times 1\\f$ or \\f$1 \\times 3\\f$\n",
      "        .   kernel is used (that is, no Gaussian smoothing is done). `ksize = 1` can only be used for the first\n",
      "        .   or the second x- or y- derivatives.\n",
      "        .   \n",
      "        .   There is also the special value `ksize = #FILTER_SCHARR (-1)` that corresponds to the \\f$3\\times3\\f$ Scharr\n",
      "        .   filter that may give more accurate results than the \\f$3\\times3\\f$ Sobel. The Scharr aperture is\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-3}{0}{3}{-10}{0}{10}{-3}{0}{3}\\f]\n",
      "        .   \n",
      "        .   for the x-derivative, or transposed for the y-derivative.\n",
      "        .   \n",
      "        .   The function calculates an image derivative by convolving the image with the appropriate kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\frac{\\partial^{xorder+yorder} \\texttt{src}}{\\partial x^{xorder} \\partial y^{yorder}}\\f]\n",
      "        .   \n",
      "        .   The Sobel operators combine Gaussian smoothing and differentiation, so the result is more or less\n",
      "        .   resistant to the noise. Most often, the function is called with ( xorder = 1, yorder = 0, ksize = 3)\n",
      "        .   or ( xorder = 0, yorder = 1, ksize = 3) to calculate the first x- or y- image derivative. The first\n",
      "        .   case corresponds to a kernel of:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-1}{0}{1}{-2}{0}{2}{-1}{0}{1}\\f]\n",
      "        .   \n",
      "        .   The second case corresponds to a kernel of:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-1}{-2}{-1}{0}{0}{0}{1}{2}{1}\\f]\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth output image depth, see @ref filter_depths \"combinations\"; in the case of\n",
      "        .   8-bit input images it will result in truncated derivatives.\n",
      "        .   @param dx order of the derivative x.\n",
      "        .   @param dy order of the derivative y.\n",
      "        .   @param ksize size of the extended Sobel kernel; it must be 1, 3, 5, or 7.\n",
      "        .   @param scale optional scale factor for the computed derivative values; by default, no scaling is\n",
      "        .   applied (see #getDerivKernels for details).\n",
      "        .   @param delta optional delta value that is added to the results prior to storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   @sa  Scharr, Laplacian, sepFilter2D, filter2D, GaussianBlur, cartToPolar\n",
      "    \n",
      "    SparsePyrLKOpticalFlow_create(...)\n",
      "        SparsePyrLKOpticalFlow_create([, winSize[, maxLevel[, crit[, flags[, minEigThreshold]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    StereoBM_create(...)\n",
      "        StereoBM_create([, numDisparities[, blockSize]]) -> retval\n",
      "        .   @brief Creates StereoBM object\n",
      "        .   \n",
      "        .   @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "        .   disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "        .   shifted by changing the minimum disparity.\n",
      "        .   @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "        .   (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "        .   accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "        .   chance for algorithm to find a wrong correspondence.\n",
      "        .   \n",
      "        .   The function create StereoBM object. You can then call StereoBM::compute() to compute disparity for\n",
      "        .   a specific stereo pair.\n",
      "    \n",
      "    StereoSGBM_create(...)\n",
      "        StereoSGBM_create([, minDisparity[, numDisparities[, blockSize[, P1[, P2[, disp12MaxDiff[, preFilterCap[, uniquenessRatio[, speckleWindowSize[, speckleRange[, mode]]]]]]]]]]]) -> retval\n",
      "        .   @brief Creates StereoSGBM object\n",
      "        .   \n",
      "        .   @param minDisparity Minimum possible disparity value. Normally, it is zero but sometimes\n",
      "        .   rectification algorithms can shift images, so this parameter needs to be adjusted accordingly.\n",
      "        .   @param numDisparities Maximum disparity minus minimum disparity. The value is always greater than\n",
      "        .   zero. In the current implementation, this parameter must be divisible by 16.\n",
      "        .   @param blockSize Matched block size. It must be an odd number \\>=1 . Normally, it should be\n",
      "        .   somewhere in the 3..11 range.\n",
      "        .   @param P1 The first parameter controlling the disparity smoothness. See below.\n",
      "        .   @param P2 The second parameter controlling the disparity smoothness. The larger the values are,\n",
      "        .   the smoother the disparity is. P1 is the penalty on the disparity change by plus or minus 1\n",
      "        .   between neighbor pixels. P2 is the penalty on the disparity change by more than 1 between neighbor\n",
      "        .   pixels. The algorithm requires P2 \\> P1 . See stereo_match.cpp sample where some reasonably good\n",
      "        .   P1 and P2 values are shown (like 8\\*number_of_image_channels\\*SADWindowSize\\*SADWindowSize and\n",
      "        .   32\\*number_of_image_channels\\*SADWindowSize\\*SADWindowSize , respectively).\n",
      "        .   @param disp12MaxDiff Maximum allowed difference (in integer pixel units) in the left-right\n",
      "        .   disparity check. Set it to a non-positive value to disable the check.\n",
      "        .   @param preFilterCap Truncation value for the prefiltered image pixels. The algorithm first\n",
      "        .   computes x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap] interval.\n",
      "        .   The result values are passed to the Birchfield-Tomasi pixel cost function.\n",
      "        .   @param uniquenessRatio Margin in percentage by which the best (minimum) computed cost function\n",
      "        .   value should \"win\" the second best value to consider the found match correct. Normally, a value\n",
      "        .   within the 5-15 range is good enough.\n",
      "        .   @param speckleWindowSize Maximum size of smooth disparity regions to consider their noise speckles\n",
      "        .   and invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the\n",
      "        .   50-200 range.\n",
      "        .   @param speckleRange Maximum disparity variation within each connected component. If you do speckle\n",
      "        .   filtering, set the parameter to a positive value, it will be implicitly multiplied by 16.\n",
      "        .   Normally, 1 or 2 is good enough.\n",
      "        .   @param mode Set it to StereoSGBM::MODE_HH to run the full-scale two-pass dynamic programming\n",
      "        .   algorithm. It will consume O(W\\*H\\*numDisparities) bytes, which is large for 640x480 stereo and\n",
      "        .   huge for HD-size pictures. By default, it is set to false .\n",
      "        .   \n",
      "        .   The first constructor initializes StereoSGBM with all the default parameters. So, you only have to\n",
      "        .   set StereoSGBM::numDisparities at minimum. The second constructor enables you to set each parameter\n",
      "        .   to a custom value.\n",
      "    \n",
      "    Stitcher_create(...)\n",
      "        Stitcher_create([, mode]) -> retval\n",
      "        .   @brief Creates a Stitcher configured in one of the stitching modes.\n",
      "        .   \n",
      "        .   @param mode Scenario for stitcher operation. This is usually determined by source of images\n",
      "        .   to stitch and their transformation. Default parameters will be chosen for operation in given\n",
      "        .   scenario.\n",
      "        .   @return Stitcher class instance.\n",
      "    \n",
      "    UMat_context(...)\n",
      "        UMat_context() -> retval\n",
      "        .\n",
      "    \n",
      "    UMat_queue(...)\n",
      "        UMat_queue() -> retval\n",
      "        .\n",
      "    \n",
      "    VariationalRefinement_create(...)\n",
      "        VariationalRefinement_create() -> retval\n",
      "        .   @brief Creates an instance of VariationalRefinement\n",
      "    \n",
      "    VideoWriter_fourcc(...)\n",
      "        VideoWriter_fourcc(c1, c2, c3, c4) -> retval\n",
      "        .   @brief Concatenates 4 chars to a fourcc code\n",
      "        .   \n",
      "        .   @return a fourcc code\n",
      "        .   \n",
      "        .   This static method constructs the fourcc code of the codec to be used in the constructor\n",
      "        .   VideoWriter::VideoWriter or VideoWriter::open.\n",
      "    \n",
      "    absdiff(...)\n",
      "        absdiff(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates the per-element absolute difference between two arrays or between an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::absdiff calculates:\n",
      "        .   *   Absolute difference between two arrays when they have the same\n",
      "        .   size and type:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1}(I) -  \\texttt{src2}(I)|)\\f]\n",
      "        .   *   Absolute difference between an array and a scalar when the second\n",
      "        .   array is constructed from Scalar or has as many elements as the\n",
      "        .   number of channels in `src1`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1}(I) -  \\texttt{src2} |)\\f]\n",
      "        .   *   Absolute difference between a scalar and an array when the first\n",
      "        .   array is constructed from Scalar or has as many elements as the\n",
      "        .   number of channels in `src2`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1} -  \\texttt{src2}(I) |)\\f]\n",
      "        .   where I is a multi-dimensional index of array elements. In case of\n",
      "        .   multi-channel arrays, each channel is processed independently.\n",
      "        .   @note Saturation is not applied when the arrays have the depth CV_32S.\n",
      "        .   You may even get a negative value in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as input arrays.\n",
      "        .   @sa cv::abs(const Mat&)\n",
      "    \n",
      "    accumulate(...)\n",
      "        accumulate(src, dst[, mask]) -> dst\n",
      "        .   @brief Adds an image to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds src or some of its elements to dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   The function cv::accumulate can be used, for example, to collect statistics of a scene background\n",
      "        .   viewed by a still camera and for the further foreground-background segmentation.\n",
      "        .   \n",
      "        .   @param src Input image of type CV_8UC(n), CV_16UC(n), CV_32FC(n) or CV_64FC(n), where n is a positive integer.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, and a depth of CV_32F or CV_64F.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulateSquare, accumulateProduct, accumulateWeighted\n",
      "    \n",
      "    accumulateProduct(...)\n",
      "        accumulateProduct(src1, src2, dst[, mask]) -> dst\n",
      "        .   @brief Adds the per-element product of two input images to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds the product of two images or their selected regions to the accumulator dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src1} (x,y)  \\cdot \\texttt{src2} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src1 First input image, 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param src2 Second input image of the same type and the same size as src1 .\n",
      "        .   @param dst %Accumulator image with the same number of channels as input images, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulate, accumulateSquare, accumulateWeighted\n",
      "    \n",
      "    accumulateSquare(...)\n",
      "        accumulateSquare(src, dst[, mask]) -> dst\n",
      "        .   @brief Adds the square of a source image to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds the input image src or its selected region, raised to a power of 2, to the\n",
      "        .   accumulator dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src} (x,y)^2  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src Input image as 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulateSquare, accumulateProduct, accumulateWeighted\n",
      "    \n",
      "    accumulateWeighted(...)\n",
      "        accumulateWeighted(src, dst, alpha[, mask]) -> dst\n",
      "        .   @brief Updates a running average.\n",
      "        .   \n",
      "        .   The function calculates the weighted sum of the input image src and the accumulator dst so that dst\n",
      "        .   becomes a running average of a frame sequence:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow (1- \\texttt{alpha} )  \\cdot \\texttt{dst} (x,y) +  \\texttt{alpha} \\cdot \\texttt{src} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   That is, alpha regulates the update speed (how fast the accumulator \"forgets\" about earlier images).\n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src Input image as 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param alpha Weight of the input image.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulate, accumulateSquare, accumulateProduct\n",
      "    \n",
      "    adaptiveThreshold(...)\n",
      "        adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
      "        .   @brief Applies an adaptive threshold to an array.\n",
      "        .   \n",
      "        .   The function transforms a grayscale image to a binary image according to the formulae:\n",
      "        .   -   **THRESH_BINARY**\n",
      "        .   \\f[dst(x,y) =  \\fork{\\texttt{maxValue}}{if \\(src(x,y) > T(x,y)\\)}{0}{otherwise}\\f]\n",
      "        .   -   **THRESH_BINARY_INV**\n",
      "        .   \\f[dst(x,y) =  \\fork{0}{if \\(src(x,y) > T(x,y)\\)}{\\texttt{maxValue}}{otherwise}\\f]\n",
      "        .   where \\f$T(x,y)\\f$ is a threshold calculated individually for each pixel (see adaptiveMethod parameter).\n",
      "        .   \n",
      "        .   The function can process the image in-place.\n",
      "        .   \n",
      "        .   @param src Source 8-bit single-channel image.\n",
      "        .   @param dst Destination image of the same size and the same type as src.\n",
      "        .   @param maxValue Non-zero value assigned to the pixels for which the condition is satisfied\n",
      "        .   @param adaptiveMethod Adaptive thresholding algorithm to use, see #AdaptiveThresholdTypes.\n",
      "        .   The #BORDER_REPLICATE | #BORDER_ISOLATED is used to process boundaries.\n",
      "        .   @param thresholdType Thresholding type that must be either #THRESH_BINARY or #THRESH_BINARY_INV,\n",
      "        .   see #ThresholdTypes.\n",
      "        .   @param blockSize Size of a pixel neighborhood that is used to calculate a threshold value for the\n",
      "        .   pixel: 3, 5, 7, and so on.\n",
      "        .   @param C Constant subtracted from the mean or weighted mean (see the details below). Normally, it\n",
      "        .   is positive but may be zero or negative as well.\n",
      "        .   \n",
      "        .   @sa  threshold, blur, GaussianBlur\n",
      "    \n",
      "    add(...)\n",
      "        add(src1, src2[, dst[, mask[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element sum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function add calculates:\n",
      "        .   - Sum of two arrays when both input arrays have the same size and the same number of channels:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) +  \\texttt{src2}(I)) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Sum of an array and a scalar when src2 is constructed from Scalar or has the same number of\n",
      "        .   elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) +  \\texttt{src2} ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Sum of a scalar and an array when src1 is constructed from Scalar or has the same number of\n",
      "        .   elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1} +  \\texttt{src2}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   where `I` is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   The first function in the list above can be replaced with matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .   dst = src1 + src2;\n",
      "        .   dst += src1; // equivalent to add(dst, src1, dst);\n",
      "        .   @endcode\n",
      "        .   The input arrays and the output array can all have the same or different depths. For example, you\n",
      "        .   can add a 16-bit unsigned array to a 8-bit signed array and store the sum as a 32-bit\n",
      "        .   floating-point array. Depth of the output array is determined by the dtype parameter. In the second\n",
      "        .   and third cases above, as well as in the first case, when src1.depth() == src2.depth(), dtype can\n",
      "        .   be set to the default -1. In this case, the output array will have the same depth as the input\n",
      "        .   array, be it src1, src2 or both.\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and number of channels as the input array(s); the\n",
      "        .   depth is defined by dtype or src1/src2.\n",
      "        .   @param mask optional operation mask - 8-bit single channel array, that specifies elements of the\n",
      "        .   output array to be changed.\n",
      "        .   @param dtype optional depth of the output array (see the discussion below).\n",
      "        .   @sa subtract, addWeighted, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    addText(...)\n",
      "        addText(img, text, org, nameFont[, pointSize[, color[, weight[, style[, spacing]]]]]) -> None\n",
      "        .   @brief Draws a text on the image.\n",
      "        .   \n",
      "        .   @param img 8-bit 3-channel image where the text should be drawn.\n",
      "        .   @param text Text to write on an image.\n",
      "        .   @param org Point(x,y) where the text should start on an image.\n",
      "        .   @param nameFont Name of the font. The name should match the name of a system font (such as\n",
      "        .   *Times*). If the font is not found, a default one is used.\n",
      "        .   @param pointSize Size of the font. If not specified, equal zero or negative, the point size of the\n",
      "        .   font is set to a system-dependent default value. Generally, this is 12 points.\n",
      "        .   @param color Color of the font in BGRA where A = 255 is fully transparent.\n",
      "        .   @param weight Font weight. Available operation flags are : cv::QtFontWeights You can also specify a positive integer for better control.\n",
      "        .   @param style Font style. Available operation flags are : cv::QtFontStyles\n",
      "        .   @param spacing Spacing between characters. It can be negative or positive.\n",
      "    \n",
      "    addWeighted(...)\n",
      "        addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst\n",
      "        .   @brief Calculates the weighted sum of two arrays.\n",
      "        .   \n",
      "        .   The function addWeighted calculates the weighted sum of two arrays as follows:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{src1} (I)* \\texttt{alpha} +  \\texttt{src2} (I)* \\texttt{beta} +  \\texttt{gamma} )\\f]\n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   The function can be replaced with a matrix expression:\n",
      "        .   @code{.cpp}\n",
      "        .   dst = src1*alpha + src2*beta + gamma;\n",
      "        .   @endcode\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param alpha weight of the first array elements.\n",
      "        .   @param src2 second input array of the same size and channel number as src1.\n",
      "        .   @param beta weight of the second array elements.\n",
      "        .   @param gamma scalar added to each sum.\n",
      "        .   @param dst output array that has the same size and number of channels as the input arrays.\n",
      "        .   @param dtype optional depth of the output array; when both input arrays have the same depth, dtype\n",
      "        .   can be set to -1, which will be equivalent to src1.depth().\n",
      "        .   @sa  add, subtract, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    applyColorMap(...)\n",
      "        applyColorMap(src, colormap[, dst]) -> dst\n",
      "        .   @brief Applies a GNU Octave/MATLAB equivalent colormap on a given image.\n",
      "        .   \n",
      "        .   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n",
      "        .   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n",
      "        .   @param colormap The colormap to apply, see #ColormapTypes\n",
      "        \n",
      "        \n",
      "        \n",
      "        applyColorMap(src, userColor[, dst]) -> dst\n",
      "        .   @brief Applies a user colormap on a given image.\n",
      "        .   \n",
      "        .   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n",
      "        .   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n",
      "        .   @param userColor The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256\n",
      "    \n",
      "    approxPolyDP(...)\n",
      "        approxPolyDP(curve, epsilon, closed[, approxCurve]) -> approxCurve\n",
      "        .   @brief Approximates a polygonal curve(s) with the specified precision.\n",
      "        .   \n",
      "        .   The function cv::approxPolyDP approximates a curve or a polygon with another curve/polygon with less\n",
      "        .   vertices so that the distance between them is less or equal to the specified precision. It uses the\n",
      "        .   Douglas-Peucker algorithm <http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm>\n",
      "        .   \n",
      "        .   @param curve Input vector of a 2D point stored in std::vector or Mat\n",
      "        .   @param approxCurve Result of the approximation. The type should match the type of the input curve.\n",
      "        .   @param epsilon Parameter specifying the approximation accuracy. This is the maximum distance\n",
      "        .   between the original curve and its approximation.\n",
      "        .   @param closed If true, the approximated curve is closed (its first and last vertices are\n",
      "        .   connected). Otherwise, it is not closed.\n",
      "    \n",
      "    arcLength(...)\n",
      "        arcLength(curve, closed) -> retval\n",
      "        .   @brief Calculates a contour perimeter or a curve length.\n",
      "        .   \n",
      "        .   The function computes a curve length or a closed contour perimeter.\n",
      "        .   \n",
      "        .   @param curve Input vector of 2D points, stored in std::vector or Mat.\n",
      "        .   @param closed Flag indicating whether the curve is closed or not.\n",
      "    \n",
      "    arrowedLine(...)\n",
      "        arrowedLine(img, pt1, pt2, color[, thickness[, line_type[, shift[, tipLength]]]]) -> img\n",
      "        .   @brief Draws a arrow segment pointing from the first point to the second one.\n",
      "        .   \n",
      "        .   The function cv::arrowedLine draws an arrow between pt1 and pt2 points in the image. See also #line.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 The point the arrow starts from.\n",
      "        .   @param pt2 The point the arrow points to.\n",
      "        .   @param color Line color.\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param line_type Type of the line. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "        .   @param tipLength The length of the arrow tip in relation to the arrow length\n",
      "    \n",
      "    batchDistance(...)\n",
      "        batchDistance(src1, src2, dtype[, dist[, nidx[, normType[, K[, mask[, update[, crosscheck]]]]]]]) -> dist, nidx\n",
      "        .   @brief naive nearest neighbor finder\n",
      "        .   \n",
      "        .   see http://en.wikipedia.org/wiki/Nearest_neighbor_search\n",
      "        .   @todo document\n",
      "    \n",
      "    bilateralFilter(...)\n",
      "        bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) -> dst\n",
      "        .   @brief Applies the bilateral filter to an image.\n",
      "        .   \n",
      "        .   The function applies bilateral filtering to the input image, as described in\n",
      "        .   http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html\n",
      "        .   bilateralFilter can reduce unwanted noise very well while keeping edges fairly sharp. However, it is\n",
      "        .   very slow compared to most filters.\n",
      "        .   \n",
      "        .   _Sigma values_: For simplicity, you can set the 2 sigma values to be the same. If they are small (\\<\n",
      "        .   10), the filter will not have much effect, whereas if they are large (\\> 150), they will have a very\n",
      "        .   strong effect, making the image look \"cartoonish\".\n",
      "        .   \n",
      "        .   _Filter size_: Large filters (d \\> 5) are very slow, so it is recommended to use d=5 for real-time\n",
      "        .   applications, and perhaps d=9 for offline applications that need heavy noise filtering.\n",
      "        .   \n",
      "        .   This filter does not work inplace.\n",
      "        .   @param src Source 8-bit or floating-point, 1-channel or 3-channel image.\n",
      "        .   @param dst Destination image of the same size and type as src .\n",
      "        .   @param d Diameter of each pixel neighborhood that is used during filtering. If it is non-positive,\n",
      "        .   it is computed from sigmaSpace.\n",
      "        .   @param sigmaColor Filter sigma in the color space. A larger value of the parameter means that\n",
      "        .   farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting\n",
      "        .   in larger areas of semi-equal color.\n",
      "        .   @param sigmaSpace Filter sigma in the coordinate space. A larger value of the parameter means that\n",
      "        .   farther pixels will influence each other as long as their colors are close enough (see sigmaColor\n",
      "        .   ). When d\\>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is\n",
      "        .   proportional to sigmaSpace.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes\n",
      "    \n",
      "    bitwise_and(...)\n",
      "        bitwise_and(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief computes bitwise conjunction of the two arrays (dst = src1 & src2)\n",
      "        .   Calculates the per-element bit-wise conjunction of two arrays or an\n",
      "        .   array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_and calculates the per-element bit-wise logical conjunction for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\wedge \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\wedge \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\wedge \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the second and third cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_not(...)\n",
      "        bitwise_not(src[, dst[, mask]]) -> dst\n",
      "        .   @brief  Inverts every bit of an array.\n",
      "        .   \n",
      "        .   The function cv::bitwise_not calculates per-element bit-wise inversion of the input\n",
      "        .   array:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\neg \\texttt{src} (I)\\f]\n",
      "        .   In case of a floating-point input array, its machine-specific bit\n",
      "        .   representation (usually IEEE754-compliant) is used for the operation. In\n",
      "        .   case of multi-channel arrays, each channel is processed independently.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   array.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_or(...)\n",
      "        bitwise_or(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief Calculates the per-element bit-wise disjunction of two arrays or an\n",
      "        .   array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_or calculates the per-element bit-wise logical disjunction for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\vee \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\vee \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\vee \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the second and third cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_xor(...)\n",
      "        bitwise_xor(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief Calculates the per-element bit-wise \"exclusive or\" operation on two\n",
      "        .   arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_xor calculates the per-element bit-wise logical \"exclusive-or\"\n",
      "        .   operation for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\oplus \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\oplus \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .   the same number of elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\oplus \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the 2nd and 3rd cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    blur(...)\n",
      "        blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image using the normalized box filter.\n",
      "        .   \n",
      "        .   The function smooths an image using the kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{K} =  \\frac{1}{\\texttt{ksize.width*ksize.height}} \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   The call `blur(src, dst, ksize, anchor, borderType)` is equivalent to `boxFilter(src, dst, src.type(),\n",
      "        .   anchor, true, borderType)`.\n",
      "        .   \n",
      "        .   @param src input image; it can have any number of channels, which are processed independently, but\n",
      "        .   the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ksize blurring kernel size.\n",
      "        .   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes\n",
      "        .   @sa  boxFilter, bilateralFilter, GaussianBlur, medianBlur\n",
      "    \n",
      "    borderInterpolate(...)\n",
      "        borderInterpolate(p, len, borderType) -> retval\n",
      "        .   @brief Computes the source location of an extrapolated pixel.\n",
      "        .   \n",
      "        .   The function computes and returns the coordinate of a donor pixel corresponding to the specified\n",
      "        .   extrapolated pixel when using the specified extrapolation border mode. For example, if you use\n",
      "        .   cv::BORDER_WRAP mode in the horizontal direction, cv::BORDER_REFLECT_101 in the vertical direction and\n",
      "        .   want to compute value of the \"virtual\" pixel Point(-5, 100) in a floating-point image img , it\n",
      "        .   looks like:\n",
      "        .   @code{.cpp}\n",
      "        .   float val = img.at<float>(borderInterpolate(100, img.rows, cv::BORDER_REFLECT_101),\n",
      "        .   borderInterpolate(-5, img.cols, cv::BORDER_WRAP));\n",
      "        .   @endcode\n",
      "        .   Normally, the function is not called directly. It is used inside filtering functions and also in\n",
      "        .   copyMakeBorder.\n",
      "        .   @param p 0-based coordinate of the extrapolated pixel along one of the axes, likely \\<0 or \\>= len\n",
      "        .   @param len Length of the array along the corresponding axis.\n",
      "        .   @param borderType Border type, one of the #BorderTypes, except for #BORDER_TRANSPARENT and\n",
      "        .   #BORDER_ISOLATED . When borderType==#BORDER_CONSTANT , the function always returns -1, regardless\n",
      "        .   of p and len.\n",
      "        .   \n",
      "        .   @sa copyMakeBorder\n",
      "    \n",
      "    boundingRect(...)\n",
      "        boundingRect(array) -> retval\n",
      "        .   @brief Calculates the up-right bounding rectangle of a point set or non-zero pixels of gray-scale image.\n",
      "        .   \n",
      "        .   The function calculates and returns the minimal up-right bounding rectangle for the specified point set or\n",
      "        .   non-zero pixels of gray-scale image.\n",
      "        .   \n",
      "        .   @param array Input gray-scale image or 2D point set, stored in std::vector or Mat.\n",
      "    \n",
      "    boxFilter(...)\n",
      "        boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
      "        .   @brief Blurs an image using the box filter.\n",
      "        .   \n",
      "        .   The function smooths an image using the kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{K} =  \\alpha \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\alpha = \\fork{\\frac{1}{\\texttt{ksize.width*ksize.height}}}{when \\texttt{normalize=true}}{1}{otherwise}\\f]\n",
      "        .   \n",
      "        .   Unnormalized box filter is useful for computing various integral characteristics over each pixel\n",
      "        .   neighborhood, such as covariance matrices of image derivatives (used in dense optical flow\n",
      "        .   algorithms, and so on). If you need to compute pixel sums over variable-size windows, use #integral.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ddepth the output image depth (-1 to use src.depth()).\n",
      "        .   @param ksize blurring kernel size.\n",
      "        .   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param normalize flag, specifying whether the kernel is normalized by its area or not.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes\n",
      "        .   @sa  blur, bilateralFilter, GaussianBlur, medianBlur, integral\n",
      "    \n",
      "    boxPoints(...)\n",
      "        boxPoints(box[, points]) -> points\n",
      "        .   @brief Finds the four vertices of a rotated rect. Useful to draw the rotated rectangle.\n",
      "        .   \n",
      "        .   The function finds the four vertices of a rotated rectangle. This function is useful to draw the\n",
      "        .   rectangle. In C++, instead of using this function, you can directly use RotatedRect::points method. Please\n",
      "        .   visit the @ref tutorial_bounding_rotated_ellipses \"tutorial on Creating Bounding rotated boxes and ellipses for contours\" for more information.\n",
      "        .   \n",
      "        .   @param box The input rotated rectangle. It may be the output of\n",
      "        .   @param points The output array of four vertices of rectangles.\n",
      "    \n",
      "    buildOpticalFlowPyramid(...)\n",
      "        buildOpticalFlowPyramid(img, winSize, maxLevel[, pyramid[, withDerivatives[, pyrBorder[, derivBorder[, tryReuseInputImage]]]]]) -> retval, pyramid\n",
      "        .   @brief Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.\n",
      "        .   \n",
      "        .   @param img 8-bit input image.\n",
      "        .   @param pyramid output pyramid.\n",
      "        .   @param winSize window size of optical flow algorithm. Must be not less than winSize argument of\n",
      "        .   calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.\n",
      "        .   @param maxLevel 0-based maximal pyramid level number.\n",
      "        .   @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is\n",
      "        .   constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.\n",
      "        .   @param pyrBorder the border mode for pyramid layers.\n",
      "        .   @param derivBorder the border mode for gradients.\n",
      "        .   @param tryReuseInputImage put ROI of input image into the pyramid if possible. You can pass false\n",
      "        .   to force data copying.\n",
      "        .   @return number of levels in constructed pyramid. Can be less than maxLevel.\n",
      "    \n",
      "    calcBackProject(...)\n",
      "        calcBackProject(images, channels, hist, ranges, scale[, dst]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcCovarMatrix(...)\n",
      "        calcCovarMatrix(samples, mean, flags[, covar[, ctype]]) -> covar, mean\n",
      "        .   @overload\n",
      "        .   @note use #COVAR_ROWS or #COVAR_COLS flag\n",
      "        .   @param samples samples stored as rows/columns of a single matrix.\n",
      "        .   @param covar output covariance matrix of the type ctype and square size.\n",
      "        .   @param mean input or output (depending on the flags) array as the average value of the input vectors.\n",
      "        .   @param flags operation flags as a combination of #CovarFlags\n",
      "        .   @param ctype type of the matrixl; it equals 'CV_64F' by default.\n",
      "    \n",
      "    calcHist(...)\n",
      "        calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) -> hist\n",
      "        .   @overload\n",
      "    \n",
      "    calcOpticalFlowFarneback(...)\n",
      "        calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
      "        .   @brief Computes a dense optical flow using the Gunnar Farneback's algorithm.\n",
      "        .   \n",
      "        .   @param prev first 8-bit single-channel input image.\n",
      "        .   @param next second input image of the same size and the same type as prev.\n",
      "        .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "        .   @param pyr_scale parameter, specifying the image scale (\\<1) to build pyramids for each image;\n",
      "        .   pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous\n",
      "        .   one.\n",
      "        .   @param levels number of pyramid layers including the initial image; levels=1 means that no extra\n",
      "        .   layers are created and only the original images are used.\n",
      "        .   @param winsize averaging window size; larger values increase the algorithm robustness to image\n",
      "        .   noise and give more chances for fast motion detection, but yield more blurred motion field.\n",
      "        .   @param iterations number of iterations the algorithm does at each pyramid level.\n",
      "        .   @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;\n",
      "        .   larger values mean that the image will be approximated with smoother surfaces, yielding more\n",
      "        .   robust algorithm and more blurred motion field, typically poly_n =5 or 7.\n",
      "        .   @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a\n",
      "        .   basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a\n",
      "        .   good value would be poly_sigma=1.5.\n",
      "        .   @param flags operation flags that can be a combination of the following:\n",
      "        .   -   **OPTFLOW_USE_INITIAL_FLOW** uses the input flow as an initial flow approximation.\n",
      "        .   -   **OPTFLOW_FARNEBACK_GAUSSIAN** uses the Gaussian \\f$\\texttt{winsize}\\times\\texttt{winsize}\\f$\n",
      "        .   filter instead of a box filter of the same size for optical flow estimation; usually, this\n",
      "        .   option gives z more accurate flow than with a box filter, at the cost of lower speed;\n",
      "        .   normally, winsize for a Gaussian window should be set to a larger value to achieve the same\n",
      "        .   level of robustness.\n",
      "        .   \n",
      "        .   The function finds an optical flow for each prev pixel using the @cite Farneback2003 algorithm so that\n",
      "        .   \n",
      "        .   \\f[\\texttt{prev} (y,x)  \\sim \\texttt{next} ( y + \\texttt{flow} (y,x)[1],  x + \\texttt{flow} (y,x)[0])\\f]\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   An example using the optical flow algorithm described by Gunnar Farneback can be found at\n",
      "        .   opencv_source_code/samples/cpp/fback.cpp\n",
      "        .   -   (Python) An example using the optical flow algorithm described by Gunnar Farneback can be\n",
      "        .   found at opencv_source_code/samples/python/opt_flow.py\n",
      "    \n",
      "    calcOpticalFlowPyrLK(...)\n",
      "        calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts[, status[, err[, winSize[, maxLevel[, criteria[, flags[, minEigThreshold]]]]]]]) -> nextPts, status, err\n",
      "        .   @brief Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with\n",
      "        .   pyramids.\n",
      "        .   \n",
      "        .   @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.\n",
      "        .   @param nextImg second input image or pyramid of the same size and the same type as prevImg.\n",
      "        .   @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be\n",
      "        .   single-precision floating-point numbers.\n",
      "        .   @param nextPts output vector of 2D points (with single-precision floating-point coordinates)\n",
      "        .   containing the calculated new positions of input features in the second image; when\n",
      "        .   OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.\n",
      "        .   @param status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
      "        .   the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
      "        .   @param err output vector of errors; each element of the vector is set to an error for the\n",
      "        .   corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't\n",
      "        .   found then the error is not defined (use the status parameter to find such cases).\n",
      "        .   @param winSize size of the search window at each pyramid level.\n",
      "        .   @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single\n",
      "        .   level), if set to 1, two levels are used, and so on; if pyramids are passed to input then\n",
      "        .   algorithm will use as many levels as pyramids have but no more than maxLevel.\n",
      "        .   @param criteria parameter, specifying the termination criteria of the iterative search algorithm\n",
      "        .   (after the specified maximum number of iterations criteria.maxCount or when the search window\n",
      "        .   moves by less than criteria.epsilon.\n",
      "        .   @param flags operation flags:\n",
      "        .   -   **OPTFLOW_USE_INITIAL_FLOW** uses initial estimations, stored in nextPts; if the flag is\n",
      "        .   not set, then prevPts is copied to nextPts and is considered the initial estimate.\n",
      "        .   -   **OPTFLOW_LK_GET_MIN_EIGENVALS** use minimum eigen values as an error measure (see\n",
      "        .   minEigThreshold description); if the flag is not set, then L1 distance between patches\n",
      "        .   around the original and a moved point, divided by number of pixels in a window, is used as a\n",
      "        .   error measure.\n",
      "        .   @param minEigThreshold the algorithm calculates the minimum eigen value of a 2x2 normal matrix of\n",
      "        .   optical flow equations (this matrix is called a spatial gradient matrix in @cite Bouguet00), divided\n",
      "        .   by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding\n",
      "        .   feature is filtered out and its flow is not processed, so it allows to remove bad points and get a\n",
      "        .   performance boost.\n",
      "        .   \n",
      "        .   The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See\n",
      "        .   @cite Bouguet00 . The function is parallelized with the TBB library.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "        .   opencv_source_code/samples/cpp/lkdemo.cpp\n",
      "        .   -   (Python) An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "        .   opencv_source_code/samples/python/lk_track.py\n",
      "        .   -   (Python) An example using the Lucas-Kanade tracker for homography matching can be found at\n",
      "        .   opencv_source_code/samples/python/lk_homography.py\n",
      "    \n",
      "    calibrateCamera(...)\n",
      "        calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs\n",
      "        .   @overload\n",
      "    \n",
      "    calibrateCameraExtended(...)\n",
      "        calibrateCameraExtended(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n",
      "        .   @brief Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.\n",
      "        .   \n",
      "        .   @param objectPoints In the new interface it is a vector of vectors of calibration pattern points in\n",
      "        .   the calibration pattern coordinate space (e.g. std::vector<std::vector<cv::Vec3f>>). The outer\n",
      "        .   vector contains as many elements as the number of the pattern views. If the same calibration pattern\n",
      "        .   is shown in each view and it is fully visible, all the vectors will be the same. Although, it is\n",
      "        .   possible to use partially occluded patterns, or even different patterns in different views. Then,\n",
      "        .   the vectors will be different. The points are 3D, but since they are in a pattern coordinate system,\n",
      "        .   then, if the rig is planar, it may make sense to put the model to a XY coordinate plane so that\n",
      "        .   Z-coordinate of each input object point is 0.\n",
      "        .   In the old interface all the vectors of object points from different views are concatenated\n",
      "        .   together.\n",
      "        .   @param imagePoints In the new interface it is a vector of vectors of the projections of calibration\n",
      "        .   pattern points (e.g. std::vector<std::vector<cv::Vec2f>>). imagePoints.size() and\n",
      "        .   objectPoints.size() and imagePoints[i].size() must be equal to objectPoints[i].size() for each i.\n",
      "        .   In the old interface all the vectors of object points from different views are concatenated\n",
      "        .   together.\n",
      "        .   @param imageSize Size of the image used only to initialize the intrinsic camera matrix.\n",
      "        .   @param cameraMatrix Output 3x3 floating-point camera matrix\n",
      "        .   \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ . If CV\\_CALIB\\_USE\\_INTRINSIC\\_GUESS\n",
      "        .   and/or CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be\n",
      "        .   initialized before calling the function.\n",
      "        .   @param distCoeffs Output vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements.\n",
      "        .   @param rvecs Output vector of rotation vectors (see Rodrigues ) estimated for each pattern view\n",
      "        .   (e.g. std::vector<cv::Mat>>). That is, each k-th rotation vector together with the corresponding\n",
      "        .   k-th translation vector (see the next output parameter description) brings the calibration pattern\n",
      "        .   from the model coordinate space (in which object points are specified) to the world coordinate\n",
      "        .   space, that is, a real position of the calibration pattern in the k-th pattern view (k=0.. *M* -1).\n",
      "        .   @param tvecs Output vector of translation vectors estimated for each pattern view.\n",
      "        .   @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic parameters.\n",
      "        .   Order of deviations values:\n",
      "        .   \\f$(f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\n",
      "        .   s_4, \\tau_x, \\tau_y)\\f$ If one of parameters is not estimated, it's deviation is equals to zero.\n",
      "        .   @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic parameters.\n",
      "        .   Order of deviations values: \\f$(R_1, T_1, \\dotsc , R_M, T_M)\\f$ where M is number of pattern views,\n",
      "        .   \\f$R_i, T_i\\f$ are concatenated 1x3 vectors.\n",
      "        .   @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of the following values:\n",
      "        .   -   **CALIB_USE_INTRINSIC_GUESS** cameraMatrix contains valid initial values of\n",
      "        .   fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially set to the image\n",
      "        .   center ( imageSize is used), and focal distances are computed in a least-squares fashion.\n",
      "        .   Note, that if intrinsic parameters are known, there is no need to use this function just to\n",
      "        .   estimate extrinsic parameters. Use solvePnP instead.\n",
      "        .   -   **CALIB_FIX_PRINCIPAL_POINT** The principal point is not changed during the global\n",
      "        .   optimization. It stays at the center or at a different location specified when\n",
      "        .   CALIB_USE_INTRINSIC_GUESS is set too.\n",
      "        .   -   **CALIB_FIX_ASPECT_RATIO** The functions considers only fy as a free parameter. The\n",
      "        .   ratio fx/fy stays the same as in the input cameraMatrix . When\n",
      "        .   CALIB_USE_INTRINSIC_GUESS is not set, the actual input values of fx and fy are\n",
      "        .   ignored, only their ratio is computed and used further.\n",
      "        .   -   **CALIB_ZERO_TANGENT_DIST** Tangential distortion coefficients \\f$(p_1, p_2)\\f$ are set\n",
      "        .   to zeros and stay zero.\n",
      "        .   -   **CALIB_FIX_K1,...,CALIB_FIX_K6** The corresponding radial distortion\n",
      "        .   coefficient is not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is\n",
      "        .   set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_RATIONAL_MODEL** Coefficients k4, k5, and k6 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the rational model and return 8 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_THIN_PRISM_MODEL** Coefficients s1, s2, s3 and s4 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the thin prism model and return 12 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_S1_S2_S3_S4** The thin prism distortion coefficients are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_TILTED_MODEL** Coefficients tauX and tauY are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the tilted sensor model and return 14 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_TAUX_TAUY** The coefficients of the tilted sensor model are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   @return the overall RMS re-projection error.\n",
      "        .   \n",
      "        .   The function estimates the intrinsic camera parameters and extrinsic parameters for each of the\n",
      "        .   views. The algorithm is based on @cite Zhang2000 and @cite BouguetMCT . The coordinates of 3D object\n",
      "        .   points and their corresponding 2D projections in each view must be specified. That may be achieved\n",
      "        .   by using an object with a known geometry and easily detectable feature points. Such an object is\n",
      "        .   called a calibration rig or calibration pattern, and OpenCV has built-in support for a chessboard as\n",
      "        .   a calibration rig (see findChessboardCorners ). Currently, initialization of intrinsic parameters\n",
      "        .   (when CALIB_USE_INTRINSIC_GUESS is not set) is only implemented for planar calibration\n",
      "        .   patterns (where Z-coordinates of the object points must be all zeros). 3D calibration rigs can also\n",
      "        .   be used as long as initial cameraMatrix is provided.\n",
      "        .   \n",
      "        .   The algorithm performs the following steps:\n",
      "        .   \n",
      "        .   -   Compute the initial intrinsic parameters (the option only available for planar calibration\n",
      "        .   patterns) or read them from the input parameters. The distortion coefficients are all set to\n",
      "        .   zeros initially unless some of CALIB_FIX_K? are specified.\n",
      "        .   \n",
      "        .   -   Estimate the initial camera pose as if the intrinsic parameters have been already known. This is\n",
      "        .   done using solvePnP .\n",
      "        .   \n",
      "        .   -   Run the global Levenberg-Marquardt optimization algorithm to minimize the reprojection error,\n",
      "        .   that is, the total sum of squared distances between the observed feature points imagePoints and\n",
      "        .   the projected (using the current estimates for camera parameters and the poses) object points\n",
      "        .   objectPoints. See projectPoints for details.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   If you use a non-square (=non-NxN) grid and findChessboardCorners for calibration, and\n",
      "        .   calibrateCamera returns bad values (zero distortion coefficients, an image center very far from\n",
      "        .   (w/2-0.5,h/2-0.5), and/or large differences between \\f$f_x\\f$ and \\f$f_y\\f$ (ratios of 10:1 or more)),\n",
      "        .   then you have probably used patternSize=cvSize(rows,cols) instead of using\n",
      "        .   patternSize=cvSize(cols,rows) in findChessboardCorners .\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   calibrateCameraRO, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate, undistort\n",
      "    \n",
      "    calibrateCameraRO(...)\n",
      "        calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, flags[, criteria]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints\n",
      "        .   @overload\n",
      "    \n",
      "    calibrateCameraROExtended(...)\n",
      "        calibrateCameraROExtended(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, stdDeviationsObjPoints[, perViewErrors[, flags[, criteria]]]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors\n",
      "        .   @brief Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.\n",
      "        .   \n",
      "        .   This function is an extension of calibrateCamera() with the method of releasing object which was\n",
      "        .   proposed in @cite strobl2011iccv. In many common cases with inaccurate, unmeasured, roughly planar\n",
      "        .   targets (calibration plates), this method can dramatically improve the precision of the estimated\n",
      "        .   camera parameters. Both the object-releasing method and standard method are supported by this\n",
      "        .   function. Use the parameter **iFixedPoint** for method selection. In the internal implementation,\n",
      "        .   calibrateCamera() is a wrapper for this function.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of calibration pattern points in the calibration pattern\n",
      "        .   coordinate space. See calibrateCamera() for details. If the method of releasing object to be used,\n",
      "        .   the identical calibration board must be used in each view and it must be fully visible, and all\n",
      "        .   objectPoints[i] must be the same and all points should be roughly close to a plane. **The calibration\n",
      "        .   target has to be rigid, or at least static if the camera (rather than the calibration target) is\n",
      "        .   shifted for grabbing images.**\n",
      "        .   @param imagePoints Vector of vectors of the projections of calibration pattern points. See\n",
      "        .   calibrateCamera() for details.\n",
      "        .   @param imageSize Size of the image used only to initialize the intrinsic camera matrix.\n",
      "        .   @param iFixedPoint The index of the 3D object point in objectPoints[0] to be fixed. It also acts as\n",
      "        .   a switch for calibration method selection. If object-releasing method to be used, pass in the\n",
      "        .   parameter in the range of [1, objectPoints[0].size()-2], otherwise a value out of this range will\n",
      "        .   make standard calibration method selected. Usually the top-right corner point of the calibration\n",
      "        .   board grid is recommended to be fixed when object-releasing method being utilized. According to\n",
      "        .   \\cite strobl2011iccv, two other points are also fixed. In this implementation, objectPoints[0].front\n",
      "        .   and objectPoints[0].back.z are used. With object-releasing method, accurate rvecs, tvecs and\n",
      "        .   newObjPoints are only possible if coordinates of these three fixed points are accurate enough.\n",
      "        .   @param cameraMatrix Output 3x3 floating-point camera matrix. See calibrateCamera() for details.\n",
      "        .   @param distCoeffs Output vector of distortion coefficients. See calibrateCamera() for details.\n",
      "        .   @param rvecs Output vector of rotation vectors estimated for each pattern view. See calibrateCamera()\n",
      "        .   for details.\n",
      "        .   @param tvecs Output vector of translation vectors estimated for each pattern view.\n",
      "        .   @param newObjPoints The updated output vector of calibration pattern points. The coordinates might\n",
      "        .   be scaled based on three fixed points. The returned coordinates are accurate only if the above\n",
      "        .   mentioned three fixed points are accurate. If not needed, noArray() can be passed in. This parameter\n",
      "        .   is ignored with standard calibration method.\n",
      "        .   @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic parameters.\n",
      "        .   See calibrateCamera() for details.\n",
      "        .   @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic parameters.\n",
      "        .   See calibrateCamera() for details.\n",
      "        .   @param stdDeviationsObjPoints Output vector of standard deviations estimated for refined coordinates\n",
      "        .   of calibration pattern points. It has the same size and order as objectPoints[0] vector. This\n",
      "        .   parameter is ignored with standard calibration method.\n",
      "        .   @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of some predefined values. See\n",
      "        .   calibrateCamera() for details. If the method of releasing object is used, the calibration time may\n",
      "        .   be much longer. CALIB_USE_QR or CALIB_USE_LU could be used for faster calibration with potentially\n",
      "        .   less precise and less stable in some rare cases.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   @return the overall RMS re-projection error.\n",
      "        .   \n",
      "        .   The function estimates the intrinsic camera parameters and extrinsic parameters for each of the\n",
      "        .   views. The algorithm is based on @cite Zhang2000, @cite BouguetMCT and @cite strobl2011iccv. See\n",
      "        .   calibrateCamera() for other detailed explanations.\n",
      "        .   @sa\n",
      "        .   calibrateCamera, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate, undistort\n",
      "    \n",
      "    calibrateHandEye(...)\n",
      "        calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam[, R_cam2gripper[, t_cam2gripper[, method]]]) -> R_cam2gripper, t_cam2gripper\n",
      "        .   @brief Computes Hand-Eye calibration: \\f$_{}^{g}\\textrm{T}_c\\f$\n",
      "        .   \n",
      "        .   @param[in] R_gripper2base Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the gripper frame to the robot base frame (\\f$_{}^{b}\\textrm{T}_g\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the rotation matrices for all the transformations\n",
      "        .   from gripper frame to robot base frame.\n",
      "        .   @param[in] t_gripper2base Translation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the gripper frame to the robot base frame (\\f$_{}^{b}\\textrm{T}_g\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the translation vectors for all the transformations\n",
      "        .   from gripper frame to robot base frame.\n",
      "        .   @param[in] R_target2cam Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the target frame to the camera frame (\\f$_{}^{c}\\textrm{T}_t\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the rotation matrices for all the transformations\n",
      "        .   from calibration target frame to camera frame.\n",
      "        .   @param[in] t_target2cam Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the target frame to the camera frame (\\f$_{}^{c}\\textrm{T}_t\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the translation vectors for all the transformations\n",
      "        .   from calibration target frame to camera frame.\n",
      "        .   @param[out] R_cam2gripper Estimated rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the camera frame to the gripper frame (\\f$_{}^{g}\\textrm{T}_c\\f$).\n",
      "        .   @param[out] t_cam2gripper Estimated translation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the camera frame to the gripper frame (\\f$_{}^{g}\\textrm{T}_c\\f$).\n",
      "        .   @param[in] method One of the implemented Hand-Eye calibration method, see cv::HandEyeCalibrationMethod\n",
      "        .   \n",
      "        .   The function performs the Hand-Eye calibration using various methods. One approach consists in estimating the\n",
      "        .   rotation then the translation (separable solutions) and the following methods are implemented:\n",
      "        .   - R. Tsai, R. Lenz A New Technique for Fully Autonomous and Efficient 3D Robotics Hand/EyeCalibration \\cite Tsai89\n",
      "        .   - F. Park, B. Martin Robot Sensor Calibration: Solving AX = XB on the Euclidean Group \\cite Park94\n",
      "        .   - R. Horaud, F. Dornaika Hand-Eye Calibration \\cite Horaud95\n",
      "        .   \n",
      "        .   Another approach consists in estimating simultaneously the rotation and the translation (simultaneous solutions),\n",
      "        .   with the following implemented method:\n",
      "        .   - N. Andreff, R. Horaud, B. Espiau On-line Hand-Eye Calibration \\cite Andreff99\n",
      "        .   - K. Daniilidis Hand-Eye Calibration Using Dual Quaternions \\cite Daniilidis98\n",
      "        .   \n",
      "        .   The following picture describes the Hand-Eye calibration problem where the transformation between a camera (\"eye\")\n",
      "        .   mounted on a robot gripper (\"hand\") has to be estimated.\n",
      "        .   \n",
      "        .   ![](pics/hand-eye_figure.png)\n",
      "        .   \n",
      "        .   The calibration procedure is the following:\n",
      "        .   - a static calibration pattern is used to estimate the transformation between the target frame\n",
      "        .   and the camera frame\n",
      "        .   - the robot gripper is moved in order to acquire several poses\n",
      "        .   - for each pose, the homogeneous transformation between the gripper frame and the robot base frame is recorded using for\n",
      "        .   instance the robot kinematics\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_b\\\\\n",
      "        .   Y_b\\\\\n",
      "        .   Z_b\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   _{}^{b}\\textrm{R}_g & _{}^{b}\\textrm{t}_g \\\\\n",
      "        .   0_{1 \\times 3} & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_g\\\\\n",
      "        .   Y_g\\\\\n",
      "        .   Z_g\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   - for each pose, the homogeneous transformation between the calibration target frame and the camera frame is recorded using\n",
      "        .   for instance a pose estimation method (PnP) from 2D-3D point correspondences\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_c\\\\\n",
      "        .   Y_c\\\\\n",
      "        .   Z_c\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   _{}^{c}\\textrm{R}_t & _{}^{c}\\textrm{t}_t \\\\\n",
      "        .   0_{1 \\times 3} & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_t\\\\\n",
      "        .   Y_t\\\\\n",
      "        .   Z_t\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The Hand-Eye calibration procedure returns the following homogeneous transformation\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_g\\\\\n",
      "        .   Y_g\\\\\n",
      "        .   Z_g\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   _{}^{g}\\textrm{R}_c & _{}^{g}\\textrm{t}_c \\\\\n",
      "        .   0_{1 \\times 3} & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_c\\\\\n",
      "        .   Y_c\\\\\n",
      "        .   Z_c\\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   This problem is also known as solving the \\f$\\mathbf{A}\\mathbf{X}=\\mathbf{X}\\mathbf{B}\\f$ equation:\n",
      "        .   \\f[\n",
      "        .   \\begin{align*}\n",
      "        .   ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(1)} &=\n",
      "        .   \\hspace{0.1em} ^{b}{\\textrm{T}_g}^{(2)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} \\\\\n",
      "        .   \n",
      "        .   (^{b}{\\textrm{T}_g}^{(2)})^{-1} \\hspace{0.2em} ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c &=\n",
      "        .   \\hspace{0.1em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} (^{c}{\\textrm{T}_t}^{(1)})^{-1} \\\\\n",
      "        .   \n",
      "        .   \\textrm{A}_i \\textrm{X} &= \\textrm{X} \\textrm{B}_i \\\\\n",
      "        .   \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   \\note\n",
      "        .   Additional information can be found on this [website](http://campar.in.tum.de/Chair/HandEyeCalibration).\n",
      "        .   \\note\n",
      "        .   A minimum of 2 motions with non parallel rotation axes are necessary to determine the hand-eye transformation.\n",
      "        .   So at least 3 different poses are required, but it is strongly recommended to use many more poses.\n",
      "    \n",
      "    calibrationMatrixValues(...)\n",
      "        calibrationMatrixValues(cameraMatrix, imageSize, apertureWidth, apertureHeight) -> fovx, fovy, focalLength, principalPoint, aspectRatio\n",
      "        .   @brief Computes useful camera characteristics from the camera matrix.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix that can be estimated by calibrateCamera or\n",
      "        .   stereoCalibrate .\n",
      "        .   @param imageSize Input image size in pixels.\n",
      "        .   @param apertureWidth Physical width in mm of the sensor.\n",
      "        .   @param apertureHeight Physical height in mm of the sensor.\n",
      "        .   @param fovx Output field of view in degrees along the horizontal sensor axis.\n",
      "        .   @param fovy Output field of view in degrees along the vertical sensor axis.\n",
      "        .   @param focalLength Focal length of the lens in mm.\n",
      "        .   @param principalPoint Principal point in mm.\n",
      "        .   @param aspectRatio \\f$f_y/f_x\\f$\n",
      "        .   \n",
      "        .   The function computes various useful camera characteristics from the previously estimated camera\n",
      "        .   matrix.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   Do keep in mind that the unity measure 'mm' stands for whatever unit of measure one chooses for\n",
      "        .   the chessboard pitch (it can thus be any value).\n",
      "    \n",
      "    cartToPolar(...)\n",
      "        cartToPolar(x, y[, magnitude[, angle[, angleInDegrees]]]) -> magnitude, angle\n",
      "        .   @brief Calculates the magnitude and angle of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::cartToPolar calculates either the magnitude, angle, or both\n",
      "        .   for every 2D vector (x(I),y(I)):\n",
      "        .   \\f[\\begin{array}{l} \\texttt{magnitude} (I)= \\sqrt{\\texttt{x}(I)^2+\\texttt{y}(I)^2} , \\\\ \\texttt{angle} (I)= \\texttt{atan2} ( \\texttt{y} (I), \\texttt{x} (I))[ \\cdot180 / \\pi ] \\end{array}\\f]\n",
      "        .   \n",
      "        .   The angles are calculated with accuracy about 0.3 degrees. For the point\n",
      "        .   (0,0), the angle is set to 0.\n",
      "        .   @param x array of x-coordinates; this must be a single-precision or\n",
      "        .   double-precision floating-point array.\n",
      "        .   @param y array of y-coordinates, that must have the same size and same type as x.\n",
      "        .   @param magnitude output array of magnitudes of the same size and type as x.\n",
      "        .   @param angle output array of angles that has the same size and type as\n",
      "        .   x; the angles are measured in radians (from 0 to 2\\*Pi) or in degrees (0 to 360 degrees).\n",
      "        .   @param angleInDegrees a flag, indicating whether the angles are measured\n",
      "        .   in radians (which is by default), or in degrees.\n",
      "        .   @sa Sobel, Scharr\n",
      "    \n",
      "    checkChessboard(...)\n",
      "        checkChessboard(img, size) -> retval\n",
      "        .\n",
      "    \n",
      "    checkHardwareSupport(...)\n",
      "        checkHardwareSupport(feature) -> retval\n",
      "        .   @brief Returns true if the specified feature is supported by the host hardware.\n",
      "        .   \n",
      "        .   The function returns true if the host hardware supports the specified feature. When user calls\n",
      "        .   setUseOptimized(false), the subsequent calls to checkHardwareSupport() will return false until\n",
      "        .   setUseOptimized(true) is called. This way user can dynamically switch on and off the optimized code\n",
      "        .   in OpenCV.\n",
      "        .   @param feature The feature of interest, one of cv::CpuFeatures\n",
      "    \n",
      "    checkRange(...)\n",
      "        checkRange(a[, quiet[, minVal[, maxVal]]]) -> retval, pos\n",
      "        .   @brief Checks every element of an input array for invalid values.\n",
      "        .   \n",
      "        .   The function cv::checkRange checks that every array element is neither NaN nor infinite. When minVal \\>\n",
      "        .   -DBL_MAX and maxVal \\< DBL_MAX, the function also checks that each value is between minVal and\n",
      "        .   maxVal. In case of multi-channel arrays, each channel is processed independently. If some values\n",
      "        .   are out of range, position of the first outlier is stored in pos (when pos != NULL). Then, the\n",
      "        .   function either returns false (when quiet=true) or throws an exception.\n",
      "        .   @param a input array.\n",
      "        .   @param quiet a flag, indicating whether the functions quietly return false when the array elements\n",
      "        .   are out of range or they throw an exception.\n",
      "        .   @param pos optional output parameter, when not NULL, must be a pointer to array of src.dims\n",
      "        .   elements.\n",
      "        .   @param minVal inclusive lower boundary of valid values range.\n",
      "        .   @param maxVal exclusive upper boundary of valid values range.\n",
      "    \n",
      "    circle(...)\n",
      "        circle(img, center, radius, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a circle.\n",
      "        .   \n",
      "        .   The function cv::circle draws a simple or filled circle with a given center and radius.\n",
      "        .   @param img Image where the circle is drawn.\n",
      "        .   @param center Center of the circle.\n",
      "        .   @param radius Radius of the circle.\n",
      "        .   @param color Circle color.\n",
      "        .   @param thickness Thickness of the circle outline, if positive. Negative values, like #FILLED,\n",
      "        .   mean that a filled circle is to be drawn.\n",
      "        .   @param lineType Type of the circle boundary. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the coordinates of the center and in the radius value.\n",
      "    \n",
      "    clipLine(...)\n",
      "        clipLine(imgRect, pt1, pt2) -> retval, pt1, pt2\n",
      "        .   @overload\n",
      "        .   @param imgRect Image rectangle.\n",
      "        .   @param pt1 First line point.\n",
      "        .   @param pt2 Second line point.\n",
      "    \n",
      "    colorChange(...)\n",
      "        colorChange(src, mask[, dst[, red_mul[, green_mul[, blue_mul]]]]) -> dst\n",
      "        .   @brief Given an original color image, two differently colored versions of this image can be mixed\n",
      "        .   seamlessly.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param red_mul R-channel multiply factor.\n",
      "        .   @param green_mul G-channel multiply factor.\n",
      "        .   @param blue_mul B-channel multiply factor.\n",
      "        .   \n",
      "        .   Multiplication factor is between .5 to 2.5.\n",
      "    \n",
      "    compare(...)\n",
      "        compare(src1, src2, cmpop[, dst]) -> dst\n",
      "        .   @brief Performs the per-element comparison of two arrays or an array and scalar value.\n",
      "        .   \n",
      "        .   The function compares:\n",
      "        .   *   Elements of two arrays when src1 and src2 have the same size:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\,\\texttt{cmpop}\\, \\texttt{src2} (I)\\f]\n",
      "        .   *   Elements of src1 with a scalar src2 when src2 is constructed from\n",
      "        .   Scalar or has a single element:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1}(I) \\,\\texttt{cmpop}\\,  \\texttt{src2}\\f]\n",
      "        .   *   src1 with elements of src2 when src1 is constructed from Scalar or\n",
      "        .   has a single element:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\,\\texttt{cmpop}\\, \\texttt{src2} (I)\\f]\n",
      "        .   When the comparison result is true, the corresponding element of output\n",
      "        .   array is set to 255. The comparison operations can be replaced with the\n",
      "        .   equivalent matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .   Mat dst1 = src1 >= src2;\n",
      "        .   Mat dst2 = src1 < 8;\n",
      "        .   ...\n",
      "        .   @endcode\n",
      "        .   @param src1 first input array or a scalar; when it is an array, it must have a single channel.\n",
      "        .   @param src2 second input array or a scalar; when it is an array, it must have a single channel.\n",
      "        .   @param dst output array of type ref CV_8U that has the same size and the same number of channels as\n",
      "        .   the input arrays.\n",
      "        .   @param cmpop a flag, that specifies correspondence between the arrays (cv::CmpTypes)\n",
      "        .   @sa checkRange, min, max, threshold\n",
      "    \n",
      "    compareHist(...)\n",
      "        compareHist(H1, H2, method) -> retval\n",
      "        .   @brief Compares two histograms.\n",
      "        .   \n",
      "        .   The function cv::compareHist compares two dense or two sparse histograms using the specified method.\n",
      "        .   \n",
      "        .   The function returns \\f$d(H_1, H_2)\\f$ .\n",
      "        .   \n",
      "        .   While the function works well with 1-, 2-, 3-dimensional dense histograms, it may not be suitable\n",
      "        .   for high-dimensional sparse histograms. In such histograms, because of aliasing and sampling\n",
      "        .   problems, the coordinates of non-zero histogram bins can slightly shift. To compare such histograms\n",
      "        .   or more general sparse configurations of weighted points, consider using the #EMD function.\n",
      "        .   \n",
      "        .   @param H1 First compared histogram.\n",
      "        .   @param H2 Second compared histogram of the same size as H1 .\n",
      "        .   @param method Comparison method, see #HistCompMethods\n",
      "    \n",
      "    completeSymm(...)\n",
      "        completeSymm(m[, lowerToUpper]) -> m\n",
      "        .   @brief Copies the lower or the upper half of a square matrix to its another half.\n",
      "        .   \n",
      "        .   The function cv::completeSymm copies the lower or the upper half of a square matrix to\n",
      "        .   its another half. The matrix diagonal remains unchanged:\n",
      "        .   - \\f$\\texttt{m}_{ij}=\\texttt{m}_{ji}\\f$ for \\f$i > j\\f$ if\n",
      "        .   lowerToUpper=false\n",
      "        .   - \\f$\\texttt{m}_{ij}=\\texttt{m}_{ji}\\f$ for \\f$i < j\\f$ if\n",
      "        .   lowerToUpper=true\n",
      "        .   \n",
      "        .   @param m input-output floating-point square matrix.\n",
      "        .   @param lowerToUpper operation flag; if true, the lower half is copied to\n",
      "        .   the upper half. Otherwise, the upper half is copied to the lower half.\n",
      "        .   @sa flip, transpose\n",
      "    \n",
      "    composeRT(...)\n",
      "        composeRT(rvec1, tvec1, rvec2, tvec2[, rvec3[, tvec3[, dr3dr1[, dr3dt1[, dr3dr2[, dr3dt2[, dt3dr1[, dt3dt1[, dt3dr2[, dt3dt2]]]]]]]]]]) -> rvec3, tvec3, dr3dr1, dr3dt1, dr3dr2, dr3dt2, dt3dr1, dt3dt1, dt3dr2, dt3dt2\n",
      "        .   @brief Combines two rotation-and-shift transformations.\n",
      "        .   \n",
      "        .   @param rvec1 First rotation vector.\n",
      "        .   @param tvec1 First translation vector.\n",
      "        .   @param rvec2 Second rotation vector.\n",
      "        .   @param tvec2 Second translation vector.\n",
      "        .   @param rvec3 Output rotation vector of the superposition.\n",
      "        .   @param tvec3 Output translation vector of the superposition.\n",
      "        .   @param dr3dr1\n",
      "        .   @param dr3dt1\n",
      "        .   @param dr3dr2\n",
      "        .   @param dr3dt2\n",
      "        .   @param dt3dr1\n",
      "        .   @param dt3dt1\n",
      "        .   @param dt3dr2\n",
      "        .   @param dt3dt2 Optional output derivatives of rvec3 or tvec3 with regard to rvec1, rvec2, tvec1 and\n",
      "        .   tvec2, respectively.\n",
      "        .   \n",
      "        .   The functions compute:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\texttt{rvec3} =  \\mathrm{rodrigues} ^{-1} \\left ( \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\mathrm{rodrigues} ( \\texttt{rvec1} ) \\right )  \\\\ \\texttt{tvec3} =  \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\texttt{tvec1} +  \\texttt{tvec2} \\end{array} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$\\mathrm{rodrigues}\\f$ denotes a rotation vector to a rotation matrix transformation, and\n",
      "        .   \\f$\\mathrm{rodrigues}^{-1}\\f$ denotes the inverse transformation. See Rodrigues for details.\n",
      "        .   \n",
      "        .   Also, the functions can compute the derivatives of the output vectors with regards to the input\n",
      "        .   vectors (see matMulDeriv ). The functions are used inside stereoCalibrate but can also be used in\n",
      "        .   your own code where Levenberg-Marquardt or another gradient-based solver is used to optimize a\n",
      "        .   function that contains a matrix multiplication.\n",
      "    \n",
      "    computeCorrespondEpilines(...)\n",
      "        computeCorrespondEpilines(points, whichImage, F[, lines]) -> lines\n",
      "        .   @brief For points in an image of a stereo pair, computes the corresponding epilines in the other image.\n",
      "        .   \n",
      "        .   @param points Input points. \\f$N \\times 1\\f$ or \\f$1 \\times N\\f$ matrix of type CV_32FC2 or\n",
      "        .   vector\\<Point2f\\> .\n",
      "        .   @param whichImage Index of the image (1 or 2) that contains the points .\n",
      "        .   @param F Fundamental matrix that can be estimated using findFundamentalMat or stereoRectify .\n",
      "        .   @param lines Output vector of the epipolar lines corresponding to the points in the other image.\n",
      "        .   Each line \\f$ax + by + c=0\\f$ is encoded by 3 numbers \\f$(a, b, c)\\f$ .\n",
      "        .   \n",
      "        .   For every point in one of the two images of a stereo pair, the function finds the equation of the\n",
      "        .   corresponding epipolar line in the other image.\n",
      "        .   \n",
      "        .   From the fundamental matrix definition (see findFundamentalMat ), line \\f$l^{(2)}_i\\f$ in the second\n",
      "        .   image for the point \\f$p^{(1)}_i\\f$ in the first image (when whichImage=1 ) is computed as:\n",
      "        .   \n",
      "        .   \\f[l^{(2)}_i = F p^{(1)}_i\\f]\n",
      "        .   \n",
      "        .   And vice versa, when whichImage=2, \\f$l^{(1)}_i\\f$ is computed from \\f$p^{(2)}_i\\f$ as:\n",
      "        .   \n",
      "        .   \\f[l^{(1)}_i = F^T p^{(2)}_i\\f]\n",
      "        .   \n",
      "        .   Line coefficients are defined up to a scale. They are normalized so that \\f$a_i^2+b_i^2=1\\f$ .\n",
      "    \n",
      "    computeECC(...)\n",
      "        computeECC(templateImage, inputImage[, inputMask]) -> retval\n",
      "        .   @brief Computes the Enhanced Correlation Coefficient value between two images @cite EP08 .\n",
      "        .   \n",
      "        .   @param templateImage single-channel template image; CV_8U or CV_32F array.\n",
      "        .   @param inputImage single-channel input image to be warped to provide an image similar to\n",
      "        .   templateImage, same type as templateImage.\n",
      "        .   @param inputMask An optional mask to indicate valid values of inputImage.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   findTransformECC\n",
      "    \n",
      "    connectedComponents(...)\n",
      "        connectedComponents(image[, labels[, connectivity[, ltype]]]) -> retval, labels\n",
      "        .   @overload\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "    \n",
      "    connectedComponentsWithAlgorithm(...)\n",
      "        connectedComponentsWithAlgorithm(image, connectivity, ltype, ccltype[, labels]) -> retval, labels\n",
      "        .   @brief computes the connected components labeled image of boolean image\n",
      "        .   \n",
      "        .   image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0\n",
      "        .   represents the background label. ltype specifies the output label image type, an important\n",
      "        .   consideration based on the total number of labels or alternatively the total number of pixels in\n",
      "        .   the source image. ccltype specifies the connected components labeling algorithm to use, currently\n",
      "        .   Grana (BBDT) and Wu's (SAUF) algorithms are supported, see the #ConnectedComponentsAlgorithmsTypes\n",
      "        .   for details. Note that SAUF algorithm forces a row major ordering of labels while BBDT does not.\n",
      "        .   This function uses parallel version of both Grana and Wu's algorithms if at least one allowed\n",
      "        .   parallel framework is enabled and if the rows of the image are at least twice the number returned by #getNumberOfCPUs.\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "        .   @param ccltype connected components algorithm type (see the #ConnectedComponentsAlgorithmsTypes).\n",
      "    \n",
      "    connectedComponentsWithStats(...)\n",
      "        connectedComponentsWithStats(image[, labels[, stats[, centroids[, connectivity[, ltype]]]]]) -> retval, labels, stats, centroids\n",
      "        .   @overload\n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param stats statistics output for each label, including the background label, see below for\n",
      "        .   available statistics. Statistics are accessed via stats(label, COLUMN) where COLUMN is one of\n",
      "        .   #ConnectedComponentsTypes. The data type is CV_32S.\n",
      "        .   @param centroids centroid output for each label, including the background label. Centroids are\n",
      "        .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "    \n",
      "    connectedComponentsWithStatsWithAlgorithm(...)\n",
      "        connectedComponentsWithStatsWithAlgorithm(image, connectivity, ltype, ccltype[, labels[, stats[, centroids]]]) -> retval, labels, stats, centroids\n",
      "        .   @brief computes the connected components labeled image of boolean image and also produces a statistics output for each label\n",
      "        .   \n",
      "        .   image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0\n",
      "        .   represents the background label. ltype specifies the output label image type, an important\n",
      "        .   consideration based on the total number of labels or alternatively the total number of pixels in\n",
      "        .   the source image. ccltype specifies the connected components labeling algorithm to use, currently\n",
      "        .   Grana's (BBDT) and Wu's (SAUF) algorithms are supported, see the #ConnectedComponentsAlgorithmsTypes\n",
      "        .   for details. Note that SAUF algorithm forces a row major ordering of labels while BBDT does not.\n",
      "        .   This function uses parallel version of both Grana and Wu's algorithms (statistics included) if at least one allowed\n",
      "        .   parallel framework is enabled and if the rows of the image are at least twice the number returned by #getNumberOfCPUs.\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param stats statistics output for each label, including the background label, see below for\n",
      "        .   available statistics. Statistics are accessed via stats(label, COLUMN) where COLUMN is one of\n",
      "        .   #ConnectedComponentsTypes. The data type is CV_32S.\n",
      "        .   @param centroids centroid output for each label, including the background label. Centroids are\n",
      "        .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "        .   @param ccltype connected components algorithm type (see #ConnectedComponentsAlgorithmsTypes).\n",
      "    \n",
      "    contourArea(...)\n",
      "        contourArea(contour[, oriented]) -> retval\n",
      "        .   @brief Calculates a contour area.\n",
      "        .   \n",
      "        .   The function computes a contour area. Similarly to moments , the area is computed using the Green\n",
      "        .   formula. Thus, the returned area and the number of non-zero pixels, if you draw the contour using\n",
      "        .   #drawContours or #fillPoly , can be different. Also, the function will most certainly give a wrong\n",
      "        .   results for contours with self-intersections.\n",
      "        .   \n",
      "        .   Example:\n",
      "        .   @code\n",
      "        .   vector<Point> contour;\n",
      "        .   contour.push_back(Point2f(0, 0));\n",
      "        .   contour.push_back(Point2f(10, 0));\n",
      "        .   contour.push_back(Point2f(10, 10));\n",
      "        .   contour.push_back(Point2f(5, 4));\n",
      "        .   \n",
      "        .   double area0 = contourArea(contour);\n",
      "        .   vector<Point> approx;\n",
      "        .   approxPolyDP(contour, approx, 5, true);\n",
      "        .   double area1 = contourArea(approx);\n",
      "        .   \n",
      "        .   cout << \"area0 =\" << area0 << endl <<\n",
      "        .   \"area1 =\" << area1 << endl <<\n",
      "        .   \"approx poly vertices\" << approx.size() << endl;\n",
      "        .   @endcode\n",
      "        .   @param contour Input vector of 2D points (contour vertices), stored in std::vector or Mat.\n",
      "        .   @param oriented Oriented area flag. If it is true, the function returns a signed area value,\n",
      "        .   depending on the contour orientation (clockwise or counter-clockwise). Using this feature you can\n",
      "        .   determine orientation of a contour by taking the sign of an area. By default, the parameter is\n",
      "        .   false, which means that the absolute value is returned.\n",
      "    \n",
      "    convertFp16(...)\n",
      "        convertFp16(src[, dst]) -> dst\n",
      "        .   @brief Converts an array to half precision floating number.\n",
      "        .   \n",
      "        .   This function converts FP32 (single precision floating point) from/to FP16 (half precision floating point). CV_16S format is used to represent FP16 data.\n",
      "        .   There are two use modes (src -> dst): CV_32F -> CV_16S and CV_16S -> CV_32F. The input array has to have type of CV_32F or\n",
      "        .   CV_16S to represent the bit depth. If the input array is neither of them, the function will raise an error.\n",
      "        .   The format of half precision floating point is defined in IEEE 754-2008.\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array.\n",
      "    \n",
      "    convertMaps(...)\n",
      "        convertMaps(map1, map2, dstmap1type[, dstmap1[, dstmap2[, nninterpolation]]]) -> dstmap1, dstmap2\n",
      "        .   @brief Converts image transformation maps from one representation to another.\n",
      "        .   \n",
      "        .   The function converts a pair of maps for remap from one representation to another. The following\n",
      "        .   options ( (map1.type(), map2.type()) \\f$\\rightarrow\\f$ (dstmap1.type(), dstmap2.type()) ) are\n",
      "        .   supported:\n",
      "        .   \n",
      "        .   - \\f$\\texttt{(CV_32FC1, CV_32FC1)} \\rightarrow \\texttt{(CV_16SC2, CV_16UC1)}\\f$. This is the\n",
      "        .   most frequently used conversion operation, in which the original floating-point maps (see remap )\n",
      "        .   are converted to a more compact and much faster fixed-point representation. The first output array\n",
      "        .   contains the rounded coordinates and the second array (created only when nninterpolation=false )\n",
      "        .   contains indices in the interpolation tables.\n",
      "        .   \n",
      "        .   - \\f$\\texttt{(CV_32FC2)} \\rightarrow \\texttt{(CV_16SC2, CV_16UC1)}\\f$. The same as above but\n",
      "        .   the original maps are stored in one 2-channel matrix.\n",
      "        .   \n",
      "        .   - Reverse conversion. Obviously, the reconstructed floating-point maps will not be exactly the same\n",
      "        .   as the originals.\n",
      "        .   \n",
      "        .   @param map1 The first input map of type CV_16SC2, CV_32FC1, or CV_32FC2 .\n",
      "        .   @param map2 The second input map of type CV_16UC1, CV_32FC1, or none (empty matrix),\n",
      "        .   respectively.\n",
      "        .   @param dstmap1 The first output map that has the type dstmap1type and the same size as src .\n",
      "        .   @param dstmap2 The second output map.\n",
      "        .   @param dstmap1type Type of the first output map that should be CV_16SC2, CV_32FC1, or\n",
      "        .   CV_32FC2 .\n",
      "        .   @param nninterpolation Flag indicating whether the fixed-point maps are used for the\n",
      "        .   nearest-neighbor or for a more complex interpolation.\n",
      "        .   \n",
      "        .   @sa  remap, undistort, initUndistortRectifyMap\n",
      "    \n",
      "    convertPointsFromHomogeneous(...)\n",
      "        convertPointsFromHomogeneous(src[, dst]) -> dst\n",
      "        .   @brief Converts points from homogeneous to Euclidean space.\n",
      "        .   \n",
      "        .   @param src Input vector of N-dimensional points.\n",
      "        .   @param dst Output vector of N-1-dimensional points.\n",
      "        .   \n",
      "        .   The function converts points homogeneous to Euclidean space using perspective projection. That is,\n",
      "        .   each point (x1, x2, ... x(n-1), xn) is converted to (x1/xn, x2/xn, ..., x(n-1)/xn). When xn=0, the\n",
      "        .   output point coordinates will be (0,0,0,...).\n",
      "    \n",
      "    convertPointsToHomogeneous(...)\n",
      "        convertPointsToHomogeneous(src[, dst]) -> dst\n",
      "        .   @brief Converts points from Euclidean to homogeneous space.\n",
      "        .   \n",
      "        .   @param src Input vector of N-dimensional points.\n",
      "        .   @param dst Output vector of N+1-dimensional points.\n",
      "        .   \n",
      "        .   The function converts points from Euclidean to homogeneous space by appending 1's to the tuple of\n",
      "        .   point coordinates. That is, each point (x1, x2, ..., xn) is converted to (x1, x2, ..., xn, 1).\n",
      "    \n",
      "    convertScaleAbs(...)\n",
      "        convertScaleAbs(src[, dst[, alpha[, beta]]]) -> dst\n",
      "        .   @brief Scales, calculates absolute values, and converts the result to 8-bit.\n",
      "        .   \n",
      "        .   On each element of the input array, the function convertScaleAbs\n",
      "        .   performs three operations sequentially: scaling, taking an absolute\n",
      "        .   value, conversion to an unsigned 8-bit type:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate\\_cast<uchar>} (| \\texttt{src} (I)* \\texttt{alpha} +  \\texttt{beta} |)\\f]\n",
      "        .   In case of multi-channel arrays, the function processes each channel\n",
      "        .   independently. When the output is not 8-bit, the operation can be\n",
      "        .   emulated by calling the Mat::convertTo method (or by using matrix\n",
      "        .   expressions) and then by calculating an absolute value of the result.\n",
      "        .   For example:\n",
      "        .   @code{.cpp}\n",
      "        .   Mat_<float> A(30,30);\n",
      "        .   randu(A, Scalar(-100), Scalar(100));\n",
      "        .   Mat_<float> B = A*5 + 3;\n",
      "        .   B = abs(B);\n",
      "        .   // Mat_<float> B = abs(A*5+3) will also do the job,\n",
      "        .   // but it will allocate a temporary matrix\n",
      "        .   @endcode\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array.\n",
      "        .   @param alpha optional scale factor.\n",
      "        .   @param beta optional delta added to the scaled values.\n",
      "        .   @sa  Mat::convertTo, cv::abs(const Mat&)\n",
      "    \n",
      "    convexHull(...)\n",
      "        convexHull(points[, hull[, clockwise[, returnPoints]]]) -> hull\n",
      "        .   @brief Finds the convex hull of a point set.\n",
      "        .   \n",
      "        .   The function cv::convexHull finds the convex hull of a 2D point set using the Sklansky's algorithm @cite Sklansky82\n",
      "        .   that has *O(N logN)* complexity in the current implementation.\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector or Mat.\n",
      "        .   @param hull Output convex hull. It is either an integer vector of indices or vector of points. In\n",
      "        .   the first case, the hull elements are 0-based indices of the convex hull points in the original\n",
      "        .   array (since the set of convex hull points is a subset of the original point set). In the second\n",
      "        .   case, hull elements are the convex hull points themselves.\n",
      "        .   @param clockwise Orientation flag. If it is true, the output convex hull is oriented clockwise.\n",
      "        .   Otherwise, it is oriented counter-clockwise. The assumed coordinate system has its X axis pointing\n",
      "        .   to the right, and its Y axis pointing upwards.\n",
      "        .   @param returnPoints Operation flag. In case of a matrix, when the flag is true, the function\n",
      "        .   returns convex hull points. Otherwise, it returns indices of the convex hull points. When the\n",
      "        .   output array is std::vector, the flag is ignored, and the output depends on the type of the\n",
      "        .   vector: std::vector\\<int\\> implies returnPoints=false, std::vector\\<Point\\> implies\n",
      "        .   returnPoints=true.\n",
      "        .   \n",
      "        .   @note `points` and `hull` should be different arrays, inplace processing isn't supported.\n",
      "        .   \n",
      "        .   Check @ref tutorial_hull \"the corresponding tutorial\" for more details.\n",
      "        .   \n",
      "        .   useful links:\n",
      "        .   \n",
      "        .   https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/\n",
      "    \n",
      "    convexityDefects(...)\n",
      "        convexityDefects(contour, convexhull[, convexityDefects]) -> convexityDefects\n",
      "        .   @brief Finds the convexity defects of a contour.\n",
      "        .   \n",
      "        .   The figure below displays convexity defects of a hand contour:\n",
      "        .   \n",
      "        .   ![image](pics/defects.png)\n",
      "        .   \n",
      "        .   @param contour Input contour.\n",
      "        .   @param convexhull Convex hull obtained using convexHull that should contain indices of the contour\n",
      "        .   points that make the hull.\n",
      "        .   @param convexityDefects The output vector of convexity defects. In C++ and the new Python/Java\n",
      "        .   interface each convexity defect is represented as 4-element integer vector (a.k.a. #Vec4i):\n",
      "        .   (start_index, end_index, farthest_pt_index, fixpt_depth), where indices are 0-based indices\n",
      "        .   in the original contour of the convexity defect beginning, end and the farthest point, and\n",
      "        .   fixpt_depth is fixed-point approximation (with 8 fractional bits) of the distance between the\n",
      "        .   farthest contour point and the hull. That is, to get the floating-point value of the depth will be\n",
      "        .   fixpt_depth/256.0.\n",
      "    \n",
      "    copyMakeBorder(...)\n",
      "        copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value]]) -> dst\n",
      "        .   @brief Forms a border around an image.\n",
      "        .   \n",
      "        .   The function copies the source image into the middle of the destination image. The areas to the\n",
      "        .   left, to the right, above and below the copied source image will be filled with extrapolated\n",
      "        .   pixels. This is not what filtering functions based on it do (they extrapolate pixels on-fly), but\n",
      "        .   what other more complex functions, including your own, may do to simplify image boundary handling.\n",
      "        .   \n",
      "        .   The function supports the mode when src is already in the middle of dst . In this case, the\n",
      "        .   function does not copy src itself but simply constructs the border, for example:\n",
      "        .   \n",
      "        .   @code{.cpp}\n",
      "        .   // let border be the same in all directions\n",
      "        .   int border=2;\n",
      "        .   // constructs a larger image to fit both the image and the border\n",
      "        .   Mat gray_buf(rgb.rows + border*2, rgb.cols + border*2, rgb.depth());\n",
      "        .   // select the middle part of it w/o copying data\n",
      "        .   Mat gray(gray_canvas, Rect(border, border, rgb.cols, rgb.rows));\n",
      "        .   // convert image from RGB to grayscale\n",
      "        .   cvtColor(rgb, gray, COLOR_RGB2GRAY);\n",
      "        .   // form a border in-place\n",
      "        .   copyMakeBorder(gray, gray_buf, border, border,\n",
      "        .   border, border, BORDER_REPLICATE);\n",
      "        .   // now do some custom filtering ...\n",
      "        .   ...\n",
      "        .   @endcode\n",
      "        .   @note When the source image is a part (ROI) of a bigger image, the function will try to use the\n",
      "        .   pixels outside of the ROI to form a border. To disable this feature and always do extrapolation, as\n",
      "        .   if src was not a ROI, use borderType | #BORDER_ISOLATED.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same type as src and the size Size(src.cols+left+right,\n",
      "        .   src.rows+top+bottom) .\n",
      "        .   @param top\n",
      "        .   @param bottom\n",
      "        .   @param left\n",
      "        .   @param right Parameter specifying how many pixels in each direction from the source image rectangle\n",
      "        .   to extrapolate. For example, top=1, bottom=1, left=1, right=1 mean that 1 pixel-wide border needs\n",
      "        .   to be built.\n",
      "        .   @param borderType Border type. See borderInterpolate for details.\n",
      "        .   @param value Border value if borderType==BORDER_CONSTANT .\n",
      "        .   \n",
      "        .   @sa  borderInterpolate\n",
      "    \n",
      "    copyTo(...)\n",
      "        copyTo(src, mask[, dst]) -> dst\n",
      "        .   @brief  This is an overloaded member function, provided for convenience (python)\n",
      "        .   Copies the matrix to another one.\n",
      "        .   When the operation mask is specified, if the Mat::create call shown above reallocates the matrix, the newly allocated matrix is initialized with all zeros before copying the data.\n",
      "        .   @param src source matrix.\n",
      "        .   @param dst Destination matrix. If it does not have a proper size or type before the operation, it is\n",
      "        .   reallocated.\n",
      "        .   @param mask Operation mask of the same size as \\*this. Its non-zero elements indicate which matrix\n",
      "        .   elements need to be copied. The mask has to be of type CV_8U and can have 1 or multiple channels.\n",
      "    \n",
      "    cornerEigenValsAndVecs(...)\n",
      "        cornerEigenValsAndVecs(src, blockSize, ksize[, dst[, borderType]]) -> dst\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of image blocks for corner detection.\n",
      "        .   \n",
      "        .   For every pixel \\f$p\\f$ , the function cornerEigenValsAndVecs considers a blockSize \\f$\\times\\f$ blockSize\n",
      "        .   neighborhood \\f$S(p)\\f$ . It calculates the covariation matrix of derivatives over the neighborhood as:\n",
      "        .   \n",
      "        .   \\f[M =  \\begin{bmatrix} \\sum _{S(p)}(dI/dx)^2 &  \\sum _{S(p)}dI/dx dI/dy  \\\\ \\sum _{S(p)}dI/dx dI/dy &  \\sum _{S(p)}(dI/dy)^2 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where the derivatives are computed using the Sobel operator.\n",
      "        .   \n",
      "        .   After that, it finds eigenvectors and eigenvalues of \\f$M\\f$ and stores them in the destination image as\n",
      "        .   \\f$(\\lambda_1, \\lambda_2, x_1, y_1, x_2, y_2)\\f$ where\n",
      "        .   \n",
      "        .   -   \\f$\\lambda_1, \\lambda_2\\f$ are the non-sorted eigenvalues of \\f$M\\f$\n",
      "        .   -   \\f$x_1, y_1\\f$ are the eigenvectors corresponding to \\f$\\lambda_1\\f$\n",
      "        .   -   \\f$x_2, y_2\\f$ are the eigenvectors corresponding to \\f$\\lambda_2\\f$\n",
      "        .   \n",
      "        .   The output of the function can be used for robust edge or corner detection.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the results. It has the same size as src and the type CV_32FC(6) .\n",
      "        .   @param blockSize Neighborhood size (see details below).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes.\n",
      "        .   \n",
      "        .   @sa  cornerMinEigenVal, cornerHarris, preCornerDetect\n",
      "    \n",
      "    cornerHarris(...)\n",
      "        cornerHarris(src, blockSize, ksize, k[, dst[, borderType]]) -> dst\n",
      "        .   @brief Harris corner detector.\n",
      "        .   \n",
      "        .   The function runs the Harris corner detector on the image. Similarly to cornerMinEigenVal and\n",
      "        .   cornerEigenValsAndVecs , for each pixel \\f$(x, y)\\f$ it calculates a \\f$2\\times2\\f$ gradient covariance\n",
      "        .   matrix \\f$M^{(x,y)}\\f$ over a \\f$\\texttt{blockSize} \\times \\texttt{blockSize}\\f$ neighborhood. Then, it\n",
      "        .   computes the following characteristic:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\mathrm{det} M^{(x,y)} - k  \\cdot \\left ( \\mathrm{tr} M^{(x,y)} \\right )^2\\f]\n",
      "        .   \n",
      "        .   Corners in the image can be found as the local maxima of this response map.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the Harris detector responses. It has the type CV_32FC1 and the same\n",
      "        .   size as src .\n",
      "        .   @param blockSize Neighborhood size (see the details on #cornerEigenValsAndVecs ).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param k Harris detector free parameter. See the formula above.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes.\n",
      "    \n",
      "    cornerMinEigenVal(...)\n",
      "        cornerMinEigenVal(src, blockSize[, dst[, ksize[, borderType]]]) -> dst\n",
      "        .   @brief Calculates the minimal eigenvalue of gradient matrices for corner detection.\n",
      "        .   \n",
      "        .   The function is similar to cornerEigenValsAndVecs but it calculates and stores only the minimal\n",
      "        .   eigenvalue of the covariance matrix of derivatives, that is, \\f$\\min(\\lambda_1, \\lambda_2)\\f$ in terms\n",
      "        .   of the formulae in the cornerEigenValsAndVecs description.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the minimal eigenvalues. It has the type CV_32FC1 and the same size as\n",
      "        .   src .\n",
      "        .   @param blockSize Neighborhood size (see the details on #cornerEigenValsAndVecs ).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes.\n",
      "    \n",
      "    cornerSubPix(...)\n",
      "        cornerSubPix(image, corners, winSize, zeroZone, criteria) -> corners\n",
      "        .   @brief Refines the corner locations.\n",
      "        .   \n",
      "        .   The function iterates to find the sub-pixel accurate location of corners or radial saddle points, as\n",
      "        .   shown on the figure below.\n",
      "        .   \n",
      "        .   ![image](pics/cornersubpix.png)\n",
      "        .   \n",
      "        .   Sub-pixel accurate corner locator is based on the observation that every vector from the center \\f$q\\f$\n",
      "        .   to a point \\f$p\\f$ located within a neighborhood of \\f$q\\f$ is orthogonal to the image gradient at \\f$p\\f$\n",
      "        .   subject to image and measurement noise. Consider the expression:\n",
      "        .   \n",
      "        .   \\f[\\epsilon _i = {DI_{p_i}}^T  \\cdot (q - p_i)\\f]\n",
      "        .   \n",
      "        .   where \\f${DI_{p_i}}\\f$ is an image gradient at one of the points \\f$p_i\\f$ in a neighborhood of \\f$q\\f$ . The\n",
      "        .   value of \\f$q\\f$ is to be found so that \\f$\\epsilon_i\\f$ is minimized. A system of equations may be set up\n",
      "        .   with \\f$\\epsilon_i\\f$ set to zero:\n",
      "        .   \n",
      "        .   \\f[\\sum _i(DI_{p_i}  \\cdot {DI_{p_i}}^T) \\cdot q -  \\sum _i(DI_{p_i}  \\cdot {DI_{p_i}}^T  \\cdot p_i)\\f]\n",
      "        .   \n",
      "        .   where the gradients are summed within a neighborhood (\"search window\") of \\f$q\\f$ . Calling the first\n",
      "        .   gradient term \\f$G\\f$ and the second gradient term \\f$b\\f$ gives:\n",
      "        .   \n",
      "        .   \\f[q = G^{-1}  \\cdot b\\f]\n",
      "        .   \n",
      "        .   The algorithm sets the center of the neighborhood window at this new center \\f$q\\f$ and then iterates\n",
      "        .   until the center stays within a set threshold.\n",
      "        .   \n",
      "        .   @param image Input single-channel, 8-bit or float image.\n",
      "        .   @param corners Initial coordinates of the input corners and refined coordinates provided for\n",
      "        .   output.\n",
      "        .   @param winSize Half of the side length of the search window. For example, if winSize=Size(5,5) ,\n",
      "        .   then a \\f$(5*2+1) \\times (5*2+1) = 11 \\times 11\\f$ search window is used.\n",
      "        .   @param zeroZone Half of the size of the dead region in the middle of the search zone over which\n",
      "        .   the summation in the formula below is not done. It is used sometimes to avoid possible\n",
      "        .   singularities of the autocorrelation matrix. The value of (-1,-1) indicates that there is no such\n",
      "        .   a size.\n",
      "        .   @param criteria Criteria for termination of the iterative process of corner refinement. That is,\n",
      "        .   the process of corner position refinement stops either after criteria.maxCount iterations or when\n",
      "        .   the corner position moves by less than criteria.epsilon on some iteration.\n",
      "    \n",
      "    correctMatches(...)\n",
      "        correctMatches(F, points1, points2[, newPoints1[, newPoints2]]) -> newPoints1, newPoints2\n",
      "        .   @brief Refines coordinates of corresponding points.\n",
      "        .   \n",
      "        .   @param F 3x3 fundamental matrix.\n",
      "        .   @param points1 1xN array containing the first set of points.\n",
      "        .   @param points2 1xN array containing the second set of points.\n",
      "        .   @param newPoints1 The optimized points1.\n",
      "        .   @param newPoints2 The optimized points2.\n",
      "        .   \n",
      "        .   The function implements the Optimal Triangulation Method (see Multiple View Geometry for details).\n",
      "        .   For each given point correspondence points1[i] \\<-\\> points2[i], and a fundamental matrix F, it\n",
      "        .   computes the corrected correspondences newPoints1[i] \\<-\\> newPoints2[i] that minimize the geometric\n",
      "        .   error \\f$d(points1[i], newPoints1[i])^2 + d(points2[i],newPoints2[i])^2\\f$ (where \\f$d(a,b)\\f$ is the\n",
      "        .   geometric distance between points \\f$a\\f$ and \\f$b\\f$ ) subject to the epipolar constraint\n",
      "        .   \\f$newPoints2^T * F * newPoints1 = 0\\f$ .\n",
      "    \n",
      "    countNonZero(...)\n",
      "        countNonZero(src) -> retval\n",
      "        .   @brief Counts non-zero array elements.\n",
      "        .   \n",
      "        .   The function returns the number of non-zero elements in src :\n",
      "        .   \\f[\\sum _{I: \\; \\texttt{src} (I) \\ne0 } 1\\f]\n",
      "        .   @param src single-channel array.\n",
      "        .   @sa  mean, meanStdDev, norm, minMaxLoc, calcCovarMatrix\n",
      "    \n",
      "    createAlignMTB(...)\n",
      "        createAlignMTB([, max_bits[, exclude_range[, cut]]]) -> retval\n",
      "        .   @brief Creates AlignMTB object\n",
      "        .   \n",
      "        .   @param max_bits logarithm to the base 2 of maximal shift in each dimension. Values of 5 and 6 are\n",
      "        .   usually good enough (31 and 63 pixels shift respectively).\n",
      "        .   @param exclude_range range for exclusion bitmap that is constructed to suppress noise around the\n",
      "        .   median value.\n",
      "        .   @param cut if true cuts images, otherwise fills the new regions with zeros.\n",
      "    \n",
      "    createBackgroundSubtractorKNN(...)\n",
      "        createBackgroundSubtractorKNN([, history[, dist2Threshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates KNN Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide\n",
      "        .   whether a pixel is close to that sample. This parameter does not affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createBackgroundSubtractorMOG2(...)\n",
      "        createBackgroundSubtractorMOG2([, history[, varThreshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates MOG2 Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model\n",
      "        .   to decide whether a pixel is well described by the background model. This parameter does not\n",
      "        .   affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createButton(...)\n",
      "        createButton(buttonName, onChange [, userData, buttonType, initialButtonState]) -> None\n",
      "    \n",
      "    createCLAHE(...)\n",
      "        createCLAHE([, clipLimit[, tileGridSize]]) -> retval\n",
      "        .   @brief Creates a smart pointer to a cv::CLAHE class and initializes it.\n",
      "        .   \n",
      "        .   @param clipLimit Threshold for contrast limiting.\n",
      "        .   @param tileGridSize Size of grid for histogram equalization. Input image will be divided into\n",
      "        .   equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
      "    \n",
      "    createCalibrateDebevec(...)\n",
      "        createCalibrateDebevec([, samples[, lambda[, random]]]) -> retval\n",
      "        .   @brief Creates CalibrateDebevec object\n",
      "        .   \n",
      "        .   @param samples number of pixel locations to use\n",
      "        .   @param lambda smoothness term weight. Greater values produce smoother results, but can alter the\n",
      "        .   response.\n",
      "        .   @param random if true sample pixel locations are chosen at random, otherwise they form a\n",
      "        .   rectangular grid.\n",
      "    \n",
      "    createCalibrateRobertson(...)\n",
      "        createCalibrateRobertson([, max_iter[, threshold]]) -> retval\n",
      "        .   @brief Creates CalibrateRobertson object\n",
      "        .   \n",
      "        .   @param max_iter maximal number of Gauss-Seidel solver iterations.\n",
      "        .   @param threshold target difference between results of two successive steps of the minimization.\n",
      "    \n",
      "    createHanningWindow(...)\n",
      "        createHanningWindow(winSize, type[, dst]) -> dst\n",
      "        .   @brief This function computes a Hanning window coefficients in two dimensions.\n",
      "        .   \n",
      "        .   See (http://en.wikipedia.org/wiki/Hann_function) and (http://en.wikipedia.org/wiki/Window_function)\n",
      "        .   for more information.\n",
      "        .   \n",
      "        .   An example is shown below:\n",
      "        .   @code\n",
      "        .   // create hanning window of size 100x100 and type CV_32F\n",
      "        .   Mat hann;\n",
      "        .   createHanningWindow(hann, Size(100, 100), CV_32F);\n",
      "        .   @endcode\n",
      "        .   @param dst Destination array to place Hann coefficients in\n",
      "        .   @param winSize The window size specifications (both width and height must be > 1)\n",
      "        .   @param type Created array type\n",
      "    \n",
      "    createLineSegmentDetector(...)\n",
      "        createLineSegmentDetector([, _refine[, _scale[, _sigma_scale[, _quant[, _ang_th[, _log_eps[, _density_th[, _n_bins]]]]]]]]) -> retval\n",
      "        .   @brief Creates a smart pointer to a LineSegmentDetector object and initializes it.\n",
      "        .   \n",
      "        .   The LineSegmentDetector algorithm is defined using the standard values. Only advanced users may want\n",
      "        .   to edit those, as to tailor it for their own application.\n",
      "        .   \n",
      "        .   @param _refine The way found lines will be refined, see #LineSegmentDetectorModes\n",
      "        .   @param _scale The scale of the image that will be used to find the lines. Range (0..1].\n",
      "        .   @param _sigma_scale Sigma for Gaussian filter. It is computed as sigma = _sigma_scale/_scale.\n",
      "        .   @param _quant Bound to the quantization error on the gradient norm.\n",
      "        .   @param _ang_th Gradient angle tolerance in degrees.\n",
      "        .   @param _log_eps Detection threshold: -log10(NFA) \\> log_eps. Used only when advance refinement\n",
      "        .   is chosen.\n",
      "        .   @param _density_th Minimal density of aligned region points in the enclosing rectangle.\n",
      "        .   @param _n_bins Number of bins in pseudo-ordering of gradient modulus.\n",
      "        .   \n",
      "        .   @note Implementation has been removed due original code license conflict\n",
      "    \n",
      "    createMergeDebevec(...)\n",
      "        createMergeDebevec() -> retval\n",
      "        .   @brief Creates MergeDebevec object\n",
      "    \n",
      "    createMergeMertens(...)\n",
      "        createMergeMertens([, contrast_weight[, saturation_weight[, exposure_weight]]]) -> retval\n",
      "        .   @brief Creates MergeMertens object\n",
      "        .   \n",
      "        .   @param contrast_weight contrast measure weight. See MergeMertens.\n",
      "        .   @param saturation_weight saturation measure weight\n",
      "        .   @param exposure_weight well-exposedness measure weight\n",
      "    \n",
      "    createMergeRobertson(...)\n",
      "        createMergeRobertson() -> retval\n",
      "        .   @brief Creates MergeRobertson object\n",
      "    \n",
      "    createTonemap(...)\n",
      "        createTonemap([, gamma]) -> retval\n",
      "        .   @brief Creates simple linear mapper with gamma correction\n",
      "        .   \n",
      "        .   @param gamma positive value for gamma correction. Gamma value of 1.0 implies no correction, gamma\n",
      "        .   equal to 2.2f is suitable for most displays.\n",
      "        .   Generally gamma \\> 1 brightens the image and gamma \\< 1 darkens it.\n",
      "    \n",
      "    createTonemapDrago(...)\n",
      "        createTonemapDrago([, gamma[, saturation[, bias]]]) -> retval\n",
      "        .   @brief Creates TonemapDrago object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param saturation positive saturation enhancement value. 1.0 preserves saturation, values greater\n",
      "        .   than 1 increase saturation and values less than 1 decrease it.\n",
      "        .   @param bias value for bias function in [0, 1] range. Values from 0.7 to 0.9 usually give best\n",
      "        .   results, default value is 0.85.\n",
      "    \n",
      "    createTonemapMantiuk(...)\n",
      "        createTonemapMantiuk([, gamma[, scale[, saturation]]]) -> retval\n",
      "        .   @brief Creates TonemapMantiuk object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param scale contrast scale factor. HVS response is multiplied by this parameter, thus compressing\n",
      "        .   dynamic range. Values from 0.6 to 0.9 produce best results.\n",
      "        .   @param saturation saturation enhancement value. See createTonemapDrago\n",
      "    \n",
      "    createTonemapReinhard(...)\n",
      "        createTonemapReinhard([, gamma[, intensity[, light_adapt[, color_adapt]]]]) -> retval\n",
      "        .   @brief Creates TonemapReinhard object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param intensity result intensity in [-8, 8] range. Greater intensity produces brighter results.\n",
      "        .   @param light_adapt light adaptation in [0, 1] range. If 1 adaptation is based only on pixel\n",
      "        .   value, if 0 it's global, otherwise it's a weighted mean of this two cases.\n",
      "        .   @param color_adapt chromatic adaptation in [0, 1] range. If 1 channels are treated independently,\n",
      "        .   if 0 adaptation level is the same for each channel.\n",
      "    \n",
      "    createTrackbar(...)\n",
      "        createTrackbar(trackbarName, windowName, value, count, onChange) -> None\n",
      "    \n",
      "    cubeRoot(...)\n",
      "        cubeRoot(val) -> retval\n",
      "        .   @brief Computes the cube root of an argument.\n",
      "        .   \n",
      "        .   The function cubeRoot computes \\f$\\sqrt[3]{\\texttt{val}}\\f$. Negative arguments are handled correctly.\n",
      "        .   NaN and Inf are not handled. The accuracy approaches the maximum possible accuracy for\n",
      "        .   single-precision data.\n",
      "        .   @param val A function argument.\n",
      "    \n",
      "    cvtColor(...)\n",
      "        cvtColor(src, code[, dst[, dstCn]]) -> dst\n",
      "        .   @brief Converts an image from one color space to another.\n",
      "        .   \n",
      "        .   The function converts an input image from one color space to another. In case of a transformation\n",
      "        .   to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note\n",
      "        .   that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the\n",
      "        .   bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue\n",
      "        .   component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and\n",
      "        .   sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n",
      "        .   \n",
      "        .   The conventional ranges for R, G, and B channel values are:\n",
      "        .   -   0 to 255 for CV_8U images\n",
      "        .   -   0 to 65535 for CV_16U images\n",
      "        .   -   0 to 1 for CV_32F images\n",
      "        .   \n",
      "        .   In case of linear transformations, the range does not matter. But in case of a non-linear\n",
      "        .   transformation, an input RGB image should be normalized to the proper value range to get the correct\n",
      "        .   results, for example, for RGB \\f$\\rightarrow\\f$ L\\*u\\*v\\* transformation. For example, if you have a\n",
      "        .   32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will\n",
      "        .   have the 0..255 value range instead of 0..1 assumed by the function. So, before calling #cvtColor ,\n",
      "        .   you need first to scale the image down:\n",
      "        .   @code\n",
      "        .   img *= 1./255;\n",
      "        .   cvtColor(img, img, COLOR_BGR2Luv);\n",
      "        .   @endcode\n",
      "        .   If you use #cvtColor with 8-bit images, the conversion will have some information lost. For many\n",
      "        .   applications, this will not be noticeable but it is recommended to use 32-bit images in applications\n",
      "        .   that need the full range of colors or that convert an image before an operation and then convert\n",
      "        .   back.\n",
      "        .   \n",
      "        .   If conversion adds the alpha channel, its value will set to the maximum of corresponding channel\n",
      "        .   range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F.\n",
      "        .   \n",
      "        .   @param src input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision\n",
      "        .   floating-point.\n",
      "        .   @param dst output image of the same size and depth as src.\n",
      "        .   @param code color space conversion code (see #ColorConversionCodes).\n",
      "        .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and code.\n",
      "        .   \n",
      "        .   @see @ref imgproc_color_conversions\n",
      "    \n",
      "    cvtColorTwoPlane(...)\n",
      "        cvtColorTwoPlane(src1, src2, code[, dst]) -> dst\n",
      "        .   @brief Converts an image from one color space to another where the source image is\n",
      "        .   stored in two planes.\n",
      "        .   \n",
      "        .   This function only supports YUV420 to RGB conversion as of now.\n",
      "        .   \n",
      "        .   @param src1: 8-bit image (#CV_8U) of the Y plane.\n",
      "        .   @param src2: image containing interleaved U/V plane.\n",
      "        .   @param dst: output image.\n",
      "        .   @param code: Specifies the type of conversion. It can take any of the following values:\n",
      "        .   - #COLOR_YUV2BGR_NV12\n",
      "        .   - #COLOR_YUV2RGB_NV12\n",
      "        .   - #COLOR_YUV2BGRA_NV12\n",
      "        .   - #COLOR_YUV2RGBA_NV12\n",
      "        .   - #COLOR_YUV2BGR_NV21\n",
      "        .   - #COLOR_YUV2RGB_NV21\n",
      "        .   - #COLOR_YUV2BGRA_NV21\n",
      "        .   - #COLOR_YUV2RGBA_NV21\n",
      "    \n",
      "    dct(...)\n",
      "        dct(src[, dst[, flags]]) -> dst\n",
      "        .   @brief Performs a forward or inverse discrete Cosine transform of 1D or 2D array.\n",
      "        .   \n",
      "        .   The function cv::dct performs a forward or inverse discrete Cosine transform (DCT) of a 1D or 2D\n",
      "        .   floating-point array:\n",
      "        .   -   Forward Cosine transform of a 1D vector of N elements:\n",
      "        .   \\f[Y = C^{(N)}  \\cdot X\\f]\n",
      "        .   where\n",
      "        .   \\f[C^{(N)}_{jk}= \\sqrt{\\alpha_j/N} \\cos \\left ( \\frac{\\pi(2k+1)j}{2N} \\right )\\f]\n",
      "        .   and\n",
      "        .   \\f$\\alpha_0=1\\f$, \\f$\\alpha_j=2\\f$ for *j \\> 0*.\n",
      "        .   -   Inverse Cosine transform of a 1D vector of N elements:\n",
      "        .   \\f[X =  \\left (C^{(N)} \\right )^{-1}  \\cdot Y =  \\left (C^{(N)} \\right )^T  \\cdot Y\\f]\n",
      "        .   (since \\f$C^{(N)}\\f$ is an orthogonal matrix, \\f$C^{(N)} \\cdot \\left(C^{(N)}\\right)^T = I\\f$ )\n",
      "        .   -   Forward 2D Cosine transform of M x N matrix:\n",
      "        .   \\f[Y = C^{(N)}  \\cdot X  \\cdot \\left (C^{(N)} \\right )^T\\f]\n",
      "        .   -   Inverse 2D Cosine transform of M x N matrix:\n",
      "        .   \\f[X =  \\left (C^{(N)} \\right )^T  \\cdot X  \\cdot C^{(N)}\\f]\n",
      "        .   \n",
      "        .   The function chooses the mode of operation by looking at the flags and size of the input array:\n",
      "        .   -   If (flags & #DCT_INVERSE) == 0 , the function does a forward 1D or 2D transform. Otherwise, it\n",
      "        .   is an inverse 1D or 2D transform.\n",
      "        .   -   If (flags & #DCT_ROWS) != 0 , the function performs a 1D transform of each row.\n",
      "        .   -   If the array is a single column or a single row, the function performs a 1D transform.\n",
      "        .   -   If none of the above is true, the function performs a 2D transform.\n",
      "        .   \n",
      "        .   @note Currently dct supports even-size arrays (2, 4, 6 ...). For data analysis and approximation, you\n",
      "        .   can pad the array when necessary.\n",
      "        .   Also, the function performance depends very much, and not monotonically, on the array size (see\n",
      "        .   getOptimalDFTSize ). In the current implementation DCT of a vector of size N is calculated via DFT\n",
      "        .   of a vector of size N/2 . Thus, the optimal DCT size N1 \\>= N can be calculated as:\n",
      "        .   @code\n",
      "        .   size_t getOptimalDCTSize(size_t N) { return 2*getOptimalDFTSize((N+1)/2); }\n",
      "        .   N1 = getOptimalDCTSize(N);\n",
      "        .   @endcode\n",
      "        .   @param src input floating-point array.\n",
      "        .   @param dst output array of the same size and type as src .\n",
      "        .   @param flags transformation flags as a combination of cv::DftFlags (DCT_*)\n",
      "        .   @sa dft , getOptimalDFTSize , idct\n",
      "    \n",
      "    decolor(...)\n",
      "        decolor(src[, grayscale[, color_boost]]) -> grayscale, color_boost\n",
      "        .   @brief Transforms a color image to a grayscale image. It is a basic tool in digital printing, stylized\n",
      "        .   black-and-white photograph rendering, and in many single channel image processing applications\n",
      "        .   @cite CL12 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param grayscale Output 8-bit 1-channel image.\n",
      "        .   @param color_boost Output 8-bit 3-channel image.\n",
      "        .   \n",
      "        .   This function is to be applied on color images.\n",
      "    \n",
      "    decomposeEssentialMat(...)\n",
      "        decomposeEssentialMat(E[, R1[, R2[, t]]]) -> R1, R2, t\n",
      "        .   @brief Decompose an essential matrix to possible rotations and translation.\n",
      "        .   \n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param R1 One possible rotation matrix.\n",
      "        .   @param R2 Another possible rotation matrix.\n",
      "        .   @param t One possible translation.\n",
      "        .   \n",
      "        .   This function decompose an essential matrix E using svd decomposition @cite HartleyZ00 . Generally 4\n",
      "        .   possible poses exists for a given E. They are \\f$[R_1, t]\\f$, \\f$[R_1, -t]\\f$, \\f$[R_2, t]\\f$, \\f$[R_2, -t]\\f$. By\n",
      "        .   decomposing E, you can only get the direction of the translation, so the function returns unit t.\n",
      "    \n",
      "    decomposeHomographyMat(...)\n",
      "        decomposeHomographyMat(H, K[, rotations[, translations[, normals]]]) -> retval, rotations, translations, normals\n",
      "        .   @brief Decompose a homography matrix to rotation(s), translation(s) and plane normal(s).\n",
      "        .   \n",
      "        .   @param H The input homography matrix between two images.\n",
      "        .   @param K The input intrinsic camera calibration matrix.\n",
      "        .   @param rotations Array of rotation matrices.\n",
      "        .   @param translations Array of translation matrices.\n",
      "        .   @param normals Array of plane normal matrices.\n",
      "        .   \n",
      "        .   This function extracts relative camera motion between two views observing a planar object from the\n",
      "        .   homography H induced by the plane. The intrinsic camera matrix K must also be provided. The function\n",
      "        .   may return up to four mathematical solution sets. At least two of the solutions may further be\n",
      "        .   invalidated if point correspondences are available by applying positive depth constraint (all points\n",
      "        .   must be in front of the camera). The decomposition method is described in detail in @cite Malis .\n",
      "    \n",
      "    decomposeProjectionMatrix(...)\n",
      "        decomposeProjectionMatrix(projMatrix[, cameraMatrix[, rotMatrix[, transVect[, rotMatrixX[, rotMatrixY[, rotMatrixZ[, eulerAngles]]]]]]]) -> cameraMatrix, rotMatrix, transVect, rotMatrixX, rotMatrixY, rotMatrixZ, eulerAngles\n",
      "        .   @brief Decomposes a projection matrix into a rotation matrix and a camera matrix.\n",
      "        .   \n",
      "        .   @param projMatrix 3x4 input projection matrix P.\n",
      "        .   @param cameraMatrix Output 3x3 camera matrix K.\n",
      "        .   @param rotMatrix Output 3x3 external rotation matrix R.\n",
      "        .   @param transVect Output 4x1 translation vector T.\n",
      "        .   @param rotMatrixX Optional 3x3 rotation matrix around x-axis.\n",
      "        .   @param rotMatrixY Optional 3x3 rotation matrix around y-axis.\n",
      "        .   @param rotMatrixZ Optional 3x3 rotation matrix around z-axis.\n",
      "        .   @param eulerAngles Optional three-element vector containing three Euler angles of rotation in\n",
      "        .   degrees.\n",
      "        .   \n",
      "        .   The function computes a decomposition of a projection matrix into a calibration and a rotation\n",
      "        .   matrix and the position of a camera.\n",
      "        .   \n",
      "        .   It optionally returns three rotation matrices, one for each axis, and three Euler angles that could\n",
      "        .   be used in OpenGL. Note, there is always more than one sequence of rotations about the three\n",
      "        .   principal axes that results in the same orientation of an object, e.g. see @cite Slabaugh . Returned\n",
      "        .   tree rotation matrices and corresponding three Euler angles are only one of the possible solutions.\n",
      "        .   \n",
      "        .   The function is based on RQDecomp3x3 .\n",
      "    \n",
      "    demosaicing(...)\n",
      "        demosaicing(src, code[, dst[, dstCn]]) -> dst\n",
      "        .   @brief main function for all demosaicing processes\n",
      "        .   \n",
      "        .   @param src input image: 8-bit unsigned or 16-bit unsigned.\n",
      "        .   @param dst output image of the same size and depth as src.\n",
      "        .   @param code Color space conversion code (see the description below).\n",
      "        .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and code.\n",
      "        .   \n",
      "        .   The function can do the following transformations:\n",
      "        .   \n",
      "        .   -   Demosaicing using bilinear interpolation\n",
      "        .   \n",
      "        .   #COLOR_BayerBG2BGR , #COLOR_BayerGB2BGR , #COLOR_BayerRG2BGR , #COLOR_BayerGR2BGR\n",
      "        .   \n",
      "        .   #COLOR_BayerBG2GRAY , #COLOR_BayerGB2GRAY , #COLOR_BayerRG2GRAY , #COLOR_BayerGR2GRAY\n",
      "        .   \n",
      "        .   -   Demosaicing using Variable Number of Gradients.\n",
      "        .   \n",
      "        .   #COLOR_BayerBG2BGR_VNG , #COLOR_BayerGB2BGR_VNG , #COLOR_BayerRG2BGR_VNG , #COLOR_BayerGR2BGR_VNG\n",
      "        .   \n",
      "        .   -   Edge-Aware Demosaicing.\n",
      "        .   \n",
      "        .   #COLOR_BayerBG2BGR_EA , #COLOR_BayerGB2BGR_EA , #COLOR_BayerRG2BGR_EA , #COLOR_BayerGR2BGR_EA\n",
      "        .   \n",
      "        .   -   Demosaicing with alpha channel\n",
      "        .   \n",
      "        .   #COLOR_BayerBG2BGRA , #COLOR_BayerGB2BGRA , #COLOR_BayerRG2BGRA , #COLOR_BayerGR2BGRA\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    denoise_TVL1(...)\n",
      "        denoise_TVL1(observations, result[, lambda[, niters]]) -> None\n",
      "        .   @brief Primal-dual algorithm is an algorithm for solving special types of variational problems (that is,\n",
      "        .   finding a function to minimize some functional). As the image denoising, in particular, may be seen\n",
      "        .   as the variational problem, primal-dual algorithm then can be used to perform denoising and this is\n",
      "        .   exactly what is implemented.\n",
      "        .   \n",
      "        .   It should be noted, that this implementation was taken from the July 2013 blog entry\n",
      "        .   @cite MA13 , which also contained (slightly more general) ready-to-use source code on Python.\n",
      "        .   Subsequently, that code was rewritten on C++ with the usage of openCV by Vadim Pisarevsky at the end\n",
      "        .   of July 2013 and finally it was slightly adapted by later authors.\n",
      "        .   \n",
      "        .   Although the thorough discussion and justification of the algorithm involved may be found in\n",
      "        .   @cite ChambolleEtAl, it might make sense to skim over it here, following @cite MA13 . To begin\n",
      "        .   with, we consider the 1-byte gray-level images as the functions from the rectangular domain of\n",
      "        .   pixels (it may be seen as set\n",
      "        .   \\f$\\left\\{(x,y)\\in\\mathbb{N}\\times\\mathbb{N}\\mid 1\\leq x\\leq n,\\;1\\leq y\\leq m\\right\\}\\f$ for some\n",
      "        .   \\f$m,\\;n\\in\\mathbb{N}\\f$) into \\f$\\{0,1,\\dots,255\\}\\f$. We shall denote the noised images as \\f$f_i\\f$ and with\n",
      "        .   this view, given some image \\f$x\\f$ of the same size, we may measure how bad it is by the formula\n",
      "        .   \n",
      "        .   \\f[\\left\\|\\left\\|\\nabla x\\right\\|\\right\\| + \\lambda\\sum_i\\left\\|\\left\\|x-f_i\\right\\|\\right\\|\\f]\n",
      "        .   \n",
      "        .   \\f$\\|\\|\\cdot\\|\\|\\f$ here denotes \\f$L_2\\f$-norm and as you see, the first addend states that we want our\n",
      "        .   image to be smooth (ideally, having zero gradient, thus being constant) and the second states that\n",
      "        .   we want our result to be close to the observations we've got. If we treat \\f$x\\f$ as a function, this is\n",
      "        .   exactly the functional what we seek to minimize and here the Primal-Dual algorithm comes into play.\n",
      "        .   \n",
      "        .   @param observations This array should contain one or more noised versions of the image that is to\n",
      "        .   be restored.\n",
      "        .   @param result Here the denoised image will be stored. There is no need to do pre-allocation of\n",
      "        .   storage space, as it will be automatically allocated, if necessary.\n",
      "        .   @param lambda Corresponds to \\f$\\lambda\\f$ in the formulas above. As it is enlarged, the smooth\n",
      "        .   (blurred) images are treated more favorably than detailed (but maybe more noised) ones. Roughly\n",
      "        .   speaking, as it becomes smaller, the result will be more blur but more sever outliers will be\n",
      "        .   removed.\n",
      "        .   @param niters Number of iterations that the algorithm will run. Of course, as more iterations as\n",
      "        .   better, but it is hard to quantitatively refine this statement, so just use the default and\n",
      "        .   increase it if the results are poor.\n",
      "    \n",
      "    destroyAllWindows(...)\n",
      "        destroyAllWindows() -> None\n",
      "        .   @brief Destroys all of the HighGUI windows.\n",
      "        .   \n",
      "        .   The function destroyAllWindows destroys all of the opened HighGUI windows.\n",
      "    \n",
      "    destroyWindow(...)\n",
      "        destroyWindow(winname) -> None\n",
      "        .   @brief Destroys the specified window.\n",
      "        .   \n",
      "        .   The function destroyWindow destroys the window with the given name.\n",
      "        .   \n",
      "        .   @param winname Name of the window to be destroyed.\n",
      "    \n",
      "    detailEnhance(...)\n",
      "        detailEnhance(src[, dst[, sigma_s[, sigma_r]]]) -> dst\n",
      "        .   @brief This filter enhances the details of a particular image.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    determinant(...)\n",
      "        determinant(mtx) -> retval\n",
      "        .   @brief Returns the determinant of a square floating-point matrix.\n",
      "        .   \n",
      "        .   The function cv::determinant calculates and returns the determinant of the\n",
      "        .   specified matrix. For small matrices ( mtx.cols=mtx.rows\\<=3 ), the\n",
      "        .   direct method is used. For larger matrices, the function uses LU\n",
      "        .   factorization with partial pivoting.\n",
      "        .   \n",
      "        .   For symmetric positively-determined matrices, it is also possible to use\n",
      "        .   eigen decomposition to calculate the determinant.\n",
      "        .   @param mtx input matrix that must have CV_32FC1 or CV_64FC1 type and\n",
      "        .   square size.\n",
      "        .   @sa trace, invert, solve, eigen, @ref MatrixExpressions\n",
      "    \n",
      "    dft(...)\n",
      "        dft(src[, dst[, flags[, nonzeroRows]]]) -> dst\n",
      "        .   @brief Performs a forward or inverse Discrete Fourier transform of a 1D or 2D floating-point array.\n",
      "        .   \n",
      "        .   The function cv::dft performs one of the following:\n",
      "        .   -   Forward the Fourier transform of a 1D vector of N elements:\n",
      "        .   \\f[Y = F^{(N)}  \\cdot X,\\f]\n",
      "        .   where \\f$F^{(N)}_{jk}=\\exp(-2\\pi i j k/N)\\f$ and \\f$i=\\sqrt{-1}\\f$\n",
      "        .   -   Inverse the Fourier transform of a 1D vector of N elements:\n",
      "        .   \\f[\\begin{array}{l} X'=  \\left (F^{(N)} \\right )^{-1}  \\cdot Y =  \\left (F^{(N)} \\right )^*  \\cdot y  \\\\ X = (1/N)  \\cdot X, \\end{array}\\f]\n",
      "        .   where \\f$F^*=\\left(\\textrm{Re}(F^{(N)})-\\textrm{Im}(F^{(N)})\\right)^T\\f$\n",
      "        .   -   Forward the 2D Fourier transform of a M x N matrix:\n",
      "        .   \\f[Y = F^{(M)}  \\cdot X  \\cdot F^{(N)}\\f]\n",
      "        .   -   Inverse the 2D Fourier transform of a M x N matrix:\n",
      "        .   \\f[\\begin{array}{l} X'=  \\left (F^{(M)} \\right )^*  \\cdot Y  \\cdot \\left (F^{(N)} \\right )^* \\\\ X =  \\frac{1}{M \\cdot N} \\cdot X' \\end{array}\\f]\n",
      "        .   \n",
      "        .   In case of real (single-channel) data, the output spectrum of the forward Fourier transform or input\n",
      "        .   spectrum of the inverse Fourier transform can be represented in a packed format called *CCS*\n",
      "        .   (complex-conjugate-symmetrical). It was borrowed from IPL (Intel\\* Image Processing Library). Here\n",
      "        .   is how 2D *CCS* spectrum looks:\n",
      "        .   \\f[\\begin{bmatrix} Re Y_{0,0} & Re Y_{0,1} & Im Y_{0,1} & Re Y_{0,2} & Im Y_{0,2} &  \\cdots & Re Y_{0,N/2-1} & Im Y_{0,N/2-1} & Re Y_{0,N/2}  \\\\ Re Y_{1,0} & Re Y_{1,1} & Im Y_{1,1} & Re Y_{1,2} & Im Y_{1,2} &  \\cdots & Re Y_{1,N/2-1} & Im Y_{1,N/2-1} & Re Y_{1,N/2}  \\\\ Im Y_{1,0} & Re Y_{2,1} & Im Y_{2,1} & Re Y_{2,2} & Im Y_{2,2} &  \\cdots & Re Y_{2,N/2-1} & Im Y_{2,N/2-1} & Im Y_{1,N/2}  \\\\ \\hdotsfor{9} \\\\ Re Y_{M/2-1,0} &  Re Y_{M-3,1}  & Im Y_{M-3,1} &  \\hdotsfor{3} & Re Y_{M-3,N/2-1} & Im Y_{M-3,N/2-1}& Re Y_{M/2-1,N/2}  \\\\ Im Y_{M/2-1,0} &  Re Y_{M-2,1}  & Im Y_{M-2,1} &  \\hdotsfor{3} & Re Y_{M-2,N/2-1} & Im Y_{M-2,N/2-1}& Im Y_{M/2-1,N/2}  \\\\ Re Y_{M/2,0}  &  Re Y_{M-1,1} &  Im Y_{M-1,1} &  \\hdotsfor{3} & Re Y_{M-1,N/2-1} & Im Y_{M-1,N/2-1}& Re Y_{M/2,N/2} \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   In case of 1D transform of a real vector, the output looks like the first row of the matrix above.\n",
      "        .   \n",
      "        .   So, the function chooses an operation mode depending on the flags and size of the input array:\n",
      "        .   -   If #DFT_ROWS is set or the input array has a single row or single column, the function\n",
      "        .   performs a 1D forward or inverse transform of each row of a matrix when #DFT_ROWS is set.\n",
      "        .   Otherwise, it performs a 2D transform.\n",
      "        .   -   If the input array is real and #DFT_INVERSE is not set, the function performs a forward 1D or\n",
      "        .   2D transform:\n",
      "        .   -   When #DFT_COMPLEX_OUTPUT is set, the output is a complex matrix of the same size as\n",
      "        .   input.\n",
      "        .   -   When #DFT_COMPLEX_OUTPUT is not set, the output is a real matrix of the same size as\n",
      "        .   input. In case of 2D transform, it uses the packed format as shown above. In case of a\n",
      "        .   single 1D transform, it looks like the first row of the matrix above. In case of\n",
      "        .   multiple 1D transforms (when using the #DFT_ROWS flag), each row of the output matrix\n",
      "        .   looks like the first row of the matrix above.\n",
      "        .   -   If the input array is complex and either #DFT_INVERSE or #DFT_REAL_OUTPUT are not set, the\n",
      "        .   output is a complex array of the same size as input. The function performs a forward or\n",
      "        .   inverse 1D or 2D transform of the whole input array or each row of the input array\n",
      "        .   independently, depending on the flags DFT_INVERSE and DFT_ROWS.\n",
      "        .   -   When #DFT_INVERSE is set and the input array is real, or it is complex but #DFT_REAL_OUTPUT\n",
      "        .   is set, the output is a real array of the same size as input. The function performs a 1D or 2D\n",
      "        .   inverse transformation of the whole input array or each individual row, depending on the flags\n",
      "        .   #DFT_INVERSE and #DFT_ROWS.\n",
      "        .   \n",
      "        .   If #DFT_SCALE is set, the scaling is done after the transformation.\n",
      "        .   \n",
      "        .   Unlike dct , the function supports arrays of arbitrary size. But only those arrays are processed\n",
      "        .   efficiently, whose sizes can be factorized in a product of small prime numbers (2, 3, and 5 in the\n",
      "        .   current implementation). Such an efficient DFT size can be calculated using the getOptimalDFTSize\n",
      "        .   method.\n",
      "        .   \n",
      "        .   The sample below illustrates how to calculate a DFT-based convolution of two 2D real arrays:\n",
      "        .   @code\n",
      "        .   void convolveDFT(InputArray A, InputArray B, OutputArray C)\n",
      "        .   {\n",
      "        .   // reallocate the output array if needed\n",
      "        .   C.create(abs(A.rows - B.rows)+1, abs(A.cols - B.cols)+1, A.type());\n",
      "        .   Size dftSize;\n",
      "        .   // calculate the size of DFT transform\n",
      "        .   dftSize.width = getOptimalDFTSize(A.cols + B.cols - 1);\n",
      "        .   dftSize.height = getOptimalDFTSize(A.rows + B.rows - 1);\n",
      "        .   \n",
      "        .   // allocate temporary buffers and initialize them with 0's\n",
      "        .   Mat tempA(dftSize, A.type(), Scalar::all(0));\n",
      "        .   Mat tempB(dftSize, B.type(), Scalar::all(0));\n",
      "        .   \n",
      "        .   // copy A and B to the top-left corners of tempA and tempB, respectively\n",
      "        .   Mat roiA(tempA, Rect(0,0,A.cols,A.rows));\n",
      "        .   A.copyTo(roiA);\n",
      "        .   Mat roiB(tempB, Rect(0,0,B.cols,B.rows));\n",
      "        .   B.copyTo(roiB);\n",
      "        .   \n",
      "        .   // now transform the padded A & B in-place;\n",
      "        .   // use \"nonzeroRows\" hint for faster processing\n",
      "        .   dft(tempA, tempA, 0, A.rows);\n",
      "        .   dft(tempB, tempB, 0, B.rows);\n",
      "        .   \n",
      "        .   // multiply the spectrums;\n",
      "        .   // the function handles packed spectrum representations well\n",
      "        .   mulSpectrums(tempA, tempB, tempA);\n",
      "        .   \n",
      "        .   // transform the product back from the frequency domain.\n",
      "        .   // Even though all the result rows will be non-zero,\n",
      "        .   // you need only the first C.rows of them, and thus you\n",
      "        .   // pass nonzeroRows == C.rows\n",
      "        .   dft(tempA, tempA, DFT_INVERSE + DFT_SCALE, C.rows);\n",
      "        .   \n",
      "        .   // now copy the result back to C.\n",
      "        .   tempA(Rect(0, 0, C.cols, C.rows)).copyTo(C);\n",
      "        .   \n",
      "        .   // all the temporary buffers will be deallocated automatically\n",
      "        .   }\n",
      "        .   @endcode\n",
      "        .   To optimize this sample, consider the following approaches:\n",
      "        .   -   Since nonzeroRows != 0 is passed to the forward transform calls and since A and B are copied to\n",
      "        .   the top-left corners of tempA and tempB, respectively, it is not necessary to clear the whole\n",
      "        .   tempA and tempB. It is only necessary to clear the tempA.cols - A.cols ( tempB.cols - B.cols)\n",
      "        .   rightmost columns of the matrices.\n",
      "        .   -   This DFT-based convolution does not have to be applied to the whole big arrays, especially if B\n",
      "        .   is significantly smaller than A or vice versa. Instead, you can calculate convolution by parts.\n",
      "        .   To do this, you need to split the output array C into multiple tiles. For each tile, estimate\n",
      "        .   which parts of A and B are required to calculate convolution in this tile. If the tiles in C are\n",
      "        .   too small, the speed will decrease a lot because of repeated work. In the ultimate case, when\n",
      "        .   each tile in C is a single pixel, the algorithm becomes equivalent to the naive convolution\n",
      "        .   algorithm. If the tiles are too big, the temporary arrays tempA and tempB become too big and\n",
      "        .   there is also a slowdown because of bad cache locality. So, there is an optimal tile size\n",
      "        .   somewhere in the middle.\n",
      "        .   -   If different tiles in C can be calculated in parallel and, thus, the convolution is done by\n",
      "        .   parts, the loop can be threaded.\n",
      "        .   \n",
      "        .   All of the above improvements have been implemented in #matchTemplate and #filter2D . Therefore, by\n",
      "        .   using them, you can get the performance even better than with the above theoretically optimal\n",
      "        .   implementation. Though, those two functions actually calculate cross-correlation, not convolution,\n",
      "        .   so you need to \"flip\" the second convolution operand B vertically and horizontally using flip .\n",
      "        .   @note\n",
      "        .   -   An example using the discrete fourier transform can be found at\n",
      "        .   opencv_source_code/samples/cpp/dft.cpp\n",
      "        .   -   (Python) An example using the dft functionality to perform Wiener deconvolution can be found\n",
      "        .   at opencv_source/samples/python/deconvolution.py\n",
      "        .   -   (Python) An example rearranging the quadrants of a Fourier image can be found at\n",
      "        .   opencv_source/samples/python/dft.py\n",
      "        .   @param src input array that could be real or complex.\n",
      "        .   @param dst output array whose size and type depends on the flags .\n",
      "        .   @param flags transformation flags, representing a combination of the #DftFlags\n",
      "        .   @param nonzeroRows when the parameter is not zero, the function assumes that only the first\n",
      "        .   nonzeroRows rows of the input array (#DFT_INVERSE is not set) or only the first nonzeroRows of the\n",
      "        .   output array (#DFT_INVERSE is set) contain non-zeros, thus, the function can handle the rest of the\n",
      "        .   rows more efficiently and save some time; this technique is very useful for calculating array\n",
      "        .   cross-correlation or convolution using DFT.\n",
      "        .   @sa dct , getOptimalDFTSize , mulSpectrums, filter2D , matchTemplate , flip , cartToPolar ,\n",
      "        .   magnitude , phase\n",
      "    \n",
      "    dilate(...)\n",
      "        dilate(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Dilates an image by using a specific structuring element.\n",
      "        .   \n",
      "        .   The function dilates the source image using the specified structuring element that determines the\n",
      "        .   shape of a pixel neighborhood over which the maximum is taken:\n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\max _{(x',y'):  \\, \\texttt{element} (x',y') \\ne0 } \\texttt{src} (x+x',y+y')\\f]\n",
      "        .   \n",
      "        .   The function supports the in-place mode. Dilation can be applied several ( iterations ) times. In\n",
      "        .   case of multi-channel images, each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src input image; the number of channels can be arbitrary, but the depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param kernel structuring element used for dilation; if elemenat=Mat(), a 3 x 3 rectangular\n",
      "        .   structuring element is used. Kernel can be created using #getStructuringElement\n",
      "        .   @param anchor position of the anchor within the element; default value (-1, -1) means that the\n",
      "        .   anchor is at the element center.\n",
      "        .   @param iterations number of times dilation is applied.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   @param borderValue border value in case of a constant border\n",
      "        .   @sa  erode, morphologyEx, getStructuringElement\n",
      "    \n",
      "    displayOverlay(...)\n",
      "        displayOverlay(winname, text[, delayms]) -> None\n",
      "        .   @brief Displays a text on a window image as an overlay for a specified duration.\n",
      "        .   \n",
      "        .   The function displayOverlay displays useful information/tips on top of the window for a certain\n",
      "        .   amount of time *delayms*. The function does not modify the image, displayed in the window, that is,\n",
      "        .   after the specified delay the original content of the window is restored.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param text Overlay text to write on a window image.\n",
      "        .   @param delayms The period (in milliseconds), during which the overlay text is displayed. If this\n",
      "        .   function is called before the previous overlay text timed out, the timer is restarted and the text\n",
      "        .   is updated. If this value is zero, the text never disappears.\n",
      "    \n",
      "    displayStatusBar(...)\n",
      "        displayStatusBar(winname, text[, delayms]) -> None\n",
      "        .   @brief Displays a text on the window statusbar during the specified period of time.\n",
      "        .   \n",
      "        .   The function displayStatusBar displays useful information/tips on top of the window for a certain\n",
      "        .   amount of time *delayms* . This information is displayed on the window statusbar (the window must be\n",
      "        .   created with the CV_GUI_EXPANDED flags).\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param text Text to write on the window statusbar.\n",
      "        .   @param delayms Duration (in milliseconds) to display the text. If this function is called before\n",
      "        .   the previous text timed out, the timer is restarted and the text is updated. If this value is\n",
      "        .   zero, the text never disappears.\n",
      "    \n",
      "    distanceTransform(...)\n",
      "        distanceTransform(src, distanceType, maskSize[, dst[, dstType]]) -> dst\n",
      "        .   @overload\n",
      "        .   @param src 8-bit, single-channel (binary) source image.\n",
      "        .   @param dst Output image with calculated distances. It is a 8-bit or 32-bit floating-point,\n",
      "        .   single-channel image of the same size as src .\n",
      "        .   @param distanceType Type of distance, see #DistanceTypes\n",
      "        .   @param maskSize Size of the distance transform mask, see #DistanceTransformMasks. In case of the\n",
      "        .   #DIST_L1 or #DIST_C distance type, the parameter is forced to 3 because a \\f$3\\times 3\\f$ mask gives\n",
      "        .   the same result as \\f$5\\times 5\\f$ or any larger aperture.\n",
      "        .   @param dstType Type of output image. It can be CV_8U or CV_32F. Type CV_8U can be used only for\n",
      "        .   the first variant of the function and distanceType == #DIST_L1.\n",
      "    \n",
      "    distanceTransformWithLabels(...)\n",
      "        distanceTransformWithLabels(src, distanceType, maskSize[, dst[, labels[, labelType]]]) -> dst, labels\n",
      "        .   @brief Calculates the distance to the closest zero pixel for each pixel of the source image.\n",
      "        .   \n",
      "        .   The function cv::distanceTransform calculates the approximate or precise distance from every binary\n",
      "        .   image pixel to the nearest zero pixel. For zero image pixels, the distance will obviously be zero.\n",
      "        .   \n",
      "        .   When maskSize == #DIST_MASK_PRECISE and distanceType == #DIST_L2 , the function runs the\n",
      "        .   algorithm described in @cite Felzenszwalb04 . This algorithm is parallelized with the TBB library.\n",
      "        .   \n",
      "        .   In other cases, the algorithm @cite Borgefors86 is used. This means that for a pixel the function\n",
      "        .   finds the shortest path to the nearest zero pixel consisting of basic shifts: horizontal, vertical,\n",
      "        .   diagonal, or knight's move (the latest is available for a \\f$5\\times 5\\f$ mask). The overall\n",
      "        .   distance is calculated as a sum of these basic distances. Since the distance function should be\n",
      "        .   symmetric, all of the horizontal and vertical shifts must have the same cost (denoted as a ), all\n",
      "        .   the diagonal shifts must have the same cost (denoted as `b`), and all knight's moves must have the\n",
      "        .   same cost (denoted as `c`). For the #DIST_C and #DIST_L1 types, the distance is calculated\n",
      "        .   precisely, whereas for #DIST_L2 (Euclidean distance) the distance can be calculated only with a\n",
      "        .   relative error (a \\f$5\\times 5\\f$ mask gives more accurate results). For `a`,`b`, and `c`, OpenCV\n",
      "        .   uses the values suggested in the original paper:\n",
      "        .   - DIST_L1: `a = 1, b = 2`\n",
      "        .   - DIST_L2:\n",
      "        .   - `3 x 3`: `a=0.955, b=1.3693`\n",
      "        .   - `5 x 5`: `a=1, b=1.4, c=2.1969`\n",
      "        .   - DIST_C: `a = 1, b = 1`\n",
      "        .   \n",
      "        .   Typically, for a fast, coarse distance estimation #DIST_L2, a \\f$3\\times 3\\f$ mask is used. For a\n",
      "        .   more accurate distance estimation #DIST_L2, a \\f$5\\times 5\\f$ mask or the precise algorithm is used.\n",
      "        .   Note that both the precise and the approximate algorithms are linear on the number of pixels.\n",
      "        .   \n",
      "        .   This variant of the function does not only compute the minimum distance for each pixel \\f$(x, y)\\f$\n",
      "        .   but also identifies the nearest connected component consisting of zero pixels\n",
      "        .   (labelType==#DIST_LABEL_CCOMP) or the nearest zero pixel (labelType==#DIST_LABEL_PIXEL). Index of the\n",
      "        .   component/pixel is stored in `labels(x, y)`. When labelType==#DIST_LABEL_CCOMP, the function\n",
      "        .   automatically finds connected components of zero pixels in the input image and marks them with\n",
      "        .   distinct labels. When labelType==#DIST_LABEL_CCOMP, the function scans through the input image and\n",
      "        .   marks all the zero pixels with distinct labels.\n",
      "        .   \n",
      "        .   In this mode, the complexity is still linear. That is, the function provides a very fast way to\n",
      "        .   compute the Voronoi diagram for a binary image. Currently, the second variant can use only the\n",
      "        .   approximate distance transform algorithm, i.e. maskSize=#DIST_MASK_PRECISE is not supported\n",
      "        .   yet.\n",
      "        .   \n",
      "        .   @param src 8-bit, single-channel (binary) source image.\n",
      "        .   @param dst Output image with calculated distances. It is a 8-bit or 32-bit floating-point,\n",
      "        .   single-channel image of the same size as src.\n",
      "        .   @param labels Output 2D array of labels (the discrete Voronoi diagram). It has the type\n",
      "        .   CV_32SC1 and the same size as src.\n",
      "        .   @param distanceType Type of distance, see #DistanceTypes\n",
      "        .   @param maskSize Size of the distance transform mask, see #DistanceTransformMasks.\n",
      "        .   #DIST_MASK_PRECISE is not supported by this variant. In case of the #DIST_L1 or #DIST_C distance type,\n",
      "        .   the parameter is forced to 3 because a \\f$3\\times 3\\f$ mask gives the same result as \\f$5\\times\n",
      "        .   5\\f$ or any larger aperture.\n",
      "        .   @param labelType Type of the label array to build, see #DistanceTransformLabelTypes.\n",
      "    \n",
      "    divide(...)\n",
      "        divide(src1, src2[, dst[, scale[, dtype]]]) -> dst\n",
      "        .   @brief Performs per-element division of two arrays or a scalar by an array.\n",
      "        .   \n",
      "        .   The function cv::divide divides one array by another:\n",
      "        .   \\f[\\texttt{dst(I) = saturate(src1(I)*scale/src2(I))}\\f]\n",
      "        .   or a scalar by an array when there is no src1 :\n",
      "        .   \\f[\\texttt{dst(I) = saturate(scale/src2(I))}\\f]\n",
      "        .   \n",
      "        .   Different channels of multi-channel arrays are processed independently.\n",
      "        .   \n",
      "        .   For integer types when src2(I) is zero, dst(I) will also be zero.\n",
      "        .   \n",
      "        .   @note In case of floating point data there is no special defined behavior for zero src2(I) values.\n",
      "        .   Regular floating-point division is used.\n",
      "        .   Expect correct IEEE-754 behaviour for floating-point data (with NaN, Inf result values).\n",
      "        .   \n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param scale scalar factor.\n",
      "        .   @param dst output array of the same size and type as src2.\n",
      "        .   @param dtype optional depth of the output array; if -1, dst will have depth src2.depth(), but in\n",
      "        .   case of an array-by-array division, you can only pass -1 when src1.depth()==src2.depth().\n",
      "        .   @sa  multiply, add, subtract\n",
      "        \n",
      "        \n",
      "        \n",
      "        divide(scale, src2[, dst[, dtype]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    dnn_registerLayer(...)\n",
      "        registerLayer(type, class) -> None\n",
      "    \n",
      "    dnn_unregisterLayer(...)\n",
      "        unregisterLayer(type) -> None\n",
      "    \n",
      "    drawChessboardCorners(...)\n",
      "        drawChessboardCorners(image, patternSize, corners, patternWasFound) -> image\n",
      "        .   @brief Renders the detected chessboard corners.\n",
      "        .   \n",
      "        .   @param image Destination image. It must be an 8-bit color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   (patternSize = cv::Size(points_per_row,points_per_column)).\n",
      "        .   @param corners Array of detected corners, the output of findChessboardCorners.\n",
      "        .   @param patternWasFound Parameter indicating whether the complete board was found or not. The\n",
      "        .   return value of findChessboardCorners should be passed here.\n",
      "        .   \n",
      "        .   The function draws individual chessboard corners detected either as red circles if the board was not\n",
      "        .   found, or as colored corners connected with lines if the board was found.\n",
      "    \n",
      "    drawContours(...)\n",
      "        drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image\n",
      "        .   @brief Draws contours outlines or filled contours.\n",
      "        .   \n",
      "        .   The function draws contour outlines in the image if \\f$\\texttt{thickness} \\ge 0\\f$ or fills the area\n",
      "        .   bounded by the contours if \\f$\\texttt{thickness}<0\\f$ . The example below shows how to retrieve\n",
      "        .   connected components from the binary image and label them: :\n",
      "        .   @include snippets/imgproc_drawContours.cpp\n",
      "        .   \n",
      "        .   @param image Destination image.\n",
      "        .   @param contours All the input contours. Each contour is stored as a point vector.\n",
      "        .   @param contourIdx Parameter indicating a contour to draw. If it is negative, all the contours are drawn.\n",
      "        .   @param color Color of the contours.\n",
      "        .   @param thickness Thickness of lines the contours are drawn with. If it is negative (for example,\n",
      "        .   thickness=#FILLED ), the contour interiors are drawn.\n",
      "        .   @param lineType Line connectivity. See #LineTypes\n",
      "        .   @param hierarchy Optional information about hierarchy. It is only needed if you want to draw only\n",
      "        .   some of the contours (see maxLevel ).\n",
      "        .   @param maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn.\n",
      "        .   If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function\n",
      "        .   draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This\n",
      "        .   parameter is only taken into account when there is hierarchy available.\n",
      "        .   @param offset Optional contour shift parameter. Shift all the drawn contours by the specified\n",
      "        .   \\f$\\texttt{offset}=(dx,dy)\\f$ .\n",
      "        .   @note When thickness=#FILLED, the function is designed to handle connected components with holes correctly\n",
      "        .   even when no hierarchy date is provided. This is done by analyzing all the outlines together\n",
      "        .   using even-odd rule. This may give incorrect results if you have a joint collection of separately retrieved\n",
      "        .   contours. In order to solve this problem, you need to call #drawContours separately for each sub-group\n",
      "        .   of contours, or iterate over the collection using contourIdx parameter.\n",
      "    \n",
      "    drawFrameAxes(...)\n",
      "        drawFrameAxes(image, cameraMatrix, distCoeffs, rvec, tvec, length[, thickness]) -> image\n",
      "        .   @brief Draw axes of the world/object coordinate system from pose estimation. @sa solvePnP\n",
      "        .   \n",
      "        .   @param image Input/output image. It must have 1 or 3 channels. The number of channels is not altered.\n",
      "        .   @param cameraMatrix Input 3x3 floating-point matrix of camera intrinsic parameters.\n",
      "        .   \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is empty, the zero distortion coefficients are assumed.\n",
      "        .   @param rvec Rotation vector (see @ref Rodrigues ) that, together with tvec , brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Translation vector.\n",
      "        .   @param length Length of the painted axes in the same unit than tvec (usually in meters).\n",
      "        .   @param thickness Line thickness of the painted axes.\n",
      "        .   \n",
      "        .   This function draws the axes of the world/object coordinate system w.r.t. to the camera frame.\n",
      "        .   OX is drawn in red, OY in green and OZ in blue.\n",
      "    \n",
      "    drawKeypoints(...)\n",
      "        drawKeypoints(image, keypoints, outImage[, color[, flags]]) -> outImage\n",
      "        .   @brief Draws keypoints.\n",
      "        .   \n",
      "        .   @param image Source image.\n",
      "        .   @param keypoints Keypoints from the source image.\n",
      "        .   @param outImage Output image. Its content depends on the flags value defining what is drawn in the\n",
      "        .   output image. See possible flags bit values below.\n",
      "        .   @param color Color of keypoints.\n",
      "        .   @param flags Flags setting drawing features. Possible flags bit values are defined by\n",
      "        .   DrawMatchesFlags. See details above in drawMatches .\n",
      "        .   \n",
      "        .   @note\n",
      "        .   For Python API, flags are modified as cv.DRAW_MATCHES_FLAGS_DEFAULT,\n",
      "        .   cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, cv.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG,\n",
      "        .   cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS\n",
      "    \n",
      "    drawMarker(...)\n",
      "        drawMarker(img, position, color[, markerType[, markerSize[, thickness[, line_type]]]]) -> img\n",
      "        .   @brief Draws a marker on a predefined position in an image.\n",
      "        .   \n",
      "        .   The function cv::drawMarker draws a marker on a given position in the image. For the moment several\n",
      "        .   marker types are supported, see #MarkerTypes for more information.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param position The point where the crosshair is positioned.\n",
      "        .   @param color Line color.\n",
      "        .   @param markerType The specific type of marker you want to use, see #MarkerTypes\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param line_type Type of the line, See #LineTypes\n",
      "        .   @param markerSize The length of the marker axis [default = 20 pixels]\n",
      "    \n",
      "    drawMatches(...)\n",
      "        drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg[, matchColor[, singlePointColor[, matchesMask[, flags]]]]) -> outImg\n",
      "        .   @brief Draws the found matches of keypoints from two images.\n",
      "        .   \n",
      "        .   @param img1 First source image.\n",
      "        .   @param keypoints1 Keypoints from the first source image.\n",
      "        .   @param img2 Second source image.\n",
      "        .   @param keypoints2 Keypoints from the second source image.\n",
      "        .   @param matches1to2 Matches from the first image to the second one, which means that keypoints1[i]\n",
      "        .   has a corresponding point in keypoints2[matches[i]] .\n",
      "        .   @param outImg Output image. Its content depends on the flags value defining what is drawn in the\n",
      "        .   output image. See possible flags bit values below.\n",
      "        .   @param matchColor Color of matches (lines and connected keypoints). If matchColor==Scalar::all(-1)\n",
      "        .   , the color is generated randomly.\n",
      "        .   @param singlePointColor Color of single keypoints (circles), which means that keypoints do not\n",
      "        .   have the matches. If singlePointColor==Scalar::all(-1) , the color is generated randomly.\n",
      "        .   @param matchesMask Mask determining which matches are drawn. If the mask is empty, all matches are\n",
      "        .   drawn.\n",
      "        .   @param flags Flags setting drawing features. Possible flags bit values are defined by\n",
      "        .   DrawMatchesFlags.\n",
      "        .   \n",
      "        .   This function draws matches of keypoints from two images in the output image. Match is a line\n",
      "        .   connecting two keypoints (circles). See cv::DrawMatchesFlags.\n",
      "    \n",
      "    drawMatchesKnn(...)\n",
      "        drawMatchesKnn(img1, keypoints1, img2, keypoints2, matches1to2, outImg[, matchColor[, singlePointColor[, matchesMask[, flags]]]]) -> outImg\n",
      "        .   @overload\n",
      "    \n",
      "    edgePreservingFilter(...)\n",
      "        edgePreservingFilter(src[, dst[, flags[, sigma_s[, sigma_r]]]]) -> dst\n",
      "        .   @brief Filtering is the fundamental operation in image and video processing. Edge-preserving smoothing\n",
      "        .   filters are used in many different applications @cite EM11 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output 8-bit 3-channel image.\n",
      "        .   @param flags Edge preserving filters: cv::RECURS_FILTER or cv::NORMCONV_FILTER\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    eigen(...)\n",
      "        eigen(src[, eigenvalues[, eigenvectors]]) -> retval, eigenvalues, eigenvectors\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of a symmetric matrix.\n",
      "        .   \n",
      "        .   The function cv::eigen calculates just eigenvalues, or eigenvalues and eigenvectors of the symmetric\n",
      "        .   matrix src:\n",
      "        .   @code\n",
      "        .   src*eigenvectors.row(i).t() = eigenvalues.at<srcType>(i)*eigenvectors.row(i).t()\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @note Use cv::eigenNonSymmetric for calculation of real eigenvalues and eigenvectors of non-symmetric matrix.\n",
      "        .   \n",
      "        .   @param src input matrix that must have CV_32FC1 or CV_64FC1 type, square size and be symmetrical\n",
      "        .   (src ^T^ == src).\n",
      "        .   @param eigenvalues output vector of eigenvalues of the same type as src; the eigenvalues are stored\n",
      "        .   in the descending order.\n",
      "        .   @param eigenvectors output matrix of eigenvectors; it has the same size and type as src; the\n",
      "        .   eigenvectors are stored as subsequent matrix rows, in the same order as the corresponding\n",
      "        .   eigenvalues.\n",
      "        .   @sa eigenNonSymmetric, completeSymm , PCA\n",
      "    \n",
      "    eigenNonSymmetric(...)\n",
      "        eigenNonSymmetric(src[, eigenvalues[, eigenvectors]]) -> eigenvalues, eigenvectors\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of a non-symmetric matrix (real eigenvalues only).\n",
      "        .   \n",
      "        .   @note Assumes real eigenvalues.\n",
      "        .   \n",
      "        .   The function calculates eigenvalues and eigenvectors (optional) of the square matrix src:\n",
      "        .   @code\n",
      "        .   src*eigenvectors.row(i).t() = eigenvalues.at<srcType>(i)*eigenvectors.row(i).t()\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input matrix (CV_32FC1 or CV_64FC1 type).\n",
      "        .   @param eigenvalues output vector of eigenvalues (type is the same type as src).\n",
      "        .   @param eigenvectors output matrix of eigenvectors (type is the same type as src). The eigenvectors are stored as subsequent matrix rows, in the same order as the corresponding eigenvalues.\n",
      "        .   @sa eigen\n",
      "    \n",
      "    ellipse(...)\n",
      "        ellipse(img, center, axes, angle, startAngle, endAngle, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a simple or thick elliptic arc or fills an ellipse sector.\n",
      "        .   \n",
      "        .   The function cv::ellipse with more parameters draws an ellipse outline, a filled ellipse, an elliptic\n",
      "        .   arc, or a filled ellipse sector. The drawing code uses general parametric form.\n",
      "        .   A piecewise-linear curve is used to approximate the elliptic arc\n",
      "        .   boundary. If you need more control of the ellipse rendering, you can retrieve the curve using\n",
      "        .   #ellipse2Poly and then render it with #polylines or fill it with #fillPoly. If you use the first\n",
      "        .   variant of the function and want to draw the whole ellipse, not an arc, pass `startAngle=0` and\n",
      "        .   `endAngle=360`. If `startAngle` is greater than `endAngle`, they are swapped. The figure below explains\n",
      "        .   the meaning of the parameters to draw the blue arc.\n",
      "        .   \n",
      "        .   ![Parameters of Elliptic Arc](pics/ellipse.svg)\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param center Center of the ellipse.\n",
      "        .   @param axes Half of the size of the ellipse main axes.\n",
      "        .   @param angle Ellipse rotation angle in degrees.\n",
      "        .   @param startAngle Starting angle of the elliptic arc in degrees.\n",
      "        .   @param endAngle Ending angle of the elliptic arc in degrees.\n",
      "        .   @param color Ellipse color.\n",
      "        .   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
      "        .   a filled ellipse sector is to be drawn.\n",
      "        .   @param lineType Type of the ellipse boundary. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the coordinates of the center and values of axes.\n",
      "        \n",
      "        \n",
      "        \n",
      "        ellipse(img, box, color[, thickness[, lineType]]) -> img\n",
      "        .   @overload\n",
      "        .   @param img Image.\n",
      "        .   @param box Alternative ellipse representation via RotatedRect. This means that the function draws\n",
      "        .   an ellipse inscribed in the rotated rectangle.\n",
      "        .   @param color Ellipse color.\n",
      "        .   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
      "        .   a filled ellipse sector is to be drawn.\n",
      "        .   @param lineType Type of the ellipse boundary. See #LineTypes\n",
      "    \n",
      "    ellipse2Poly(...)\n",
      "        ellipse2Poly(center, axes, angle, arcStart, arcEnd, delta) -> pts\n",
      "        .   @brief Approximates an elliptic arc with a polyline.\n",
      "        .   \n",
      "        .   The function ellipse2Poly computes the vertices of a polyline that approximates the specified\n",
      "        .   elliptic arc. It is used by #ellipse. If `arcStart` is greater than `arcEnd`, they are swapped.\n",
      "        .   \n",
      "        .   @param center Center of the arc.\n",
      "        .   @param axes Half of the size of the ellipse main axes. See #ellipse for details.\n",
      "        .   @param angle Rotation angle of the ellipse in degrees. See #ellipse for details.\n",
      "        .   @param arcStart Starting angle of the elliptic arc in degrees.\n",
      "        .   @param arcEnd Ending angle of the elliptic arc in degrees.\n",
      "        .   @param delta Angle between the subsequent polyline vertices. It defines the approximation\n",
      "        .   accuracy.\n",
      "        .   @param pts Output vector of polyline vertices.\n",
      "    \n",
      "    equalizeHist(...)\n",
      "        equalizeHist(src[, dst]) -> dst\n",
      "        .   @brief Equalizes the histogram of a grayscale image.\n",
      "        .   \n",
      "        .   The function equalizes the histogram of the input image using the following algorithm:\n",
      "        .   \n",
      "        .   - Calculate the histogram \\f$H\\f$ for src .\n",
      "        .   - Normalize the histogram so that the sum of histogram bins is 255.\n",
      "        .   - Compute the integral of the histogram:\n",
      "        .   \\f[H'_i =  \\sum _{0  \\le j < i} H(j)\\f]\n",
      "        .   - Transform the image using \\f$H'\\f$ as a look-up table: \\f$\\texttt{dst}(x,y) = H'(\\texttt{src}(x,y))\\f$\n",
      "        .   \n",
      "        .   The algorithm normalizes the brightness and increases the contrast of the image.\n",
      "        .   \n",
      "        .   @param src Source 8-bit single channel image.\n",
      "        .   @param dst Destination image of the same size and type as src .\n",
      "    \n",
      "    erode(...)\n",
      "        erode(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Erodes an image by using a specific structuring element.\n",
      "        .   \n",
      "        .   The function erodes the source image using the specified structuring element that determines the\n",
      "        .   shape of a pixel neighborhood over which the minimum is taken:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\min _{(x',y'):  \\, \\texttt{element} (x',y') \\ne0 } \\texttt{src} (x+x',y+y')\\f]\n",
      "        .   \n",
      "        .   The function supports the in-place mode. Erosion can be applied several ( iterations ) times. In\n",
      "        .   case of multi-channel images, each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src input image; the number of channels can be arbitrary, but the depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param kernel structuring element used for erosion; if `element=Mat()`, a `3 x 3` rectangular\n",
      "        .   structuring element is used. Kernel can be created using #getStructuringElement.\n",
      "        .   @param anchor position of the anchor within the element; default value (-1, -1) means that the\n",
      "        .   anchor is at the element center.\n",
      "        .   @param iterations number of times erosion is applied.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   @param borderValue border value in case of a constant border\n",
      "        .   @sa  dilate, morphologyEx, getStructuringElement\n",
      "    \n",
      "    estimateAffine2D(...)\n",
      "        estimateAffine2D(from, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inliers\n",
      "        .   @brief Computes an optimal affine transformation between two 2D point sets.\n",
      "        .   \n",
      "        .   It computes\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   x\\\\\n",
      "        .   y\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12}\\\\\n",
      "        .   a_{21} & a_{22}\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X\\\\\n",
      "        .   Y\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   +\n",
      "        .   \\begin{bmatrix}\n",
      "        .   b_1\\\\\n",
      "        .   b_2\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @param from First input 2D point set containing \\f$(X,Y)\\f$.\n",
      "        .   @param to Second input 2D point set containing \\f$(x,y)\\f$.\n",
      "        .   @param inliers Output vector indicating which points are inliers (1-inlier, 0-outlier).\n",
      "        .   @param method Robust method used to compute transformation. The following methods are possible:\n",
      "        .   -   cv::RANSAC - RANSAC-based robust method\n",
      "        .   -   cv::LMEDS - Least-Median robust method\n",
      "        .   RANSAC is the default method.\n",
      "        .   @param ransacReprojThreshold Maximum reprojection error in the RANSAC algorithm to consider\n",
      "        .   a point as an inlier. Applies only to RANSAC.\n",
      "        .   @param maxIters The maximum number of robust method iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   @param refineIters Maximum number of iterations of refining algorithm (Levenberg-Marquardt).\n",
      "        .   Passing 0 will disable refining, so the output matrix will be output of robust method.\n",
      "        .   \n",
      "        .   @return Output 2D affine transformation matrix \\f$2 \\times 3\\f$ or empty matrix if transformation\n",
      "        .   could not be estimated. The returned matrix has the following form:\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & b_1\\\\\n",
      "        .   a_{21} & a_{22} & b_2\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The function estimates an optimal 2D affine transformation between two 2D point sets using the\n",
      "        .   selected robust algorithm.\n",
      "        .   \n",
      "        .   The computed transformation is then refined further (using only inliers) with the\n",
      "        .   Levenberg-Marquardt method to reduce the re-projection error even more.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The RANSAC method can handle practically any ratio of outliers but needs a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers.\n",
      "        .   \n",
      "        .   @sa estimateAffinePartial2D, getAffineTransform\n",
      "    \n",
      "    estimateAffine3D(...)\n",
      "        estimateAffine3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inliers\n",
      "        .   @brief Computes an optimal affine transformation between two 3D point sets.\n",
      "        .   \n",
      "        .   It computes\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   x\\\\\n",
      "        .   y\\\\\n",
      "        .   z\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & a_{13}\\\\\n",
      "        .   a_{21} & a_{22} & a_{23}\\\\\n",
      "        .   a_{31} & a_{32} & a_{33}\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X\\\\\n",
      "        .   Y\\\\\n",
      "        .   Z\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   +\n",
      "        .   \\begin{bmatrix}\n",
      "        .   b_1\\\\\n",
      "        .   b_2\\\\\n",
      "        .   b_3\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @param src First input 3D point set containing \\f$(X,Y,Z)\\f$.\n",
      "        .   @param dst Second input 3D point set containing \\f$(x,y,z)\\f$.\n",
      "        .   @param out Output 3D affine transformation matrix \\f$3 \\times 4\\f$ of the form\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & a_{13} & b_1\\\\\n",
      "        .   a_{21} & a_{22} & a_{23} & b_2\\\\\n",
      "        .   a_{31} & a_{32} & a_{33} & b_3\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   @param inliers Output vector indicating which points are inliers (1-inlier, 0-outlier).\n",
      "        .   @param ransacThreshold Maximum reprojection error in the RANSAC algorithm to consider a point as\n",
      "        .   an inlier.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   \n",
      "        .   The function estimates an optimal 3D affine transformation between two 3D point sets using the\n",
      "        .   RANSAC algorithm.\n",
      "    \n",
      "    estimateAffinePartial2D(...)\n",
      "        estimateAffinePartial2D(from, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inliers\n",
      "        .   @brief Computes an optimal limited affine transformation with 4 degrees of freedom between\n",
      "        .   two 2D point sets.\n",
      "        .   \n",
      "        .   @param from First input 2D point set.\n",
      "        .   @param to Second input 2D point set.\n",
      "        .   @param inliers Output vector indicating which points are inliers.\n",
      "        .   @param method Robust method used to compute transformation. The following methods are possible:\n",
      "        .   -   cv::RANSAC - RANSAC-based robust method\n",
      "        .   -   cv::LMEDS - Least-Median robust method\n",
      "        .   RANSAC is the default method.\n",
      "        .   @param ransacReprojThreshold Maximum reprojection error in the RANSAC algorithm to consider\n",
      "        .   a point as an inlier. Applies only to RANSAC.\n",
      "        .   @param maxIters The maximum number of robust method iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   @param refineIters Maximum number of iterations of refining algorithm (Levenberg-Marquardt).\n",
      "        .   Passing 0 will disable refining, so the output matrix will be output of robust method.\n",
      "        .   \n",
      "        .   @return Output 2D affine transformation (4 degrees of freedom) matrix \\f$2 \\times 3\\f$ or\n",
      "        .   empty matrix if transformation could not be estimated.\n",
      "        .   \n",
      "        .   The function estimates an optimal 2D affine transformation with 4 degrees of freedom limited to\n",
      "        .   combinations of translation, rotation, and uniform scaling. Uses the selected algorithm for robust\n",
      "        .   estimation.\n",
      "        .   \n",
      "        .   The computed transformation is then refined further (using only inliers) with the\n",
      "        .   Levenberg-Marquardt method to reduce the re-projection error even more.\n",
      "        .   \n",
      "        .   Estimated transformation matrix is:\n",
      "        .   \\f[ \\begin{bmatrix} \\cos(\\theta) \\cdot s & -\\sin(\\theta) \\cdot s & t_x \\\\\n",
      "        .   \\sin(\\theta) \\cdot s & \\cos(\\theta) \\cdot s & t_y\n",
      "        .   \\end{bmatrix} \\f]\n",
      "        .   Where \\f$ \\theta \\f$ is the rotation angle, \\f$ s \\f$ the scaling factor and \\f$ t_x, t_y \\f$ are\n",
      "        .   translations in \\f$ x, y \\f$ axes respectively.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The RANSAC method can handle practically any ratio of outliers but need a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers.\n",
      "        .   \n",
      "        .   @sa estimateAffine2D, getAffineTransform\n",
      "    \n",
      "    exp(...)\n",
      "        exp(src[, dst]) -> dst\n",
      "        .   @brief Calculates the exponent of every array element.\n",
      "        .   \n",
      "        .   The function cv::exp calculates the exponent of every element of the input\n",
      "        .   array:\n",
      "        .   \\f[\\texttt{dst} [I] = e^{ src(I) }\\f]\n",
      "        .   \n",
      "        .   The maximum relative error is about 7e-6 for single-precision input and\n",
      "        .   less than 1e-10 for double-precision input. Currently, the function\n",
      "        .   converts denormalized values to zeros on output. Special values (NaN,\n",
      "        .   Inf) are not handled.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @sa log , cartToPolar , polarToCart , phase , pow , sqrt , magnitude\n",
      "    \n",
      "    extractChannel(...)\n",
      "        extractChannel(src, coi[, dst]) -> dst\n",
      "        .   @brief Extracts a single channel from src (coi is 0-based index)\n",
      "        .   @param src input array\n",
      "        .   @param dst output array\n",
      "        .   @param coi index of channel to extract\n",
      "        .   @sa mixChannels, split\n",
      "    \n",
      "    fastAtan2(...)\n",
      "        fastAtan2(y, x) -> retval\n",
      "        .   @brief Calculates the angle of a 2D vector in degrees.\n",
      "        .   \n",
      "        .   The function fastAtan2 calculates the full-range angle of an input 2D vector. The angle is measured\n",
      "        .   in degrees and varies from 0 to 360 degrees. The accuracy is about 0.3 degrees.\n",
      "        .   @param x x-coordinate of the vector.\n",
      "        .   @param y y-coordinate of the vector.\n",
      "    \n",
      "    fastNlMeansDenoising(...)\n",
      "        fastNlMeansDenoising(src[, dst[, h[, templateWindowSize[, searchWindowSize]]]]) -> dst\n",
      "        .   @brief Perform image denoising using Non-local Means Denoising algorithm\n",
      "        .   <http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/> with several computational\n",
      "        .   optimizations. Noise expected to be a gaussian white noise\n",
      "        .   \n",
      "        .   @param src Input 8-bit 1-channel, 2-channel, 3-channel or 4-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength. Big h value perfectly removes noise but also\n",
      "        .   removes image details, smaller h value preserves details but also preserves some noise\n",
      "        .   \n",
      "        .   This function expected to be applied to grayscale images. For colored images look at\n",
      "        .   fastNlMeansDenoisingColored. Advanced usage of this functions can be manual denoising of colored\n",
      "        .   image in different colorspaces. Such approach is used in fastNlMeansDenoisingColored by converting\n",
      "        .   image to CIELAB colorspace and then separately denoise L and AB components with different h\n",
      "        .   parameter.\n",
      "        \n",
      "        \n",
      "        \n",
      "        fastNlMeansDenoising(src, h[, dst[, templateWindowSize[, searchWindowSize[, normType]]]]) -> dst\n",
      "        .   @brief Perform image denoising using Non-local Means Denoising algorithm\n",
      "        .   <http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/> with several computational\n",
      "        .   optimizations. Noise expected to be a gaussian white noise\n",
      "        .   \n",
      "        .   @param src Input 8-bit or 16-bit (only with NORM_L1) 1-channel,\n",
      "        .   2-channel, 3-channel or 4-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Array of parameters regulating filter strength, either one\n",
      "        .   parameter applied to all channels or one per channel in dst. Big h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        .   @param normType Type of norm used for weight calculation. Can be either NORM_L2 or NORM_L1\n",
      "        .   \n",
      "        .   This function expected to be applied to grayscale images. For colored images look at\n",
      "        .   fastNlMeansDenoisingColored. Advanced usage of this functions can be manual denoising of colored\n",
      "        .   image in different colorspaces. Such approach is used in fastNlMeansDenoisingColored by converting\n",
      "        .   image to CIELAB colorspace and then separately denoise L and AB components with different h\n",
      "        .   parameter.\n",
      "    \n",
      "    fastNlMeansDenoisingColored(...)\n",
      "        fastNlMeansDenoisingColored(src[, dst[, h[, hColor[, templateWindowSize[, searchWindowSize]]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for colored images\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength for luminance component. Bigger h value perfectly\n",
      "        .   removes noise but also removes image details, smaller h value preserves details but also preserves\n",
      "        .   some noise\n",
      "        .   @param hColor The same as h but for color components. For most images value equals 10\n",
      "        .   will be enough to remove colored noise and do not distort colors\n",
      "        .   \n",
      "        .   The function converts image to CIELAB colorspace and then separately denoise L and AB components\n",
      "        .   with given h parameters using fastNlMeansDenoising function.\n",
      "    \n",
      "    fastNlMeansDenoisingColoredMulti(...)\n",
      "        fastNlMeansDenoisingColoredMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize[, dst[, h[, hColor[, templateWindowSize[, searchWindowSize]]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoisingMulti function for colored images sequences\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit 3-channel images sequence. All images should have the same type and\n",
      "        .   size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength for luminance component. Bigger h value perfectly\n",
      "        .   removes noise but also removes image details, smaller h value preserves details but also preserves\n",
      "        .   some noise.\n",
      "        .   @param hColor The same as h but for color components.\n",
      "        .   \n",
      "        .   The function converts images to CIELAB colorspace and then separately denoise L and AB components\n",
      "        .   with given h parameters using fastNlMeansDenoisingMulti function.\n",
      "    \n",
      "    fastNlMeansDenoisingMulti(...)\n",
      "        fastNlMeansDenoisingMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize[, dst[, h[, templateWindowSize[, searchWindowSize]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for images sequence where consecutive images have been\n",
      "        .   captured in small period of time. For example video. This version of the function is for grayscale\n",
      "        .   images or for manual manipulation with colorspaces. For more details see\n",
      "        .   <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6394>\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit 1-channel, 2-channel, 3-channel or\n",
      "        .   4-channel images sequence. All images should have the same type and\n",
      "        .   size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength. Bigger h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        \n",
      "        \n",
      "        \n",
      "        fastNlMeansDenoisingMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize, h[, dst[, templateWindowSize[, searchWindowSize[, normType]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for images sequence where consecutive images have been\n",
      "        .   captured in small period of time. For example video. This version of the function is for grayscale\n",
      "        .   images or for manual manipulation with colorspaces. For more details see\n",
      "        .   <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6394>\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit or 16-bit (only with NORM_L1) 1-channel,\n",
      "        .   2-channel, 3-channel or 4-channel images sequence. All images should\n",
      "        .   have the same type and size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Array of parameters regulating filter strength, either one\n",
      "        .   parameter applied to all channels or one per channel in dst. Big h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        .   @param normType Type of norm used for weight calculation. Can be either NORM_L2 or NORM_L1\n",
      "    \n",
      "    fillConvexPoly(...)\n",
      "        fillConvexPoly(img, points, color[, lineType[, shift]]) -> img\n",
      "        .   @brief Fills a convex polygon.\n",
      "        .   \n",
      "        .   The function cv::fillConvexPoly draws a filled convex polygon. This function is much faster than the\n",
      "        .   function #fillPoly . It can fill not only convex polygons but any monotonic polygon without\n",
      "        .   self-intersections, that is, a polygon whose contour intersects every horizontal line (scan line)\n",
      "        .   twice at the most (though, its top-most and/or the bottom edge could be horizontal).\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param points Polygon vertices.\n",
      "        .   @param color Polygon color.\n",
      "        .   @param lineType Type of the polygon boundaries. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "    \n",
      "    fillPoly(...)\n",
      "        fillPoly(img, pts, color[, lineType[, shift[, offset]]]) -> img\n",
      "        .   @brief Fills the area bounded by one or more polygons.\n",
      "        .   \n",
      "        .   The function cv::fillPoly fills an area bounded by several polygonal contours. The function can fill\n",
      "        .   complex areas, for example, areas with holes, contours with self-intersections (some of their\n",
      "        .   parts), and so forth.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pts Array of polygons where each polygon is represented as an array of points.\n",
      "        .   @param color Polygon color.\n",
      "        .   @param lineType Type of the polygon boundaries. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "        .   @param offset Optional offset of all points of the contours.\n",
      "    \n",
      "    filter2D(...)\n",
      "        filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Convolves an image with the kernel.\n",
      "        .   \n",
      "        .   The function applies an arbitrary linear filter to an image. In-place operation is supported. When\n",
      "        .   the aperture is partially outside the image, the function interpolates outlier pixel values\n",
      "        .   according to the specified border mode.\n",
      "        .   \n",
      "        .   The function does actually compute correlation, not the convolution:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\sum _{ \\stackrel{0\\leq x' < \\texttt{kernel.cols},}{0\\leq y' < \\texttt{kernel.rows}} }  \\texttt{kernel} (x',y')* \\texttt{src} (x+x'- \\texttt{anchor.x} ,y+y'- \\texttt{anchor.y} )\\f]\n",
      "        .   \n",
      "        .   That is, the kernel is not mirrored around the anchor point. If you need a real convolution, flip\n",
      "        .   the kernel using #flip and set the new anchor to `(kernel.cols - anchor.x - 1, kernel.rows -\n",
      "        .   anchor.y - 1)`.\n",
      "        .   \n",
      "        .   The function uses the DFT-based algorithm in case of sufficiently large kernels (~`11 x 11` or\n",
      "        .   larger) and the direct algorithm for small kernels.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src.\n",
      "        .   @param ddepth desired depth of the destination image, see @ref filter_depths \"combinations\"\n",
      "        .   @param kernel convolution kernel (or rather a correlation kernel), a single-channel floating point\n",
      "        .   matrix; if you want to apply different kernels to different channels, split the image into\n",
      "        .   separate color planes using split and process them individually.\n",
      "        .   @param anchor anchor of the kernel that indicates the relative position of a filtered point within\n",
      "        .   the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor\n",
      "        .   is at the kernel center.\n",
      "        .   @param delta optional value added to the filtered pixels before storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   @sa  sepFilter2D, dft, matchTemplate\n",
      "    \n",
      "    filterHomographyDecompByVisibleRefpoints(...)\n",
      "        filterHomographyDecompByVisibleRefpoints(rotations, normals, beforePoints, afterPoints[, possibleSolutions[, pointsMask]]) -> possibleSolutions\n",
      "        .   @brief Filters homography decompositions based on additional information.\n",
      "        .   \n",
      "        .   @param rotations Vector of rotation matrices.\n",
      "        .   @param normals Vector of plane normal matrices.\n",
      "        .   @param beforePoints Vector of (rectified) visible reference points before the homography is applied\n",
      "        .   @param afterPoints Vector of (rectified) visible reference points after the homography is applied\n",
      "        .   @param possibleSolutions Vector of int indices representing the viable solution set after filtering\n",
      "        .   @param pointsMask optional Mat/Vector of 8u type representing the mask for the inliers as given by the findHomography function\n",
      "        .   \n",
      "        .   This function is intended to filter the output of the decomposeHomographyMat based on additional\n",
      "        .   information as described in @cite Malis . The summary of the method: the decomposeHomographyMat function\n",
      "        .   returns 2 unique solutions and their \"opposites\" for a total of 4 solutions. If we have access to the\n",
      "        .   sets of points visible in the camera frame before and after the homography transformation is applied,\n",
      "        .   we can determine which are the true potential solutions and which are the opposites by verifying which\n",
      "        .   homographies are consistent with all visible reference points being in front of the camera. The inputs\n",
      "        .   are left unchanged; the filtered solution set is returned as indices into the existing one.\n",
      "    \n",
      "    filterSpeckles(...)\n",
      "        filterSpeckles(img, newVal, maxSpeckleSize, maxDiff[, buf]) -> img, buf\n",
      "        .   @brief Filters off small noise blobs (speckles) in the disparity map\n",
      "        .   \n",
      "        .   @param img The input 16-bit signed disparity image\n",
      "        .   @param newVal The disparity value used to paint-off the speckles\n",
      "        .   @param maxSpeckleSize The maximum speckle size to consider it a speckle. Larger blobs are not\n",
      "        .   affected by the algorithm\n",
      "        .   @param maxDiff Maximum difference between neighbor disparity pixels to put them into the same\n",
      "        .   blob. Note that since StereoBM, StereoSGBM and may be other algorithms return a fixed-point\n",
      "        .   disparity map, where disparity values are multiplied by 16, this scale factor should be taken into\n",
      "        .   account when specifying this parameter value.\n",
      "        .   @param buf The optional temporary buffer to avoid memory allocation within the function.\n",
      "    \n",
      "    findChessboardCorners(...)\n",
      "        findChessboardCorners(image, patternSize[, corners[, flags]]) -> retval, corners\n",
      "        .   @brief Finds the positions of internal corners of the chessboard.\n",
      "        .   \n",
      "        .   @param image Source chessboard view. It must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ).\n",
      "        .   @param corners Output array of detected corners.\n",
      "        .   @param flags Various operation flags that can be zero or a combination of the following values:\n",
      "        .   -   **CALIB_CB_ADAPTIVE_THRESH** Use adaptive thresholding to convert the image to black\n",
      "        .   and white, rather than a fixed threshold level (computed from the average image brightness).\n",
      "        .   -   **CALIB_CB_NORMALIZE_IMAGE** Normalize the image gamma with equalizeHist before\n",
      "        .   applying fixed or adaptive thresholding.\n",
      "        .   -   **CALIB_CB_FILTER_QUADS** Use additional criteria (like contour area, perimeter,\n",
      "        .   square-like shape) to filter out false quads extracted at the contour retrieval stage.\n",
      "        .   -   **CALIB_CB_FAST_CHECK** Run a fast check on the image that looks for chessboard corners,\n",
      "        .   and shortcut the call if none is found. This can drastically speed up the call in the\n",
      "        .   degenerate condition when no chessboard is observed.\n",
      "        .   \n",
      "        .   The function attempts to determine whether the input image is a view of the chessboard pattern and\n",
      "        .   locate the internal chessboard corners. The function returns a non-zero value if all of the corners\n",
      "        .   are found and they are placed in a certain order (row by row, left to right in every row).\n",
      "        .   Otherwise, if the function fails to find all the corners or reorder them, it returns 0. For example,\n",
      "        .   a regular chessboard has 8 x 8 squares and 7 x 7 internal corners, that is, points where the black\n",
      "        .   squares touch each other. The detected coordinates are approximate, and to determine their positions\n",
      "        .   more accurately, the function calls cornerSubPix. You also may use the function cornerSubPix with\n",
      "        .   different parameters if returned coordinates are not accurate enough.\n",
      "        .   \n",
      "        .   Sample usage of detecting and drawing chessboard corners: :\n",
      "        .   @code\n",
      "        .   Size patternsize(8,6); //interior number of corners\n",
      "        .   Mat gray = ....; //source image\n",
      "        .   vector<Point2f> corners; //this will be filled by the detected corners\n",
      "        .   \n",
      "        .   //CALIB_CB_FAST_CHECK saves a lot of time on images\n",
      "        .   //that do not contain any chessboard corners\n",
      "        .   bool patternfound = findChessboardCorners(gray, patternsize, corners,\n",
      "        .   CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE\n",
      "        .   + CALIB_CB_FAST_CHECK);\n",
      "        .   \n",
      "        .   if(patternfound)\n",
      "        .   cornerSubPix(gray, corners, Size(11, 11), Size(-1, -1),\n",
      "        .   TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 30, 0.1));\n",
      "        .   \n",
      "        .   drawChessboardCorners(img, patternsize, Mat(corners), patternfound);\n",
      "        .   @endcode\n",
      "        .   @note The function requires white space (like a square-thick border, the wider the better) around\n",
      "        .   the board to make the detection more robust in various environments. Otherwise, if there is no\n",
      "        .   border and the background is dark, the outer black squares cannot be segmented properly and so the\n",
      "        .   square grouping and ordering algorithm fails.\n",
      "    \n",
      "    findChessboardCornersSB(...)\n",
      "        findChessboardCornersSB(image, patternSize[, corners[, flags]]) -> retval, corners\n",
      "        .   @brief Finds the positions of internal corners of the chessboard using a sector based approach.\n",
      "        .   \n",
      "        .   @param image Source chessboard view. It must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ).\n",
      "        .   @param corners Output array of detected corners.\n",
      "        .   @param flags Various operation flags that can be zero or a combination of the following values:\n",
      "        .   -   **CALIB_CB_NORMALIZE_IMAGE** Normalize the image gamma with equalizeHist before detection.\n",
      "        .   -   **CALIB_CB_EXHAUSTIVE ** Run an exhaustive search to improve detection rate.\n",
      "        .   -   **CALIB_CB_ACCURACY ** Up sample input image to improve sub-pixel accuracy due to aliasing effects.\n",
      "        .   This should be used if an accurate camera calibration is required.\n",
      "        .   \n",
      "        .   The function is analog to findchessboardCorners but uses a localized radon\n",
      "        .   transformation approximated by box filters being more robust to all sort of\n",
      "        .   noise, faster on larger images and is able to directly return the sub-pixel\n",
      "        .   position of the internal chessboard corners. The Method is based on the paper\n",
      "        .   @cite duda2018 \"Accurate Detection and Localization of Checkerboard Corners for\n",
      "        .   Calibration\" demonstrating that the returned sub-pixel positions are more\n",
      "        .   accurate than the one returned by cornerSubPix allowing a precise camera\n",
      "        .   calibration for demanding applications.\n",
      "        .   \n",
      "        .   @note The function requires a white boarder with roughly the same width as one\n",
      "        .   of the checkerboard fields around the whole board to improve the detection in\n",
      "        .   various environments. In addition, because of the localized radon\n",
      "        .   transformation it is beneficial to use round corners for the field corners\n",
      "        .   which are located on the outside of the board. The following figure illustrates\n",
      "        .   a sample checkerboard optimized for the detection. However, any other checkerboard\n",
      "        .   can be used as well.\n",
      "        .   ![Checkerboard](pics/checkerboard_radon.png)\n",
      "    \n",
      "    findCirclesGrid(...)\n",
      "        findCirclesGrid(image, patternSize, flags, blobDetector, parameters[, centers]) -> retval, centers\n",
      "        .   @brief Finds centers in the grid of circles.\n",
      "        .   \n",
      "        .   @param image grid view of input circles; it must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize number of circles per row and column\n",
      "        .   ( patternSize = Size(points_per_row, points_per_colum) ).\n",
      "        .   @param centers output array of detected centers.\n",
      "        .   @param flags various operation flags that can be one of the following values:\n",
      "        .   -   **CALIB_CB_SYMMETRIC_GRID** uses symmetric pattern of circles.\n",
      "        .   -   **CALIB_CB_ASYMMETRIC_GRID** uses asymmetric pattern of circles.\n",
      "        .   -   **CALIB_CB_CLUSTERING** uses a special algorithm for grid detection. It is more robust to\n",
      "        .   perspective distortions but much more sensitive to background clutter.\n",
      "        .   @param blobDetector feature detector that finds blobs like dark circles on light background.\n",
      "        .   @param parameters struct for finding circles in a grid pattern.\n",
      "        .   \n",
      "        .   The function attempts to determine whether the input image contains a grid of circles. If it is, the\n",
      "        .   function locates centers of the circles. The function returns a non-zero value if all of the centers\n",
      "        .   have been found and they have been placed in a certain order (row by row, left to right in every\n",
      "        .   row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0.\n",
      "        .   \n",
      "        .   Sample usage of detecting and drawing the centers of circles: :\n",
      "        .   @code\n",
      "        .   Size patternsize(7,7); //number of centers\n",
      "        .   Mat gray = ....; //source image\n",
      "        .   vector<Point2f> centers; //this will be filled by the detected centers\n",
      "        .   \n",
      "        .   bool patternfound = findCirclesGrid(gray, patternsize, centers);\n",
      "        .   \n",
      "        .   drawChessboardCorners(img, patternsize, Mat(centers), patternfound);\n",
      "        .   @endcode\n",
      "        .   @note The function requires white space (like a square-thick border, the wider the better) around\n",
      "        .   the board to make the detection more robust in various environments.\n",
      "        \n",
      "        \n",
      "        \n",
      "        findCirclesGrid(image, patternSize[, centers[, flags[, blobDetector]]]) -> retval, centers\n",
      "        .   @overload\n",
      "    \n",
      "    findContours(...)\n",
      "        findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\n",
      "        .   @brief Finds contours in a binary image.\n",
      "        .   \n",
      "        .   The function retrieves contours from the binary image using the algorithm @cite Suzuki85 . The contours\n",
      "        .   are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the\n",
      "        .   OpenCV sample directory.\n",
      "        .   @note Since opencv 3.2 source image is not modified by this function.\n",
      "        .   \n",
      "        .   @param image Source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero\n",
      "        .   pixels remain 0's, so the image is treated as binary . You can use #compare, #inRange, #threshold ,\n",
      "        .   #adaptiveThreshold, #Canny, and others to create a binary image out of a grayscale or color one.\n",
      "        .   If mode equals to #RETR_CCOMP or #RETR_FLOODFILL, the input can also be a 32-bit integer image of labels (CV_32SC1).\n",
      "        .   @param contours Detected contours. Each contour is stored as a vector of points (e.g.\n",
      "        .   std::vector<std::vector<cv::Point> >).\n",
      "        .   @param hierarchy Optional output vector (e.g. std::vector<cv::Vec4i>), containing information about the image topology. It has\n",
      "        .   as many elements as the number of contours. For each i-th contour contours[i], the elements\n",
      "        .   hierarchy[i][0] , hierarchy[i][1] , hierarchy[i][2] , and hierarchy[i][3] are set to 0-based indices\n",
      "        .   in contours of the next and previous contours at the same hierarchical level, the first child\n",
      "        .   contour and the parent contour, respectively. If for the contour i there are no next, previous,\n",
      "        .   parent, or nested contours, the corresponding elements of hierarchy[i] will be negative.\n",
      "        .   @param mode Contour retrieval mode, see #RetrievalModes\n",
      "        .   @param method Contour approximation method, see #ContourApproximationModes\n",
      "        .   @param offset Optional offset by which every contour point is shifted. This is useful if the\n",
      "        .   contours are extracted from the image ROI and then they should be analyzed in the whole image\n",
      "        .   context.\n",
      "    \n",
      "    findEssentialMat(...)\n",
      "        findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, mask]]]]) -> retval, mask\n",
      "        .   @brief Calculates an essential matrix from the corresponding points in two images.\n",
      "        .   \n",
      "        .   @param points1 Array of N (N \\>= 5) 2D points from the first image. The point coordinates should\n",
      "        .   be floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param cameraMatrix Camera matrix \\f$K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix.\n",
      "        .   @param method Method for computing an essential matrix.\n",
      "        .   -   **RANSAC** for the RANSAC algorithm.\n",
      "        .   -   **LMEDS** for the LMedS algorithm.\n",
      "        .   @param prob Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of\n",
      "        .   confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param threshold Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param mask Output array of N elements, every element of which is set to 0 for outliers and to 1\n",
      "        .   for the other points. The array is computed only in the RANSAC and LMedS methods.\n",
      "        .   \n",
      "        .   This function estimates essential matrix based on the five-point algorithm solver in @cite Nister03 .\n",
      "        .   @cite SteweniusCFS is also a related. The epipolar geometry is described by the following equation:\n",
      "        .   \n",
      "        .   \\f[[p_2; 1]^T K^{-T} E K^{-1} [p_1; 1] = 0\\f]\n",
      "        .   \n",
      "        .   where \\f$E\\f$ is an essential matrix, \\f$p_1\\f$ and \\f$p_2\\f$ are corresponding points in the first and the\n",
      "        .   second images, respectively. The result of this function may be passed further to\n",
      "        .   decomposeEssentialMat or recoverPose to recover the relative pose between cameras.\n",
      "        \n",
      "        \n",
      "        \n",
      "        findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, mask]]]]]]) -> retval, mask\n",
      "        .   @overload\n",
      "        .   @param points1 Array of N (N \\>= 5) 2D points from the first image. The point coordinates should\n",
      "        .   be floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param focal focal length of the camera. Note that this function assumes that points1 and points2\n",
      "        .   are feature points from cameras with same focal length and principal point.\n",
      "        .   @param pp principal point of the camera.\n",
      "        .   @param method Method for computing a fundamental matrix.\n",
      "        .   -   **RANSAC** for the RANSAC algorithm.\n",
      "        .   -   **LMEDS** for the LMedS algorithm.\n",
      "        .   @param threshold Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param prob Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of\n",
      "        .   confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param mask Output array of N elements, every element of which is set to 0 for outliers and to 1\n",
      "        .   for the other points. The array is computed only in the RANSAC and LMedS methods.\n",
      "        .   \n",
      "        .   This function differs from the one above that it computes camera matrix from focal length and\n",
      "        .   principal point:\n",
      "        .   \n",
      "        .   \\f[K =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   f & 0 & x_{pp}  \\\\\n",
      "        .   0 & f & y_{pp}  \\\\\n",
      "        .   0 & 0 & 1\n",
      "        .   \\end{bmatrix}\\f]\n",
      "    \n",
      "    findFundamentalMat(...)\n",
      "        findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, mask\n",
      "        .   @brief Calculates a fundamental matrix from the corresponding points in two images.\n",
      "        .   \n",
      "        .   @param points1 Array of N points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param method Method for computing a fundamental matrix.\n",
      "        .   -   **CV_FM_7POINT** for a 7-point algorithm. \\f$N = 7\\f$\n",
      "        .   -   **CV_FM_8POINT** for an 8-point algorithm. \\f$N \\ge 8\\f$\n",
      "        .   -   **CV_FM_RANSAC** for the RANSAC algorithm. \\f$N \\ge 8\\f$\n",
      "        .   -   **CV_FM_LMEDS** for the LMedS algorithm. \\f$N \\ge 8\\f$\n",
      "        .   @param ransacReprojThreshold Parameter used only for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param confidence Parameter used for the RANSAC and LMedS methods only. It specifies a desirable level\n",
      "        .   of confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param mask\n",
      "        .   \n",
      "        .   The epipolar geometry is described by the following equation:\n",
      "        .   \n",
      "        .   \\f[[p_2; 1]^T F [p_1; 1] = 0\\f]\n",
      "        .   \n",
      "        .   where \\f$F\\f$ is a fundamental matrix, \\f$p_1\\f$ and \\f$p_2\\f$ are corresponding points in the first and the\n",
      "        .   second images, respectively.\n",
      "        .   \n",
      "        .   The function calculates the fundamental matrix using one of four methods listed above and returns\n",
      "        .   the found fundamental matrix. Normally just one matrix is found. But in case of the 7-point\n",
      "        .   algorithm, the function may return up to 3 solutions ( \\f$9 \\times 3\\f$ matrix that stores all 3\n",
      "        .   matrices sequentially).\n",
      "        .   \n",
      "        .   The calculated fundamental matrix may be passed further to computeCorrespondEpilines that finds the\n",
      "        .   epipolar lines corresponding to the specified points. It can also be passed to\n",
      "        .   stereoRectifyUncalibrated to compute the rectification transformation. :\n",
      "        .   @code\n",
      "        .   // Example. Estimation of fundamental matrix using the RANSAC algorithm\n",
      "        .   int point_count = 100;\n",
      "        .   vector<Point2f> points1(point_count);\n",
      "        .   vector<Point2f> points2(point_count);\n",
      "        .   \n",
      "        .   // initialize the points here ...\n",
      "        .   for( int i = 0; i < point_count; i++ )\n",
      "        .   {\n",
      "        .   points1[i] = ...;\n",
      "        .   points2[i] = ...;\n",
      "        .   }\n",
      "        .   \n",
      "        .   Mat fundamental_matrix =\n",
      "        .   findFundamentalMat(points1, points2, FM_RANSAC, 3, 0.99);\n",
      "        .   @endcode\n",
      "    \n",
      "    findHomography(...)\n",
      "        findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, mask\n",
      "        .   @brief Finds a perspective transformation between two planes.\n",
      "        .   \n",
      "        .   @param srcPoints Coordinates of the points in the original plane, a matrix of the type CV_32FC2\n",
      "        .   or vector\\<Point2f\\> .\n",
      "        .   @param dstPoints Coordinates of the points in the target plane, a matrix of the type CV_32FC2 or\n",
      "        .   a vector\\<Point2f\\> .\n",
      "        .   @param method Method used to compute a homography matrix. The following methods are possible:\n",
      "        .   -   **0** - a regular method using all the points, i.e., the least squares method\n",
      "        .   -   **RANSAC** - RANSAC-based robust method\n",
      "        .   -   **LMEDS** - Least-Median robust method\n",
      "        .   -   **RHO** - PROSAC-based robust method\n",
      "        .   @param ransacReprojThreshold Maximum allowed reprojection error to treat a point pair as an inlier\n",
      "        .   (used in the RANSAC and RHO methods only). That is, if\n",
      "        .   \\f[\\| \\texttt{dstPoints} _i -  \\texttt{convertPointsHomogeneous} ( \\texttt{H} * \\texttt{srcPoints} _i) \\|_2  >  \\texttt{ransacReprojThreshold}\\f]\n",
      "        .   then the point \\f$i\\f$ is considered as an outlier. If srcPoints and dstPoints are measured in pixels,\n",
      "        .   it usually makes sense to set this parameter somewhere in the range of 1 to 10.\n",
      "        .   @param mask Optional output mask set by a robust method ( RANSAC or LMEDS ). Note that the input\n",
      "        .   mask values are ignored.\n",
      "        .   @param maxIters The maximum number of RANSAC iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1.\n",
      "        .   \n",
      "        .   The function finds and returns the perspective transformation \\f$H\\f$ between the source and the\n",
      "        .   destination planes:\n",
      "        .   \n",
      "        .   \\f[s_i  \\vecthree{x'_i}{y'_i}{1} \\sim H  \\vecthree{x_i}{y_i}{1}\\f]\n",
      "        .   \n",
      "        .   so that the back-projection error\n",
      "        .   \n",
      "        .   \\f[\\sum _i \\left ( x'_i- \\frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2+ \\left ( y'_i- \\frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2\\f]\n",
      "        .   \n",
      "        .   is minimized. If the parameter method is set to the default value 0, the function uses all the point\n",
      "        .   pairs to compute an initial homography estimate with a simple least-squares scheme.\n",
      "        .   \n",
      "        .   However, if not all of the point pairs ( \\f$srcPoints_i\\f$, \\f$dstPoints_i\\f$ ) fit the rigid perspective\n",
      "        .   transformation (that is, there are some outliers), this initial estimate will be poor. In this case,\n",
      "        .   you can use one of the three robust methods. The methods RANSAC, LMeDS and RHO try many different\n",
      "        .   random subsets of the corresponding point pairs (of four pairs each, collinear pairs are discarded), estimate the homography matrix\n",
      "        .   using this subset and a simple least-squares algorithm, and then compute the quality/goodness of the\n",
      "        .   computed homography (which is the number of inliers for RANSAC or the least median re-projection error for\n",
      "        .   LMeDS). The best subset is then used to produce the initial estimate of the homography matrix and\n",
      "        .   the mask of inliers/outliers.\n",
      "        .   \n",
      "        .   Regardless of the method, robust or not, the computed homography matrix is refined further (using\n",
      "        .   inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the\n",
      "        .   re-projection error even more.\n",
      "        .   \n",
      "        .   The methods RANSAC and RHO can handle practically any ratio of outliers but need a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the\n",
      "        .   noise is rather small, use the default method (method=0).\n",
      "        .   \n",
      "        .   The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is\n",
      "        .   determined up to a scale. Thus, it is normalized so that \\f$h_{33}=1\\f$. Note that whenever an \\f$H\\f$ matrix\n",
      "        .   cannot be estimated, an empty one will be returned.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   getAffineTransform, estimateAffine2D, estimateAffinePartial2D, getPerspectiveTransform, warpPerspective,\n",
      "        .   perspectiveTransform\n",
      "    \n",
      "    findNonZero(...)\n",
      "        findNonZero(src[, idx]) -> idx\n",
      "        .   @brief Returns the list of locations of non-zero pixels\n",
      "        .   \n",
      "        .   Given a binary matrix (likely returned from an operation such\n",
      "        .   as threshold(), compare(), >, ==, etc, return all of\n",
      "        .   the non-zero indices as a cv::Mat or std::vector<cv::Point> (x,y)\n",
      "        .   For example:\n",
      "        .   @code{.cpp}\n",
      "        .   cv::Mat binaryImage; // input, binary image\n",
      "        .   cv::Mat locations;   // output, locations of non-zero pixels\n",
      "        .   cv::findNonZero(binaryImage, locations);\n",
      "        .   \n",
      "        .   // access pixel coordinates\n",
      "        .   Point pnt = locations.at<Point>(i);\n",
      "        .   @endcode\n",
      "        .   or\n",
      "        .   @code{.cpp}\n",
      "        .   cv::Mat binaryImage; // input, binary image\n",
      "        .   vector<Point> locations;   // output, locations of non-zero pixels\n",
      "        .   cv::findNonZero(binaryImage, locations);\n",
      "        .   \n",
      "        .   // access pixel coordinates\n",
      "        .   Point pnt = locations[i];\n",
      "        .   @endcode\n",
      "        .   @param src single-channel array\n",
      "        .   @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input\n",
      "    \n",
      "    findTransformECC(...)\n",
      "        findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask, gaussFiltSize) -> retval, warpMatrix\n",
      "        .   @brief Finds the geometric transform (warp) between two images in terms of the ECC criterion @cite EP08 .\n",
      "        .   \n",
      "        .   @param templateImage single-channel template image; CV_8U or CV_32F array.\n",
      "        .   @param inputImage single-channel input image which should be warped with the final warpMatrix in\n",
      "        .   order to provide an image similar to templateImage, same type as templateImage.\n",
      "        .   @param warpMatrix floating-point \\f$2\\times 3\\f$ or \\f$3\\times 3\\f$ mapping matrix (warp).\n",
      "        .   @param motionType parameter, specifying the type of motion:\n",
      "        .   -   **MOTION_TRANSLATION** sets a translational motion model; warpMatrix is \\f$2\\times 3\\f$ with\n",
      "        .   the first \\f$2\\times 2\\f$ part being the unity matrix and the rest two parameters being\n",
      "        .   estimated.\n",
      "        .   -   **MOTION_EUCLIDEAN** sets a Euclidean (rigid) transformation as motion model; three\n",
      "        .   parameters are estimated; warpMatrix is \\f$2\\times 3\\f$.\n",
      "        .   -   **MOTION_AFFINE** sets an affine motion model (DEFAULT); six parameters are estimated;\n",
      "        .   warpMatrix is \\f$2\\times 3\\f$.\n",
      "        .   -   **MOTION_HOMOGRAPHY** sets a homography as a motion model; eight parameters are\n",
      "        .   estimated;\\`warpMatrix\\` is \\f$3\\times 3\\f$.\n",
      "        .   @param criteria parameter, specifying the termination criteria of the ECC algorithm;\n",
      "        .   criteria.epsilon defines the threshold of the increment in the correlation coefficient between two\n",
      "        .   iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).\n",
      "        .   Default values are shown in the declaration above.\n",
      "        .   @param inputMask An optional mask to indicate valid values of inputImage.\n",
      "        .   @param gaussFiltSize An optional value indicating size of gaussian blur filter; (DEFAULT: 5)\n",
      "        .   \n",
      "        .   The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion\n",
      "        .   (@cite EP08), that is\n",
      "        .   \n",
      "        .   \\f[\\texttt{warpMatrix} = \\texttt{warpMatrix} = \\arg\\max_{W} \\texttt{ECC}(\\texttt{templateImage}(x,y),\\texttt{inputImage}(x',y'))\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = W \\cdot \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   (the equation holds with homogeneous coordinates for homography). It returns the final enhanced\n",
      "        .   correlation coefficient, that is the correlation coefficient between the template image and the\n",
      "        .   final warped input image. When a \\f$3\\times 3\\f$ matrix is given with motionType =0, 1 or 2, the third\n",
      "        .   row is ignored.\n",
      "        .   \n",
      "        .   Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an\n",
      "        .   area-based alignment that builds on intensity similarities. In essence, the function updates the\n",
      "        .   initial transformation that roughly aligns the images. If this information is missing, the identity\n",
      "        .   warp (unity matrix) is used as an initialization. Note that if images undergo strong\n",
      "        .   displacements/rotations, an initial transformation that roughly aligns the images is necessary\n",
      "        .   (e.g., a simple euclidean/similarity transform that allows for the images showing the same image\n",
      "        .   content approximately). Use inverse warping in the second image to take an image close to the first\n",
      "        .   one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV\n",
      "        .   sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws\n",
      "        .   an exception if algorithm does not converges.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   computeECC, estimateAffine2D, estimateAffinePartial2D, findHomography\n",
      "    \n",
      "    fitEllipse(...)\n",
      "        fitEllipse(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .   The function calculates the ellipse that fits (in a least-squares sense) a set of 2D points best of\n",
      "        .   all. It returns the rotated rectangle in which the ellipse is inscribed. The first algorithm described by @cite Fitzgibbon95\n",
      "        .   is used. Developer should keep in mind that it is possible that the returned\n",
      "        .   ellipse/rotatedRect data contains negative indices, due to the data points being close to the\n",
      "        .   border of the containing Mat element.\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitEllipseAMS(...)\n",
      "        fitEllipseAMS(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .   The function calculates the ellipse that fits a set of 2D points.\n",
      "        .   It returns the rotated rectangle in which the ellipse is inscribed.\n",
      "        .   The Approximate Mean Square (AMS) proposed by @cite Taubin1991 is used.\n",
      "        .   \n",
      "        .   For an ellipse, this basis set is \\f$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) \\f$,\n",
      "        .   which is a set of six free coefficients \\f$ A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} \\f$.\n",
      "        .   However, to specify an ellipse, all that is needed is five numbers; the major and minor axes lengths \\f$ (a,b) \\f$,\n",
      "        .   the position \\f$ (x_0,y_0) \\f$, and the orientation \\f$ \\theta \\f$. This is because the basis set includes lines,\n",
      "        .   quadratics, parabolic and hyperbolic functions as well as elliptical functions as possible fits.\n",
      "        .   If the fit is found to be a parabolic or hyperbolic function then the standard #fitEllipse method is used.\n",
      "        .   The AMS method restricts the fit to parabolic, hyperbolic and elliptical curves\n",
      "        .   by imposing the condition that \\f$ A^T ( D_x^T D_x  +   D_y^T D_y) A = 1 \\f$ where\n",
      "        .   the matrices \\f$ Dx \\f$ and \\f$ Dy \\f$ are the partial derivatives of the design matrix \\f$ D \\f$ with\n",
      "        .   respect to x and y. The matrices are formed row by row applying the following to\n",
      "        .   each of the points in the set:\n",
      "        .   \\f{align*}{\n",
      "        .   D(i,:)&=\\left\\{x_i^2, x_i y_i, y_i^2, x_i, y_i, 1\\right\\} &\n",
      "        .   D_x(i,:)&=\\left\\{2 x_i,y_i,0,1,0,0\\right\\} &\n",
      "        .   D_y(i,:)&=\\left\\{0,x_i,2 y_i,0,1,0\\right\\}\n",
      "        .   \\f}\n",
      "        .   The AMS method minimizes the cost function\n",
      "        .   \\f{equation*}{\n",
      "        .   \\epsilon ^2=\\frac{ A^T D^T D A }{ A^T (D_x^T D_x +  D_y^T D_y) A^T }\n",
      "        .   \\f}\n",
      "        .   \n",
      "        .   The minimum cost is found by solving the generalized eigenvalue problem.\n",
      "        .   \n",
      "        .   \\f{equation*}{\n",
      "        .   D^T D A = \\lambda  \\left( D_x^T D_x +  D_y^T D_y\\right) A\n",
      "        .   \\f}\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitEllipseDirect(...)\n",
      "        fitEllipseDirect(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .   The function calculates the ellipse that fits a set of 2D points.\n",
      "        .   It returns the rotated rectangle in which the ellipse is inscribed.\n",
      "        .   The Direct least square (Direct) method by @cite Fitzgibbon1999 is used.\n",
      "        .   \n",
      "        .   For an ellipse, this basis set is \\f$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) \\f$,\n",
      "        .   which is a set of six free coefficients \\f$ A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} \\f$.\n",
      "        .   However, to specify an ellipse, all that is needed is five numbers; the major and minor axes lengths \\f$ (a,b) \\f$,\n",
      "        .   the position \\f$ (x_0,y_0) \\f$, and the orientation \\f$ \\theta \\f$. This is because the basis set includes lines,\n",
      "        .   quadratics, parabolic and hyperbolic functions as well as elliptical functions as possible fits.\n",
      "        .   The Direct method confines the fit to ellipses by ensuring that \\f$ 4 A_{xx} A_{yy}- A_{xy}^2 > 0 \\f$.\n",
      "        .   The condition imposed is that \\f$ 4 A_{xx} A_{yy}- A_{xy}^2=1 \\f$ which satisfies the inequality\n",
      "        .   and as the coefficients can be arbitrarily scaled is not overly restrictive.\n",
      "        .   \n",
      "        .   \\f{equation*}{\n",
      "        .   \\epsilon ^2= A^T D^T D A \\quad \\text{with} \\quad A^T C A =1 \\quad \\text{and} \\quad C=\\left(\\begin{matrix}\n",
      "        .   0 & 0  & 2  & 0  & 0  &  0  \\\\\n",
      "        .   0 & -1  & 0  & 0  & 0  &  0 \\\\\n",
      "        .   2 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .   0 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .   0 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .   0 & 0  & 0  & 0  & 0  &  0\n",
      "        .   \\end{matrix} \\right)\n",
      "        .   \\f}\n",
      "        .   \n",
      "        .   The minimum cost is found by solving the generalized eigenvalue problem.\n",
      "        .   \n",
      "        .   \\f{equation*}{\n",
      "        .   D^T D A = \\lambda  \\left( C\\right) A\n",
      "        .   \\f}\n",
      "        .   \n",
      "        .   The system produces only one positive eigenvalue \\f$ \\lambda\\f$ which is chosen as the solution\n",
      "        .   with its eigenvector \\f$\\mathbf{u}\\f$. These are used to find the coefficients\n",
      "        .   \n",
      "        .   \\f{equation*}{\n",
      "        .   A = \\sqrt{\\frac{1}{\\mathbf{u}^T C \\mathbf{u}}}  \\mathbf{u}\n",
      "        .   \\f}\n",
      "        .   The scaling factor guarantees that  \\f$A^T C A =1\\f$.\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitLine(...)\n",
      "        fitLine(points, distType, param, reps, aeps[, line]) -> line\n",
      "        .   @brief Fits a line to a 2D or 3D point set.\n",
      "        .   \n",
      "        .   The function fitLine fits a line to a 2D or 3D point set by minimizing \\f$\\sum_i \\rho(r_i)\\f$ where\n",
      "        .   \\f$r_i\\f$ is a distance between the \\f$i^{th}\\f$ point, the line and \\f$\\rho(r)\\f$ is a distance function, one\n",
      "        .   of the following:\n",
      "        .   -  DIST_L2\n",
      "        .   \\f[\\rho (r) = r^2/2  \\quad \\text{(the simplest and the fastest least-squares method)}\\f]\n",
      "        .   - DIST_L1\n",
      "        .   \\f[\\rho (r) = r\\f]\n",
      "        .   - DIST_L12\n",
      "        .   \\f[\\rho (r) = 2  \\cdot ( \\sqrt{1 + \\frac{r^2}{2}} - 1)\\f]\n",
      "        .   - DIST_FAIR\n",
      "        .   \\f[\\rho \\left (r \\right ) = C^2  \\cdot \\left (  \\frac{r}{C} -  \\log{\\left(1 + \\frac{r}{C}\\right)} \\right )  \\quad \\text{where} \\quad C=1.3998\\f]\n",
      "        .   - DIST_WELSCH\n",
      "        .   \\f[\\rho \\left (r \\right ) =  \\frac{C^2}{2} \\cdot \\left ( 1 -  \\exp{\\left(-\\left(\\frac{r}{C}\\right)^2\\right)} \\right )  \\quad \\text{where} \\quad C=2.9846\\f]\n",
      "        .   - DIST_HUBER\n",
      "        .   \\f[\\rho (r) =  \\fork{r^2/2}{if \\(r < C\\)}{C \\cdot (r-C/2)}{otherwise} \\quad \\text{where} \\quad C=1.345\\f]\n",
      "        .   \n",
      "        .   The algorithm is based on the M-estimator ( <http://en.wikipedia.org/wiki/M-estimator> ) technique\n",
      "        .   that iteratively fits the line using the weighted least-squares algorithm. After each iteration the\n",
      "        .   weights \\f$w_i\\f$ are adjusted to be inversely proportional to \\f$\\rho(r_i)\\f$ .\n",
      "        .   \n",
      "        .   @param points Input vector of 2D or 3D points, stored in std::vector\\<\\> or Mat.\n",
      "        .   @param line Output line parameters. In case of 2D fitting, it should be a vector of 4 elements\n",
      "        .   (like Vec4f) - (vx, vy, x0, y0), where (vx, vy) is a normalized vector collinear to the line and\n",
      "        .   (x0, y0) is a point on the line. In case of 3D fitting, it should be a vector of 6 elements (like\n",
      "        .   Vec6f) - (vx, vy, vz, x0, y0, z0), where (vx, vy, vz) is a normalized vector collinear to the line\n",
      "        .   and (x0, y0, z0) is a point on the line.\n",
      "        .   @param distType Distance used by the M-estimator, see #DistanceTypes\n",
      "        .   @param param Numerical parameter ( C ) for some types of distances. If it is 0, an optimal value\n",
      "        .   is chosen.\n",
      "        .   @param reps Sufficient accuracy for the radius (distance between the coordinate origin and the line).\n",
      "        .   @param aeps Sufficient accuracy for the angle. 0.01 would be a good default value for reps and aeps.\n",
      "    \n",
      "    flip(...)\n",
      "        flip(src, flipCode[, dst]) -> dst\n",
      "        .   @brief Flips a 2D array around vertical, horizontal, or both axes.\n",
      "        .   \n",
      "        .   The function cv::flip flips the array in one of three different ways (row\n",
      "        .   and column indices are 0-based):\n",
      "        .   \\f[\\texttt{dst} _{ij} =\n",
      "        .   \\left\\{\n",
      "        .   \\begin{array}{l l}\n",
      "        .   \\texttt{src} _{\\texttt{src.rows}-i-1,j} & if\\;  \\texttt{flipCode} = 0 \\\\\n",
      "        .   \\texttt{src} _{i, \\texttt{src.cols} -j-1} & if\\;  \\texttt{flipCode} > 0 \\\\\n",
      "        .   \\texttt{src} _{ \\texttt{src.rows} -i-1, \\texttt{src.cols} -j-1} & if\\; \\texttt{flipCode} < 0 \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\right.\\f]\n",
      "        .   The example scenarios of using the function are the following:\n",
      "        .   *   Vertical flipping of the image (flipCode == 0) to switch between\n",
      "        .   top-left and bottom-left image origin. This is a typical operation\n",
      "        .   in video processing on Microsoft Windows\\* OS.\n",
      "        .   *   Horizontal flipping of the image with the subsequent horizontal\n",
      "        .   shift and absolute difference calculation to check for a\n",
      "        .   vertical-axis symmetry (flipCode \\> 0).\n",
      "        .   *   Simultaneous horizontal and vertical flipping of the image with\n",
      "        .   the subsequent shift and absolute difference calculation to check\n",
      "        .   for a central symmetry (flipCode \\< 0).\n",
      "        .   *   Reversing the order of point arrays (flipCode \\> 0 or\n",
      "        .   flipCode == 0).\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flipCode a flag to specify how to flip the array; 0 means\n",
      "        .   flipping around the x-axis and positive value (for example, 1) means\n",
      "        .   flipping around y-axis. Negative value (for example, -1) means flipping\n",
      "        .   around both axes.\n",
      "        .   @sa transpose , repeat , completeSymm\n",
      "    \n",
      "    floodFill(...)\n",
      "        floodFill(image, mask, seedPoint, newVal[, loDiff[, upDiff[, flags]]]) -> retval, image, mask, rect\n",
      "        .   @brief Fills a connected component with the given color.\n",
      "        .   \n",
      "        .   The function cv::floodFill fills a connected component starting from the seed point with the specified\n",
      "        .   color. The connectivity is determined by the color/brightness closeness of the neighbor pixels. The\n",
      "        .   pixel at \\f$(x,y)\\f$ is considered to belong to the repainted domain if:\n",
      "        .   \n",
      "        .   - in case of a grayscale image and floating range\n",
      "        .   \\f[\\texttt{src} (x',y')- \\texttt{loDiff} \\leq \\texttt{src} (x,y)  \\leq \\texttt{src} (x',y')+ \\texttt{upDiff}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a grayscale image and fixed range\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)- \\texttt{loDiff} \\leq \\texttt{src} (x,y)  \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)+ \\texttt{upDiff}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a color image and floating range\n",
      "        .   \\f[\\texttt{src} (x',y')_r- \\texttt{loDiff} _r \\leq \\texttt{src} (x,y)_r \\leq \\texttt{src} (x',y')_r+ \\texttt{upDiff} _r,\\f]\n",
      "        .   \\f[\\texttt{src} (x',y')_g- \\texttt{loDiff} _g \\leq \\texttt{src} (x,y)_g \\leq \\texttt{src} (x',y')_g+ \\texttt{upDiff} _g\\f]\n",
      "        .   and\n",
      "        .   \\f[\\texttt{src} (x',y')_b- \\texttt{loDiff} _b \\leq \\texttt{src} (x,y)_b \\leq \\texttt{src} (x',y')_b+ \\texttt{upDiff} _b\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a color image and fixed range\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_r- \\texttt{loDiff} _r \\leq \\texttt{src} (x,y)_r \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_r+ \\texttt{upDiff} _r,\\f]\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_g- \\texttt{loDiff} _g \\leq \\texttt{src} (x,y)_g \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_g+ \\texttt{upDiff} _g\\f]\n",
      "        .   and\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_b- \\texttt{loDiff} _b \\leq \\texttt{src} (x,y)_b \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_b+ \\texttt{upDiff} _b\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   where \\f$src(x',y')\\f$ is the value of one of pixel neighbors that is already known to belong to the\n",
      "        .   component. That is, to be added to the connected component, a color/brightness of the pixel should\n",
      "        .   be close enough to:\n",
      "        .   - Color/brightness of one of its neighbors that already belong to the connected component in case\n",
      "        .   of a floating range.\n",
      "        .   - Color/brightness of the seed point in case of a fixed range.\n",
      "        .   \n",
      "        .   Use these functions to either mark a connected component with the specified color in-place, or build\n",
      "        .   a mask and then extract the contour, or copy the region to another image, and so on.\n",
      "        .   \n",
      "        .   @param image Input/output 1- or 3-channel, 8-bit, or floating-point image. It is modified by the\n",
      "        .   function unless the #FLOODFILL_MASK_ONLY flag is set in the second variant of the function. See\n",
      "        .   the details below.\n",
      "        .   @param mask Operation mask that should be a single-channel 8-bit image, 2 pixels wider and 2 pixels\n",
      "        .   taller than image. Since this is both an input and output parameter, you must take responsibility\n",
      "        .   of initializing it. Flood-filling cannot go across non-zero pixels in the input mask. For example,\n",
      "        .   an edge detector output can be used as a mask to stop filling at edges. On output, pixels in the\n",
      "        .   mask corresponding to filled pixels in the image are set to 1 or to the a value specified in flags\n",
      "        .   as described below. Additionally, the function fills the border of the mask with ones to simplify\n",
      "        .   internal processing. It is therefore possible to use the same mask in multiple calls to the function\n",
      "        .   to make sure the filled areas do not overlap.\n",
      "        .   @param seedPoint Starting point.\n",
      "        .   @param newVal New value of the repainted domain pixels.\n",
      "        .   @param loDiff Maximal lower brightness/color difference between the currently observed pixel and\n",
      "        .   one of its neighbors belonging to the component, or a seed pixel being added to the component.\n",
      "        .   @param upDiff Maximal upper brightness/color difference between the currently observed pixel and\n",
      "        .   one of its neighbors belonging to the component, or a seed pixel being added to the component.\n",
      "        .   @param rect Optional output parameter set by the function to the minimum bounding rectangle of the\n",
      "        .   repainted domain.\n",
      "        .   @param flags Operation flags. The first 8 bits contain a connectivity value. The default value of\n",
      "        .   4 means that only the four nearest neighbor pixels (those that share an edge) are considered. A\n",
      "        .   connectivity value of 8 means that the eight nearest neighbor pixels (those that share a corner)\n",
      "        .   will be considered. The next 8 bits (8-16) contain a value between 1 and 255 with which to fill\n",
      "        .   the mask (the default value is 1). For example, 4 | ( 255 \\<\\< 8 ) will consider 4 nearest\n",
      "        .   neighbours and fill the mask with a value of 255. The following additional options occupy higher\n",
      "        .   bits and therefore may be further combined with the connectivity and mask fill values using\n",
      "        .   bit-wise or (|), see #FloodFillFlags.\n",
      "        .   \n",
      "        .   @note Since the mask is larger than the filled image, a pixel \\f$(x, y)\\f$ in image corresponds to the\n",
      "        .   pixel \\f$(x+1, y+1)\\f$ in the mask .\n",
      "        .   \n",
      "        .   @sa findContours\n",
      "    \n",
      "    gemm(...)\n",
      "        gemm(src1, src2, alpha, src3, beta[, dst[, flags]]) -> dst\n",
      "        .   @brief Performs generalized matrix multiplication.\n",
      "        .   \n",
      "        .   The function cv::gemm performs generalized matrix multiplication similar to the\n",
      "        .   gemm functions in BLAS level 3. For example,\n",
      "        .   `gemm(src1, src2, alpha, src3, beta, dst, GEMM_1_T + GEMM_3_T)`\n",
      "        .   corresponds to\n",
      "        .   \\f[\\texttt{dst} =  \\texttt{alpha} \\cdot \\texttt{src1} ^T  \\cdot \\texttt{src2} +  \\texttt{beta} \\cdot \\texttt{src3} ^T\\f]\n",
      "        .   \n",
      "        .   In case of complex (two-channel) data, performed a complex matrix\n",
      "        .   multiplication.\n",
      "        .   \n",
      "        .   The function can be replaced with a matrix expression. For example, the\n",
      "        .   above call can be replaced with:\n",
      "        .   @code{.cpp}\n",
      "        .   dst = alpha*src1.t()*src2 + beta*src3.t();\n",
      "        .   @endcode\n",
      "        .   @param src1 first multiplied input matrix that could be real(CV_32FC1,\n",
      "        .   CV_64FC1) or complex(CV_32FC2, CV_64FC2).\n",
      "        .   @param src2 second multiplied input matrix of the same type as src1.\n",
      "        .   @param alpha weight of the matrix product.\n",
      "        .   @param src3 third optional delta matrix added to the matrix product; it\n",
      "        .   should have the same type as src1 and src2.\n",
      "        .   @param beta weight of src3.\n",
      "        .   @param dst output matrix; it has the proper size and the same type as\n",
      "        .   input matrices.\n",
      "        .   @param flags operation flags (cv::GemmFlags)\n",
      "        .   @sa mulTransposed , transform\n",
      "    \n",
      "    getAffineTransform(...)\n",
      "        getAffineTransform(src, dst) -> retval\n",
      "        .   @overload\n",
      "    \n",
      "    getBuildInformation(...)\n",
      "        getBuildInformation() -> retval\n",
      "        .   @brief Returns full configuration time cmake output.\n",
      "        .   \n",
      "        .   Returned value is raw cmake output including version control system revision, compiler version,\n",
      "        .   compiler flags, enabled modules and third party libraries, etc. Output format depends on target\n",
      "        .   architecture.\n",
      "    \n",
      "    getCPUTickCount(...)\n",
      "        getCPUTickCount() -> retval\n",
      "        .   @brief Returns the number of CPU ticks.\n",
      "        .   \n",
      "        .   The function returns the current number of CPU ticks on some architectures (such as x86, x64,\n",
      "        .   PowerPC). On other platforms the function is equivalent to getTickCount. It can also be used for\n",
      "        .   very accurate time measurements, as well as for RNG initialization. Note that in case of multi-CPU\n",
      "        .   systems a thread, from which getCPUTickCount is called, can be suspended and resumed at another CPU\n",
      "        .   with its own counter. So, theoretically (and practically) the subsequent calls to the function do\n",
      "        .   not necessary return the monotonously increasing values. Also, since a modern CPU varies the CPU\n",
      "        .   frequency depending on the load, the number of CPU clocks spent in some code cannot be directly\n",
      "        .   converted to time units. Therefore, getTickCount is generally a preferable solution for measuring\n",
      "        .   execution time.\n",
      "    \n",
      "    getDefaultNewCameraMatrix(...)\n",
      "        getDefaultNewCameraMatrix(cameraMatrix[, imgsize[, centerPrincipalPoint]]) -> retval\n",
      "        .   @brief Returns the default new camera matrix.\n",
      "        .   \n",
      "        .   The function returns the camera matrix that is either an exact copy of the input cameraMatrix (when\n",
      "        .   centerPrinicipalPoint=false ), or the modified one (when centerPrincipalPoint=true).\n",
      "        .   \n",
      "        .   In the latter case, the new camera matrix will be:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} f_x && 0 && ( \\texttt{imgSize.width} -1)*0.5  \\\\ 0 && f_y && ( \\texttt{imgSize.height} -1)*0.5  \\\\ 0 && 0 && 1 \\end{bmatrix} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$f_x\\f$ and \\f$f_y\\f$ are \\f$(0,0)\\f$ and \\f$(1,1)\\f$ elements of cameraMatrix, respectively.\n",
      "        .   \n",
      "        .   By default, the undistortion functions in OpenCV (see #initUndistortRectifyMap, #undistort) do not\n",
      "        .   move the principal point. However, when you work with stereo, it is important to move the principal\n",
      "        .   points in both views to the same y-coordinate (which is required by most of stereo correspondence\n",
      "        .   algorithms), and may be to the same x-coordinate too. So, you can form the new camera matrix for\n",
      "        .   each view where the principal points are located at the center.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix.\n",
      "        .   @param imgsize Camera view image size in pixels.\n",
      "        .   @param centerPrincipalPoint Location of the principal point in the new camera matrix. The\n",
      "        .   parameter indicates whether this location should be at the image center or not.\n",
      "    \n",
      "    getDerivKernels(...)\n",
      "        getDerivKernels(dx, dy, ksize[, kx[, ky[, normalize[, ktype]]]]) -> kx, ky\n",
      "        .   @brief Returns filter coefficients for computing spatial image derivatives.\n",
      "        .   \n",
      "        .   The function computes and returns the filter coefficients for spatial image derivatives. When\n",
      "        .   `ksize=FILTER_SCHARR`, the Scharr \\f$3 \\times 3\\f$ kernels are generated (see #Scharr). Otherwise, Sobel\n",
      "        .   kernels are generated (see #Sobel). The filters are normally passed to #sepFilter2D or to\n",
      "        .   \n",
      "        .   @param kx Output matrix of row filter coefficients. It has the type ktype .\n",
      "        .   @param ky Output matrix of column filter coefficients. It has the type ktype .\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Aperture size. It can be FILTER_SCHARR, 1, 3, 5, or 7.\n",
      "        .   @param normalize Flag indicating whether to normalize (scale down) the filter coefficients or not.\n",
      "        .   Theoretically, the coefficients should have the denominator \\f$=2^{ksize*2-dx-dy-2}\\f$. If you are\n",
      "        .   going to filter floating-point images, you are likely to use the normalized kernels. But if you\n",
      "        .   compute derivatives of an 8-bit image, store the results in a 16-bit image, and wish to preserve\n",
      "        .   all the fractional bits, you may want to set normalize=false .\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32f or CV_64F .\n",
      "    \n",
      "    getFontScaleFromHeight(...)\n",
      "        getFontScaleFromHeight(fontFace, pixelHeight[, thickness]) -> retval\n",
      "        .   @brief Calculates the font-specific size to use to achieve a given height in pixels.\n",
      "        .   \n",
      "        .   @param fontFace Font to use, see cv::HersheyFonts.\n",
      "        .   @param pixelHeight Pixel height to compute the fontScale for\n",
      "        .   @param thickness Thickness of lines used to render the text.See putText for details.\n",
      "        .   @return The fontSize to use for cv::putText\n",
      "        .   \n",
      "        .   @see cv::putText\n",
      "    \n",
      "    getGaborKernel(...)\n",
      "        getGaborKernel(ksize, sigma, theta, lambd, gamma[, psi[, ktype]]) -> retval\n",
      "        .   @brief Returns Gabor filter coefficients.\n",
      "        .   \n",
      "        .   For more details about gabor filter equations and parameters, see: [Gabor\n",
      "        .   Filter](http://en.wikipedia.org/wiki/Gabor_filter).\n",
      "        .   \n",
      "        .   @param ksize Size of the filter returned.\n",
      "        .   @param sigma Standard deviation of the gaussian envelope.\n",
      "        .   @param theta Orientation of the normal to the parallel stripes of a Gabor function.\n",
      "        .   @param lambd Wavelength of the sinusoidal factor.\n",
      "        .   @param gamma Spatial aspect ratio.\n",
      "        .   @param psi Phase offset.\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32F or CV_64F .\n",
      "    \n",
      "    getGaussianKernel(...)\n",
      "        getGaussianKernel(ksize, sigma[, ktype]) -> retval\n",
      "        .   @brief Returns Gaussian filter coefficients.\n",
      "        .   \n",
      "        .   The function computes and returns the \\f$\\texttt{ksize} \\times 1\\f$ matrix of Gaussian filter\n",
      "        .   coefficients:\n",
      "        .   \n",
      "        .   \\f[G_i= \\alpha *e^{-(i-( \\texttt{ksize} -1)/2)^2/(2* \\texttt{sigma}^2)},\\f]\n",
      "        .   \n",
      "        .   where \\f$i=0..\\texttt{ksize}-1\\f$ and \\f$\\alpha\\f$ is the scale factor chosen so that \\f$\\sum_i G_i=1\\f$.\n",
      "        .   \n",
      "        .   Two of such generated kernels can be passed to sepFilter2D. Those functions automatically recognize\n",
      "        .   smoothing kernels (a symmetrical kernel with sum of weights equal to 1) and handle them accordingly.\n",
      "        .   You may also use the higher-level GaussianBlur.\n",
      "        .   @param ksize Aperture size. It should be odd ( \\f$\\texttt{ksize} \\mod 2 = 1\\f$ ) and positive.\n",
      "        .   @param sigma Gaussian standard deviation. If it is non-positive, it is computed from ksize as\n",
      "        .   `sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8`.\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32F or CV_64F .\n",
      "        .   @sa  sepFilter2D, getDerivKernels, getStructuringElement, GaussianBlur\n",
      "    \n",
      "    getHardwareFeatureName(...)\n",
      "        getHardwareFeatureName(feature) -> retval\n",
      "        .   @brief Returns feature name by ID\n",
      "        .   \n",
      "        .   Returns empty string if feature is not defined\n",
      "    \n",
      "    getNumThreads(...)\n",
      "        getNumThreads() -> retval\n",
      "        .   @brief Returns the number of threads used by OpenCV for parallel regions.\n",
      "        .   \n",
      "        .   Always returns 1 if OpenCV is built without threading support.\n",
      "        .   \n",
      "        .   The exact meaning of return value depends on the threading framework used by OpenCV library:\n",
      "        .   - `TBB` - The number of threads, that OpenCV will try to use for parallel regions. If there is\n",
      "        .   any tbb::thread_scheduler_init in user code conflicting with OpenCV, then function returns\n",
      "        .   default number of threads used by TBB library.\n",
      "        .   - `OpenMP` - An upper bound on the number of threads that could be used to form a new team.\n",
      "        .   - `Concurrency` - The number of threads, that OpenCV will try to use for parallel regions.\n",
      "        .   - `GCD` - Unsupported; returns the GCD thread pool limit (512) for compatibility.\n",
      "        .   - `C=` - The number of threads, that OpenCV will try to use for parallel regions, if before\n",
      "        .   called setNumThreads with threads \\> 0, otherwise returns the number of logical CPUs,\n",
      "        .   available for the process.\n",
      "        .   @sa setNumThreads, getThreadNum\n",
      "    \n",
      "    getNumberOfCPUs(...)\n",
      "        getNumberOfCPUs() -> retval\n",
      "        .   @brief Returns the number of logical CPUs available for the process.\n",
      "    \n",
      "    getOptimalDFTSize(...)\n",
      "        getOptimalDFTSize(vecsize) -> retval\n",
      "        .   @brief Returns the optimal DFT size for a given vector size.\n",
      "        .   \n",
      "        .   DFT performance is not a monotonic function of a vector size. Therefore, when you calculate\n",
      "        .   convolution of two arrays or perform the spectral analysis of an array, it usually makes sense to\n",
      "        .   pad the input data with zeros to get a bit larger array that can be transformed much faster than the\n",
      "        .   original one. Arrays whose size is a power-of-two (2, 4, 8, 16, 32, ...) are the fastest to process.\n",
      "        .   Though, the arrays whose size is a product of 2's, 3's, and 5's (for example, 300 = 5\\*5\\*3\\*2\\*2)\n",
      "        .   are also processed quite efficiently.\n",
      "        .   \n",
      "        .   The function cv::getOptimalDFTSize returns the minimum number N that is greater than or equal to vecsize\n",
      "        .   so that the DFT of a vector of size N can be processed efficiently. In the current implementation N\n",
      "        .   = 2 ^p^ \\* 3 ^q^ \\* 5 ^r^ for some integer p, q, r.\n",
      "        .   \n",
      "        .   The function returns a negative number if vecsize is too large (very close to INT_MAX ).\n",
      "        .   \n",
      "        .   While the function cannot be used directly to estimate the optimal vector size for DCT transform\n",
      "        .   (since the current DCT implementation supports only even-size vectors), it can be easily processed\n",
      "        .   as getOptimalDFTSize((vecsize+1)/2)\\*2.\n",
      "        .   @param vecsize vector size.\n",
      "        .   @sa dft , dct , idft , idct , mulSpectrums\n",
      "    \n",
      "    getOptimalNewCameraMatrix(...)\n",
      "        getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, alpha[, newImgSize[, centerPrincipalPoint]]) -> retval, validPixROI\n",
      "        .   @brief Returns the new camera matrix based on the free scaling parameter.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix.\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param imageSize Original image size.\n",
      "        .   @param alpha Free scaling parameter between 0 (when all the pixels in the undistorted image are\n",
      "        .   valid) and 1 (when all the source image pixels are retained in the undistorted image). See\n",
      "        .   stereoRectify for details.\n",
      "        .   @param newImgSize Image size after rectification. By default, it is set to imageSize .\n",
      "        .   @param validPixROI Optional output rectangle that outlines all-good-pixels region in the\n",
      "        .   undistorted image. See roi1, roi2 description in stereoRectify .\n",
      "        .   @param centerPrincipalPoint Optional flag that indicates whether in the new camera matrix the\n",
      "        .   principal point should be at the image center or not. By default, the principal point is chosen to\n",
      "        .   best fit a subset of the source image (determined by alpha) to the corrected image.\n",
      "        .   @return new_camera_matrix Output new camera matrix.\n",
      "        .   \n",
      "        .   The function computes and returns the optimal new camera matrix based on the free scaling parameter.\n",
      "        .   By varying this parameter, you may retrieve only sensible pixels alpha=0 , keep all the original\n",
      "        .   image pixels if there is valuable information in the corners alpha=1 , or get something in between.\n",
      "        .   When alpha\\>0 , the undistorted result is likely to have some black pixels corresponding to\n",
      "        .   \"virtual\" pixels outside of the captured distorted image. The original camera matrix, distortion\n",
      "        .   coefficients, the computed new camera matrix, and newImageSize should be passed to\n",
      "        .   initUndistortRectifyMap to produce the maps for remap .\n",
      "    \n",
      "    getPerspectiveTransform(...)\n",
      "        getPerspectiveTransform(src, dst[, solveMethod]) -> retval\n",
      "        .   @brief Calculates a perspective transform from four pairs of the corresponding points.\n",
      "        .   \n",
      "        .   The function calculates the \\f$3 \\times 3\\f$ matrix of a perspective transform so that:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} t_i x'_i \\\\ t_i y'_i \\\\ t_i \\end{bmatrix} = \\texttt{map_matrix} \\cdot \\begin{bmatrix} x_i \\\\ y_i \\\\ 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[dst(i)=(x'_i,y'_i), src(i)=(x_i, y_i), i=0,1,2,3\\f]\n",
      "        .   \n",
      "        .   @param src Coordinates of quadrangle vertices in the source image.\n",
      "        .   @param dst Coordinates of the corresponding quadrangle vertices in the destination image.\n",
      "        .   @param solveMethod method passed to cv::solve (#DecompTypes)\n",
      "        .   \n",
      "        .   @sa  findHomography, warpPerspective, perspectiveTransform\n",
      "    \n",
      "    getRectSubPix(...)\n",
      "        getRectSubPix(image, patchSize, center[, patch[, patchType]]) -> patch\n",
      "        .   @brief Retrieves a pixel rectangle from an image with sub-pixel accuracy.\n",
      "        .   \n",
      "        .   The function getRectSubPix extracts pixels from src:\n",
      "        .   \n",
      "        .   \\f[patch(x, y) = src(x +  \\texttt{center.x} - ( \\texttt{dst.cols} -1)*0.5, y +  \\texttt{center.y} - ( \\texttt{dst.rows} -1)*0.5)\\f]\n",
      "        .   \n",
      "        .   where the values of the pixels at non-integer coordinates are retrieved using bilinear\n",
      "        .   interpolation. Every channel of multi-channel images is processed independently. Also\n",
      "        .   the image should be a single channel or three channel image. While the center of the\n",
      "        .   rectangle must be inside the image, parts of the rectangle may be outside.\n",
      "        .   \n",
      "        .   @param image Source image.\n",
      "        .   @param patchSize Size of the extracted patch.\n",
      "        .   @param center Floating point coordinates of the center of the extracted rectangle within the\n",
      "        .   source image. The center must be inside the image.\n",
      "        .   @param patch Extracted patch that has the size patchSize and the same number of channels as src .\n",
      "        .   @param patchType Depth of the extracted pixels. By default, they have the same depth as src .\n",
      "        .   \n",
      "        .   @sa  warpAffine, warpPerspective\n",
      "    \n",
      "    getRotationMatrix2D(...)\n",
      "        getRotationMatrix2D(center, angle, scale) -> retval\n",
      "        .   @brief Calculates an affine matrix of 2D rotation.\n",
      "        .   \n",
      "        .   The function calculates the following matrix:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} \\alpha &  \\beta & (1- \\alpha )  \\cdot \\texttt{center.x} -  \\beta \\cdot \\texttt{center.y} \\\\ - \\beta &  \\alpha &  \\beta \\cdot \\texttt{center.x} + (1- \\alpha )  \\cdot \\texttt{center.y} \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\alpha =  \\texttt{scale} \\cdot \\cos \\texttt{angle} , \\\\ \\beta =  \\texttt{scale} \\cdot \\sin \\texttt{angle} \\end{array}\\f]\n",
      "        .   \n",
      "        .   The transformation maps the rotation center to itself. If this is not the target, adjust the shift.\n",
      "        .   \n",
      "        .   @param center Center of the rotation in the source image.\n",
      "        .   @param angle Rotation angle in degrees. Positive values mean counter-clockwise rotation (the\n",
      "        .   coordinate origin is assumed to be the top-left corner).\n",
      "        .   @param scale Isotropic scale factor.\n",
      "        .   \n",
      "        .   @sa  getAffineTransform, warpAffine, transform\n",
      "    \n",
      "    getStructuringElement(...)\n",
      "        getStructuringElement(shape, ksize[, anchor]) -> retval\n",
      "        .   @brief Returns a structuring element of the specified size and shape for morphological operations.\n",
      "        .   \n",
      "        .   The function constructs and returns the structuring element that can be further passed to #erode,\n",
      "        .   #dilate or #morphologyEx. But you can also construct an arbitrary binary mask yourself and use it as\n",
      "        .   the structuring element.\n",
      "        .   \n",
      "        .   @param shape Element shape that could be one of #MorphShapes\n",
      "        .   @param ksize Size of the structuring element.\n",
      "        .   @param anchor Anchor position within the element. The default value \\f$(-1, -1)\\f$ means that the\n",
      "        .   anchor is at the center. Note that only the shape of a cross-shaped element depends on the anchor\n",
      "        .   position. In other cases the anchor just regulates how much the result of the morphological\n",
      "        .   operation is shifted.\n",
      "    \n",
      "    getTextSize(...)\n",
      "        getTextSize(text, fontFace, fontScale, thickness) -> retval, baseLine\n",
      "        .   @brief Calculates the width and height of a text string.\n",
      "        .   \n",
      "        .   The function cv::getTextSize calculates and returns the size of a box that contains the specified text.\n",
      "        .   That is, the following code renders some text, the tight box surrounding it, and the baseline: :\n",
      "        .   @code\n",
      "        .   String text = \"Funny text inside the box\";\n",
      "        .   int fontFace = FONT_HERSHEY_SCRIPT_SIMPLEX;\n",
      "        .   double fontScale = 2;\n",
      "        .   int thickness = 3;\n",
      "        .   \n",
      "        .   Mat img(600, 800, CV_8UC3, Scalar::all(0));\n",
      "        .   \n",
      "        .   int baseline=0;\n",
      "        .   Size textSize = getTextSize(text, fontFace,\n",
      "        .   fontScale, thickness, &baseline);\n",
      "        .   baseline += thickness;\n",
      "        .   \n",
      "        .   // center the text\n",
      "        .   Point textOrg((img.cols - textSize.width)/2,\n",
      "        .   (img.rows + textSize.height)/2);\n",
      "        .   \n",
      "        .   // draw the box\n",
      "        .   rectangle(img, textOrg + Point(0, baseline),\n",
      "        .   textOrg + Point(textSize.width, -textSize.height),\n",
      "        .   Scalar(0,0,255));\n",
      "        .   // ... and the baseline first\n",
      "        .   line(img, textOrg + Point(0, thickness),\n",
      "        .   textOrg + Point(textSize.width, thickness),\n",
      "        .   Scalar(0, 0, 255));\n",
      "        .   \n",
      "        .   // then put the text itself\n",
      "        .   putText(img, text, textOrg, fontFace, fontScale,\n",
      "        .   Scalar::all(255), thickness, 8);\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param text Input text string.\n",
      "        .   @param fontFace Font to use, see #HersheyFonts.\n",
      "        .   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
      "        .   @param thickness Thickness of lines used to render the text. See #putText for details.\n",
      "        .   @param[out] baseLine y-coordinate of the baseline relative to the bottom-most text\n",
      "        .   point.\n",
      "        .   @return The size of a box that contains the specified text.\n",
      "        .   \n",
      "        .   @see putText\n",
      "    \n",
      "    getThreadNum(...)\n",
      "        getThreadNum() -> retval\n",
      "        .   @brief Returns the index of the currently executed thread within the current parallel region. Always\n",
      "        .   returns 0 if called outside of parallel region.\n",
      "        .   \n",
      "        .   @deprecated Current implementation doesn't corresponding to this documentation.\n",
      "        .   \n",
      "        .   The exact meaning of the return value depends on the threading framework used by OpenCV library:\n",
      "        .   - `TBB` - Unsupported with current 4.1 TBB release. Maybe will be supported in future.\n",
      "        .   - `OpenMP` - The thread number, within the current team, of the calling thread.\n",
      "        .   - `Concurrency` - An ID for the virtual processor that the current context is executing on (0\n",
      "        .   for master thread and unique number for others, but not necessary 1,2,3,...).\n",
      "        .   - `GCD` - System calling thread's ID. Never returns 0 inside parallel region.\n",
      "        .   - `C=` - The index of the current parallel task.\n",
      "        .   @sa setNumThreads, getNumThreads\n",
      "    \n",
      "    getTickCount(...)\n",
      "        getTickCount() -> retval\n",
      "        .   @brief Returns the number of ticks.\n",
      "        .   \n",
      "        .   The function returns the number of ticks after the certain event (for example, when the machine was\n",
      "        .   turned on). It can be used to initialize RNG or to measure a function execution time by reading the\n",
      "        .   tick count before and after the function call.\n",
      "        .   @sa getTickFrequency, TickMeter\n",
      "    \n",
      "    getTickFrequency(...)\n",
      "        getTickFrequency() -> retval\n",
      "        .   @brief Returns the number of ticks per second.\n",
      "        .   \n",
      "        .   The function returns the number of ticks per second. That is, the following code computes the\n",
      "        .   execution time in seconds:\n",
      "        .   @code\n",
      "        .   double t = (double)getTickCount();\n",
      "        .   // do something ...\n",
      "        .   t = ((double)getTickCount() - t)/getTickFrequency();\n",
      "        .   @endcode\n",
      "        .   @sa getTickCount, TickMeter\n",
      "    \n",
      "    getTrackbarPos(...)\n",
      "        getTrackbarPos(trackbarname, winname) -> retval\n",
      "        .   @brief Returns the trackbar position.\n",
      "        .   \n",
      "        .   The function returns the current position of the specified trackbar.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of the trackbar.\n",
      "    \n",
      "    getValidDisparityROI(...)\n",
      "        getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, SADWindowSize) -> retval\n",
      "        .\n",
      "    \n",
      "    getVersionMajor(...)\n",
      "        getVersionMajor() -> retval\n",
      "        .   @brief Returns major library version\n",
      "    \n",
      "    getVersionMinor(...)\n",
      "        getVersionMinor() -> retval\n",
      "        .   @brief Returns minor library version\n",
      "    \n",
      "    getVersionRevision(...)\n",
      "        getVersionRevision() -> retval\n",
      "        .   @brief Returns revision field of the library version\n",
      "    \n",
      "    getVersionString(...)\n",
      "        getVersionString() -> retval\n",
      "        .   @brief Returns library version string\n",
      "        .   \n",
      "        .   For example \"3.4.1-dev\".\n",
      "        .   \n",
      "        .   @sa getMajorVersion, getMinorVersion, getRevisionVersion\n",
      "    \n",
      "    getWindowImageRect(...)\n",
      "        getWindowImageRect(winname) -> retval\n",
      "        .   @brief Provides rectangle of image in the window.\n",
      "        .   \n",
      "        .   The function getWindowImageRect returns the client screen coordinates, width and height of the image rendering area.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   \n",
      "        .   @sa resizeWindow moveWindow\n",
      "    \n",
      "    getWindowProperty(...)\n",
      "        getWindowProperty(winname, prop_id) -> retval\n",
      "        .   @brief Provides parameters of a window.\n",
      "        .   \n",
      "        .   The function getWindowProperty returns properties of a window.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param prop_id Window property to retrieve. The following operation flags are available: (cv::WindowPropertyFlags)\n",
      "        .   \n",
      "        .   @sa setWindowProperty\n",
      "    \n",
      "    goodFeaturesToTrack(...)\n",
      "        goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\n",
      "        .   @brief Determines strong corners on an image.\n",
      "        .   \n",
      "        .   The function finds the most prominent corners in the image or in the specified image region, as\n",
      "        .   described in @cite Shi94\n",
      "        .   \n",
      "        .   -   Function calculates the corner quality measure at every source image pixel using the\n",
      "        .   #cornerMinEigenVal or #cornerHarris .\n",
      "        .   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\n",
      "        .   retained).\n",
      "        .   -   The corners with the minimal eigenvalue less than\n",
      "        .   \\f$\\texttt{qualityLevel} \\cdot \\max_{x,y} qualityMeasureMap(x,y)\\f$ are rejected.\n",
      "        .   -   The remaining corners are sorted by the quality measure in the descending order.\n",
      "        .   -   Function throws away each corner for which there is a stronger corner at a distance less than\n",
      "        .   maxDistance.\n",
      "        .   \n",
      "        .   The function can be used to initialize a point-based tracker of an object.\n",
      "        .   \n",
      "        .   @note If the function is called with different values A and B of the parameter qualityLevel , and\n",
      "        .   A \\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\n",
      "        .   with qualityLevel=B .\n",
      "        .   \n",
      "        .   @param image Input 8-bit or floating-point 32-bit, single-channel image.\n",
      "        .   @param corners Output vector of detected corners.\n",
      "        .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
      "        .   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\n",
      "        .   and all detected corners are returned.\n",
      "        .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
      "        .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
      "        .   (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the\n",
      "        .   quality measure less than the product are rejected. For example, if the best corner has the\n",
      "        .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
      "        .   less than 15 are rejected.\n",
      "        .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
      "        .   @param mask Optional region of interest. If the image is not empty (it needs to have the type\n",
      "        .   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n",
      "        .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
      "        .   pixel neighborhood. See cornerEigenValsAndVecs .\n",
      "        .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see #cornerHarris)\n",
      "        .   or #cornerMinEigenVal.\n",
      "        .   @param k Free parameter of the Harris detector.\n",
      "        .   \n",
      "        .   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\n",
      "        \n",
      "        \n",
      "        \n",
      "        goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\n",
      "        .\n",
      "    \n",
      "    grabCut(...)\n",
      "        grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\n",
      "        .   @brief Runs the GrabCut algorithm.\n",
      "        .   \n",
      "        .   The function implements the [GrabCut image segmentation algorithm](http://en.wikipedia.org/wiki/GrabCut).\n",
      "        .   \n",
      "        .   @param img Input 8-bit 3-channel image.\n",
      "        .   @param mask Input/output 8-bit single-channel mask. The mask is initialized by the function when\n",
      "        .   mode is set to #GC_INIT_WITH_RECT. Its elements may have one of the #GrabCutClasses.\n",
      "        .   @param rect ROI containing a segmented object. The pixels outside of the ROI are marked as\n",
      "        .   \"obvious background\". The parameter is only used when mode==#GC_INIT_WITH_RECT .\n",
      "        .   @param bgdModel Temporary array for the background model. Do not modify it while you are\n",
      "        .   processing the same image.\n",
      "        .   @param fgdModel Temporary arrays for the foreground model. Do not modify it while you are\n",
      "        .   processing the same image.\n",
      "        .   @param iterCount Number of iterations the algorithm should make before returning the result. Note\n",
      "        .   that the result can be refined with further calls with mode==#GC_INIT_WITH_MASK or\n",
      "        .   mode==GC_EVAL .\n",
      "        .   @param mode Operation mode that could be one of the #GrabCutModes\n",
      "    \n",
      "    groupRectangles(...)\n",
      "        groupRectangles(rectList, groupThreshold[, eps]) -> rectList, weights\n",
      "        .   @overload\n",
      "    \n",
      "    haveImageReader(...)\n",
      "        haveImageReader(filename) -> retval\n",
      "        .   @brief Returns true if the specified image can be decoded by OpenCV\n",
      "        .   \n",
      "        .   @param filename File name of the image\n",
      "    \n",
      "    haveImageWriter(...)\n",
      "        haveImageWriter(filename) -> retval\n",
      "        .   @brief Returns true if an image with the specified filename can be encoded by OpenCV\n",
      "        .   \n",
      "        .   @param filename File name of the image\n",
      "    \n",
      "    haveOpenVX(...)\n",
      "        haveOpenVX() -> retval\n",
      "        .\n",
      "    \n",
      "    hconcat(...)\n",
      "        hconcat(src[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .   @code{.cpp}\n",
      "        .   std::vector<cv::Mat> matrices = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\n",
      "        .   cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\n",
      "        .   cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\n",
      "        .   \n",
      "        .   cv::Mat out;\n",
      "        .   cv::hconcat( matrices, out );\n",
      "        .   //out:\n",
      "        .   //[1, 2, 3;\n",
      "        .   // 1, 2, 3;\n",
      "        .   // 1, 2, 3;\n",
      "        .   // 1, 2, 3]\n",
      "        .   @endcode\n",
      "        .   @param src input array or vector of matrices. all of the matrices must have the same number of rows and the same depth.\n",
      "        .   @param dst output array. It has the same number of rows and depth as the src, and the sum of cols of the src.\n",
      "        .   same depth.\n",
      "    \n",
      "    idct(...)\n",
      "        idct(src[, dst[, flags]]) -> dst\n",
      "        .   @brief Calculates the inverse Discrete Cosine Transform of a 1D or 2D array.\n",
      "        .   \n",
      "        .   idct(src, dst, flags) is equivalent to dct(src, dst, flags | DCT_INVERSE).\n",
      "        .   @param src input floating-point single-channel array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flags operation flags.\n",
      "        .   @sa  dct, dft, idft, getOptimalDFTSize\n",
      "    \n",
      "    idft(...)\n",
      "        idft(src[, dst[, flags[, nonzeroRows]]]) -> dst\n",
      "        .   @brief Calculates the inverse Discrete Fourier Transform of a 1D or 2D array.\n",
      "        .   \n",
      "        .   idft(src, dst, flags) is equivalent to dft(src, dst, flags | #DFT_INVERSE) .\n",
      "        .   @note None of dft and idft scales the result by default. So, you should pass #DFT_SCALE to one of\n",
      "        .   dft or idft explicitly to make these transforms mutually inverse.\n",
      "        .   @sa dft, dct, idct, mulSpectrums, getOptimalDFTSize\n",
      "        .   @param src input floating-point real or complex array.\n",
      "        .   @param dst output array whose size and type depend on the flags.\n",
      "        .   @param flags operation flags (see dft and #DftFlags).\n",
      "        .   @param nonzeroRows number of dst rows to process; the rest of the rows have undefined content (see\n",
      "        .   the convolution sample in dft description.\n",
      "    \n",
      "    illuminationChange(...)\n",
      "        illuminationChange(src, mask[, dst[, alpha[, beta]]]) -> dst\n",
      "        .   @brief Applying an appropriate non-linear transformation to the gradient field inside the selection and\n",
      "        .   then integrating back with a Poisson solver, modifies locally the apparent illumination of an image.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param alpha Value ranges between 0-2.\n",
      "        .   @param beta Value ranges between 0-2.\n",
      "        .   \n",
      "        .   This is useful to highlight under-exposed foreground objects or to reduce specular reflections.\n",
      "    \n",
      "    imdecode(...)\n",
      "        imdecode(buf, flags) -> retval\n",
      "        .   @brief Reads an image from a buffer in memory.\n",
      "        .   \n",
      "        .   The function imdecode reads an image from the specified buffer in the memory. If the buffer is too short or\n",
      "        .   contains invalid data, the function returns an empty matrix ( Mat::data==NULL ).\n",
      "        .   \n",
      "        .   See cv::imread for the list of supported formats and flags description.\n",
      "        .   \n",
      "        .   @note In the case of color images, the decoded images will have the channels stored in **B G R** order.\n",
      "        .   @param buf Input array or vector of bytes.\n",
      "        .   @param flags The same flags as in cv::imread, see cv::ImreadModes.\n",
      "    \n",
      "    imencode(...)\n",
      "        imencode(ext, img[, params]) -> retval, buf\n",
      "        .   @brief Encodes an image into a memory buffer.\n",
      "        .   \n",
      "        .   The function imencode compresses the image and stores it in the memory buffer that is resized to fit the\n",
      "        .   result. See cv::imwrite for the list of supported formats and flags description.\n",
      "        .   \n",
      "        .   @param ext File extension that defines the output format.\n",
      "        .   @param img Image to be written.\n",
      "        .   @param buf Output buffer resized to fit the compressed image.\n",
      "        .   @param params Format-specific parameters. See cv::imwrite and cv::ImwriteFlags.\n",
      "    \n",
      "    imread(...)\n",
      "        imread(filename[, flags]) -> retval\n",
      "        .   @brief Loads an image from a file.\n",
      "        .   \n",
      "        .   @anchor imread\n",
      "        .   \n",
      "        .   The function imread loads an image from the specified file and returns it. If the image cannot be\n",
      "        .   read (because of missing file, improper permissions, unsupported or invalid format), the function\n",
      "        .   returns an empty matrix ( Mat::data==NULL ).\n",
      "        .   \n",
      "        .   Currently, the following file formats are supported:\n",
      "        .   \n",
      "        .   -   Windows bitmaps - \\*.bmp, \\*.dib (always supported)\n",
      "        .   -   JPEG files - \\*.jpeg, \\*.jpg, \\*.jpe (see the *Note* section)\n",
      "        .   -   JPEG 2000 files - \\*.jp2 (see the *Note* section)\n",
      "        .   -   Portable Network Graphics - \\*.png (see the *Note* section)\n",
      "        .   -   WebP - \\*.webp (see the *Note* section)\n",
      "        .   -   Portable image format - \\*.pbm, \\*.pgm, \\*.ppm \\*.pxm, \\*.pnm (always supported)\n",
      "        .   -   PFM files - \\*.pfm (see the *Note* section)\n",
      "        .   -   Sun rasters - \\*.sr, \\*.ras (always supported)\n",
      "        .   -   TIFF files - \\*.tiff, \\*.tif (see the *Note* section)\n",
      "        .   -   OpenEXR Image files - \\*.exr (see the *Note* section)\n",
      "        .   -   Radiance HDR - \\*.hdr, \\*.pic (always supported)\n",
      "        .   -   Raster and Vector geospatial data supported by GDAL (see the *Note* section)\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function determines the type of an image by the content, not by the file extension.\n",
      "        .   -   In the case of color images, the decoded images will have the channels stored in **B G R** order.\n",
      "        .   -   When using IMREAD_GRAYSCALE, the codec's internal grayscale conversion will be used, if available.\n",
      "        .   Results may differ to the output of cvtColor()\n",
      "        .   -   On Microsoft Windows\\* OS and MacOSX\\*, the codecs shipped with an OpenCV image (libjpeg,\n",
      "        .   libpng, libtiff, and libjasper) are used by default. So, OpenCV can always read JPEGs, PNGs,\n",
      "        .   and TIFFs. On MacOSX, there is also an option to use native MacOSX image readers. But beware\n",
      "        .   that currently these native image loaders give images with different pixel values because of\n",
      "        .   the color management embedded into MacOSX.\n",
      "        .   -   On Linux\\*, BSD flavors and other Unix-like open-source operating systems, OpenCV looks for\n",
      "        .   codecs supplied with an OS image. Install the relevant packages (do not forget the development\n",
      "        .   files, for example, \"libjpeg-dev\", in Debian\\* and Ubuntu\\*) to get the codec support or turn\n",
      "        .   on the OPENCV_BUILD_3RDPARTY_LIBS flag in CMake.\n",
      "        .   -   In the case you set *WITH_GDAL* flag to true in CMake and @ref IMREAD_LOAD_GDAL to load the image,\n",
      "        .   then the [GDAL](http://www.gdal.org) driver will be used in order to decode the image, supporting\n",
      "        .   the following formats: [Raster](http://www.gdal.org/formats_list.html),\n",
      "        .   [Vector](http://www.gdal.org/ogr_formats.html).\n",
      "        .   -   If EXIF information are embedded in the image file, the EXIF orientation will be taken into account\n",
      "        .   and thus the image will be rotated accordingly except if the flag @ref IMREAD_IGNORE_ORIENTATION is passed.\n",
      "        .   -   Use the IMREAD_UNCHANGED flag to keep the floating point values from PFM image.\n",
      "        .   -   By default number of pixels must be less than 2^30. Limit can be set using system\n",
      "        .   variable OPENCV_IO_MAX_IMAGE_PIXELS\n",
      "        .   \n",
      "        .   @param filename Name of file to be loaded.\n",
      "        .   @param flags Flag that can take values of cv::ImreadModes\n",
      "    \n",
      "    imreadmulti(...)\n",
      "        imreadmulti(filename[, mats[, flags]]) -> retval, mats\n",
      "        .   @brief Loads a multi-page image from a file.\n",
      "        .   \n",
      "        .   The function imreadmulti loads a multi-page image from the specified file into a vector of Mat objects.\n",
      "        .   @param filename Name of file to be loaded.\n",
      "        .   @param flags Flag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR.\n",
      "        .   @param mats A vector of Mat objects holding each page, if more than one.\n",
      "        .   @sa cv::imread\n",
      "    \n",
      "    imshow(...)\n",
      "        imshow(winname, mat) -> None\n",
      "        .   @brief Displays an image in the specified window.\n",
      "        .   \n",
      "        .   The function imshow displays an image in the specified window. If the window was created with the\n",
      "        .   cv::WINDOW_AUTOSIZE flag, the image is shown with its original size, however it is still limited by the screen resolution.\n",
      "        .   Otherwise, the image is scaled to fit the window. The function may scale the image, depending on its depth:\n",
      "        .   \n",
      "        .   -   If the image is 8-bit unsigned, it is displayed as is.\n",
      "        .   -   If the image is 16-bit unsigned or 32-bit integer, the pixels are divided by 256. That is, the\n",
      "        .   value range [0,255\\*256] is mapped to [0,255].\n",
      "        .   -   If the image is 32-bit or 64-bit floating-point, the pixel values are multiplied by 255. That is, the\n",
      "        .   value range [0,1] is mapped to [0,255].\n",
      "        .   \n",
      "        .   If window was created with OpenGL support, cv::imshow also support ogl::Buffer , ogl::Texture2D and\n",
      "        .   cuda::GpuMat as input.\n",
      "        .   \n",
      "        .   If the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE.\n",
      "        .   \n",
      "        .   If you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\"\", WINDOW_NORMAL) before the imshow.\n",
      "        .   \n",
      "        .   @note This function should be followed by cv::waitKey function which displays the image for specified\n",
      "        .   milliseconds. Otherwise, it won't display the image. For example, **waitKey(0)** will display the window\n",
      "        .   infinitely until any keypress (it is suitable for image display). **waitKey(25)** will display a frame\n",
      "        .   for 25 ms, after which display will be automatically closed. (If you put it in a loop to read\n",
      "        .   videos, it will display the video frame-by-frame)\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Windows Backend Only__] Pressing Ctrl+C will copy the image to the clipboard.\n",
      "        .   \n",
      "        .   [__Windows Backend Only__] Pressing Ctrl+S will show a dialog to save the image.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param mat Image to be shown.\n",
      "    \n",
      "    imwrite(...)\n",
      "        imwrite(filename, img[, params]) -> retval\n",
      "        .   @brief Saves an image to a specified file.\n",
      "        .   \n",
      "        .   The function imwrite saves the image to the specified file. The image format is chosen based on the\n",
      "        .   filename extension (see cv::imread for the list of extensions). In general, only 8-bit\n",
      "        .   single-channel or 3-channel (with 'BGR' channel order) images\n",
      "        .   can be saved using this function, with these exceptions:\n",
      "        .   \n",
      "        .   - 16-bit unsigned (CV_16U) images can be saved in the case of PNG, JPEG 2000, and TIFF formats\n",
      "        .   - 32-bit float (CV_32F) images can be saved in PFM, TIFF, OpenEXR, and Radiance HDR formats;\n",
      "        .   3-channel (CV_32FC3) TIFF images will be saved using the LogLuv high dynamic range encoding\n",
      "        .   (4 bytes per pixel)\n",
      "        .   - PNG images with an alpha channel can be saved using this function. To do this, create\n",
      "        .   8-bit (or 16-bit) 4-channel image BGRA, where the alpha channel goes last. Fully transparent pixels\n",
      "        .   should have alpha set to 0, fully opaque pixels should have alpha set to 255/65535 (see the code sample below).\n",
      "        .   \n",
      "        .   If the format, depth or channel order is different, use\n",
      "        .   Mat::convertTo and cv::cvtColor to convert it before saving. Or, use the universal FileStorage I/O\n",
      "        .   functions to save the image to XML or YAML format.\n",
      "        .   \n",
      "        .   The sample below shows how to create a BGRA image and save it to a PNG file. It also demonstrates how to set custom\n",
      "        .   compression parameters:\n",
      "        .   @include snippets/imgcodecs_imwrite.cpp\n",
      "        .   @param filename Name of the file.\n",
      "        .   @param img Image to be saved.\n",
      "        .   @param params Format-specific parameters encoded as pairs (paramId_1, paramValue_1, paramId_2, paramValue_2, ... .) see cv::ImwriteFlags\n",
      "    \n",
      "    inRange(...)\n",
      "        inRange(src, lowerb, upperb[, dst]) -> dst\n",
      "        .   @brief  Checks if array elements lie between the elements of two other arrays.\n",
      "        .   \n",
      "        .   The function checks the range as follows:\n",
      "        .   -   For every element of a single-channel input array:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{lowerb} (I)_0  \\leq \\texttt{src} (I)_0 \\leq  \\texttt{upperb} (I)_0\\f]\n",
      "        .   -   For two-channel arrays:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{lowerb} (I)_0  \\leq \\texttt{src} (I)_0 \\leq  \\texttt{upperb} (I)_0  \\land \\texttt{lowerb} (I)_1  \\leq \\texttt{src} (I)_1 \\leq  \\texttt{upperb} (I)_1\\f]\n",
      "        .   -   and so forth.\n",
      "        .   \n",
      "        .   That is, dst (I) is set to 255 (all 1 -bits) if src (I) is within the\n",
      "        .   specified 1D, 2D, 3D, ... box and 0 otherwise.\n",
      "        .   \n",
      "        .   When the lower and/or upper boundary parameters are scalars, the indexes\n",
      "        .   (I) at lowerb and upperb in the above formulas should be omitted.\n",
      "        .   @param src first input array.\n",
      "        .   @param lowerb inclusive lower boundary array or a scalar.\n",
      "        .   @param upperb inclusive upper boundary array or a scalar.\n",
      "        .   @param dst output array of the same size as src and CV_8U type.\n",
      "    \n",
      "    initCameraMatrix2D(...)\n",
      "        initCameraMatrix2D(objectPoints, imagePoints, imageSize[, aspectRatio]) -> retval\n",
      "        .   @brief Finds an initial camera matrix from 3D-2D point correspondences.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of the calibration pattern points in the calibration pattern\n",
      "        .   coordinate space. In the old interface all the per-view vectors are concatenated. See\n",
      "        .   calibrateCamera for details.\n",
      "        .   @param imagePoints Vector of vectors of the projections of the calibration pattern points. In the\n",
      "        .   old interface all the per-view vectors are concatenated.\n",
      "        .   @param imageSize Image size in pixels used to initialize the principal point.\n",
      "        .   @param aspectRatio If it is zero or negative, both \\f$f_x\\f$ and \\f$f_y\\f$ are estimated independently.\n",
      "        .   Otherwise, \\f$f_x = f_y * \\texttt{aspectRatio}\\f$ .\n",
      "        .   \n",
      "        .   The function estimates and returns an initial camera matrix for the camera calibration process.\n",
      "        .   Currently, the function only supports planar calibration patterns, which are patterns where each\n",
      "        .   object point has z-coordinate =0.\n",
      "    \n",
      "    initUndistortRectifyMap(...)\n",
      "        initUndistortRectifyMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type[, map1[, map2]]) -> map1, map2\n",
      "        .   @brief Computes the undistortion and rectification transformation map.\n",
      "        .   \n",
      "        .   The function computes the joint undistortion and rectification transformation and represents the\n",
      "        .   result in the form of maps for remap. The undistorted image looks like original, as if it is\n",
      "        .   captured with a camera using the camera matrix =newCameraMatrix and zero distortion. In case of a\n",
      "        .   monocular camera, newCameraMatrix is usually equal to cameraMatrix, or it can be computed by\n",
      "        .   #getOptimalNewCameraMatrix for a better control over scaling. In case of a stereo camera,\n",
      "        .   newCameraMatrix is normally set to P1 or P2 computed by #stereoRectify .\n",
      "        .   \n",
      "        .   Also, this new camera is oriented differently in the coordinate space, according to R. That, for\n",
      "        .   example, helps to align two heads of a stereo camera so that the epipolar lines on both images\n",
      "        .   become horizontal and have the same y- coordinate (in case of a horizontally aligned stereo camera).\n",
      "        .   \n",
      "        .   The function actually builds the maps for the inverse mapping algorithm that is used by remap. That\n",
      "        .   is, for each pixel \\f$(u, v)\\f$ in the destination (corrected and rectified) image, the function\n",
      "        .   computes the corresponding coordinates in the source image (that is, in the original image from\n",
      "        .   camera). The following process is applied:\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   x  \\leftarrow (u - {c'}_x)/{f'}_x  \\\\\n",
      "        .   y  \\leftarrow (v - {c'}_y)/{f'}_y  \\\\\n",
      "        .   {[X\\,Y\\,W]} ^T  \\leftarrow R^{-1}*[x \\, y \\, 1]^T  \\\\\n",
      "        .   x'  \\leftarrow X/W  \\\\\n",
      "        .   y'  \\leftarrow Y/W  \\\\\n",
      "        .   r^2  \\leftarrow x'^2 + y'^2 \\\\\n",
      "        .   x''  \\leftarrow x' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n",
      "        .   + 2p_1 x' y' + p_2(r^2 + 2 x'^2)  + s_1 r^2 + s_2 r^4\\\\\n",
      "        .   y''  \\leftarrow y' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n",
      "        .   + p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4 \\\\\n",
      "        .   s\\vecthree{x'''}{y'''}{1} =\n",
      "        .   \\vecthreethree{R_{33}(\\tau_x, \\tau_y)}{0}{-R_{13}((\\tau_x, \\tau_y)}\n",
      "        .   {0}{R_{33}(\\tau_x, \\tau_y)}{-R_{23}(\\tau_x, \\tau_y)}\n",
      "        .   {0}{0}{1} R(\\tau_x, \\tau_y) \\vecthree{x''}{y''}{1}\\\\\n",
      "        .   map_x(u,v)  \\leftarrow x''' f_x + c_x  \\\\\n",
      "        .   map_y(u,v)  \\leftarrow y''' f_y + c_y\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   where \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   are the distortion coefficients.\n",
      "        .   \n",
      "        .   In case of a stereo camera, this function is called twice: once for each camera head, after\n",
      "        .   stereoRectify, which in its turn is called after #stereoCalibrate. But if the stereo camera\n",
      "        .   was not calibrated, it is still possible to compute the rectification transformations directly from\n",
      "        .   the fundamental matrix using #stereoRectifyUncalibrated. For each camera, the function computes\n",
      "        .   homography H as the rectification transformation in a pixel domain, not a rotation matrix R in 3D\n",
      "        .   space. R can be computed from H as\n",
      "        .   \\f[\\texttt{R} = \\texttt{cameraMatrix} ^{-1} \\cdot \\texttt{H} \\cdot \\texttt{cameraMatrix}\\f]\n",
      "        .   where cameraMatrix can be chosen arbitrarily.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix \\f$A=\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param R Optional rectification transformation in the object space (3x3 matrix). R1 or R2 ,\n",
      "        .   computed by #stereoRectify can be passed here. If the matrix is empty, the identity transformation\n",
      "        .   is assumed. In cvInitUndistortMap R assumed to be an identity matrix.\n",
      "        .   @param newCameraMatrix New camera matrix \\f$A'=\\vecthreethree{f_x'}{0}{c_x'}{0}{f_y'}{c_y'}{0}{0}{1}\\f$.\n",
      "        .   @param size Undistorted image size.\n",
      "        .   @param m1type Type of the first output map that can be CV_32FC1, CV_32FC2 or CV_16SC2, see #convertMaps\n",
      "        .   @param map1 The first output map.\n",
      "        .   @param map2 The second output map.\n",
      "    \n",
      "    inpaint(...)\n",
      "        inpaint(src, inpaintMask, inpaintRadius, flags[, dst]) -> dst\n",
      "        .   @brief Restores the selected region in an image using the region neighborhood.\n",
      "        .   \n",
      "        .   @param src Input 8-bit, 16-bit unsigned or 32-bit float 1-channel or 8-bit 3-channel image.\n",
      "        .   @param inpaintMask Inpainting mask, 8-bit 1-channel image. Non-zero pixels indicate the area that\n",
      "        .   needs to be inpainted.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param inpaintRadius Radius of a circular neighborhood of each point inpainted that is considered\n",
      "        .   by the algorithm.\n",
      "        .   @param flags Inpainting method that could be cv::INPAINT_NS or cv::INPAINT_TELEA\n",
      "        .   \n",
      "        .   The function reconstructs the selected image area from the pixel near the area boundary. The\n",
      "        .   function may be used to remove dust and scratches from a scanned photo, or to remove undesirable\n",
      "        .   objects from still images or video. See <http://en.wikipedia.org/wiki/Inpainting> for more details.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   An example using the inpainting technique can be found at\n",
      "        .   opencv_source_code/samples/cpp/inpaint.cpp\n",
      "        .   -   (Python) An example using the inpainting technique can be found at\n",
      "        .   opencv_source_code/samples/python/inpaint.py\n",
      "    \n",
      "    insertChannel(...)\n",
      "        insertChannel(src, dst, coi) -> dst\n",
      "        .   @brief Inserts a single channel to dst (coi is 0-based index)\n",
      "        .   @param src input array\n",
      "        .   @param dst output array\n",
      "        .   @param coi index of channel for insertion\n",
      "        .   @sa mixChannels, merge\n",
      "    \n",
      "    integral(...)\n",
      "        integral(src[, sum[, sdepth]]) -> sum\n",
      "        .   @overload\n",
      "    \n",
      "    integral2(...)\n",
      "        integral2(src[, sum[, sqsum[, sdepth[, sqdepth]]]]) -> sum, sqsum\n",
      "        .   @overload\n",
      "    \n",
      "    integral3(...)\n",
      "        integral3(src[, sum[, sqsum[, tilted[, sdepth[, sqdepth]]]]]) -> sum, sqsum, tilted\n",
      "        .   @brief Calculates the integral of an image.\n",
      "        .   \n",
      "        .   The function calculates one or more integral images for the source image as follows:\n",
      "        .   \n",
      "        .   \\f[\\texttt{sum} (X,Y) =  \\sum _{x<X,y<Y}  \\texttt{image} (x,y)\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{sqsum} (X,Y) =  \\sum _{x<X,y<Y}  \\texttt{image} (x,y)^2\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{tilted} (X,Y) =  \\sum _{y<Y,abs(x-X+1) \\leq Y-y-1}  \\texttt{image} (x,y)\\f]\n",
      "        .   \n",
      "        .   Using these integral images, you can calculate sum, mean, and standard deviation over a specific\n",
      "        .   up-right or rotated rectangular region of the image in a constant time, for example:\n",
      "        .   \n",
      "        .   \\f[\\sum _{x_1 \\leq x < x_2,  \\, y_1  \\leq y < y_2}  \\texttt{image} (x,y) =  \\texttt{sum} (x_2,y_2)- \\texttt{sum} (x_1,y_2)- \\texttt{sum} (x_2,y_1)+ \\texttt{sum} (x_1,y_1)\\f]\n",
      "        .   \n",
      "        .   It makes possible to do a fast blurring or fast block correlation with a variable window size, for\n",
      "        .   example. In case of multi-channel images, sums for each channel are accumulated independently.\n",
      "        .   \n",
      "        .   As a practical example, the next figure shows the calculation of the integral of a straight\n",
      "        .   rectangle Rect(3,3,3,2) and of a tilted rectangle Rect(5,1,2,3) . The selected pixels in the\n",
      "        .   original image are shown, as well as the relative pixels in the integral images sum and tilted .\n",
      "        .   \n",
      "        .   ![integral calculation example](pics/integral.png)\n",
      "        .   \n",
      "        .   @param src input image as \\f$W \\times H\\f$, 8-bit or floating-point (32f or 64f).\n",
      "        .   @param sum integral image as \\f$(W+1)\\times (H+1)\\f$ , 32-bit integer or floating-point (32f or 64f).\n",
      "        .   @param sqsum integral image for squared pixel values; it is \\f$(W+1)\\times (H+1)\\f$, double-precision\n",
      "        .   floating-point (64f) array.\n",
      "        .   @param tilted integral for the image rotated by 45 degrees; it is \\f$(W+1)\\times (H+1)\\f$ array with\n",
      "        .   the same data type as sum.\n",
      "        .   @param sdepth desired depth of the integral and the tilted integral images, CV_32S, CV_32F, or\n",
      "        .   CV_64F.\n",
      "        .   @param sqdepth desired depth of the integral image of squared pixel values, CV_32F or CV_64F.\n",
      "    \n",
      "    intersectConvexConvex(...)\n",
      "        intersectConvexConvex(_p1, _p2[, _p12[, handleNested]]) -> retval, _p12\n",
      "        .\n",
      "    \n",
      "    invert(...)\n",
      "        invert(src[, dst[, flags]]) -> retval, dst\n",
      "        .   @brief Finds the inverse or pseudo-inverse of a matrix.\n",
      "        .   \n",
      "        .   The function cv::invert inverts the matrix src and stores the result in dst\n",
      "        .   . When the matrix src is singular or non-square, the function calculates\n",
      "        .   the pseudo-inverse matrix (the dst matrix) so that norm(src\\*dst - I) is\n",
      "        .   minimal, where I is an identity matrix.\n",
      "        .   \n",
      "        .   In case of the #DECOMP_LU method, the function returns non-zero value if\n",
      "        .   the inverse has been successfully calculated and 0 if src is singular.\n",
      "        .   \n",
      "        .   In case of the #DECOMP_SVD method, the function returns the inverse\n",
      "        .   condition number of src (the ratio of the smallest singular value to the\n",
      "        .   largest singular value) and 0 if src is singular. The SVD method\n",
      "        .   calculates a pseudo-inverse matrix if src is singular.\n",
      "        .   \n",
      "        .   Similarly to #DECOMP_LU, the method #DECOMP_CHOLESKY works only with\n",
      "        .   non-singular square matrices that should also be symmetrical and\n",
      "        .   positively defined. In this case, the function stores the inverted\n",
      "        .   matrix in dst and returns non-zero. Otherwise, it returns 0.\n",
      "        .   \n",
      "        .   @param src input floating-point M x N matrix.\n",
      "        .   @param dst output matrix of N x M size and the same type as src.\n",
      "        .   @param flags inversion method (cv::DecompTypes)\n",
      "        .   @sa solve, SVD\n",
      "    \n",
      "    invertAffineTransform(...)\n",
      "        invertAffineTransform(M[, iM]) -> iM\n",
      "        .   @brief Inverts an affine transformation.\n",
      "        .   \n",
      "        .   The function computes an inverse affine transformation represented by \\f$2 \\times 3\\f$ matrix M:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} a_{11} & a_{12} & b_1  \\\\ a_{21} & a_{22} & b_2 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   The result is also a \\f$2 \\times 3\\f$ matrix of the same type as M.\n",
      "        .   \n",
      "        .   @param M Original affine transformation.\n",
      "        .   @param iM Output reverse affine transformation.\n",
      "    \n",
      "    isContourConvex(...)\n",
      "        isContourConvex(contour) -> retval\n",
      "        .   @brief Tests a contour convexity.\n",
      "        .   \n",
      "        .   The function tests whether the input contour is convex or not. The contour must be simple, that is,\n",
      "        .   without self-intersections. Otherwise, the function output is undefined.\n",
      "        .   \n",
      "        .   @param contour Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    kmeans(...)\n",
      "        kmeans(data, K, bestLabels, criteria, attempts, flags[, centers]) -> retval, bestLabels, centers\n",
      "        .   @brief Finds centers of clusters and groups input samples around the clusters.\n",
      "        .   \n",
      "        .   The function kmeans implements a k-means algorithm that finds the centers of cluster_count clusters\n",
      "        .   and groups the input samples around the clusters. As an output, \\f$\\texttt{bestLabels}_i\\f$ contains a\n",
      "        .   0-based cluster index for the sample stored in the \\f$i^{th}\\f$ row of the samples matrix.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   (Python) An example on K-means clustering can be found at\n",
      "        .   opencv_source_code/samples/python/kmeans.py\n",
      "        .   @param data Data for clustering. An array of N-Dimensional points with float coordinates is needed.\n",
      "        .   Examples of this array can be:\n",
      "        .   -   Mat points(count, 2, CV_32F);\n",
      "        .   -   Mat points(count, 1, CV_32FC2);\n",
      "        .   -   Mat points(1, count, CV_32FC2);\n",
      "        .   -   std::vector\\<cv::Point2f\\> points(sampleCount);\n",
      "        .   @param K Number of clusters to split the set by.\n",
      "        .   @param bestLabels Input/output integer array that stores the cluster indices for every sample.\n",
      "        .   @param criteria The algorithm termination criteria, that is, the maximum number of iterations and/or\n",
      "        .   the desired accuracy. The accuracy is specified as criteria.epsilon. As soon as each of the cluster\n",
      "        .   centers moves by less than criteria.epsilon on some iteration, the algorithm stops.\n",
      "        .   @param attempts Flag to specify the number of times the algorithm is executed using different\n",
      "        .   initial labellings. The algorithm returns the labels that yield the best compactness (see the last\n",
      "        .   function parameter).\n",
      "        .   @param flags Flag that can take values of cv::KmeansFlags\n",
      "        .   @param centers Output matrix of the cluster centers, one row per each cluster center.\n",
      "        .   @return The function returns the compactness measure that is computed as\n",
      "        .   \\f[\\sum _i  \\| \\texttt{samples} _i -  \\texttt{centers} _{ \\texttt{labels} _i} \\| ^2\\f]\n",
      "        .   after every attempt. The best (minimum) value is chosen and the corresponding labels and the\n",
      "        .   compactness value are returned by the function. Basically, you can use only the core of the\n",
      "        .   function, set the number of attempts to 1, initialize labels each time using a custom algorithm,\n",
      "        .   pass them with the ( flags = #KMEANS_USE_INITIAL_LABELS ) flag, and then choose the best\n",
      "        .   (most-compact) clustering.\n",
      "    \n",
      "    line(...)\n",
      "        line(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a line segment connecting two points.\n",
      "        .   \n",
      "        .   The function line draws the line segment between pt1 and pt2 points in the image. The line is\n",
      "        .   clipped by the image boundaries. For non-antialiased lines with integer coordinates, the 8-connected\n",
      "        .   or 4-connected Bresenham algorithm is used. Thick lines are drawn with rounding endings. Antialiased\n",
      "        .   lines are drawn using Gaussian filtering.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 First point of the line segment.\n",
      "        .   @param pt2 Second point of the line segment.\n",
      "        .   @param color Line color.\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param lineType Type of the line. See #LineTypes.\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "    \n",
      "    linearPolar(...)\n",
      "        linearPolar(src, center, maxRadius, flags[, dst]) -> dst\n",
      "        .   @brief Remaps an image to polar coordinates space.\n",
      "        .   \n",
      "        .   @deprecated This function produces same result as cv::warpPolar(src, dst, src.size(), center, maxRadius, flags)\n",
      "        .   \n",
      "        .   @internal\n",
      "        .   Transform the source image using the following transformation (See @ref polar_remaps_reference_image \"Polar remaps reference image c)\"):\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dst( \\rho , \\phi ) = src(x,y) \\\\\n",
      "        .   dst.size() \\leftarrow src.size()\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   I = (dx,dy) = (x - center.x,y - center.y) \\\\\n",
      "        .   \\rho = Kmag \\cdot \\texttt{magnitude} (I) ,\\\\\n",
      "        .   \\phi = angle \\cdot \\texttt{angle} (I)\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   Kx = src.cols / maxRadius \\\\\n",
      "        .   Ky = src.rows / 2\\Pi\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   @param src Source image\n",
      "        .   @param dst Destination image. It will have same size and type as src.\n",
      "        .   @param center The transformation center;\n",
      "        .   @param maxRadius The radius of the bounding circle to transform. It determines the inverse magnitude scale parameter too.\n",
      "        .   @param flags A combination of interpolation methods, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function can not operate in-place.\n",
      "        .   -   To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   \n",
      "        .   @sa cv::logPolar\n",
      "        .   @endinternal\n",
      "    \n",
      "    log(...)\n",
      "        log(src[, dst]) -> dst\n",
      "        .   @brief Calculates the natural logarithm of every array element.\n",
      "        .   \n",
      "        .   The function cv::log calculates the natural logarithm of every element of the input array:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\log (\\texttt{src}(I)) \\f]\n",
      "        .   \n",
      "        .   Output on zero, negative and special (NaN, Inf) values is undefined.\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src .\n",
      "        .   @sa exp, cartToPolar, polarToCart, phase, pow, sqrt, magnitude\n",
      "    \n",
      "    logPolar(...)\n",
      "        logPolar(src, center, M, flags[, dst]) -> dst\n",
      "        .   @brief Remaps an image to semilog-polar coordinates space.\n",
      "        .   \n",
      "        .   @deprecated This function produces same result as cv::warpPolar(src, dst, src.size(), center, maxRadius, flags+WARP_POLAR_LOG);\n",
      "        .   \n",
      "        .   @internal\n",
      "        .   Transform the source image using the following transformation (See @ref polar_remaps_reference_image \"Polar remaps reference image d)\"):\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dst( \\rho , \\phi ) = src(x,y) \\\\\n",
      "        .   dst.size() \\leftarrow src.size()\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   I = (dx,dy) = (x - center.x,y - center.y) \\\\\n",
      "        .   \\rho = M \\cdot log_e(\\texttt{magnitude} (I)) ,\\\\\n",
      "        .   \\phi = Kangle \\cdot \\texttt{angle} (I) \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   M = src.cols / log_e(maxRadius) \\\\\n",
      "        .   Kangle = src.rows / 2\\Pi \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function emulates the human \"foveal\" vision and can be used for fast scale and\n",
      "        .   rotation-invariant template matching, for object tracking and so forth.\n",
      "        .   @param src Source image\n",
      "        .   @param dst Destination image. It will have same size and type as src.\n",
      "        .   @param center The transformation center; where the output precision is maximal\n",
      "        .   @param M Magnitude scale parameter. It determines the radius of the bounding circle to transform too.\n",
      "        .   @param flags A combination of interpolation methods, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function can not operate in-place.\n",
      "        .   -   To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   \n",
      "        .   @sa cv::linearPolar\n",
      "        .   @endinternal\n",
      "    \n",
      "    magnitude(...)\n",
      "        magnitude(x, y[, magnitude]) -> magnitude\n",
      "        .   @brief Calculates the magnitude of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::magnitude calculates the magnitude of 2D vectors formed\n",
      "        .   from the corresponding elements of x and y arrays:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\sqrt{\\texttt{x}(I)^2 + \\texttt{y}(I)^2}\\f]\n",
      "        .   @param x floating-point array of x-coordinates of the vectors.\n",
      "        .   @param y floating-point array of y-coordinates of the vectors; it must\n",
      "        .   have the same size as x.\n",
      "        .   @param magnitude output array of the same size and type as x.\n",
      "        .   @sa cartToPolar, polarToCart, phase, sqrt\n",
      "    \n",
      "    matMulDeriv(...)\n",
      "        matMulDeriv(A, B[, dABdA[, dABdB]]) -> dABdA, dABdB\n",
      "        .   @brief Computes partial derivatives of the matrix product for each multiplied matrix.\n",
      "        .   \n",
      "        .   @param A First multiplied matrix.\n",
      "        .   @param B Second multiplied matrix.\n",
      "        .   @param dABdA First output derivative matrix d(A\\*B)/dA of size\n",
      "        .   \\f$\\texttt{A.rows*B.cols} \\times {A.rows*A.cols}\\f$ .\n",
      "        .   @param dABdB Second output derivative matrix d(A\\*B)/dB of size\n",
      "        .   \\f$\\texttt{A.rows*B.cols} \\times {B.rows*B.cols}\\f$ .\n",
      "        .   \n",
      "        .   The function computes partial derivatives of the elements of the matrix product \\f$A*B\\f$ with regard to\n",
      "        .   the elements of each of the two input matrices. The function is used to compute the Jacobian\n",
      "        .   matrices in stereoCalibrate but can also be used in any other similar optimization function.\n",
      "    \n",
      "    matchShapes(...)\n",
      "        matchShapes(contour1, contour2, method, parameter) -> retval\n",
      "        .   @brief Compares two shapes.\n",
      "        .   \n",
      "        .   The function compares two shapes. All three implemented methods use the Hu invariants (see #HuMoments)\n",
      "        .   \n",
      "        .   @param contour1 First contour or grayscale image.\n",
      "        .   @param contour2 Second contour or grayscale image.\n",
      "        .   @param method Comparison method, see #ShapeMatchModes\n",
      "        .   @param parameter Method-specific parameter (not supported now).\n",
      "    \n",
      "    matchTemplate(...)\n",
      "        matchTemplate(image, templ, method[, result[, mask]]) -> result\n",
      "        .   @brief Compares a template against overlapped image regions.\n",
      "        .   \n",
      "        .   The function slides through image , compares the overlapped patches of size \\f$w \\times h\\f$ against\n",
      "        .   templ using the specified method and stores the comparison results in result . Here are the formulae\n",
      "        .   for the available comparison methods ( \\f$I\\f$ denotes image, \\f$T\\f$ template, \\f$R\\f$ result ). The summation\n",
      "        .   is done over template and/or the image patch: \\f$x' = 0...w-1, y' = 0...h-1\\f$\n",
      "        .   \n",
      "        .   After the function finishes the comparison, the best matches can be found as global minimums (when\n",
      "        .   #TM_SQDIFF was used) or maximums (when #TM_CCORR or #TM_CCOEFF was used) using the\n",
      "        .   #minMaxLoc function. In case of a color image, template summation in the numerator and each sum in\n",
      "        .   the denominator is done over all of the channels and separate mean values are used for each channel.\n",
      "        .   That is, the function can take a color template and a color image. The result will still be a\n",
      "        .   single-channel image, which is easier to analyze.\n",
      "        .   \n",
      "        .   @param image Image where the search is running. It must be 8-bit or 32-bit floating-point.\n",
      "        .   @param templ Searched template. It must be not greater than the source image and have the same\n",
      "        .   data type.\n",
      "        .   @param result Map of comparison results. It must be single-channel 32-bit floating-point. If image\n",
      "        .   is \\f$W \\times H\\f$ and templ is \\f$w \\times h\\f$ , then result is \\f$(W-w+1) \\times (H-h+1)\\f$ .\n",
      "        .   @param method Parameter specifying the comparison method, see #TemplateMatchModes\n",
      "        .   @param mask Mask of searched template. It must have the same datatype and size with templ. It is\n",
      "        .   not set by default. Currently, only the #TM_SQDIFF and #TM_CCORR_NORMED methods are supported.\n",
      "    \n",
      "    max(...)\n",
      "        max(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates per-element maximum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::max calculates the per-element maximum of two arrays:\n",
      "        .   \\f[\\texttt{dst} (I)= \\max ( \\texttt{src1} (I), \\texttt{src2} (I))\\f]\n",
      "        .   or array and a scalar:\n",
      "        .   \\f[\\texttt{dst} (I)= \\max ( \\texttt{src1} (I), \\texttt{value} )\\f]\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1 .\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa  min, compare, inRange, minMaxLoc, @ref MatrixExpressions\n",
      "    \n",
      "    mean(...)\n",
      "        mean(src[, mask]) -> retval\n",
      "        .   @brief Calculates an average (mean) of array elements.\n",
      "        .   \n",
      "        .   The function cv::mean calculates the mean value M of array elements,\n",
      "        .   independently for each channel, and return it:\n",
      "        .   \\f[\\begin{array}{l} N =  \\sum _{I: \\; \\texttt{mask} (I) \\ne 0} 1 \\\\ M_c =  \\left ( \\sum _{I: \\; \\texttt{mask} (I) \\ne 0}{ \\texttt{mtx} (I)_c} \\right )/N \\end{array}\\f]\n",
      "        .   When all the mask elements are 0's, the function returns Scalar::all(0)\n",
      "        .   @param src input array that should have from 1 to 4 channels so that the result can be stored in\n",
      "        .   Scalar_ .\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa  countNonZero, meanStdDev, norm, minMaxLoc\n",
      "    \n",
      "    meanShift(...)\n",
      "        meanShift(probImage, window, criteria) -> retval, window\n",
      "        .   @brief Finds an object on a back projection image.\n",
      "        .   \n",
      "        .   @param probImage Back projection of the object histogram. See calcBackProject for details.\n",
      "        .   @param window Initial search window.\n",
      "        .   @param criteria Stop criteria for the iterative search algorithm.\n",
      "        .   returns\n",
      "        .   :   Number of iterations CAMSHIFT took to converge.\n",
      "        .   The function implements the iterative object search algorithm. It takes the input back projection of\n",
      "        .   an object and the initial position. The mass center in window of the back projection image is\n",
      "        .   computed and the search window center shifts to the mass center. The procedure is repeated until the\n",
      "        .   specified number of iterations criteria.maxCount is done or until the window center shifts by less\n",
      "        .   than criteria.epsilon. The algorithm is used inside CamShift and, unlike CamShift , the search\n",
      "        .   window size or orientation do not change during the search. You can simply pass the output of\n",
      "        .   calcBackProject to this function. But better results can be obtained if you pre-filter the back\n",
      "        .   projection and remove the noise. For example, you can do this by retrieving connected components\n",
      "        .   with findContours , throwing away contours with small area ( contourArea ), and rendering the\n",
      "        .   remaining contours with drawContours.\n",
      "    \n",
      "    meanStdDev(...)\n",
      "        meanStdDev(src[, mean[, stddev[, mask]]]) -> mean, stddev\n",
      "        .   Calculates a mean and standard deviation of array elements.\n",
      "        .   \n",
      "        .   The function cv::meanStdDev calculates the mean and the standard deviation M\n",
      "        .   of array elements independently for each channel and returns it via the\n",
      "        .   output parameters:\n",
      "        .   \\f[\\begin{array}{l} N =  \\sum _{I, \\texttt{mask} (I)  \\ne 0} 1 \\\\ \\texttt{mean} _c =  \\frac{\\sum_{ I: \\; \\texttt{mask}(I) \\ne 0} \\texttt{src} (I)_c}{N} \\\\ \\texttt{stddev} _c =  \\sqrt{\\frac{\\sum_{ I: \\; \\texttt{mask}(I) \\ne 0} \\left ( \\texttt{src} (I)_c -  \\texttt{mean} _c \\right )^2}{N}} \\end{array}\\f]\n",
      "        .   When all the mask elements are 0's, the function returns\n",
      "        .   mean=stddev=Scalar::all(0).\n",
      "        .   @note The calculated standard deviation is only the diagonal of the\n",
      "        .   complete normalized covariance matrix. If the full matrix is needed, you\n",
      "        .   can reshape the multi-channel array M x N to the single-channel array\n",
      "        .   M\\*N x mtx.channels() (only possible when the matrix is continuous) and\n",
      "        .   then pass the matrix to calcCovarMatrix .\n",
      "        .   @param src input array that should have from 1 to 4 channels so that the results can be stored in\n",
      "        .   Scalar_ 's.\n",
      "        .   @param mean output parameter: calculated mean value.\n",
      "        .   @param stddev output parameter: calculated standard deviation.\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa  countNonZero, mean, norm, minMaxLoc, calcCovarMatrix\n",
      "    \n",
      "    medianBlur(...)\n",
      "        medianBlur(src, ksize[, dst]) -> dst\n",
      "        .   @brief Blurs an image using the median filter.\n",
      "        .   \n",
      "        .   The function smoothes an image using the median filter with the \\f$\\texttt{ksize} \\times\n",
      "        .   \\texttt{ksize}\\f$ aperture. Each channel of a multi-channel image is processed independently.\n",
      "        .   In-place operation is supported.\n",
      "        .   \n",
      "        .   @note The median filter uses #BORDER_REPLICATE internally to cope with border pixels, see #BorderTypes\n",
      "        .   \n",
      "        .   @param src input 1-, 3-, or 4-channel image; when ksize is 3 or 5, the image depth should be\n",
      "        .   CV_8U, CV_16U, or CV_32F, for larger aperture sizes, it can only be CV_8U.\n",
      "        .   @param dst destination array of the same size and type as src.\n",
      "        .   @param ksize aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ...\n",
      "        .   @sa  bilateralFilter, blur, boxFilter, GaussianBlur\n",
      "    \n",
      "    merge(...)\n",
      "        merge(mv[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .   @param mv input vector of matrices to be merged; all the matrices in mv must have the same\n",
      "        .   size and the same depth.\n",
      "        .   @param dst output array of the same size and the same depth as mv[0]; The number of channels will\n",
      "        .   be the total number of channels in the matrix array.\n",
      "    \n",
      "    min(...)\n",
      "        min(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates per-element minimum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::min calculates the per-element minimum of two arrays:\n",
      "        .   \\f[\\texttt{dst} (I)= \\min ( \\texttt{src1} (I), \\texttt{src2} (I))\\f]\n",
      "        .   or array and a scalar:\n",
      "        .   \\f[\\texttt{dst} (I)= \\min ( \\texttt{src1} (I), \\texttt{value} )\\f]\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa max, compare, inRange, minMaxLoc\n",
      "    \n",
      "    minAreaRect(...)\n",
      "        minAreaRect(points) -> retval\n",
      "        .   @brief Finds a rotated rectangle of the minimum area enclosing the input 2D point set.\n",
      "        .   \n",
      "        .   The function calculates and returns the minimum-area bounding rectangle (possibly rotated) for a\n",
      "        .   specified point set. Developer should keep in mind that the returned RotatedRect can contain negative\n",
      "        .   indices when data is close to the containing Mat element boundary.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    minEnclosingCircle(...)\n",
      "        minEnclosingCircle(points) -> center, radius\n",
      "        .   @brief Finds a circle of the minimum area enclosing a 2D point set.\n",
      "        .   \n",
      "        .   The function finds the minimal enclosing circle of a 2D point set using an iterative algorithm.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "        .   @param center Output center of the circle.\n",
      "        .   @param radius Output radius of the circle.\n",
      "    \n",
      "    minEnclosingTriangle(...)\n",
      "        minEnclosingTriangle(points[, triangle]) -> retval, triangle\n",
      "        .   @brief Finds a triangle of minimum area enclosing a 2D point set and returns its area.\n",
      "        .   \n",
      "        .   The function finds a triangle of minimum area enclosing the given set of 2D points and returns its\n",
      "        .   area. The output for a given 2D point set is shown in the image below. 2D points are depicted in\n",
      "        .   *red* and the enclosing triangle in *yellow*.\n",
      "        .   \n",
      "        .   ![Sample output of the minimum enclosing triangle function](pics/minenclosingtriangle.png)\n",
      "        .   \n",
      "        .   The implementation of the algorithm is based on O'Rourke's @cite ORourke86 and Klee and Laskowski's\n",
      "        .   @cite KleeLaskowski85 papers. O'Rourke provides a \\f$\\theta(n)\\f$ algorithm for finding the minimal\n",
      "        .   enclosing triangle of a 2D convex polygon with n vertices. Since the #minEnclosingTriangle function\n",
      "        .   takes a 2D point set as input an additional preprocessing step of computing the convex hull of the\n",
      "        .   2D point set is required. The complexity of the #convexHull function is \\f$O(n log(n))\\f$ which is higher\n",
      "        .   than \\f$\\theta(n)\\f$. Thus the overall complexity of the function is \\f$O(n log(n))\\f$.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points with depth CV_32S or CV_32F, stored in std::vector\\<\\> or Mat\n",
      "        .   @param triangle Output vector of three 2D points defining the vertices of the triangle. The depth\n",
      "        .   of the OutputArray must be CV_32F.\n",
      "    \n",
      "    minMaxLoc(...)\n",
      "        minMaxLoc(src[, mask]) -> minVal, maxVal, minLoc, maxLoc\n",
      "        .   @brief Finds the global minimum and maximum in an array.\n",
      "        .   \n",
      "        .   The function cv::minMaxLoc finds the minimum and maximum element values and their positions. The\n",
      "        .   extremums are searched across the whole array or, if mask is not an empty array, in the specified\n",
      "        .   array region.\n",
      "        .   \n",
      "        .   The function do not work with multi-channel arrays. If you need to find minimum or maximum\n",
      "        .   elements across all the channels, use Mat::reshape first to reinterpret the array as\n",
      "        .   single-channel. Or you may extract the particular channel using either extractImageCOI , or\n",
      "        .   mixChannels , or split .\n",
      "        .   @param src input single-channel array.\n",
      "        .   @param minVal pointer to the returned minimum value; NULL is used if not required.\n",
      "        .   @param maxVal pointer to the returned maximum value; NULL is used if not required.\n",
      "        .   @param minLoc pointer to the returned minimum location (in 2D case); NULL is used if not required.\n",
      "        .   @param maxLoc pointer to the returned maximum location (in 2D case); NULL is used if not required.\n",
      "        .   @param mask optional mask used to select a sub-array.\n",
      "        .   @sa max, min, compare, inRange, extractImageCOI, mixChannels, split, Mat::reshape\n",
      "    \n",
      "    mixChannels(...)\n",
      "        mixChannels(src, dst, fromTo) -> dst\n",
      "        .   @overload\n",
      "        .   @param src input array or vector of matrices; all of the matrices must have the same size and the\n",
      "        .   same depth.\n",
      "        .   @param dst output array or vector of matrices; all the matrices **must be allocated**; their size and\n",
      "        .   depth must be the same as in src[0].\n",
      "        .   @param fromTo array of index pairs specifying which channels are copied and where; fromTo[k\\*2] is\n",
      "        .   a 0-based index of the input channel in src, fromTo[k\\*2+1] is an index of the output channel in\n",
      "        .   dst; the continuous channel numbering is used: the first input image channels are indexed from 0 to\n",
      "        .   src[0].channels()-1, the second input image channels are indexed from src[0].channels() to\n",
      "        .   src[0].channels() + src[1].channels()-1, and so on, the same scheme is used for the output image\n",
      "        .   channels; as a special case, when fromTo[k\\*2] is negative, the corresponding output channel is\n",
      "        .   filled with zero .\n",
      "    \n",
      "    moments(...)\n",
      "        moments(array[, binaryImage]) -> retval\n",
      "        .   @brief Calculates all of the moments up to the third order of a polygon or rasterized shape.\n",
      "        .   \n",
      "        .   The function computes moments, up to the 3rd order, of a vector shape or a rasterized shape. The\n",
      "        .   results are returned in the structure cv::Moments.\n",
      "        .   \n",
      "        .   @param array Raster image (single-channel, 8-bit or floating-point 2D array) or an array (\n",
      "        .   \\f$1 \\times N\\f$ or \\f$N \\times 1\\f$ ) of 2D points (Point or Point2f ).\n",
      "        .   @param binaryImage If it is true, all non-zero image pixels are treated as 1's. The parameter is\n",
      "        .   used for images only.\n",
      "        .   @returns moments.\n",
      "        .   \n",
      "        .   @note Only applicable to contour moments calculations from Python bindings: Note that the numpy\n",
      "        .   type for the input array should be either np.int32 or np.float32.\n",
      "        .   \n",
      "        .   @sa  contourArea, arcLength\n",
      "    \n",
      "    morphologyEx(...)\n",
      "        morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Performs advanced morphological transformations.\n",
      "        .   \n",
      "        .   The function cv::morphologyEx can perform advanced morphological transformations using an erosion and dilation as\n",
      "        .   basic operations.\n",
      "        .   \n",
      "        .   Any of the operations can be done in-place. In case of multi-channel images, each channel is\n",
      "        .   processed independently.\n",
      "        .   \n",
      "        .   @param src Source image. The number of channels can be arbitrary. The depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst Destination image of the same size and type as source image.\n",
      "        .   @param op Type of a morphological operation, see #MorphTypes\n",
      "        .   @param kernel Structuring element. It can be created using #getStructuringElement.\n",
      "        .   @param anchor Anchor position with the kernel. Negative values mean that the anchor is at the\n",
      "        .   kernel center.\n",
      "        .   @param iterations Number of times erosion and dilation are applied.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes\n",
      "        .   @param borderValue Border value in case of a constant border. The default value has a special\n",
      "        .   meaning.\n",
      "        .   @sa  dilate, erode, getStructuringElement\n",
      "        .   @note The number of iterations is the number of times erosion or dilatation operation will be applied.\n",
      "        .   For instance, an opening operation (#MORPH_OPEN) with two iterations is equivalent to apply\n",
      "        .   successively: erode -> erode -> dilate -> dilate (and not erode -> dilate -> erode -> dilate).\n",
      "    \n",
      "    moveWindow(...)\n",
      "        moveWindow(winname, x, y) -> None\n",
      "        .   @brief Moves window to the specified position\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param x The new x-coordinate of the window.\n",
      "        .   @param y The new y-coordinate of the window.\n",
      "    \n",
      "    mulSpectrums(...)\n",
      "        mulSpectrums(a, b, flags[, c[, conjB]]) -> c\n",
      "        .   @brief Performs the per-element multiplication of two Fourier spectrums.\n",
      "        .   \n",
      "        .   The function cv::mulSpectrums performs the per-element multiplication of the two CCS-packed or complex\n",
      "        .   matrices that are results of a real or complex Fourier transform.\n",
      "        .   \n",
      "        .   The function, together with dft and idft , may be used to calculate convolution (pass conjB=false )\n",
      "        .   or correlation (pass conjB=true ) of two arrays rapidly. When the arrays are complex, they are\n",
      "        .   simply multiplied (per element) with an optional conjugation of the second-array elements. When the\n",
      "        .   arrays are real, they are assumed to be CCS-packed (see dft for details).\n",
      "        .   @param a first input array.\n",
      "        .   @param b second input array of the same size and type as src1 .\n",
      "        .   @param c output array of the same size and type as src1 .\n",
      "        .   @param flags operation flags; currently, the only supported flag is cv::DFT_ROWS, which indicates that\n",
      "        .   each row of src1 and src2 is an independent 1D Fourier spectrum. If you do not want to use this flag, then simply add a `0` as value.\n",
      "        .   @param conjB optional flag that conjugates the second input array before the multiplication (true)\n",
      "        .   or not (false).\n",
      "    \n",
      "    mulTransposed(...)\n",
      "        mulTransposed(src, aTa[, dst[, delta[, scale[, dtype]]]]) -> dst\n",
      "        .   @brief Calculates the product of a matrix and its transposition.\n",
      "        .   \n",
      "        .   The function cv::mulTransposed calculates the product of src and its\n",
      "        .   transposition:\n",
      "        .   \\f[\\texttt{dst} = \\texttt{scale} ( \\texttt{src} - \\texttt{delta} )^T ( \\texttt{src} - \\texttt{delta} )\\f]\n",
      "        .   if aTa=true , and\n",
      "        .   \\f[\\texttt{dst} = \\texttt{scale} ( \\texttt{src} - \\texttt{delta} ) ( \\texttt{src} - \\texttt{delta} )^T\\f]\n",
      "        .   otherwise. The function is used to calculate the covariance matrix. With\n",
      "        .   zero delta, it can be used as a faster substitute for general matrix\n",
      "        .   product A\\*B when B=A'\n",
      "        .   @param src input single-channel matrix. Note that unlike gemm, the\n",
      "        .   function can multiply not only floating-point matrices.\n",
      "        .   @param dst output square matrix.\n",
      "        .   @param aTa Flag specifying the multiplication ordering. See the\n",
      "        .   description below.\n",
      "        .   @param delta Optional delta matrix subtracted from src before the\n",
      "        .   multiplication. When the matrix is empty ( delta=noArray() ), it is\n",
      "        .   assumed to be zero, that is, nothing is subtracted. If it has the same\n",
      "        .   size as src , it is simply subtracted. Otherwise, it is \"repeated\" (see\n",
      "        .   repeat ) to cover the full src and then subtracted. Type of the delta\n",
      "        .   matrix, when it is not empty, must be the same as the type of created\n",
      "        .   output matrix. See the dtype parameter description below.\n",
      "        .   @param scale Optional scale factor for the matrix product.\n",
      "        .   @param dtype Optional type of the output matrix. When it is negative,\n",
      "        .   the output matrix will have the same type as src . Otherwise, it will be\n",
      "        .   type=CV_MAT_DEPTH(dtype) that should be either CV_32F or CV_64F .\n",
      "        .   @sa calcCovarMatrix, gemm, repeat, reduce\n",
      "    \n",
      "    multiply(...)\n",
      "        multiply(src1, src2[, dst[, scale[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element scaled product of two arrays.\n",
      "        .   \n",
      "        .   The function multiply calculates the per-element product of two arrays:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{scale} \\cdot \\texttt{src1} (I)  \\cdot \\texttt{src2} (I))\\f]\n",
      "        .   \n",
      "        .   There is also a @ref MatrixExpressions -friendly variant of the first function. See Mat::mul .\n",
      "        .   \n",
      "        .   For a not-per-element matrix product, see gemm .\n",
      "        .   \n",
      "        .   @note Saturation is not applied when the output array has the depth\n",
      "        .   CV_32S. You may even get result of an incorrect sign in the case of\n",
      "        .   overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and the same type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @param scale optional scale factor.\n",
      "        .   @param dtype optional depth of the output array\n",
      "        .   @sa add, subtract, divide, scaleAdd, addWeighted, accumulate, accumulateProduct, accumulateSquare,\n",
      "        .   Mat::convertTo\n",
      "    \n",
      "    namedWindow(...)\n",
      "        namedWindow(winname[, flags]) -> None\n",
      "        .   @brief Creates a window.\n",
      "        .   \n",
      "        .   The function namedWindow creates a window that can be used as a placeholder for images and\n",
      "        .   trackbars. Created windows are referred to by their names.\n",
      "        .   \n",
      "        .   If a window with the same name already exists, the function does nothing.\n",
      "        .   \n",
      "        .   You can call cv::destroyWindow or cv::destroyAllWindows to close the window and de-allocate any associated\n",
      "        .   memory usage. For a simple program, you do not really have to call these functions because all the\n",
      "        .   resources and windows of the application are closed automatically by the operating system upon exit.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   Qt backend supports additional flags:\n",
      "        .   -   **WINDOW_NORMAL or WINDOW_AUTOSIZE:** WINDOW_NORMAL enables you to resize the\n",
      "        .   window, whereas WINDOW_AUTOSIZE adjusts automatically the window size to fit the\n",
      "        .   displayed image (see imshow ), and you cannot change the window size manually.\n",
      "        .   -   **WINDOW_FREERATIO or WINDOW_KEEPRATIO:** WINDOW_FREERATIO adjusts the image\n",
      "        .   with no respect to its ratio, whereas WINDOW_KEEPRATIO keeps the image ratio.\n",
      "        .   -   **WINDOW_GUI_NORMAL or WINDOW_GUI_EXPANDED:** WINDOW_GUI_NORMAL is the old way to draw the window\n",
      "        .   without statusbar and toolbar, whereas WINDOW_GUI_EXPANDED is a new enhanced GUI.\n",
      "        .   By default, flags == WINDOW_AUTOSIZE | WINDOW_KEEPRATIO | WINDOW_GUI_EXPANDED\n",
      "        .   \n",
      "        .   @param winname Name of the window in the window caption that may be used as a window identifier.\n",
      "        .   @param flags Flags of the window. The supported flags are: (cv::WindowFlags)\n",
      "    \n",
      "    norm(...)\n",
      "        norm(src1[, normType[, mask]]) -> retval\n",
      "        .   @brief Calculates the  absolute norm of an array.\n",
      "        .   \n",
      "        .   This version of #norm calculates the absolute norm of src1. The type of norm to calculate is specified using #NormTypes.\n",
      "        .   \n",
      "        .   As example for one array consider the function \\f$r(x)= \\begin{pmatrix} x \\\\ 1-x \\end{pmatrix}, x \\in [-1;1]\\f$.\n",
      "        .   The \\f$ L_{1}, L_{2} \\f$ and \\f$ L_{\\infty} \\f$ norm for the sample value \\f$r(-1) = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\\f$\n",
      "        .   is calculated as follows\n",
      "        .   \\f{align*}\n",
      "        .   \\| r(-1) \\|_{L_1} &= |-1| + |2| = 3 \\\\\n",
      "        .   \\| r(-1) \\|_{L_2} &= \\sqrt{(-1)^{2} + (2)^{2}} = \\sqrt{5} \\\\\n",
      "        .   \\| r(-1) \\|_{L_\\infty} &= \\max(|-1|,|2|) = 2\n",
      "        .   \\f}\n",
      "        .   and for \\f$r(0.5) = \\begin{pmatrix} 0.5 \\\\ 0.5 \\end{pmatrix}\\f$ the calculation is\n",
      "        .   \\f{align*}\n",
      "        .   \\| r(0.5) \\|_{L_1} &= |0.5| + |0.5| = 1 \\\\\n",
      "        .   \\| r(0.5) \\|_{L_2} &= \\sqrt{(0.5)^{2} + (0.5)^{2}} = \\sqrt{0.5} \\\\\n",
      "        .   \\| r(0.5) \\|_{L_\\infty} &= \\max(|0.5|,|0.5|) = 0.5.\n",
      "        .   \\f}\n",
      "        .   The following graphic shows all values for the three norm functions \\f$\\| r(x) \\|_{L_1}, \\| r(x) \\|_{L_2}\\f$ and \\f$\\| r(x) \\|_{L_\\infty}\\f$.\n",
      "        .   It is notable that the \\f$ L_{1} \\f$ norm forms the upper and the \\f$ L_{\\infty} \\f$ norm forms the lower border for the example function \\f$ r(x) \\f$.\n",
      "        .   ![Graphs for the different norm functions from the above example](pics/NormTypes_OneArray_1-2-INF.png)\n",
      "        .   \n",
      "        .   When the mask parameter is specified and it is not empty, the norm is\n",
      "        .   \n",
      "        .   If normType is not specified, #NORM_L2 is used.\n",
      "        .   calculated only over the region specified by the mask.\n",
      "        .   \n",
      "        .   Multi-channel input arrays are treated as single-channel arrays, that is,\n",
      "        .   the results for all channels are combined.\n",
      "        .   \n",
      "        .   Hamming norms can only be calculated with CV_8U depth arrays.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param normType type of the norm (see #NormTypes).\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        \n",
      "        \n",
      "        \n",
      "        norm(src1, src2[, normType[, mask]]) -> retval\n",
      "        .   @brief Calculates an absolute difference norm or a relative difference norm.\n",
      "        .   \n",
      "        .   This version of cv::norm calculates the absolute difference norm\n",
      "        .   or the relative difference norm of arrays src1 and src2.\n",
      "        .   The type of norm to calculate is specified using #NormTypes.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and the same type as src1.\n",
      "        .   @param normType type of the norm (see #NormTypes).\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    normalize(...)\n",
      "        normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]) -> dst\n",
      "        .   @brief Normalizes the norm or value range of an array.\n",
      "        .   \n",
      "        .   The function cv::normalize normalizes scale and shift the input array elements so that\n",
      "        .   \\f[\\| \\texttt{dst} \\| _{L_p}= \\texttt{alpha}\\f]\n",
      "        .   (where p=Inf, 1 or 2) when normType=NORM_INF, NORM_L1, or NORM_L2, respectively; or so that\n",
      "        .   \\f[\\min _I  \\texttt{dst} (I)= \\texttt{alpha} , \\, \\, \\max _I  \\texttt{dst} (I)= \\texttt{beta}\\f]\n",
      "        .   \n",
      "        .   when normType=NORM_MINMAX (for dense arrays only). The optional mask specifies a sub-array to be\n",
      "        .   normalized. This means that the norm or min-n-max are calculated over the sub-array, and then this\n",
      "        .   sub-array is modified to be normalized. If you want to only use the mask to calculate the norm or\n",
      "        .   min-max but modify the whole array, you can use norm and Mat::convertTo.\n",
      "        .   \n",
      "        .   In case of sparse matrices, only the non-zero values are analyzed and transformed. Because of this,\n",
      "        .   the range transformation for sparse matrices is not allowed since it can shift the zero level.\n",
      "        .   \n",
      "        .   Possible usage with some positive example data:\n",
      "        .   @code{.cpp}\n",
      "        .   vector<double> positiveData = { 2.0, 8.0, 10.0 };\n",
      "        .   vector<double> normalizedData_l1, normalizedData_l2, normalizedData_inf, normalizedData_minmax;\n",
      "        .   \n",
      "        .   // Norm to probability (total count)\n",
      "        .   // sum(numbers) = 20.0\n",
      "        .   // 2.0      0.1     (2.0/20.0)\n",
      "        .   // 8.0      0.4     (8.0/20.0)\n",
      "        .   // 10.0     0.5     (10.0/20.0)\n",
      "        .   normalize(positiveData, normalizedData_l1, 1.0, 0.0, NORM_L1);\n",
      "        .   \n",
      "        .   // Norm to unit vector: ||positiveData|| = 1.0\n",
      "        .   // 2.0      0.15\n",
      "        .   // 8.0      0.62\n",
      "        .   // 10.0     0.77\n",
      "        .   normalize(positiveData, normalizedData_l2, 1.0, 0.0, NORM_L2);\n",
      "        .   \n",
      "        .   // Norm to max element\n",
      "        .   // 2.0      0.2     (2.0/10.0)\n",
      "        .   // 8.0      0.8     (8.0/10.0)\n",
      "        .   // 10.0     1.0     (10.0/10.0)\n",
      "        .   normalize(positiveData, normalizedData_inf, 1.0, 0.0, NORM_INF);\n",
      "        .   \n",
      "        .   // Norm to range [0.0;1.0]\n",
      "        .   // 2.0      0.0     (shift to left border)\n",
      "        .   // 8.0      0.75    (6.0/8.0)\n",
      "        .   // 10.0     1.0     (shift to right border)\n",
      "        .   normalize(positiveData, normalizedData_minmax, 1.0, 0.0, NORM_MINMAX);\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size as src .\n",
      "        .   @param alpha norm value to normalize to or the lower range boundary in case of the range\n",
      "        .   normalization.\n",
      "        .   @param beta upper range boundary in case of the range normalization; it is not used for the norm\n",
      "        .   normalization.\n",
      "        .   @param norm_type normalization type (see cv::NormTypes).\n",
      "        .   @param dtype when negative, the output array has the same type as src; otherwise, it has the same\n",
      "        .   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa norm, Mat::convertTo, SparseMat::convertTo\n",
      "    \n",
      "    patchNaNs(...)\n",
      "        patchNaNs(a[, val]) -> a\n",
      "        .   @brief converts NaN's to the given number\n",
      "    \n",
      "    pencilSketch(...)\n",
      "        pencilSketch(src[, dst1[, dst2[, sigma_s[, sigma_r[, shade_factor]]]]]) -> dst1, dst2\n",
      "        .   @brief Pencil-like non-photorealistic line drawing\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst1 Output 8-bit 1-channel image.\n",
      "        .   @param dst2 Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "        .   @param shade_factor %Range between 0 to 0.1.\n",
      "    \n",
      "    perspectiveTransform(...)\n",
      "        perspectiveTransform(src, m[, dst]) -> dst\n",
      "        .   @brief Performs the perspective matrix transformation of vectors.\n",
      "        .   \n",
      "        .   The function cv::perspectiveTransform transforms every element of src by\n",
      "        .   treating it as a 2D or 3D vector, in the following way:\n",
      "        .   \\f[(x, y, z)  \\rightarrow (x'/w, y'/w, z'/w)\\f]\n",
      "        .   where\n",
      "        .   \\f[(x', y', z', w') =  \\texttt{mat} \\cdot \\begin{bmatrix} x & y & z & 1  \\end{bmatrix}\\f]\n",
      "        .   and\n",
      "        .   \\f[w =  \\fork{w'}{if \\(w' \\ne 0\\)}{\\infty}{otherwise}\\f]\n",
      "        .   \n",
      "        .   Here a 3D vector transformation is shown. In case of a 2D vector\n",
      "        .   transformation, the z component is omitted.\n",
      "        .   \n",
      "        .   @note The function transforms a sparse set of 2D or 3D vectors. If you\n",
      "        .   want to transform an image using perspective transformation, use\n",
      "        .   warpPerspective . If you have an inverse problem, that is, you want to\n",
      "        .   compute the most probable perspective transformation out of several\n",
      "        .   pairs of corresponding points, you can use getPerspectiveTransform or\n",
      "        .   findHomography .\n",
      "        .   @param src input two-channel or three-channel floating-point array; each\n",
      "        .   element is a 2D/3D vector to be transformed.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param m 3x3 or 4x4 floating-point transformation matrix.\n",
      "        .   @sa  transform, warpPerspective, getPerspectiveTransform, findHomography\n",
      "    \n",
      "    phase(...)\n",
      "        phase(x, y[, angle[, angleInDegrees]]) -> angle\n",
      "        .   @brief Calculates the rotation angle of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::phase calculates the rotation angle of each 2D vector that\n",
      "        .   is formed from the corresponding elements of x and y :\n",
      "        .   \\f[\\texttt{angle} (I) =  \\texttt{atan2} ( \\texttt{y} (I), \\texttt{x} (I))\\f]\n",
      "        .   \n",
      "        .   The angle estimation accuracy is about 0.3 degrees. When x(I)=y(I)=0 ,\n",
      "        .   the corresponding angle(I) is set to 0.\n",
      "        .   @param x input floating-point array of x-coordinates of 2D vectors.\n",
      "        .   @param y input array of y-coordinates of 2D vectors; it must have the\n",
      "        .   same size and the same type as x.\n",
      "        .   @param angle output array of vector angles; it has the same size and\n",
      "        .   same type as x .\n",
      "        .   @param angleInDegrees when true, the function calculates the angle in\n",
      "        .   degrees, otherwise, they are measured in radians.\n",
      "    \n",
      "    phaseCorrelate(...)\n",
      "        phaseCorrelate(src1, src2[, window]) -> retval, response\n",
      "        .   @brief The function is used to detect translational shifts that occur between two images.\n",
      "        .   \n",
      "        .   The operation takes advantage of the Fourier shift theorem for detecting the translational shift in\n",
      "        .   the frequency domain. It can be used for fast image registration as well as motion estimation. For\n",
      "        .   more information please see <http://en.wikipedia.org/wiki/Phase_correlation>\n",
      "        .   \n",
      "        .   Calculates the cross-power spectrum of two supplied source arrays. The arrays are padded if needed\n",
      "        .   with getOptimalDFTSize.\n",
      "        .   \n",
      "        .   The function performs the following equations:\n",
      "        .   - First it applies a Hanning window (see <http://en.wikipedia.org/wiki/Hann_function>) to each\n",
      "        .   image to remove possible edge effects. This window is cached until the array size changes to speed\n",
      "        .   up processing time.\n",
      "        .   - Next it computes the forward DFTs of each source array:\n",
      "        .   \\f[\\mathbf{G}_a = \\mathcal{F}\\{src_1\\}, \\; \\mathbf{G}_b = \\mathcal{F}\\{src_2\\}\\f]\n",
      "        .   where \\f$\\mathcal{F}\\f$ is the forward DFT.\n",
      "        .   - It then computes the cross-power spectrum of each frequency domain array:\n",
      "        .   \\f[R = \\frac{ \\mathbf{G}_a \\mathbf{G}_b^*}{|\\mathbf{G}_a \\mathbf{G}_b^*|}\\f]\n",
      "        .   - Next the cross-correlation is converted back into the time domain via the inverse DFT:\n",
      "        .   \\f[r = \\mathcal{F}^{-1}\\{R\\}\\f]\n",
      "        .   - Finally, it computes the peak location and computes a 5x5 weighted centroid around the peak to\n",
      "        .   achieve sub-pixel accuracy.\n",
      "        .   \\f[(\\Delta x, \\Delta y) = \\texttt{weightedCentroid} \\{\\arg \\max_{(x, y)}\\{r\\}\\}\\f]\n",
      "        .   - If non-zero, the response parameter is computed as the sum of the elements of r within the 5x5\n",
      "        .   centroid around the peak location. It is normalized to a maximum of 1 (meaning there is a single\n",
      "        .   peak) and will be smaller when there are multiple peaks.\n",
      "        .   \n",
      "        .   @param src1 Source floating point array (CV_32FC1 or CV_64FC1)\n",
      "        .   @param src2 Source floating point array (CV_32FC1 or CV_64FC1)\n",
      "        .   @param window Floating point array with windowing coefficients to reduce edge effects (optional).\n",
      "        .   @param response Signal power within the 5x5 centroid around the peak, between 0 and 1 (optional).\n",
      "        .   @returns detected phase shift (sub-pixel) between the two arrays.\n",
      "        .   \n",
      "        .   @sa dft, getOptimalDFTSize, idft, mulSpectrums createHanningWindow\n",
      "    \n",
      "    pointPolygonTest(...)\n",
      "        pointPolygonTest(contour, pt, measureDist) -> retval\n",
      "        .   @brief Performs a point-in-contour test.\n",
      "        .   \n",
      "        .   The function determines whether the point is inside a contour, outside, or lies on an edge (or\n",
      "        .   coincides with a vertex). It returns positive (inside), negative (outside), or zero (on an edge)\n",
      "        .   value, correspondingly. When measureDist=false , the return value is +1, -1, and 0, respectively.\n",
      "        .   Otherwise, the return value is a signed distance between the point and the nearest contour edge.\n",
      "        .   \n",
      "        .   See below a sample output of the function where each image pixel is tested against the contour:\n",
      "        .   \n",
      "        .   ![sample output](pics/pointpolygon.png)\n",
      "        .   \n",
      "        .   @param contour Input contour.\n",
      "        .   @param pt Point tested against the contour.\n",
      "        .   @param measureDist If true, the function estimates the signed distance from the point to the\n",
      "        .   nearest contour edge. Otherwise, the function only checks if the point is inside a contour or not.\n",
      "    \n",
      "    polarToCart(...)\n",
      "        polarToCart(magnitude, angle[, x[, y[, angleInDegrees]]]) -> x, y\n",
      "        .   @brief Calculates x and y coordinates of 2D vectors from their magnitude and angle.\n",
      "        .   \n",
      "        .   The function cv::polarToCart calculates the Cartesian coordinates of each 2D\n",
      "        .   vector represented by the corresponding elements of magnitude and angle:\n",
      "        .   \\f[\\begin{array}{l} \\texttt{x} (I) =  \\texttt{magnitude} (I) \\cos ( \\texttt{angle} (I)) \\\\ \\texttt{y} (I) =  \\texttt{magnitude} (I) \\sin ( \\texttt{angle} (I)) \\\\ \\end{array}\\f]\n",
      "        .   \n",
      "        .   The relative accuracy of the estimated coordinates is about 1e-6.\n",
      "        .   @param magnitude input floating-point array of magnitudes of 2D vectors;\n",
      "        .   it can be an empty matrix (=Mat()), in this case, the function assumes\n",
      "        .   that all the magnitudes are =1; if it is not empty, it must have the\n",
      "        .   same size and type as angle.\n",
      "        .   @param angle input floating-point array of angles of 2D vectors.\n",
      "        .   @param x output array of x-coordinates of 2D vectors; it has the same\n",
      "        .   size and type as angle.\n",
      "        .   @param y output array of y-coordinates of 2D vectors; it has the same\n",
      "        .   size and type as angle.\n",
      "        .   @param angleInDegrees when true, the input angles are measured in\n",
      "        .   degrees, otherwise, they are measured in radians.\n",
      "        .   @sa cartToPolar, magnitude, phase, exp, log, pow, sqrt\n",
      "    \n",
      "    polylines(...)\n",
      "        polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws several polygonal curves.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pts Array of polygonal curves.\n",
      "        .   @param isClosed Flag indicating whether the drawn polylines are closed or not. If they are closed,\n",
      "        .   the function draws a line from the last vertex of each curve to its first vertex.\n",
      "        .   @param color Polyline color.\n",
      "        .   @param thickness Thickness of the polyline edges.\n",
      "        .   @param lineType Type of the line segments. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "        .   \n",
      "        .   The function cv::polylines draws one or more polygonal curves.\n",
      "    \n",
      "    pow(...)\n",
      "        pow(src, power[, dst]) -> dst\n",
      "        .   @brief Raises every array element to a power.\n",
      "        .   \n",
      "        .   The function cv::pow raises every element of the input array to power :\n",
      "        .   \\f[\\texttt{dst} (I) =  \\fork{\\texttt{src}(I)^{power}}{if \\(\\texttt{power}\\) is integer}{|\\texttt{src}(I)|^{power}}{otherwise}\\f]\n",
      "        .   \n",
      "        .   So, for a non-integer power exponent, the absolute values of input array\n",
      "        .   elements are used. However, it is possible to get true values for\n",
      "        .   negative values using some extra operations. In the example below,\n",
      "        .   computing the 5th root of array src shows:\n",
      "        .   @code{.cpp}\n",
      "        .   Mat mask = src < 0;\n",
      "        .   pow(src, 1./5, dst);\n",
      "        .   subtract(Scalar::all(0), dst, dst, mask);\n",
      "        .   @endcode\n",
      "        .   For some values of power, such as integer values, 0.5 and -0.5,\n",
      "        .   specialized faster algorithms are used.\n",
      "        .   \n",
      "        .   Special values (NaN, Inf) are not handled.\n",
      "        .   @param src input array.\n",
      "        .   @param power exponent of power.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @sa sqrt, exp, log, cartToPolar, polarToCart\n",
      "    \n",
      "    preCornerDetect(...)\n",
      "        preCornerDetect(src, ksize[, dst[, borderType]]) -> dst\n",
      "        .   @brief Calculates a feature map for corner detection.\n",
      "        .   \n",
      "        .   The function calculates the complex spatial derivative-based function of the source image\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} = (D_x  \\texttt{src} )^2  \\cdot D_{yy}  \\texttt{src} + (D_y  \\texttt{src} )^2  \\cdot D_{xx}  \\texttt{src} - 2 D_x  \\texttt{src} \\cdot D_y  \\texttt{src} \\cdot D_{xy}  \\texttt{src}\\f]\n",
      "        .   \n",
      "        .   where \\f$D_x\\f$,\\f$D_y\\f$ are the first image derivatives, \\f$D_{xx}\\f$,\\f$D_{yy}\\f$ are the second image\n",
      "        .   derivatives, and \\f$D_{xy}\\f$ is the mixed derivative.\n",
      "        .   \n",
      "        .   The corners can be found as local maximums of the functions, as shown below:\n",
      "        .   @code\n",
      "        .   Mat corners, dilated_corners;\n",
      "        .   preCornerDetect(image, corners, 3);\n",
      "        .   // dilation with 3x3 rectangular structuring element\n",
      "        .   dilate(corners, dilated_corners, Mat(), 1);\n",
      "        .   Mat corner_mask = corners == dilated_corners;\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src Source single-channel 8-bit of floating-point image.\n",
      "        .   @param dst Output image that has the type CV_32F and the same size as src .\n",
      "        .   @param ksize %Aperture size of the Sobel .\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes.\n",
      "    \n",
      "    projectPoints(...)\n",
      "        projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs[, imagePoints[, jacobian[, aspectRatio]]]) -> imagePoints, jacobian\n",
      "        .   @brief Projects 3D points to an image plane.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points, 3xN/Nx3 1-channel or 1xN/Nx1 3-channel (or\n",
      "        .   vector\\<Point3f\\> ), where N is the number of points in the view.\n",
      "        .   @param rvec Rotation vector. See Rodrigues for details.\n",
      "        .   @param tvec Translation vector.\n",
      "        .   @param cameraMatrix Camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is empty, the zero distortion coefficients are assumed.\n",
      "        .   @param imagePoints Output array of image points, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel, or\n",
      "        .   vector\\<Point2f\\> .\n",
      "        .   @param jacobian Optional output 2Nx(10+\\<numDistCoeffs\\>) jacobian matrix of derivatives of image\n",
      "        .   points with respect to components of the rotation vector, translation vector, focal lengths,\n",
      "        .   coordinates of the principal point and the distortion coefficients. In the old interface different\n",
      "        .   components of the jacobian are returned via different output parameters.\n",
      "        .   @param aspectRatio Optional \"fixed aspect ratio\" parameter. If the parameter is not 0, the\n",
      "        .   function assumes that the aspect ratio (*fx/fy*) is fixed and correspondingly adjusts the jacobian\n",
      "        .   matrix.\n",
      "        .   \n",
      "        .   The function computes projections of 3D points to the image plane given intrinsic and extrinsic\n",
      "        .   camera parameters. Optionally, the function computes Jacobians - matrices of partial derivatives of\n",
      "        .   image points coordinates (as functions of all the input parameters) with respect to the particular\n",
      "        .   parameters, intrinsic and/or extrinsic. The Jacobians are used during the global optimization in\n",
      "        .   calibrateCamera, solvePnP, and stereoCalibrate . The function itself can also be used to compute a\n",
      "        .   re-projection error given the current intrinsic and extrinsic parameters.\n",
      "        .   \n",
      "        .   @note By setting rvec=tvec=(0,0,0) or by setting cameraMatrix to a 3x3 identity matrix, or by\n",
      "        .   passing zero distortion coefficients, you can get various useful partial cases of the function. This\n",
      "        .   means that you can compute the distorted coordinates for a sparse set of points or apply a\n",
      "        .   perspective transformation (and also compute the derivatives) in the ideal zero-distortion setup.\n",
      "    \n",
      "    putText(...)\n",
      "        putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) -> img\n",
      "        .   @brief Draws a text string.\n",
      "        .   \n",
      "        .   The function cv::putText renders the specified text string in the image. Symbols that cannot be rendered\n",
      "        .   using the specified font are replaced by question marks. See #getTextSize for a text rendering code\n",
      "        .   example.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param text Text string to be drawn.\n",
      "        .   @param org Bottom-left corner of the text string in the image.\n",
      "        .   @param fontFace Font type, see #HersheyFonts.\n",
      "        .   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
      "        .   @param color Text color.\n",
      "        .   @param thickness Thickness of the lines used to draw a text.\n",
      "        .   @param lineType Line type. See #LineTypes\n",
      "        .   @param bottomLeftOrigin When true, the image data origin is at the bottom-left corner. Otherwise,\n",
      "        .   it is at the top-left corner.\n",
      "    \n",
      "    pyrDown(...)\n",
      "        pyrDown(src[, dst[, dstsize[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image and downsamples it.\n",
      "        .   \n",
      "        .   By default, size of the output image is computed as `Size((src.cols+1)/2, (src.rows+1)/2)`, but in\n",
      "        .   any case, the following conditions should be satisfied:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} | \\texttt{dstsize.width} *2-src.cols| \\leq 2 \\\\ | \\texttt{dstsize.height} *2-src.rows| \\leq 2 \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function performs the downsampling step of the Gaussian pyramid construction. First, it\n",
      "        .   convolves the source image with the kernel:\n",
      "        .   \n",
      "        .   \\f[\\frac{1}{256} \\begin{bmatrix} 1 & 4 & 6 & 4 & 1  \\\\ 4 & 16 & 24 & 16 & 4  \\\\ 6 & 24 & 36 & 24 & 6  \\\\ 4 & 16 & 24 & 16 & 4  \\\\ 1 & 4 & 6 & 4 & 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   Then, it downsamples the image by rejecting even rows and columns.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image; it has the specified size and the same type as src.\n",
      "        .   @param dstsize size of the output image.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes (#BORDER_CONSTANT isn't supported)\n",
      "    \n",
      "    pyrMeanShiftFiltering(...)\n",
      "        pyrMeanShiftFiltering(src, sp, sr[, dst[, maxLevel[, termcrit]]]) -> dst\n",
      "        .   @brief Performs initial step of meanshift segmentation of an image.\n",
      "        .   \n",
      "        .   The function implements the filtering stage of meanshift segmentation, that is, the output of the\n",
      "        .   function is the filtered \"posterized\" image with color gradients and fine-grain texture flattened.\n",
      "        .   At every pixel (X,Y) of the input image (or down-sized input image, see below) the function executes\n",
      "        .   meanshift iterations, that is, the pixel (X,Y) neighborhood in the joint space-color hyperspace is\n",
      "        .   considered:\n",
      "        .   \n",
      "        .   \\f[(x,y): X- \\texttt{sp} \\le x  \\le X+ \\texttt{sp} , Y- \\texttt{sp} \\le y  \\le Y+ \\texttt{sp} , ||(R,G,B)-(r,g,b)||   \\le \\texttt{sr}\\f]\n",
      "        .   \n",
      "        .   where (R,G,B) and (r,g,b) are the vectors of color components at (X,Y) and (x,y), respectively\n",
      "        .   (though, the algorithm does not depend on the color space used, so any 3-component color space can\n",
      "        .   be used instead). Over the neighborhood the average spatial value (X',Y') and average color vector\n",
      "        .   (R',G',B') are found and they act as the neighborhood center on the next iteration:\n",
      "        .   \n",
      "        .   \\f[(X,Y)~(X',Y'), (R,G,B)~(R',G',B').\\f]\n",
      "        .   \n",
      "        .   After the iterations over, the color components of the initial pixel (that is, the pixel from where\n",
      "        .   the iterations started) are set to the final value (average color at the last iteration):\n",
      "        .   \n",
      "        .   \\f[I(X,Y) <- (R*,G*,B*)\\f]\n",
      "        .   \n",
      "        .   When maxLevel \\> 0, the gaussian pyramid of maxLevel+1 levels is built, and the above procedure is\n",
      "        .   run on the smallest layer first. After that, the results are propagated to the larger layer and the\n",
      "        .   iterations are run again only on those pixels where the layer colors differ by more than sr from the\n",
      "        .   lower-resolution layer of the pyramid. That makes boundaries of color regions sharper. Note that the\n",
      "        .   results will be actually different from the ones obtained by running the meanshift procedure on the\n",
      "        .   whole original image (i.e. when maxLevel==0).\n",
      "        .   \n",
      "        .   @param src The source 8-bit, 3-channel image.\n",
      "        .   @param dst The destination image of the same format and the same size as the source.\n",
      "        .   @param sp The spatial window radius.\n",
      "        .   @param sr The color window radius.\n",
      "        .   @param maxLevel Maximum level of the pyramid for the segmentation.\n",
      "        .   @param termcrit Termination criteria: when to stop meanshift iterations.\n",
      "    \n",
      "    pyrUp(...)\n",
      "        pyrUp(src[, dst[, dstsize[, borderType]]]) -> dst\n",
      "        .   @brief Upsamples an image and then blurs it.\n",
      "        .   \n",
      "        .   By default, size of the output image is computed as `Size(src.cols\\*2, (src.rows\\*2)`, but in any\n",
      "        .   case, the following conditions should be satisfied:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} | \\texttt{dstsize.width} -src.cols*2| \\leq  ( \\texttt{dstsize.width}   \\mod  2)  \\\\ | \\texttt{dstsize.height} -src.rows*2| \\leq  ( \\texttt{dstsize.height}   \\mod  2) \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function performs the upsampling step of the Gaussian pyramid construction, though it can\n",
      "        .   actually be used to construct the Laplacian pyramid. First, it upsamples the source image by\n",
      "        .   injecting even zero rows and columns and then convolves the result with the same kernel as in\n",
      "        .   pyrDown multiplied by 4.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image. It has the specified size and the same type as src .\n",
      "        .   @param dstsize size of the output image.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes (only #BORDER_DEFAULT is supported)\n",
      "    \n",
      "    randShuffle(...)\n",
      "        randShuffle(dst[, iterFactor]) -> dst\n",
      "        .   @brief Shuffles the array elements randomly.\n",
      "        .   \n",
      "        .   The function cv::randShuffle shuffles the specified 1D array by randomly choosing pairs of elements and\n",
      "        .   swapping them. The number of such swap operations will be dst.rows\\*dst.cols\\*iterFactor .\n",
      "        .   @param dst input/output numerical 1D array.\n",
      "        .   @param iterFactor scale factor that determines the number of random swap operations (see the details\n",
      "        .   below).\n",
      "        .   @param rng optional random number generator used for shuffling; if it is zero, theRNG () is used\n",
      "        .   instead.\n",
      "        .   @sa RNG, sort\n",
      "    \n",
      "    randn(...)\n",
      "        randn(dst, mean, stddev) -> dst\n",
      "        .   @brief Fills the array with normally distributed random numbers.\n",
      "        .   \n",
      "        .   The function cv::randn fills the matrix dst with normally distributed random numbers with the specified\n",
      "        .   mean vector and the standard deviation matrix. The generated random numbers are clipped to fit the\n",
      "        .   value range of the output array data type.\n",
      "        .   @param dst output array of random numbers; the array must be pre-allocated and have 1 to 4 channels.\n",
      "        .   @param mean mean value (expectation) of the generated random numbers.\n",
      "        .   @param stddev standard deviation of the generated random numbers; it can be either a vector (in\n",
      "        .   which case a diagonal standard deviation matrix is assumed) or a square matrix.\n",
      "        .   @sa RNG, randu\n",
      "    \n",
      "    randu(...)\n",
      "        randu(dst, low, high) -> dst\n",
      "        .   @brief Generates a single uniformly-distributed random number or an array of random numbers.\n",
      "        .   \n",
      "        .   Non-template variant of the function fills the matrix dst with uniformly-distributed\n",
      "        .   random numbers from the specified range:\n",
      "        .   \\f[\\texttt{low} _c  \\leq \\texttt{dst} (I)_c <  \\texttt{high} _c\\f]\n",
      "        .   @param dst output array of random numbers; the array must be pre-allocated.\n",
      "        .   @param low inclusive lower boundary of the generated random numbers.\n",
      "        .   @param high exclusive upper boundary of the generated random numbers.\n",
      "        .   @sa RNG, randn, theRNG\n",
      "    \n",
      "    readOpticalFlow(...)\n",
      "        readOpticalFlow(path) -> retval\n",
      "        .   @brief Read a .flo file\n",
      "        .   \n",
      "        .   @param path Path to the file to be loaded\n",
      "        .   \n",
      "        .   The function readOpticalFlow loads a flow field from a file and returns it as a single matrix.\n",
      "        .   Resulting Mat has a type CV_32FC2 - floating-point, 2-channel. First channel corresponds to the\n",
      "        .   flow in the horizontal direction (u), second - vertical (v).\n",
      "    \n",
      "    recoverPose(...)\n",
      "        recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, mask\n",
      "        .   @brief Recover relative camera rotation and translation from an estimated essential matrix and the\n",
      "        .   corresponding points in two images, using cheirality check. Returns the number of inliers which pass\n",
      "        .   the check.\n",
      "        .   \n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param cameraMatrix Camera matrix \\f$K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix.\n",
      "        .   @param R Recovered relative rotation.\n",
      "        .   @param t Recovered relative translation.\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2.\n",
      "        .   :   If it is not empty, then it marks inliers in points1 and points2 for then given essential\n",
      "        .   matrix E. Only these inliers will be used to recover pose. In the output mask only inliers\n",
      "        .   which pass the cheirality check.\n",
      "        .   This function decomposes an essential matrix using decomposeEssentialMat and then verifies possible\n",
      "        .   pose hypotheses by doing cheirality check. The cheirality check basically means that the\n",
      "        .   triangulated 3D points should have positive depth. Some details can be found in @cite Nister03 .\n",
      "        .   \n",
      "        .   This function can be used to process output E and mask from findEssentialMat. In this scenario,\n",
      "        .   points1 and points2 are the same input for findEssentialMat. :\n",
      "        .   @code\n",
      "        .   // Example. Estimation of fundamental matrix using the RANSAC algorithm\n",
      "        .   int point_count = 100;\n",
      "        .   vector<Point2f> points1(point_count);\n",
      "        .   vector<Point2f> points2(point_count);\n",
      "        .   \n",
      "        .   // initialize the points here ...\n",
      "        .   for( int i = 0; i < point_count; i++ )\n",
      "        .   {\n",
      "        .   points1[i] = ...;\n",
      "        .   points2[i] = ...;\n",
      "        .   }\n",
      "        .   \n",
      "        .   // cametra matrix with both focal lengths = 1, and principal point = (0, 0)\n",
      "        .   Mat cameraMatrix = Mat::eye(3, 3, CV_64F);\n",
      "        .   \n",
      "        .   Mat E, R, t, mask;\n",
      "        .   \n",
      "        .   E = findEssentialMat(points1, points2, cameraMatrix, RANSAC, 0.999, 1.0, mask);\n",
      "        .   recoverPose(E, points1, points2, cameraMatrix, R, t, mask);\n",
      "        .   @endcode\n",
      "        \n",
      "        \n",
      "        \n",
      "        recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, mask\n",
      "        .   @overload\n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param R Recovered relative rotation.\n",
      "        .   @param t Recovered relative translation.\n",
      "        .   @param focal Focal length of the camera. Note that this function assumes that points1 and points2\n",
      "        .   are feature points from cameras with same focal length and principal point.\n",
      "        .   @param pp principal point of the camera.\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2.\n",
      "        .   :   If it is not empty, then it marks inliers in points1 and points2 for then given essential\n",
      "        .   matrix E. Only these inliers will be used to recover pose. In the output mask only inliers\n",
      "        .   which pass the cheirality check.\n",
      "        .   \n",
      "        .   This function differs from the one above that it computes camera matrix from focal length and\n",
      "        .   principal point:\n",
      "        .   \n",
      "        .   \\f[K =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   f & 0 & x_{pp}  \\\\\n",
      "        .   0 & f & y_{pp}  \\\\\n",
      "        .   0 & 0 & 1\n",
      "        .   \\end{bmatrix}\\f]\n",
      "        \n",
      "        \n",
      "        \n",
      "        recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n",
      "        .   @overload\n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1.\n",
      "        .   @param cameraMatrix Camera matrix \\f$K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix.\n",
      "        .   @param R Recovered relative rotation.\n",
      "        .   @param t Recovered relative translation.\n",
      "        .   @param distanceThresh threshold distance which is used to filter out far away points (i.e. infinite points).\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2.\n",
      "        .   :   If it is not empty, then it marks inliers in points1 and points2 for then given essential\n",
      "        .   matrix E. Only these inliers will be used to recover pose. In the output mask only inliers\n",
      "        .   which pass the cheirality check.\n",
      "        .   @param triangulatedPoints 3d points which were reconstructed by triangulation.\n",
      "    \n",
      "    rectangle(...)\n",
      "        rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a simple, thick, or filled up-right rectangle.\n",
      "        .   \n",
      "        .   The function cv::rectangle draws a rectangle outline or a filled rectangle whose two opposite corners\n",
      "        .   are pt1 and pt2.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 Vertex of the rectangle.\n",
      "        .   @param pt2 Vertex of the rectangle opposite to pt1 .\n",
      "        .   @param color Rectangle color or brightness (grayscale image).\n",
      "        .   @param thickness Thickness of lines that make up the rectangle. Negative values, like #FILLED,\n",
      "        .   mean that the function has to draw a filled rectangle.\n",
      "        .   @param lineType Type of the line. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "        \n",
      "        \n",
      "        \n",
      "        rectangle(img, rec, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @overload\n",
      "        .   \n",
      "        .   use `rec` parameter as alternative specification of the drawn rectangle: `r.tl() and\n",
      "        .   r.br()-Point(1,1)` are opposite corners\n",
      "    \n",
      "    rectify3Collinear(...)\n",
      "        rectify3Collinear(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, cameraMatrix3, distCoeffs3, imgpt1, imgpt3, imageSize, R12, T12, R13, T13, alpha, newImgSize, flags[, R1[, R2[, R3[, P1[, P2[, P3[, Q]]]]]]]) -> retval, R1, R2, R3, P1, P2, P3, Q, roi1, roi2\n",
      "        .\n",
      "    \n",
      "    redirectError(...)\n",
      "        redirectError(onError) -> None\n",
      "    \n",
      "    reduce(...)\n",
      "        reduce(src, dim, rtype[, dst[, dtype]]) -> dst\n",
      "        .   @brief Reduces a matrix to a vector.\n",
      "        .   \n",
      "        .   The function #reduce reduces the matrix to a vector by treating the matrix rows/columns as a set of\n",
      "        .   1D vectors and performing the specified operation on the vectors until a single row/column is\n",
      "        .   obtained. For example, the function can be used to compute horizontal and vertical projections of a\n",
      "        .   raster image. In case of #REDUCE_MAX and #REDUCE_MIN , the output image should have the same type as the source one.\n",
      "        .   In case of #REDUCE_SUM and #REDUCE_AVG , the output may have a larger element bit-depth to preserve accuracy.\n",
      "        .   And multi-channel arrays are also supported in these two reduction modes.\n",
      "        .   \n",
      "        .   The following code demonstrates its usage for a single channel matrix.\n",
      "        .   @snippet snippets/core_reduce.cpp example\n",
      "        .   \n",
      "        .   And the following code demonstrates its usage for a two-channel matrix.\n",
      "        .   @snippet snippets/core_reduce.cpp example2\n",
      "        .   \n",
      "        .   @param src input 2D matrix.\n",
      "        .   @param dst output vector. Its size and type is defined by dim and dtype parameters.\n",
      "        .   @param dim dimension index along which the matrix is reduced. 0 means that the matrix is reduced to\n",
      "        .   a single row. 1 means that the matrix is reduced to a single column.\n",
      "        .   @param rtype reduction operation that could be one of #ReduceTypes\n",
      "        .   @param dtype when negative, the output vector will have the same type as the input matrix,\n",
      "        .   otherwise, its type will be CV_MAKE_TYPE(CV_MAT_DEPTH(dtype), src.channels()).\n",
      "        .   @sa repeat\n",
      "    \n",
      "    remap(...)\n",
      "        remap(src, map1, map2, interpolation[, dst[, borderMode[, borderValue]]]) -> dst\n",
      "        .   @brief Applies a generic geometrical transformation to an image.\n",
      "        .   \n",
      "        .   The function remap transforms the source image using the specified map:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} (map_x(x,y),map_y(x,y))\\f]\n",
      "        .   \n",
      "        .   where values of pixels with non-integer coordinates are computed using one of available\n",
      "        .   interpolation methods. \\f$map_x\\f$ and \\f$map_y\\f$ can be encoded as separate floating-point maps\n",
      "        .   in \\f$map_1\\f$ and \\f$map_2\\f$ respectively, or interleaved floating-point maps of \\f$(x,y)\\f$ in\n",
      "        .   \\f$map_1\\f$, or fixed-point maps created by using convertMaps. The reason you might want to\n",
      "        .   convert from floating to fixed-point representations of a map is that they can yield much faster\n",
      "        .   (\\~2x) remapping operations. In the converted case, \\f$map_1\\f$ contains pairs (cvFloor(x),\n",
      "        .   cvFloor(y)) and \\f$map_2\\f$ contains indices in a table of interpolation coefficients.\n",
      "        .   \n",
      "        .   This function cannot operate in-place.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. It has the same size as map1 and the same type as src .\n",
      "        .   @param map1 The first map of either (x,y) points or just x values having the type CV_16SC2 ,\n",
      "        .   CV_32FC1, or CV_32FC2. See convertMaps for details on converting a floating point\n",
      "        .   representation to fixed-point for speed.\n",
      "        .   @param map2 The second map of y values having the type CV_16UC1, CV_32FC1, or none (empty map\n",
      "        .   if map1 is (x,y) points), respectively.\n",
      "        .   @param interpolation Interpolation method (see #InterpolationFlags). The method #INTER_AREA is\n",
      "        .   not supported by this function.\n",
      "        .   @param borderMode Pixel extrapolation method (see #BorderTypes). When\n",
      "        .   borderMode=#BORDER_TRANSPARENT, it means that the pixels in the destination image that\n",
      "        .   corresponds to the \"outliers\" in the source image are not modified by the function.\n",
      "        .   @param borderValue Value used in case of a constant border. By default, it is 0.\n",
      "        .   @note\n",
      "        .   Due to current implementation limitations the size of an input and output images should be less than 32767x32767.\n",
      "    \n",
      "    repeat(...)\n",
      "        repeat(src, ny, nx[, dst]) -> dst\n",
      "        .   @brief Fills the output array with repeated copies of the input array.\n",
      "        .   \n",
      "        .   The function cv::repeat duplicates the input array one or more times along each of the two axes:\n",
      "        .   \\f[\\texttt{dst} _{ij}= \\texttt{src} _{i\\mod src.rows, \\; j\\mod src.cols }\\f]\n",
      "        .   The second variant of the function is more convenient to use with @ref MatrixExpressions.\n",
      "        .   @param src input array to replicate.\n",
      "        .   @param ny Flag to specify how many times the `src` is repeated along the\n",
      "        .   vertical axis.\n",
      "        .   @param nx Flag to specify how many times the `src` is repeated along the\n",
      "        .   horizontal axis.\n",
      "        .   @param dst output array of the same type as `src`.\n",
      "        .   @sa cv::reduce\n",
      "    \n",
      "    reprojectImageTo3D(...)\n",
      "        reprojectImageTo3D(disparity, Q[, _3dImage[, handleMissingValues[, ddepth]]]) -> _3dImage\n",
      "        .   @brief Reprojects a disparity image to 3D space.\n",
      "        .   \n",
      "        .   @param disparity Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no\n",
      "        .   fractional bits.\n",
      "        .   @param _3dImage Output 3-channel floating-point image of the same size as disparity . Each\n",
      "        .   element of _3dImage(x,y) contains 3D coordinates of the point (x,y) computed from the disparity\n",
      "        .   map.\n",
      "        .   @param Q \\f$4 \\times 4\\f$ perspective transformation matrix that can be obtained with stereoRectify.\n",
      "        .   @param handleMissingValues Indicates, whether the function should handle missing values (i.e.\n",
      "        .   points where the disparity was not computed). If handleMissingValues=true, then pixels with the\n",
      "        .   minimal disparity that corresponds to the outliers (see StereoMatcher::compute ) are transformed\n",
      "        .   to 3D points with a very large Z value (currently set to 10000).\n",
      "        .   @param ddepth The optional output array depth. If it is -1, the output image will have CV_32F\n",
      "        .   depth. ddepth can also be set to CV_16S, CV_32S or CV_32F.\n",
      "        .   \n",
      "        .   The function transforms a single-channel disparity map to a 3-channel image representing a 3D\n",
      "        .   surface. That is, for each pixel (x,y) and the corresponding disparity d=disparity(x,y) , it\n",
      "        .   computes:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} [X \\; Y \\; Z \\; W]^T =  \\texttt{Q} *[x \\; y \\; \\texttt{disparity} (x,y) \\; 1]^T  \\\\ \\texttt{\\_3dImage} (x,y) = (X/W, \\; Y/W, \\; Z/W) \\end{array}\\f]\n",
      "        .   \n",
      "        .   The matrix Q can be an arbitrary \\f$4 \\times 4\\f$ matrix (for example, the one computed by\n",
      "        .   stereoRectify). To reproject a sparse set of points {(x,y,d),...} to 3D space, use\n",
      "        .   perspectiveTransform .\n",
      "    \n",
      "    resize(...)\n",
      "        resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
      "        .   @brief Resizes an image.\n",
      "        .   \n",
      "        .   The function resize resizes the image src down to or up to the specified size. Note that the\n",
      "        .   initial dst type or size are not taken into account. Instead, the size and type are derived from\n",
      "        .   the `src`,`dsize`,`fx`, and `fy`. If you want to resize src so that it fits the pre-created dst,\n",
      "        .   you may call the function as follows:\n",
      "        .   @code\n",
      "        .   // explicitly specify dsize=dst.size(); fx and fy will be computed from that.\n",
      "        .   resize(src, dst, dst.size(), 0, 0, interpolation);\n",
      "        .   @endcode\n",
      "        .   If you want to decimate the image by factor of 2 in each direction, you can call the function this\n",
      "        .   way:\n",
      "        .   @code\n",
      "        .   // specify fx and fy and let the function compute the destination image size.\n",
      "        .   resize(src, dst, Size(), 0.5, 0.5, interpolation);\n",
      "        .   @endcode\n",
      "        .   To shrink an image, it will generally look best with #INTER_AREA interpolation, whereas to\n",
      "        .   enlarge an image, it will generally look best with c#INTER_CUBIC (slow) or #INTER_LINEAR\n",
      "        .   (faster but still looks OK).\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image; it has the size dsize (when it is non-zero) or the size computed from\n",
      "        .   src.size(), fx, and fy; the type of dst is the same as of src.\n",
      "        .   @param dsize output image size; if it equals zero, it is computed as:\n",
      "        .   \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "        .   Either dsize or both fx and fy must be non-zero.\n",
      "        .   @param fx scale factor along the horizontal axis; when it equals 0, it is computed as\n",
      "        .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "        .   @param fy scale factor along the vertical axis; when it equals 0, it is computed as\n",
      "        .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "        .   @param interpolation interpolation method, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @sa  warpAffine, warpPerspective, remap\n",
      "    \n",
      "    resizeWindow(...)\n",
      "        resizeWindow(winname, width, height) -> None\n",
      "        .   @brief Resizes window to the specified size\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   The specified window size is for the image area. Toolbars are not counted.\n",
      "        .   -   Only windows created without cv::WINDOW_AUTOSIZE flag can be resized.\n",
      "        .   \n",
      "        .   @param winname Window name.\n",
      "        .   @param width The new window width.\n",
      "        .   @param height The new window height.\n",
      "        \n",
      "        \n",
      "        \n",
      "        resizeWindow(winname, size) -> None\n",
      "        .   @overload\n",
      "        .   @param winname Window name.\n",
      "        .   @param size The new window size.\n",
      "    \n",
      "    rotate(...)\n",
      "        rotate(src, rotateCode[, dst]) -> dst\n",
      "        .   @brief Rotates a 2D array in multiples of 90 degrees.\n",
      "        .   The function cv::rotate rotates the array in one of three different ways:\n",
      "        .   *   Rotate by 90 degrees clockwise (rotateCode = ROTATE_90_CLOCKWISE).\n",
      "        .   *   Rotate by 180 degrees clockwise (rotateCode = ROTATE_180).\n",
      "        .   *   Rotate by 270 degrees clockwise (rotateCode = ROTATE_90_COUNTERCLOCKWISE).\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same type as src.  The size is the same with ROTATE_180,\n",
      "        .   and the rows and cols are switched for ROTATE_90_CLOCKWISE and ROTATE_90_COUNTERCLOCKWISE.\n",
      "        .   @param rotateCode an enum to specify how to rotate the array; see the enum #RotateFlags\n",
      "        .   @sa transpose , repeat , completeSymm, flip, RotateFlags\n",
      "    \n",
      "    rotatedRectangleIntersection(...)\n",
      "        rotatedRectangleIntersection(rect1, rect2[, intersectingRegion]) -> retval, intersectingRegion\n",
      "        .   @brief Finds out if there is any intersection between two rotated rectangles.\n",
      "        .   \n",
      "        .   If there is then the vertices of the intersecting region are returned as well.\n",
      "        .   \n",
      "        .   Below are some examples of intersection configurations. The hatched pattern indicates the\n",
      "        .   intersecting region and the red vertices are returned by the function.\n",
      "        .   \n",
      "        .   ![intersection examples](pics/intersection.png)\n",
      "        .   \n",
      "        .   @param rect1 First rectangle\n",
      "        .   @param rect2 Second rectangle\n",
      "        .   @param intersectingRegion The output array of the vertices of the intersecting region. It returns\n",
      "        .   at most 8 vertices. Stored as std::vector\\<cv::Point2f\\> or cv::Mat as Mx1 of type CV_32FC2.\n",
      "        .   @returns One of #RectanglesIntersectTypes\n",
      "    \n",
      "    sampsonDistance(...)\n",
      "        sampsonDistance(pt1, pt2, F) -> retval\n",
      "        .   @brief Calculates the Sampson Distance between two points.\n",
      "        .   \n",
      "        .   The function cv::sampsonDistance calculates and returns the first order approximation of the geometric error as:\n",
      "        .   \\f[\n",
      "        .   sd( \\texttt{pt1} , \\texttt{pt2} )=\n",
      "        .   \\frac{(\\texttt{pt2}^t \\cdot \\texttt{F} \\cdot \\texttt{pt1})^2}\n",
      "        .   {((\\texttt{F} \\cdot \\texttt{pt1})(0))^2 +\n",
      "        .   ((\\texttt{F} \\cdot \\texttt{pt1})(1))^2 +\n",
      "        .   ((\\texttt{F}^t \\cdot \\texttt{pt2})(0))^2 +\n",
      "        .   ((\\texttt{F}^t \\cdot \\texttt{pt2})(1))^2}\n",
      "        .   \\f]\n",
      "        .   The fundamental matrix may be calculated using the cv::findFundamentalMat function. See @cite HartleyZ00 11.4.3 for details.\n",
      "        .   @param pt1 first homogeneous 2d point\n",
      "        .   @param pt2 second homogeneous 2d point\n",
      "        .   @param F fundamental matrix\n",
      "        .   @return The computed Sampson distance.\n",
      "    \n",
      "    scaleAdd(...)\n",
      "        scaleAdd(src1, alpha, src2[, dst]) -> dst\n",
      "        .   @brief Calculates the sum of a scaled array and another array.\n",
      "        .   \n",
      "        .   The function scaleAdd is one of the classical primitive linear algebra operations, known as DAXPY\n",
      "        .   or SAXPY in [BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). It calculates\n",
      "        .   the sum of a scaled array and another array:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{scale} \\cdot \\texttt{src1} (I) +  \\texttt{src2} (I)\\f]\n",
      "        .   The function can also be emulated with a matrix expression, for example:\n",
      "        .   @code{.cpp}\n",
      "        .   Mat A(3, 3, CV_64F);\n",
      "        .   ...\n",
      "        .   A.row(0) = A.row(1)*2 + A.row(2);\n",
      "        .   @endcode\n",
      "        .   @param src1 first input array.\n",
      "        .   @param alpha scale factor for the first array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa add, addWeighted, subtract, Mat::dot, Mat::convertTo\n",
      "    \n",
      "    seamlessClone(...)\n",
      "        seamlessClone(src, dst, mask, p, flags[, blend]) -> blend\n",
      "        .   @brief Image editing tasks concern either global changes (color/intensity corrections, filters,\n",
      "        .   deformations) or local changes concerned to a selection. Here we are interested in achieving local\n",
      "        .   changes, ones that are restricted to a region manually selected (ROI), in a seamless and effortless\n",
      "        .   manner. The extent of the changes ranges from slight distortions to complete replacement by novel\n",
      "        .   content @cite PM03 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param p Point in dst image where object is placed.\n",
      "        .   @param blend Output image with the same size and type as dst.\n",
      "        .   @param flags Cloning method that could be cv::NORMAL_CLONE, cv::MIXED_CLONE or cv::MONOCHROME_TRANSFER\n",
      "    \n",
      "    selectROI(...)\n",
      "        selectROI(windowName, img[, showCrosshair[, fromCenter]]) -> retval\n",
      "        .   @brief Selects ROI on the given image.\n",
      "        .   Function creates a window and allows user to select a ROI using mouse.\n",
      "        .   Controls: use `space` or `enter` to finish selection, use key `c` to cancel selection (function will return the zero cv::Rect).\n",
      "        .   \n",
      "        .   @param windowName name of the window where selection process will be shown.\n",
      "        .   @param img image to select a ROI.\n",
      "        .   @param showCrosshair if true crosshair of selection rectangle will be shown.\n",
      "        .   @param fromCenter if true center of selection will match initial mouse position. In opposite case a corner of\n",
      "        .   selection rectangle will correspont to the initial mouse position.\n",
      "        .   @return selected ROI or empty rect if selection canceled.\n",
      "        .   \n",
      "        .   @note The function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...).\n",
      "        .   After finish of work an empty callback will be set for the used window.\n",
      "        \n",
      "        \n",
      "        \n",
      "        selectROI(img[, showCrosshair[, fromCenter]]) -> retval\n",
      "        .   @overload\n",
      "    \n",
      "    selectROIs(...)\n",
      "        selectROIs(windowName, img[, showCrosshair[, fromCenter]]) -> boundingBoxes\n",
      "        .   @brief Selects ROIs on the given image.\n",
      "        .   Function creates a window and allows user to select a ROIs using mouse.\n",
      "        .   Controls: use `space` or `enter` to finish current selection and start a new one,\n",
      "        .   use `esc` to terminate multiple ROI selection process.\n",
      "        .   \n",
      "        .   @param windowName name of the window where selection process will be shown.\n",
      "        .   @param img image to select a ROI.\n",
      "        .   @param boundingBoxes selected ROIs.\n",
      "        .   @param showCrosshair if true crosshair of selection rectangle will be shown.\n",
      "        .   @param fromCenter if true center of selection will match initial mouse position. In opposite case a corner of\n",
      "        .   selection rectangle will correspont to the initial mouse position.\n",
      "        .   \n",
      "        .   @note The function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...).\n",
      "        .   After finish of work an empty callback will be set for the used window.\n",
      "    \n",
      "    sepFilter2D(...)\n",
      "        sepFilter2D(src, ddepth, kernelX, kernelY[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Applies a separable linear filter to an image.\n",
      "        .   \n",
      "        .   The function applies a separable linear filter to the image. That is, first, every row of src is\n",
      "        .   filtered with the 1D kernel kernelX. Then, every column of the result is filtered with the 1D\n",
      "        .   kernel kernelY. The final result shifted by delta is stored in dst .\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth Destination image depth, see @ref filter_depths \"combinations\"\n",
      "        .   @param kernelX Coefficients for filtering each row.\n",
      "        .   @param kernelY Coefficients for filtering each column.\n",
      "        .   @param anchor Anchor position within the kernel. The default value \\f$(-1,-1)\\f$ means that the anchor\n",
      "        .   is at the kernel center.\n",
      "        .   @param delta Value added to the filtered results before storing them.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes\n",
      "        .   @sa  filter2D, Sobel, GaussianBlur, boxFilter, blur\n",
      "    \n",
      "    setIdentity(...)\n",
      "        setIdentity(mtx[, s]) -> mtx\n",
      "        .   @brief Initializes a scaled identity matrix.\n",
      "        .   \n",
      "        .   The function cv::setIdentity initializes a scaled identity matrix:\n",
      "        .   \\f[\\texttt{mtx} (i,j)= \\fork{\\texttt{value}}{ if \\(i=j\\)}{0}{otherwise}\\f]\n",
      "        .   \n",
      "        .   The function can also be emulated using the matrix initializers and the\n",
      "        .   matrix expressions:\n",
      "        .   @code\n",
      "        .   Mat A = Mat::eye(4, 3, CV_32F)*5;\n",
      "        .   // A will be set to [[5, 0, 0], [0, 5, 0], [0, 0, 5], [0, 0, 0]]\n",
      "        .   @endcode\n",
      "        .   @param mtx matrix to initialize (not necessarily square).\n",
      "        .   @param s value to assign to diagonal elements.\n",
      "        .   @sa Mat::zeros, Mat::ones, Mat::setTo, Mat::operator=\n",
      "    \n",
      "    setMouseCallback(...)\n",
      "        setMouseCallback(windowName, onMouse [, param]) -> None\n",
      "    \n",
      "    setNumThreads(...)\n",
      "        setNumThreads(nthreads) -> None\n",
      "        .   @brief OpenCV will try to set the number of threads for the next parallel region.\n",
      "        .   \n",
      "        .   If threads == 0, OpenCV will disable threading optimizations and run all it's functions\n",
      "        .   sequentially. Passing threads \\< 0 will reset threads number to system default. This function must\n",
      "        .   be called outside of parallel region.\n",
      "        .   \n",
      "        .   OpenCV will try to run its functions with specified threads number, but some behaviour differs from\n",
      "        .   framework:\n",
      "        .   -   `TBB` - User-defined parallel constructions will run with the same threads number, if\n",
      "        .   another is not specified. If later on user creates his own scheduler, OpenCV will use it.\n",
      "        .   -   `OpenMP` - No special defined behaviour.\n",
      "        .   -   `Concurrency` - If threads == 1, OpenCV will disable threading optimizations and run its\n",
      "        .   functions sequentially.\n",
      "        .   -   `GCD` - Supports only values \\<= 0.\n",
      "        .   -   `C=` - No special defined behaviour.\n",
      "        .   @param nthreads Number of threads used by OpenCV.\n",
      "        .   @sa getNumThreads, getThreadNum\n",
      "    \n",
      "    setRNGSeed(...)\n",
      "        setRNGSeed(seed) -> None\n",
      "        .   @brief Sets state of default random number generator.\n",
      "        .   \n",
      "        .   The function cv::setRNGSeed sets state of default random number generator to custom value.\n",
      "        .   @param seed new state for default random number generator\n",
      "        .   @sa RNG, randu, randn\n",
      "    \n",
      "    setTrackbarMax(...)\n",
      "        setTrackbarMax(trackbarname, winname, maxval) -> None\n",
      "        .   @brief Sets the trackbar maximum position.\n",
      "        .   \n",
      "        .   The function sets the maximum position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param maxval New maximum position.\n",
      "    \n",
      "    setTrackbarMin(...)\n",
      "        setTrackbarMin(trackbarname, winname, minval) -> None\n",
      "        .   @brief Sets the trackbar minimum position.\n",
      "        .   \n",
      "        .   The function sets the minimum position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param minval New minimum position.\n",
      "    \n",
      "    setTrackbarPos(...)\n",
      "        setTrackbarPos(trackbarname, winname, pos) -> None\n",
      "        .   @brief Sets the trackbar position.\n",
      "        .   \n",
      "        .   The function sets the position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param pos New position.\n",
      "    \n",
      "    setUseOpenVX(...)\n",
      "        setUseOpenVX(flag) -> None\n",
      "        .\n",
      "    \n",
      "    setUseOptimized(...)\n",
      "        setUseOptimized(onoff) -> None\n",
      "        .   @brief Enables or disables the optimized code.\n",
      "        .   \n",
      "        .   The function can be used to dynamically turn on and off optimized dispatched code (code that uses SSE4.2, AVX/AVX2,\n",
      "        .   and other instructions on the platforms that support it). It sets a global flag that is further\n",
      "        .   checked by OpenCV functions. Since the flag is not checked in the inner OpenCV loops, it is only\n",
      "        .   safe to call the function on the very top level in your application where you can be sure that no\n",
      "        .   other OpenCV function is currently executed.\n",
      "        .   \n",
      "        .   By default, the optimized code is enabled unless you disable it in CMake. The current status can be\n",
      "        .   retrieved using useOptimized.\n",
      "        .   @param onoff The boolean flag specifying whether the optimized code should be used (onoff=true)\n",
      "        .   or not (onoff=false).\n",
      "    \n",
      "    setWindowProperty(...)\n",
      "        setWindowProperty(winname, prop_id, prop_value) -> None\n",
      "        .   @brief Changes parameters of a window dynamically.\n",
      "        .   \n",
      "        .   The function setWindowProperty enables changing properties of a window.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param prop_id Window property to edit. The supported operation flags are: (cv::WindowPropertyFlags)\n",
      "        .   @param prop_value New value of the window property. The supported flags are: (cv::WindowFlags)\n",
      "    \n",
      "    setWindowTitle(...)\n",
      "        setWindowTitle(winname, title) -> None\n",
      "        .   @brief Updates window title\n",
      "        .   @param winname Name of the window.\n",
      "        .   @param title New title.\n",
      "    \n",
      "    solve(...)\n",
      "        solve(src1, src2[, dst[, flags]]) -> retval, dst\n",
      "        .   @brief Solves one or more linear systems or least-squares problems.\n",
      "        .   \n",
      "        .   The function cv::solve solves a linear system or least-squares problem (the\n",
      "        .   latter is possible with SVD or QR methods, or by specifying the flag\n",
      "        .   #DECOMP_NORMAL ):\n",
      "        .   \\f[\\texttt{dst} =  \\arg \\min _X \\| \\texttt{src1} \\cdot \\texttt{X} -  \\texttt{src2} \\|\\f]\n",
      "        .   \n",
      "        .   If #DECOMP_LU or #DECOMP_CHOLESKY method is used, the function returns 1\n",
      "        .   if src1 (or \\f$\\texttt{src1}^T\\texttt{src1}\\f$ ) is non-singular. Otherwise,\n",
      "        .   it returns 0. In the latter case, dst is not valid. Other methods find a\n",
      "        .   pseudo-solution in case of a singular left-hand side part.\n",
      "        .   \n",
      "        .   @note If you want to find a unity-norm solution of an under-defined\n",
      "        .   singular system \\f$\\texttt{src1}\\cdot\\texttt{dst}=0\\f$ , the function solve\n",
      "        .   will not do the work. Use SVD::solveZ instead.\n",
      "        .   \n",
      "        .   @param src1 input matrix on the left-hand side of the system.\n",
      "        .   @param src2 input matrix on the right-hand side of the system.\n",
      "        .   @param dst output solution.\n",
      "        .   @param flags solution (matrix inversion) method (#DecompTypes)\n",
      "        .   @sa invert, SVD, eigen\n",
      "    \n",
      "    solveCubic(...)\n",
      "        solveCubic(coeffs[, roots]) -> retval, roots\n",
      "        .   @brief Finds the real roots of a cubic equation.\n",
      "        .   \n",
      "        .   The function solveCubic finds the real roots of a cubic equation:\n",
      "        .   -   if coeffs is a 4-element vector:\n",
      "        .   \\f[\\texttt{coeffs} [0] x^3 +  \\texttt{coeffs} [1] x^2 +  \\texttt{coeffs} [2] x +  \\texttt{coeffs} [3] = 0\\f]\n",
      "        .   -   if coeffs is a 3-element vector:\n",
      "        .   \\f[x^3 +  \\texttt{coeffs} [0] x^2 +  \\texttt{coeffs} [1] x +  \\texttt{coeffs} [2] = 0\\f]\n",
      "        .   \n",
      "        .   The roots are stored in the roots array.\n",
      "        .   @param coeffs equation coefficients, an array of 3 or 4 elements.\n",
      "        .   @param roots output array of real roots that has 1 or 3 elements.\n",
      "        .   @return number of real roots. It can be 0, 1 or 2.\n",
      "    \n",
      "    solveLP(...)\n",
      "        solveLP(Func, Constr[, z]) -> retval, z\n",
      "        .   @brief Solve given (non-integer) linear programming problem using the Simplex Algorithm (Simplex Method).\n",
      "        .   \n",
      "        .   What we mean here by \"linear programming problem\" (or LP problem, for short) can be formulated as:\n",
      "        .   \n",
      "        .   \\f[\\mbox{Maximize } c\\cdot x\\\\\n",
      "        .   \\mbox{Subject to:}\\\\\n",
      "        .   Ax\\leq b\\\\\n",
      "        .   x\\geq 0\\f]\n",
      "        .   \n",
      "        .   Where \\f$c\\f$ is fixed `1`-by-`n` row-vector, \\f$A\\f$ is fixed `m`-by-`n` matrix, \\f$b\\f$ is fixed `m`-by-`1`\n",
      "        .   column vector and \\f$x\\f$ is an arbitrary `n`-by-`1` column vector, which satisfies the constraints.\n",
      "        .   \n",
      "        .   Simplex algorithm is one of many algorithms that are designed to handle this sort of problems\n",
      "        .   efficiently. Although it is not optimal in theoretical sense (there exist algorithms that can solve\n",
      "        .   any problem written as above in polynomial time, while simplex method degenerates to exponential\n",
      "        .   time for some special cases), it is well-studied, easy to implement and is shown to work well for\n",
      "        .   real-life purposes.\n",
      "        .   \n",
      "        .   The particular implementation is taken almost verbatim from **Introduction to Algorithms, third\n",
      "        .   edition** by T. H. Cormen, C. E. Leiserson, R. L. Rivest and Clifford Stein. In particular, the\n",
      "        .   Bland's rule <http://en.wikipedia.org/wiki/Bland%27s_rule> is used to prevent cycling.\n",
      "        .   \n",
      "        .   @param Func This row-vector corresponds to \\f$c\\f$ in the LP problem formulation (see above). It should\n",
      "        .   contain 32- or 64-bit floating point numbers. As a convenience, column-vector may be also submitted,\n",
      "        .   in the latter case it is understood to correspond to \\f$c^T\\f$.\n",
      "        .   @param Constr `m`-by-`n+1` matrix, whose rightmost column corresponds to \\f$b\\f$ in formulation above\n",
      "        .   and the remaining to \\f$A\\f$. It should contain 32- or 64-bit floating point numbers.\n",
      "        .   @param z The solution will be returned here as a column-vector - it corresponds to \\f$c\\f$ in the\n",
      "        .   formulation above. It will contain 64-bit floating point numbers.\n",
      "        .   @return One of cv::SolveLPResult\n",
      "    \n",
      "    solveP3P(...)\n",
      "        solveP3P(objectPoints, imagePoints, cameraMatrix, distCoeffs, flags[, rvecs[, tvecs]]) -> retval, rvecs, tvecs\n",
      "        .   @brief Finds an object pose from 3 3D-2D point correspondences.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, 3x3 1-channel or\n",
      "        .   1x3/3x1 3-channel. vector\\<Point3f\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, 3x2 1-channel or 1x3/3x1 2-channel.\n",
      "        .   vector\\<Point2f\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{fx}{0}{cx}{0}{fy}{cy}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvecs Output rotation vectors (see Rodrigues ) that, together with tvecs , brings points from\n",
      "        .   the model coordinate system to the camera coordinate system. A P3P problem has up to 4 solutions.\n",
      "        .   @param tvecs Output translation vectors.\n",
      "        .   @param flags Method for solving a P3P problem:\n",
      "        .   -   **SOLVEPNP_P3P** Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang\n",
      "        .   \"Complete Solution Classification for the Perspective-Three-Point Problem\" (@cite gao2003complete).\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of Tong Ke and Stergios I. Roumeliotis.\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17).\n",
      "        .   \n",
      "        .   The function estimates the object pose given 3 object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients.\n",
      "    \n",
      "    solvePnP(...)\n",
      "        solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, flags]]]]) -> retval, rvec, tvec\n",
      "        .   @brief Finds an object pose from 3D-2D point correspondences.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or\n",
      "        .   1xN/Nx1 3-channel, where N is the number of points. vector\\<Point3f\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2f\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{fx}{0}{cx}{0}{fy}{cy}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Output rotation vector (see @ref Rodrigues ) that, together with tvec , brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Output translation vector.\n",
      "        .   @param useExtrinsicGuess Parameter used for #SOLVEPNP_ITERATIVE. If true (1), the function uses\n",
      "        .   the provided rvec and tvec values as initial approximations of the rotation and translation\n",
      "        .   vectors, respectively, and further optimizes them.\n",
      "        .   @param flags Method for solving a PnP problem:\n",
      "        .   -   **SOLVEPNP_ITERATIVE** Iterative method is based on Levenberg-Marquardt optimization. In\n",
      "        .   this case the function finds such a pose that minimizes reprojection error, that is the sum\n",
      "        .   of squared distances between the observed projections imagePoints and the projected (using\n",
      "        .   projectPoints ) objectPoints .\n",
      "        .   -   **SOLVEPNP_P3P** Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang\n",
      "        .   \"Complete Solution Classification for the Perspective-Three-Point Problem\" (@cite gao2003complete).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of T. Ke, S. Roumeliotis\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_EPNP** Method has been introduced by F.Moreno-Noguer, V.Lepetit and P.Fua in the\n",
      "        .   paper \"EPnP: Efficient Perspective-n-Point Camera Pose Estimation\" (@cite lepetit2009epnp).\n",
      "        .   -   **SOLVEPNP_DLS** Method is based on the paper of Joel A. Hesch and Stergios I. Roumeliotis.\n",
      "        .   \"A Direct Least-Squares (DLS) Method for PnP\" (@cite hesch2011direct).\n",
      "        .   -   **SOLVEPNP_UPNP** Method is based on the paper of A.Penate-Sanchez, J.Andrade-Cetto,\n",
      "        .   F.Moreno-Noguer. \"Exhaustive Linearization for Robust Camera Pose and Focal Length\n",
      "        .   Estimation\" (@cite penate2013exhaustive). In this case the function also estimates the parameters \\f$f_x\\f$ and \\f$f_y\\f$\n",
      "        .   assuming that both have the same value. Then the cameraMatrix is updated with the estimated\n",
      "        .   focal length.\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of Tong Ke and Stergios I. Roumeliotis.\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17). In this case the\n",
      "        .   function requires exactly four object and image points.\n",
      "        .   \n",
      "        .   The function estimates the object pose given a set of object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients, see the figure below\n",
      "        .   (more precisely, the X-axis of the camera frame is pointing to the right, the Y-axis downward\n",
      "        .   and the Z-axis forward).\n",
      "        .   \n",
      "        .   ![](pnp.jpg)\n",
      "        .   \n",
      "        .   Points expressed in the world frame \\f$ \\bf{X}_w \\f$ are projected into the image plane \\f$ \\left[ u, v \\right] \\f$\n",
      "        .   using the perspective projection model \\f$ \\Pi \\f$ and the camera intrinsic parameters matrix \\f$ \\bf{A} \\f$:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .   \\begin{align*}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   u \\\\\n",
      "        .   v \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} &=\n",
      "        .   \\bf{A} \\hspace{0.1em} \\Pi \\hspace{0.2em} ^{c}\\bf{M}_w\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_{w} \\\\\n",
      "        .   Y_{w} \\\\\n",
      "        .   Z_{w} \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} \\\\\n",
      "        .   \\begin{bmatrix}\n",
      "        .   u \\\\\n",
      "        .   v \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} &=\n",
      "        .   \\begin{bmatrix}\n",
      "        .   f_x & 0 & c_x \\\\\n",
      "        .   0 & f_y & c_y \\\\\n",
      "        .   0 & 0 & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   1 & 0 & 0 & 0 \\\\\n",
      "        .   0 & 1 & 0 & 0 \\\\\n",
      "        .   0 & 0 & 1 & 0\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .   r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .   r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .   0 & 0 & 0 & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_{w} \\\\\n",
      "        .   Y_{w} \\\\\n",
      "        .   Z_{w} \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The estimated pose is thus the rotation (`rvec`) and the translation (`tvec`) vectors that allow to transform\n",
      "        .   a 3D point expressed in the world frame into the camera frame:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .   \\begin{align*}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_c \\\\\n",
      "        .   Y_c \\\\\n",
      "        .   Z_c \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} &=\n",
      "        .   \\hspace{0.2em} ^{c}\\bf{M}_w\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_{w} \\\\\n",
      "        .   Y_{w} \\\\\n",
      "        .   Z_{w} \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} \\\\\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_c \\\\\n",
      "        .   Y_c \\\\\n",
      "        .   Z_c \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} &=\n",
      "        .   \\begin{bmatrix}\n",
      "        .   r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .   r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .   r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .   0 & 0 & 0 & 1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X_{w} \\\\\n",
      "        .   Y_{w} \\\\\n",
      "        .   Z_{w} \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   An example of how to use solvePnP for planar augmented reality can be found at\n",
      "        .   opencv_source_code/samples/python/plane_ar.py\n",
      "        .   -   If you are using Python:\n",
      "        .   - Numpy array slices won't work as input because solvePnP requires contiguous\n",
      "        .   arrays (enforced by the assertion using cv::Mat::checkVector() around line 55 of\n",
      "        .   modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .   - The P3P algorithm requires image points to be in an array of shape (N,1,2) due\n",
      "        .   to its calling of cv::undistortPoints (around line 75 of modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .   which requires 2-channel information.\n",
      "        .   - Thus, given some data D = np.array(...) where D.shape = (N,M), in order to use a subset of\n",
      "        .   it as, e.g., imagePoints, one must effectively copy it into a new array: imagePoints =\n",
      "        .   np.ascontiguousarray(D[:,:2]).reshape((N,1,2))\n",
      "        .   -   The methods **SOLVEPNP_DLS** and **SOLVEPNP_UPNP** cannot be used as the current implementations are\n",
      "        .   unstable and sometimes give completely wrong results. If you pass one of these two\n",
      "        .   flags, **SOLVEPNP_EPNP** method will be used instead.\n",
      "        .   -   The minimum number of points is 4 in the general case. In the case of **SOLVEPNP_P3P** and **SOLVEPNP_AP3P**\n",
      "        .   methods, it is required to use exactly 4 points (the first 3 points are used to estimate all the solutions\n",
      "        .   of the P3P problem, the last one is used to retain the best solution that minimizes the reprojection error).\n",
      "        .   -   With **SOLVEPNP_ITERATIVE** method and `useExtrinsicGuess=true`, the minimum number of points is 3 (3 points\n",
      "        .   are sufficient to compute a pose but there are up to 4 solutions). The initial solution should be close to the\n",
      "        .   global solution to converge.\n",
      "    \n",
      "    solvePnPRansac(...)\n",
      "        solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, iterationsCount[, reprojectionError[, confidence[, inliers[, flags]]]]]]]]) -> retval, rvec, tvec, inliers\n",
      "        .   @brief Finds an object pose from 3D-2D point correspondences using the RANSAC scheme.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or\n",
      "        .   1xN/Nx1 3-channel, where N is the number of points. vector\\<Point3f\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2f\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{fx}{0}{cx}{0}{fy}{cy}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Output rotation vector (see Rodrigues ) that, together with tvec , brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Output translation vector.\n",
      "        .   @param useExtrinsicGuess Parameter used for SOLVEPNP_ITERATIVE. If true (1), the function uses\n",
      "        .   the provided rvec and tvec values as initial approximations of the rotation and translation\n",
      "        .   vectors, respectively, and further optimizes them.\n",
      "        .   @param iterationsCount Number of iterations.\n",
      "        .   @param reprojectionError Inlier threshold value used by the RANSAC procedure. The parameter value\n",
      "        .   is the maximum allowed distance between the observed and computed point projections to consider it\n",
      "        .   an inlier.\n",
      "        .   @param confidence The probability that the algorithm produces a useful result.\n",
      "        .   @param inliers Output vector that contains indices of inliers in objectPoints and imagePoints .\n",
      "        .   @param flags Method for solving a PnP problem (see solvePnP ).\n",
      "        .   \n",
      "        .   The function estimates an object pose given a set of object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients. This function finds such\n",
      "        .   a pose that minimizes reprojection error, that is, the sum of squared distances between the observed\n",
      "        .   projections imagePoints and the projected (using projectPoints ) objectPoints. The use of RANSAC\n",
      "        .   makes the function resistant to outliers.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   An example of how to use solvePNPRansac for object detection can be found at\n",
      "        .   opencv_source_code/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/\n",
      "        .   -   The default method used to estimate the camera pose for the Minimal Sample Sets step\n",
      "        .   is #SOLVEPNP_EPNP. Exceptions are:\n",
      "        .   - if you choose #SOLVEPNP_P3P or #SOLVEPNP_AP3P, these methods will be used.\n",
      "        .   - if the number of input points is equal to 4, #SOLVEPNP_P3P is used.\n",
      "        .   -   The method used to estimate the camera pose using all the inliers is defined by the\n",
      "        .   flags parameters unless it is equal to #SOLVEPNP_P3P or #SOLVEPNP_AP3P. In this case,\n",
      "        .   the method #SOLVEPNP_EPNP will be used instead.\n",
      "    \n",
      "    solvePoly(...)\n",
      "        solvePoly(coeffs[, roots[, maxIters]]) -> retval, roots\n",
      "        .   @brief Finds the real or complex roots of a polynomial equation.\n",
      "        .   \n",
      "        .   The function cv::solvePoly finds real and complex roots of a polynomial equation:\n",
      "        .   \\f[\\texttt{coeffs} [n] x^{n} +  \\texttt{coeffs} [n-1] x^{n-1} + ... +  \\texttt{coeffs} [1] x +  \\texttt{coeffs} [0] = 0\\f]\n",
      "        .   @param coeffs array of polynomial coefficients.\n",
      "        .   @param roots output (complex) array of roots.\n",
      "        .   @param maxIters maximum number of iterations the algorithm does.\n",
      "    \n",
      "    sort(...)\n",
      "        sort(src, flags[, dst]) -> dst\n",
      "        .   @brief Sorts each row or each column of a matrix.\n",
      "        .   \n",
      "        .   The function cv::sort sorts each matrix row or each matrix column in\n",
      "        .   ascending or descending order. So you should pass two operation flags to\n",
      "        .   get desired behaviour. If you want to sort matrix rows or columns\n",
      "        .   lexicographically, you can use STL std::sort generic function with the\n",
      "        .   proper comparison predicate.\n",
      "        .   \n",
      "        .   @param src input single-channel array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flags operation flags, a combination of #SortFlags\n",
      "        .   @sa sortIdx, randShuffle\n",
      "    \n",
      "    sortIdx(...)\n",
      "        sortIdx(src, flags[, dst]) -> dst\n",
      "        .   @brief Sorts each row or each column of a matrix.\n",
      "        .   \n",
      "        .   The function cv::sortIdx sorts each matrix row or each matrix column in the\n",
      "        .   ascending or descending order. So you should pass two operation flags to\n",
      "        .   get desired behaviour. Instead of reordering the elements themselves, it\n",
      "        .   stores the indices of sorted elements in the output array. For example:\n",
      "        .   @code\n",
      "        .   Mat A = Mat::eye(3,3,CV_32F), B;\n",
      "        .   sortIdx(A, B, SORT_EVERY_ROW + SORT_ASCENDING);\n",
      "        .   // B will probably contain\n",
      "        .   // (because of equal elements in A some permutations are possible):\n",
      "        .   // [[1, 2, 0], [0, 2, 1], [0, 1, 2]]\n",
      "        .   @endcode\n",
      "        .   @param src input single-channel array.\n",
      "        .   @param dst output integer array of the same size as src.\n",
      "        .   @param flags operation flags that could be a combination of cv::SortFlags\n",
      "        .   @sa sort, randShuffle\n",
      "    \n",
      "    spatialGradient(...)\n",
      "        spatialGradient(src[, dx[, dy[, ksize[, borderType]]]]) -> dx, dy\n",
      "        .   @brief Calculates the first order image derivative in both x and y using a Sobel operator\n",
      "        .   \n",
      "        .   Equivalent to calling:\n",
      "        .   \n",
      "        .   @code\n",
      "        .   Sobel( src, dx, CV_16SC1, 1, 0, 3 );\n",
      "        .   Sobel( src, dy, CV_16SC1, 0, 1, 3 );\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dx output image with first-order derivative in x.\n",
      "        .   @param dy output image with first-order derivative in y.\n",
      "        .   @param ksize size of Sobel kernel. It must be 3.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes\n",
      "        .   \n",
      "        .   @sa Sobel\n",
      "    \n",
      "    split(...)\n",
      "        split(m[, mv]) -> mv\n",
      "        .   @overload\n",
      "        .   @param m input multi-channel array.\n",
      "        .   @param mv output vector of arrays; the arrays themselves are reallocated, if needed.\n",
      "    \n",
      "    sqrBoxFilter(...)\n",
      "        sqrBoxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
      "        .   @brief Calculates the normalized sum of squares of the pixel values overlapping the filter.\n",
      "        .   \n",
      "        .   For every pixel \\f$ (x, y) \\f$ in the source image, the function calculates the sum of squares of those neighboring\n",
      "        .   pixel values which overlap the filter placed over the pixel \\f$ (x, y) \\f$.\n",
      "        .   \n",
      "        .   The unnormalized square box filter can be useful in computing local image statistics such as the the local\n",
      "        .   variance and standard deviation around the neighborhood of a pixel.\n",
      "        .   \n",
      "        .   @param src input image\n",
      "        .   @param dst output image of the same size and type as _src\n",
      "        .   @param ddepth the output image depth (-1 to use src.depth())\n",
      "        .   @param ksize kernel size\n",
      "        .   @param anchor kernel anchor point. The default value of Point(-1, -1) denotes that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param normalize flag, specifying whether the kernel is to be normalized by it's area or not.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes\n",
      "        .   @sa boxFilter\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(src[, dst]) -> dst\n",
      "        .   @brief Calculates a square root of array elements.\n",
      "        .   \n",
      "        .   The function cv::sqrt calculates a square root of each input array element.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. The accuracy is approximately the same as of the built-in\n",
      "        .   std::sqrt .\n",
      "        .   @param src input floating-point array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "    \n",
      "    startWindowThread(...)\n",
      "        startWindowThread() -> retval\n",
      "        .\n",
      "    \n",
      "    stereoCalibrate(...)\n",
      "        stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize[, R[, T[, E[, F[, flags[, criteria]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F\n",
      "        .\n",
      "    \n",
      "    stereoCalibrateExtended(...)\n",
      "        stereoCalibrateExtended(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, perViewErrors[, flags[, criteria]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, perViewErrors\n",
      "        .   @brief Calibrates the stereo camera.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of the calibration pattern points.\n",
      "        .   @param imagePoints1 Vector of vectors of the projections of the calibration pattern points,\n",
      "        .   observed by the first camera.\n",
      "        .   @param imagePoints2 Vector of vectors of the projections of the calibration pattern points,\n",
      "        .   observed by the second camera.\n",
      "        .   @param cameraMatrix1 Input/output first camera matrix:\n",
      "        .   \\f$\\vecthreethree{f_x^{(j)}}{0}{c_x^{(j)}}{0}{f_y^{(j)}}{c_y^{(j)}}{0}{0}{1}\\f$ , \\f$j = 0,\\, 1\\f$ . If\n",
      "        .   any of CALIB_USE_INTRINSIC_GUESS , CALIB_FIX_ASPECT_RATIO ,\n",
      "        .   CALIB_FIX_INTRINSIC , or CALIB_FIX_FOCAL_LENGTH are specified, some or all of the\n",
      "        .   matrix components must be initialized. See the flags description for details.\n",
      "        .   @param distCoeffs1 Input/output vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. The output vector length depends on the flags.\n",
      "        .   @param cameraMatrix2 Input/output second camera matrix. The parameter is similar to cameraMatrix1\n",
      "        .   @param distCoeffs2 Input/output lens distortion coefficients for the second camera. The parameter\n",
      "        .   is similar to distCoeffs1 .\n",
      "        .   @param imageSize Size of the image used only to initialize intrinsic camera matrix.\n",
      "        .   @param R Output rotation matrix between the 1st and the 2nd camera coordinate systems.\n",
      "        .   @param T Output translation vector between the coordinate systems of the cameras.\n",
      "        .   @param E Output essential matrix.\n",
      "        .   @param F Output fundamental matrix.\n",
      "        .   @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of the following values:\n",
      "        .   -   **CALIB_FIX_INTRINSIC** Fix cameraMatrix? and distCoeffs? so that only R, T, E , and F\n",
      "        .   matrices are estimated.\n",
      "        .   -   **CALIB_USE_INTRINSIC_GUESS** Optimize some or all of the intrinsic parameters\n",
      "        .   according to the specified flags. Initial values are provided by the user.\n",
      "        .   -   **CALIB_USE_EXTRINSIC_GUESS** R, T contain valid initial values that are optimized further.\n",
      "        .   Otherwise R, T are initialized to the median value of the pattern views (each dimension separately).\n",
      "        .   -   **CALIB_FIX_PRINCIPAL_POINT** Fix the principal points during the optimization.\n",
      "        .   -   **CALIB_FIX_FOCAL_LENGTH** Fix \\f$f^{(j)}_x\\f$ and \\f$f^{(j)}_y\\f$ .\n",
      "        .   -   **CALIB_FIX_ASPECT_RATIO** Optimize \\f$f^{(j)}_y\\f$ . Fix the ratio \\f$f^{(j)}_x/f^{(j)}_y\\f$\n",
      "        .   .\n",
      "        .   -   **CALIB_SAME_FOCAL_LENGTH** Enforce \\f$f^{(0)}_x=f^{(1)}_x\\f$ and \\f$f^{(0)}_y=f^{(1)}_y\\f$ .\n",
      "        .   -   **CALIB_ZERO_TANGENT_DIST** Set tangential distortion coefficients for each camera to\n",
      "        .   zeros and fix there.\n",
      "        .   -   **CALIB_FIX_K1,...,CALIB_FIX_K6** Do not change the corresponding radial\n",
      "        .   distortion coefficient during the optimization. If CALIB_USE_INTRINSIC_GUESS is set,\n",
      "        .   the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_RATIONAL_MODEL** Enable coefficients k4, k5, and k6. To provide the backward\n",
      "        .   compatibility, this extra flag should be explicitly specified to make the calibration\n",
      "        .   function use the rational model and return 8 coefficients. If the flag is not set, the\n",
      "        .   function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_THIN_PRISM_MODEL** Coefficients s1, s2, s3 and s4 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the thin prism model and return 12 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_S1_S2_S3_S4** The thin prism distortion coefficients are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_TILTED_MODEL** Coefficients tauX and tauY are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the tilted sensor model and return 14 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_TAUX_TAUY** The coefficients of the tilted sensor model are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   The function estimates transformation between two cameras making a stereo pair. If you have a stereo\n",
      "        .   camera where the relative position and orientation of two cameras is fixed, and if you computed\n",
      "        .   poses of an object relative to the first camera and to the second camera, (R1, T1) and (R2, T2),\n",
      "        .   respectively (this can be done with solvePnP ), then those poses definitely relate to each other.\n",
      "        .   This means that, given ( \\f$R_1\\f$,\\f$T_1\\f$ ), it should be possible to compute ( \\f$R_2\\f$,\\f$T_2\\f$ ). You only\n",
      "        .   need to know the position and orientation of the second camera relative to the first camera. This is\n",
      "        .   what the described function does. It computes ( \\f$R\\f$,\\f$T\\f$ ) so that:\n",
      "        .   \n",
      "        .   \\f[R_2=R*R_1\\f]\n",
      "        .   \\f[T_2=R*T_1 + T,\\f]\n",
      "        .   \n",
      "        .   Optionally, it computes the essential matrix E:\n",
      "        .   \n",
      "        .   \\f[E= \\vecthreethree{0}{-T_2}{T_1}{T_2}{0}{-T_0}{-T_1}{T_0}{0} *R\\f]\n",
      "        .   \n",
      "        .   where \\f$T_i\\f$ are components of the translation vector \\f$T\\f$ : \\f$T=[T_0, T_1, T_2]^T\\f$ . And the function\n",
      "        .   can also compute the fundamental matrix F:\n",
      "        .   \n",
      "        .   \\f[F = cameraMatrix2^{-T} E cameraMatrix1^{-1}\\f]\n",
      "        .   \n",
      "        .   Besides the stereo-related information, the function can also perform a full calibration of each of\n",
      "        .   two cameras. However, due to the high dimensionality of the parameter space and noise in the input\n",
      "        .   data, the function can diverge from the correct solution. If the intrinsic parameters can be\n",
      "        .   estimated with high accuracy for each of the cameras individually (for example, using\n",
      "        .   calibrateCamera ), you are recommended to do so and then pass CALIB_FIX_INTRINSIC flag to the\n",
      "        .   function along with the computed intrinsic parameters. Otherwise, if all the parameters are\n",
      "        .   estimated at once, it makes sense to restrict some parameters, for example, pass\n",
      "        .   CALIB_SAME_FOCAL_LENGTH and CALIB_ZERO_TANGENT_DIST flags, which is usually a\n",
      "        .   reasonable assumption.\n",
      "        .   \n",
      "        .   Similarly to calibrateCamera , the function minimizes the total re-projection error for all the\n",
      "        .   points in all the available views from both cameras. The function returns the final value of the\n",
      "        .   re-projection error.\n",
      "    \n",
      "    stereoRectify(...)\n",
      "        stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, R1[, R2[, P1[, P2[, Q[, flags[, alpha[, newImageSize]]]]]]]]) -> R1, R2, P1, P2, Q, validPixROI1, validPixROI2\n",
      "        .   @brief Computes rectification transforms for each head of a calibrated stereo camera.\n",
      "        .   \n",
      "        .   @param cameraMatrix1 First camera matrix.\n",
      "        .   @param distCoeffs1 First camera distortion parameters.\n",
      "        .   @param cameraMatrix2 Second camera matrix.\n",
      "        .   @param distCoeffs2 Second camera distortion parameters.\n",
      "        .   @param imageSize Size of the image used for stereo calibration.\n",
      "        .   @param R Rotation matrix between the coordinate systems of the first and the second cameras.\n",
      "        .   @param T Translation vector between coordinate systems of the cameras.\n",
      "        .   @param R1 Output 3x3 rectification transform (rotation matrix) for the first camera.\n",
      "        .   @param R2 Output 3x3 rectification transform (rotation matrix) for the second camera.\n",
      "        .   @param P1 Output 3x4 projection matrix in the new (rectified) coordinate systems for the first\n",
      "        .   camera.\n",
      "        .   @param P2 Output 3x4 projection matrix in the new (rectified) coordinate systems for the second\n",
      "        .   camera.\n",
      "        .   @param Q Output \\f$4 \\times 4\\f$ disparity-to-depth mapping matrix (see reprojectImageTo3D ).\n",
      "        .   @param flags Operation flags that may be zero or CALIB_ZERO_DISPARITY . If the flag is set,\n",
      "        .   the function makes the principal points of each camera have the same pixel coordinates in the\n",
      "        .   rectified views. And if the flag is not set, the function may still shift the images in the\n",
      "        .   horizontal or vertical direction (depending on the orientation of epipolar lines) to maximize the\n",
      "        .   useful image area.\n",
      "        .   @param alpha Free scaling parameter. If it is -1 or absent, the function performs the default\n",
      "        .   scaling. Otherwise, the parameter should be between 0 and 1. alpha=0 means that the rectified\n",
      "        .   images are zoomed and shifted so that only valid pixels are visible (no black areas after\n",
      "        .   rectification). alpha=1 means that the rectified image is decimated and shifted so that all the\n",
      "        .   pixels from the original images from the cameras are retained in the rectified images (no source\n",
      "        .   image pixels are lost). Obviously, any intermediate value yields an intermediate result between\n",
      "        .   those two extreme cases.\n",
      "        .   @param newImageSize New image resolution after rectification. The same size should be passed to\n",
      "        .   initUndistortRectifyMap (see the stereo_calib.cpp sample in OpenCV samples directory). When (0,0)\n",
      "        .   is passed (default), it is set to the original imageSize . Setting it to larger value can help you\n",
      "        .   preserve details in the original image, especially when there is a big radial distortion.\n",
      "        .   @param validPixROI1 Optional output rectangles inside the rectified images where all the pixels\n",
      "        .   are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller\n",
      "        .   (see the picture below).\n",
      "        .   @param validPixROI2 Optional output rectangles inside the rectified images where all the pixels\n",
      "        .   are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller\n",
      "        .   (see the picture below).\n",
      "        .   \n",
      "        .   The function computes the rotation matrices for each camera that (virtually) make both camera image\n",
      "        .   planes the same plane. Consequently, this makes all the epipolar lines parallel and thus simplifies\n",
      "        .   the dense stereo correspondence problem. The function takes the matrices computed by stereoCalibrate\n",
      "        .   as input. As output, it provides two rotation matrices and also two projection matrices in the new\n",
      "        .   coordinates. The function distinguishes the following two cases:\n",
      "        .   \n",
      "        .   -   **Horizontal stereo**: the first and the second camera views are shifted relative to each other\n",
      "        .   mainly along the x axis (with possible small vertical shift). In the rectified images, the\n",
      "        .   corresponding epipolar lines in the left and right cameras are horizontal and have the same\n",
      "        .   y-coordinate. P1 and P2 look like:\n",
      "        .   \n",
      "        .   \\f[\\texttt{P1} = \\begin{bmatrix} f & 0 & cx_1 & 0 \\\\ 0 & f & cy & 0 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{P2} = \\begin{bmatrix} f & 0 & cx_2 & T_x*f \\\\ 0 & f & cy & 0 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$T_x\\f$ is a horizontal shift between the cameras and \\f$cx_1=cx_2\\f$ if\n",
      "        .   CALIB_ZERO_DISPARITY is set.\n",
      "        .   \n",
      "        .   -   **Vertical stereo**: the first and the second camera views are shifted relative to each other\n",
      "        .   mainly in vertical direction (and probably a bit in the horizontal direction too). The epipolar\n",
      "        .   lines in the rectified images are vertical and have the same x-coordinate. P1 and P2 look like:\n",
      "        .   \n",
      "        .   \\f[\\texttt{P1} = \\begin{bmatrix} f & 0 & cx & 0 \\\\ 0 & f & cy_1 & 0 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{P2} = \\begin{bmatrix} f & 0 & cx & 0 \\\\ 0 & f & cy_2 & T_y*f \\\\ 0 & 0 & 1 & 0 \\end{bmatrix} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$T_y\\f$ is a vertical shift between the cameras and \\f$cy_1=cy_2\\f$ if CALIB_ZERO_DISPARITY is\n",
      "        .   set.\n",
      "        .   \n",
      "        .   As you can see, the first three columns of P1 and P2 will effectively be the new \"rectified\" camera\n",
      "        .   matrices. The matrices, together with R1 and R2 , can then be passed to initUndistortRectifyMap to\n",
      "        .   initialize the rectification map for each camera.\n",
      "        .   \n",
      "        .   See below the screenshot from the stereo_calib.cpp sample. Some red horizontal lines pass through\n",
      "        .   the corresponding image regions. This means that the images are well rectified, which is what most\n",
      "        .   stereo correspondence algorithms rely on. The green rectangles are roi1 and roi2 . You see that\n",
      "        .   their interiors are all valid pixels.\n",
      "        .   \n",
      "        .   ![image](pics/stereo_undistort.jpg)\n",
      "    \n",
      "    stereoRectifyUncalibrated(...)\n",
      "        stereoRectifyUncalibrated(points1, points2, F, imgSize[, H1[, H2[, threshold]]]) -> retval, H1, H2\n",
      "        .   @brief Computes a rectification transform for an uncalibrated stereo camera.\n",
      "        .   \n",
      "        .   @param points1 Array of feature points in the first image.\n",
      "        .   @param points2 The corresponding points in the second image. The same formats as in\n",
      "        .   findFundamentalMat are supported.\n",
      "        .   @param F Input fundamental matrix. It can be computed from the same set of point pairs using\n",
      "        .   findFundamentalMat .\n",
      "        .   @param imgSize Size of the image.\n",
      "        .   @param H1 Output rectification homography matrix for the first image.\n",
      "        .   @param H2 Output rectification homography matrix for the second image.\n",
      "        .   @param threshold Optional threshold used to filter out the outliers. If the parameter is greater\n",
      "        .   than zero, all the point pairs that do not comply with the epipolar geometry (that is, the points\n",
      "        .   for which \\f$|\\texttt{points2[i]}^T*\\texttt{F}*\\texttt{points1[i]}|>\\texttt{threshold}\\f$ ) are\n",
      "        .   rejected prior to computing the homographies. Otherwise, all the points are considered inliers.\n",
      "        .   \n",
      "        .   The function computes the rectification transformations without knowing intrinsic parameters of the\n",
      "        .   cameras and their relative position in the space, which explains the suffix \"uncalibrated\". Another\n",
      "        .   related difference from stereoRectify is that the function outputs not the rectification\n",
      "        .   transformations in the object (3D) space, but the planar perspective transformations encoded by the\n",
      "        .   homography matrices H1 and H2 . The function implements the algorithm @cite Hartley99 .\n",
      "        .   \n",
      "        .   @note\n",
      "        .   While the algorithm does not need to know the intrinsic parameters of the cameras, it heavily\n",
      "        .   depends on the epipolar geometry. Therefore, if the camera lenses have a significant distortion,\n",
      "        .   it would be better to correct it before computing the fundamental matrix and calling this\n",
      "        .   function. For example, distortion coefficients can be estimated for each head of stereo camera\n",
      "        .   separately by using calibrateCamera . Then, the images can be corrected using undistort , or\n",
      "        .   just the point coordinates can be corrected with undistortPoints .\n",
      "    \n",
      "    stylization(...)\n",
      "        stylization(src[, dst[, sigma_s[, sigma_r]]]) -> dst\n",
      "        .   @brief Stylization aims to produce digital imagery with a wide variety of effects not focused on\n",
      "        .   photorealism. Edge-aware filters are ideal for stylization, as they can abstract regions of low\n",
      "        .   contrast while preserving, or enhancing, high-contrast features.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    subtract(...)\n",
      "        subtract(src1, src2[, dst[, mask[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element difference between two arrays or array and a scalar.\n",
      "        .   \n",
      "        .   The function subtract calculates:\n",
      "        .   - Difference between two arrays, when both input arrays have the same size and the same number of\n",
      "        .   channels:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) -  \\texttt{src2}(I)) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Difference between an array and a scalar, when src2 is constructed from Scalar or has the same\n",
      "        .   number of elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) -  \\texttt{src2} ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Difference between a scalar and an array, when src1 is constructed from Scalar or has the same\n",
      "        .   number of elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1} -  \\texttt{src2}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - The reverse difference between a scalar and an array in the case of `SubRS`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src2} -  \\texttt{src1}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   The first function in the list above can be replaced with matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .   dst = src1 - src2;\n",
      "        .   dst -= src1; // equivalent to subtract(dst, src1, dst);\n",
      "        .   @endcode\n",
      "        .   The input arrays and the output array can all have the same or different depths. For example, you\n",
      "        .   can subtract to 8-bit unsigned arrays and store the difference in a 16-bit signed array. Depth of\n",
      "        .   the output array is determined by dtype parameter. In the second and third cases above, as well as\n",
      "        .   in the first case, when src1.depth() == src2.depth(), dtype can be set to the default -1. In this\n",
      "        .   case the output array will have the same depth as the input array, be it src1, src2 or both.\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array of the same size and the same number of channels as the input array.\n",
      "        .   @param mask optional operation mask; this is an 8-bit single channel array that specifies elements\n",
      "        .   of the output array to be changed.\n",
      "        .   @param dtype optional depth of the output array\n",
      "        .   @sa  add, addWeighted, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    sumElems(...)\n",
      "        sumElems(src) -> retval\n",
      "        .   @brief Calculates the sum of array elements.\n",
      "        .   \n",
      "        .   The function cv::sum calculates and returns the sum of array elements,\n",
      "        .   independently for each channel.\n",
      "        .   @param src input array that must have from 1 to 4 channels.\n",
      "        .   @sa  countNonZero, mean, meanStdDev, norm, minMaxLoc, reduce\n",
      "    \n",
      "    textureFlattening(...)\n",
      "        textureFlattening(src, mask[, dst[, low_threshold[, high_threshold[, kernel_size]]]]) -> dst\n",
      "        .   @brief By retaining only the gradients at edge locations, before integrating with the Poisson solver, one\n",
      "        .   washes out the texture of the selected region, giving its contents a flat aspect. Here Canny Edge %Detector is used.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param low_threshold %Range from 0 to 100.\n",
      "        .   @param high_threshold Value \\> 100.\n",
      "        .   @param kernel_size The size of the Sobel kernel to be used.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The algorithm assumes that the color of the source image is close to that of the destination. This\n",
      "        .   assumption means that when the colors don't match, the source image color gets tinted toward the\n",
      "        .   color of the destination image.\n",
      "    \n",
      "    threshold(...)\n",
      "        threshold(src, thresh, maxval, type[, dst]) -> retval, dst\n",
      "        .   @brief Applies a fixed-level threshold to each array element.\n",
      "        .   \n",
      "        .   The function applies fixed-level thresholding to a multiple-channel array. The function is typically\n",
      "        .   used to get a bi-level (binary) image out of a grayscale image ( #compare could be also used for\n",
      "        .   this purpose) or for removing a noise, that is, filtering out pixels with too small or too large\n",
      "        .   values. There are several types of thresholding supported by the function. They are determined by\n",
      "        .   type parameter.\n",
      "        .   \n",
      "        .   Also, the special values #THRESH_OTSU or #THRESH_TRIANGLE may be combined with one of the\n",
      "        .   above values. In these cases, the function determines the optimal threshold value using the Otsu's\n",
      "        .   or Triangle algorithm and uses it instead of the specified thresh.\n",
      "        .   \n",
      "        .   @note Currently, the Otsu's and Triangle methods are implemented only for 8-bit single-channel images.\n",
      "        .   \n",
      "        .   @param src input array (multiple-channel, 8-bit or 32-bit floating point).\n",
      "        .   @param dst output array of the same size  and type and the same number of channels as src.\n",
      "        .   @param thresh threshold value.\n",
      "        .   @param maxval maximum value to use with the #THRESH_BINARY and #THRESH_BINARY_INV thresholding\n",
      "        .   types.\n",
      "        .   @param type thresholding type (see #ThresholdTypes).\n",
      "        .   @return the computed threshold value if Otsu's or Triangle methods used.\n",
      "        .   \n",
      "        .   @sa  adaptiveThreshold, findContours, compare, min, max\n",
      "    \n",
      "    trace(...)\n",
      "        trace(mtx) -> retval\n",
      "        .   @brief Returns the trace of a matrix.\n",
      "        .   \n",
      "        .   The function cv::trace returns the sum of the diagonal elements of the\n",
      "        .   matrix mtx .\n",
      "        .   \\f[\\mathrm{tr} ( \\texttt{mtx} ) =  \\sum _i  \\texttt{mtx} (i,i)\\f]\n",
      "        .   @param mtx input matrix.\n",
      "    \n",
      "    transform(...)\n",
      "        transform(src, m[, dst]) -> dst\n",
      "        .   @brief Performs the matrix transformation of every array element.\n",
      "        .   \n",
      "        .   The function cv::transform performs the matrix transformation of every\n",
      "        .   element of the array src and stores the results in dst :\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{m} \\cdot \\texttt{src} (I)\\f]\n",
      "        .   (when m.cols=src.channels() ), or\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{m} \\cdot [ \\texttt{src} (I); 1]\\f]\n",
      "        .   (when m.cols=src.channels()+1 )\n",
      "        .   \n",
      "        .   Every element of the N -channel array src is interpreted as N -element\n",
      "        .   vector that is transformed using the M x N or M x (N+1) matrix m to\n",
      "        .   M-element vector - the corresponding element of the output array dst .\n",
      "        .   \n",
      "        .   The function may be used for geometrical transformation of\n",
      "        .   N -dimensional points, arbitrary linear color space transformation (such\n",
      "        .   as various kinds of RGB to YUV transforms), shuffling the image\n",
      "        .   channels, and so forth.\n",
      "        .   @param src input array that must have as many channels (1 to 4) as\n",
      "        .   m.cols or m.cols-1.\n",
      "        .   @param dst output array of the same size and depth as src; it has as\n",
      "        .   many channels as m.rows.\n",
      "        .   @param m transformation 2x2 or 2x3 floating-point matrix.\n",
      "        .   @sa perspectiveTransform, getAffineTransform, estimateAffine2D, warpAffine, warpPerspective\n",
      "    \n",
      "    transpose(...)\n",
      "        transpose(src[, dst]) -> dst\n",
      "        .   @brief Transposes a matrix.\n",
      "        .   \n",
      "        .   The function cv::transpose transposes the matrix src :\n",
      "        .   \\f[\\texttt{dst} (i,j) =  \\texttt{src} (j,i)\\f]\n",
      "        .   @note No complex conjugation is done in case of a complex matrix. It\n",
      "        .   should be done separately if needed.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same type as src.\n",
      "    \n",
      "    triangulatePoints(...)\n",
      "        triangulatePoints(projMatr1, projMatr2, projPoints1, projPoints2[, points4D]) -> points4D\n",
      "        .   @brief Reconstructs points by triangulation.\n",
      "        .   \n",
      "        .   @param projMatr1 3x4 projection matrix of the first camera.\n",
      "        .   @param projMatr2 3x4 projection matrix of the second camera.\n",
      "        .   @param projPoints1 2xN array of feature points in the first image. In case of c++ version it can\n",
      "        .   be also a vector of feature points or two-channel matrix of size 1xN or Nx1.\n",
      "        .   @param projPoints2 2xN array of corresponding points in the second image. In case of c++ version\n",
      "        .   it can be also a vector of feature points or two-channel matrix of size 1xN or Nx1.\n",
      "        .   @param points4D 4xN array of reconstructed points in homogeneous coordinates.\n",
      "        .   \n",
      "        .   The function reconstructs 3-dimensional points (in homogeneous coordinates) by using their\n",
      "        .   observations with a stereo camera. Projections matrices can be obtained from stereoRectify.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   Keep in mind that all input data should be of float type in order for this function to work.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   reprojectImageTo3D\n",
      "    \n",
      "    undistort(...)\n",
      "        undistort(src, cameraMatrix, distCoeffs[, dst[, newCameraMatrix]]) -> dst\n",
      "        .   @brief Transforms an image to compensate for lens distortion.\n",
      "        .   \n",
      "        .   The function transforms an image to compensate radial and tangential lens distortion.\n",
      "        .   \n",
      "        .   The function is simply a combination of #initUndistortRectifyMap (with unity R ) and #remap\n",
      "        .   (with bilinear interpolation). See the former function for details of the transformation being\n",
      "        .   performed.\n",
      "        .   \n",
      "        .   Those pixels in the destination image, for which there is no correspondent pixels in the source\n",
      "        .   image, are filled with zeros (black color).\n",
      "        .   \n",
      "        .   A particular subset of the source image that will be visible in the corrected image can be regulated\n",
      "        .   by newCameraMatrix. You can use #getOptimalNewCameraMatrix to compute the appropriate\n",
      "        .   newCameraMatrix depending on your requirements.\n",
      "        .   \n",
      "        .   The camera matrix and the distortion parameters can be determined using #calibrateCamera. If\n",
      "        .   the resolution of images is different from the resolution used at the calibration stage, \\f$f_x,\n",
      "        .   f_y, c_x\\f$ and \\f$c_y\\f$ need to be scaled accordingly, while the distortion coefficients remain\n",
      "        .   the same.\n",
      "        .   \n",
      "        .   @param src Input (distorted) image.\n",
      "        .   @param dst Output (corrected) image that has the same size and type as src .\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param newCameraMatrix Camera matrix of the distorted image. By default, it is the same as\n",
      "        .   cameraMatrix but you may additionally scale and shift the result by using a different matrix.\n",
      "    \n",
      "    undistortPoints(...)\n",
      "        undistortPoints(src, cameraMatrix, distCoeffs[, dst[, R[, P]]]) -> dst\n",
      "        .   @brief Computes the ideal point coordinates from the observed point coordinates.\n",
      "        .   \n",
      "        .   The function is similar to #undistort and #initUndistortRectifyMap but it operates on a\n",
      "        .   sparse set of points instead of a raster image. Also the function performs a reverse transformation\n",
      "        .   to projectPoints. In case of a 3D object, it does not reconstruct its 3D coordinates, but for a\n",
      "        .   planar object, it does, up to a translation vector, if the proper R is specified.\n",
      "        .   \n",
      "        .   For each observed point coordinate \\f$(u, v)\\f$ the function computes:\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   x^{\"}  \\leftarrow (u - c_x)/f_x  \\\\\n",
      "        .   y^{\"}  \\leftarrow (v - c_y)/f_y  \\\\\n",
      "        .   (x',y') = undistort(x^{\"},y^{\"}, \\texttt{distCoeffs}) \\\\\n",
      "        .   {[X\\,Y\\,W]} ^T  \\leftarrow R*[x' \\, y' \\, 1]^T  \\\\\n",
      "        .   x  \\leftarrow X/W  \\\\\n",
      "        .   y  \\leftarrow Y/W  \\\\\n",
      "        .   \\text{only performed if P is specified:} \\\\\n",
      "        .   u'  \\leftarrow x {f'}_x + {c'}_x  \\\\\n",
      "        .   v'  \\leftarrow y {f'}_y + {c'}_y\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where *undistort* is an approximate iterative algorithm that estimates the normalized original\n",
      "        .   point coordinates out of the normalized distorted point coordinates (\"normalized\" means that the\n",
      "        .   coordinates do not depend on the camera matrix).\n",
      "        .   \n",
      "        .   The function can be used for both a stereo camera head or a monocular camera (when R is empty).\n",
      "        .   \n",
      "        .   @param src Observed point coordinates, 1xN or Nx1 2-channel (CV_32FC2 or CV_64FC2).\n",
      "        .   @param dst Output ideal point coordinates after undistortion and reverse perspective\n",
      "        .   transformation. If matrix P is identity or omitted, dst will contain normalized point coordinates.\n",
      "        .   @param cameraMatrix Camera matrix \\f$\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param R Rectification transformation in the object space (3x3 matrix). R1 or R2 computed by\n",
      "        .   #stereoRectify can be passed here. If the matrix is empty, the identity transformation is used.\n",
      "        .   @param P New camera matrix (3x3) or new projection matrix (3x4) \\f$\\begin{bmatrix} {f'}_x & 0 & {c'}_x & t_x \\\\ 0 & {f'}_y & {c'}_y & t_y \\\\ 0 & 0 & 1 & t_z \\end{bmatrix}\\f$. P1 or P2 computed by\n",
      "        .   #stereoRectify can be passed here. If the matrix is empty, the identity new camera matrix is used.\n",
      "    \n",
      "    undistortPointsIter(...)\n",
      "        undistortPointsIter(src, cameraMatrix, distCoeffs, R, P, criteria[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .   @note Default version of #undistortPoints does 5 iterations to compute undistorted points.\n",
      "    \n",
      "    useOpenVX(...)\n",
      "        useOpenVX() -> retval\n",
      "        .\n",
      "    \n",
      "    useOptimized(...)\n",
      "        useOptimized() -> retval\n",
      "        .   @brief Returns the status of optimized code usage.\n",
      "        .   \n",
      "        .   The function returns true if the optimized code is enabled. Otherwise, it returns false.\n",
      "    \n",
      "    validateDisparity(...)\n",
      "        validateDisparity(disparity, cost, minDisparity, numberOfDisparities[, disp12MaxDisp]) -> disparity\n",
      "        .\n",
      "    \n",
      "    vconcat(...)\n",
      "        vconcat(src[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .   @code{.cpp}\n",
      "        .   std::vector<cv::Mat> matrices = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\n",
      "        .   cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\n",
      "        .   cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\n",
      "        .   \n",
      "        .   cv::Mat out;\n",
      "        .   cv::vconcat( matrices, out );\n",
      "        .   //out:\n",
      "        .   //[1,   1,   1,   1;\n",
      "        .   // 2,   2,   2,   2;\n",
      "        .   // 3,   3,   3,   3]\n",
      "        .   @endcode\n",
      "        .   @param src input array or vector of matrices. all of the matrices must have the same number of cols and the same depth\n",
      "        .   @param dst output array. It has the same number of cols and depth as the src, and the sum of rows of the src.\n",
      "        .   same depth.\n",
      "    \n",
      "    waitKey(...)\n",
      "        waitKey([, delay]) -> retval\n",
      "        .   @brief Waits for a pressed key.\n",
      "        .   \n",
      "        .   The function waitKey waits for a key event infinitely (when \\f$\\texttt{delay}\\leq 0\\f$ ) or for delay\n",
      "        .   milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the\n",
      "        .   function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is\n",
      "        .   running on your computer at that time. It returns the code of the pressed key or -1 if no key was\n",
      "        .   pressed before the specified time had elapsed.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   This function is the only method in HighGUI that can fetch and handle events, so it needs to be\n",
      "        .   called periodically for normal event processing unless HighGUI is used within an environment that\n",
      "        .   takes care of event processing.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   The function only works if there is at least one HighGUI window created and the window is active.\n",
      "        .   If there are several HighGUI windows, any of them can be active.\n",
      "        .   \n",
      "        .   @param delay Delay in milliseconds. 0 is the special value that means \"forever\".\n",
      "    \n",
      "    waitKeyEx(...)\n",
      "        waitKeyEx([, delay]) -> retval\n",
      "        .   @brief Similar to #waitKey, but returns full key code.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   Key code is implementation specific and depends on used backend: QT/GTK/Win32/etc\n",
      "    \n",
      "    warpAffine(...)\n",
      "        warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
      "        .   @brief Applies an affine transformation to an image.\n",
      "        .   \n",
      "        .   The function warpAffine transforms the source image using the specified matrix:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} ( \\texttt{M} _{11} x +  \\texttt{M} _{12} y +  \\texttt{M} _{13}, \\texttt{M} _{21} x +  \\texttt{M} _{22} y +  \\texttt{M} _{23})\\f]\n",
      "        .   \n",
      "        .   when the flag #WARP_INVERSE_MAP is set. Otherwise, the transformation is first inverted\n",
      "        .   with #invertAffineTransform and then put in the formula above instead of M. The function cannot\n",
      "        .   operate in-place.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image that has the size dsize and the same type as src .\n",
      "        .   @param M \\f$2\\times 3\\f$ transformation matrix.\n",
      "        .   @param dsize size of the output image.\n",
      "        .   @param flags combination of interpolation methods (see #InterpolationFlags) and the optional\n",
      "        .   flag #WARP_INVERSE_MAP that means that M is the inverse transformation (\n",
      "        .   \\f$\\texttt{dst}\\rightarrow\\texttt{src}\\f$ ).\n",
      "        .   @param borderMode pixel extrapolation method (see #BorderTypes); when\n",
      "        .   borderMode=#BORDER_TRANSPARENT, it means that the pixels in the destination image corresponding to\n",
      "        .   the \"outliers\" in the source image are not modified by the function.\n",
      "        .   @param borderValue value used in case of a constant border; by default, it is 0.\n",
      "        .   \n",
      "        .   @sa  warpPerspective, resize, remap, getRectSubPix, transform\n",
      "    \n",
      "    warpPerspective(...)\n",
      "        warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
      "        .   @brief Applies a perspective transformation to an image.\n",
      "        .   \n",
      "        .   The function warpPerspective transforms the source image using the specified matrix:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} \\left ( \\frac{M_{11} x + M_{12} y + M_{13}}{M_{31} x + M_{32} y + M_{33}} ,\n",
      "        .   \\frac{M_{21} x + M_{22} y + M_{23}}{M_{31} x + M_{32} y + M_{33}} \\right )\\f]\n",
      "        .   \n",
      "        .   when the flag #WARP_INVERSE_MAP is set. Otherwise, the transformation is first inverted with invert\n",
      "        .   and then put in the formula above instead of M. The function cannot operate in-place.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image that has the size dsize and the same type as src .\n",
      "        .   @param M \\f$3\\times 3\\f$ transformation matrix.\n",
      "        .   @param dsize size of the output image.\n",
      "        .   @param flags combination of interpolation methods (#INTER_LINEAR or #INTER_NEAREST) and the\n",
      "        .   optional flag #WARP_INVERSE_MAP, that sets M as the inverse transformation (\n",
      "        .   \\f$\\texttt{dst}\\rightarrow\\texttt{src}\\f$ ).\n",
      "        .   @param borderMode pixel extrapolation method (#BORDER_CONSTANT or #BORDER_REPLICATE).\n",
      "        .   @param borderValue value used in case of a constant border; by default, it equals 0.\n",
      "        .   \n",
      "        .   @sa  warpAffine, resize, remap, getRectSubPix, perspectiveTransform\n",
      "    \n",
      "    warpPolar(...)\n",
      "        warpPolar(src, dsize, center, maxRadius, flags[, dst]) -> dst\n",
      "        .   \\brief Remaps an image to polar or semilog-polar coordinates space\n",
      "        .   \n",
      "        .   @anchor polar_remaps_reference_image\n",
      "        .   ![Polar remaps reference](pics/polar_remap_doc.png)\n",
      "        .   \n",
      "        .   Transform the source image using the following transformation:\n",
      "        .   \\f[\n",
      "        .   dst(\\rho , \\phi ) = src(x,y)\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   \\vec{I} = (x - center.x, \\;y - center.y) \\\\\n",
      "        .   \\phi = Kangle \\cdot \\texttt{angle} (\\vec{I}) \\\\\n",
      "        .   \\rho = \\left\\{\\begin{matrix}\n",
      "        .   Klin \\cdot \\texttt{magnitude} (\\vec{I}) & default \\\\\n",
      "        .   Klog \\cdot log_e(\\texttt{magnitude} (\\vec{I})) & if \\; semilog \\\\\n",
      "        .   \\end{matrix}\\right.\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   Kangle = dsize.height / 2\\Pi \\\\\n",
      "        .   Klin = dsize.width / maxRadius \\\\\n",
      "        .   Klog = dsize.width / log_e(maxRadius) \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   \\par Linear vs semilog mapping\n",
      "        .   \n",
      "        .   Polar mapping can be linear or semi-log. Add one of #WarpPolarMode to `flags` to specify the polar mapping mode.\n",
      "        .   \n",
      "        .   Linear is the default mode.\n",
      "        .   \n",
      "        .   The semilog mapping emulates the human \"foveal\" vision that permit very high acuity on the line of sight (central vision)\n",
      "        .   in contrast to peripheral vision where acuity is minor.\n",
      "        .   \n",
      "        .   \\par Option on `dsize`:\n",
      "        .   \n",
      "        .   - if both values in `dsize <=0 ` (default),\n",
      "        .   the destination image will have (almost) same area of source bounding circle:\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dsize.area  \\leftarrow (maxRadius^2 \\cdot \\Pi) \\\\\n",
      "        .   dsize.width = \\texttt{cvRound}(maxRadius) \\\\\n",
      "        .   dsize.height = \\texttt{cvRound}(maxRadius \\cdot \\Pi) \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - if only `dsize.height <= 0`,\n",
      "        .   the destination image area will be proportional to the bounding circle area but scaled by `Kx * Kx`:\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dsize.height = \\texttt{cvRound}(dsize.width \\cdot \\Pi) \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   - if both values in `dsize > 0 `,\n",
      "        .   the destination image will have the given size therefore the area of the bounding circle will be scaled to `dsize`.\n",
      "        .   \n",
      "        .   \n",
      "        .   \\par Reverse mapping\n",
      "        .   \n",
      "        .   You can get reverse mapping adding #WARP_INVERSE_MAP to `flags`\n",
      "        .   \\snippet polar_transforms.cpp InverseMap\n",
      "        .   \n",
      "        .   In addiction, to calculate the original coordinate from a polar mapped coordinate \\f$(rho, phi)->(x, y)\\f$:\n",
      "        .   \\snippet polar_transforms.cpp InverseCoordinate\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. It will have same type as src.\n",
      "        .   @param dsize The destination image size (see description for valid options).\n",
      "        .   @param center The transformation center.\n",
      "        .   @param maxRadius The radius of the bounding circle to transform. It determines the inverse magnitude scale parameter too.\n",
      "        .   @param flags A combination of interpolation methods, #InterpolationFlags + #WarpPolarMode.\n",
      "        .   - Add #WARP_POLAR_LINEAR to select linear polar mapping (default)\n",
      "        .   - Add #WARP_POLAR_LOG to select semilog polar mapping\n",
      "        .   - Add #WARP_INVERSE_MAP for reverse mapping.\n",
      "        .   @note\n",
      "        .   -  The function can not operate in-place.\n",
      "        .   -  To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   -  This function uses #remap. Due to current implementation limitations the size of an input and output images should be less than 32767x32767.\n",
      "        .   \n",
      "        .   @sa cv::remap\n",
      "    \n",
      "    watershed(...)\n",
      "        watershed(image, markers) -> markers\n",
      "        .   @brief Performs a marker-based image segmentation using the watershed algorithm.\n",
      "        .   \n",
      "        .   The function implements one of the variants of watershed, non-parametric marker-based segmentation\n",
      "        .   algorithm, described in @cite Meyer92 .\n",
      "        .   \n",
      "        .   Before passing the image to the function, you have to roughly outline the desired regions in the\n",
      "        .   image markers with positive (\\>0) indices. So, every region is represented as one or more connected\n",
      "        .   components with the pixel values 1, 2, 3, and so on. Such markers can be retrieved from a binary\n",
      "        .   mask using #findContours and #drawContours (see the watershed.cpp demo). The markers are \"seeds\" of\n",
      "        .   the future image regions. All the other pixels in markers , whose relation to the outlined regions\n",
      "        .   is not known and should be defined by the algorithm, should be set to 0's. In the function output,\n",
      "        .   each pixel in markers is set to a value of the \"seed\" components or to -1 at boundaries between the\n",
      "        .   regions.\n",
      "        .   \n",
      "        .   @note Any two neighbor connected components are not necessarily separated by a watershed boundary\n",
      "        .   (-1's pixels); for example, they can touch each other in the initial marker image passed to the\n",
      "        .   function.\n",
      "        .   \n",
      "        .   @param image Input 8-bit 3-channel image.\n",
      "        .   @param markers Input/output 32-bit single-channel image (map) of markers. It should have the same\n",
      "        .   size as image .\n",
      "        .   \n",
      "        .   @sa findContours\n",
      "        .   \n",
      "        .   @ingroup imgproc_misc\n",
      "    \n",
      "    writeOpticalFlow(...)\n",
      "        writeOpticalFlow(path, flow) -> retval\n",
      "        .   @brief Write a .flo to disk\n",
      "        .   \n",
      "        .   @param path Path to the file to be written\n",
      "        .   @param flow Flow field to be stored\n",
      "        .   \n",
      "        .   The function stores a flow field in a file, returns true on success, false otherwise.\n",
      "        .   The flow field must be a 2-channel, floating-point matrix (CV_32FC2). First channel corresponds\n",
      "        .   to the flow in the horizontal direction (u), second - vertical (v).\n",
      "\n",
      "DATA\n",
      "    ACCESS_FAST = 67108864\n",
      "    ACCESS_MASK = 50331648\n",
      "    ACCESS_READ = 16777216\n",
      "    ACCESS_RW = 50331648\n",
      "    ACCESS_WRITE = 33554432\n",
      "    ADAPTIVE_THRESH_GAUSSIAN_C = 1\n",
      "    ADAPTIVE_THRESH_MEAN_C = 0\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_5_8 = 0\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_7_12D = 1\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_7_12S = 2\n",
      "    AGAST_FEATURE_DETECTOR_NONMAX_SUPPRESSION = 10001\n",
      "    AGAST_FEATURE_DETECTOR_OAST_9_16 = 3\n",
      "    AGAST_FEATURE_DETECTOR_THRESHOLD = 10000\n",
      "    AKAZE_DESCRIPTOR_KAZE = 3\n",
      "    AKAZE_DESCRIPTOR_KAZE_UPRIGHT = 2\n",
      "    AKAZE_DESCRIPTOR_MLDB = 5\n",
      "    AKAZE_DESCRIPTOR_MLDB_UPRIGHT = 4\n",
      "    AgastFeatureDetector_AGAST_5_8 = 0\n",
      "    AgastFeatureDetector_AGAST_7_12d = 1\n",
      "    AgastFeatureDetector_AGAST_7_12s = 2\n",
      "    AgastFeatureDetector_NONMAX_SUPPRESSION = 10001\n",
      "    AgastFeatureDetector_OAST_9_16 = 3\n",
      "    AgastFeatureDetector_THRESHOLD = 10000\n",
      "    BORDER_CONSTANT = 0\n",
      "    BORDER_DEFAULT = 4\n",
      "    BORDER_ISOLATED = 16\n",
      "    BORDER_REFLECT = 2\n",
      "    BORDER_REFLECT101 = 4\n",
      "    BORDER_REFLECT_101 = 4\n",
      "    BORDER_REPLICATE = 1\n",
      "    BORDER_TRANSPARENT = 5\n",
      "    BORDER_WRAP = 3\n",
      "    CALIB_CB_ACCURACY = 32\n",
      "    CALIB_CB_ADAPTIVE_THRESH = 1\n",
      "    CALIB_CB_ASYMMETRIC_GRID = 2\n",
      "    CALIB_CB_CLUSTERING = 4\n",
      "    CALIB_CB_EXHAUSTIVE = 16\n",
      "    CALIB_CB_FAST_CHECK = 8\n",
      "    CALIB_CB_FILTER_QUADS = 4\n",
      "    CALIB_CB_NORMALIZE_IMAGE = 2\n",
      "    CALIB_CB_SYMMETRIC_GRID = 1\n",
      "    CALIB_FIX_ASPECT_RATIO = 2\n",
      "    CALIB_FIX_FOCAL_LENGTH = 16\n",
      "    CALIB_FIX_INTRINSIC = 256\n",
      "    CALIB_FIX_K1 = 32\n",
      "    CALIB_FIX_K2 = 64\n",
      "    CALIB_FIX_K3 = 128\n",
      "    CALIB_FIX_K4 = 2048\n",
      "    CALIB_FIX_K5 = 4096\n",
      "    CALIB_FIX_K6 = 8192\n",
      "    CALIB_FIX_PRINCIPAL_POINT = 4\n",
      "    CALIB_FIX_S1_S2_S3_S4 = 65536\n",
      "    CALIB_FIX_TANGENT_DIST = 2097152\n",
      "    CALIB_FIX_TAUX_TAUY = 524288\n",
      "    CALIB_HAND_EYE_ANDREFF = 3\n",
      "    CALIB_HAND_EYE_DANIILIDIS = 4\n",
      "    CALIB_HAND_EYE_HORAUD = 2\n",
      "    CALIB_HAND_EYE_PARK = 1\n",
      "    CALIB_HAND_EYE_TSAI = 0\n",
      "    CALIB_NINTRINSIC = 18\n",
      "    CALIB_RATIONAL_MODEL = 16384\n",
      "    CALIB_SAME_FOCAL_LENGTH = 512\n",
      "    CALIB_THIN_PRISM_MODEL = 32768\n",
      "    CALIB_TILTED_MODEL = 262144\n",
      "    CALIB_USE_EXTRINSIC_GUESS = 4194304\n",
      "    CALIB_USE_INTRINSIC_GUESS = 1\n",
      "    CALIB_USE_LU = 131072\n",
      "    CALIB_USE_QR = 1048576\n",
      "    CALIB_ZERO_DISPARITY = 1024\n",
      "    CALIB_ZERO_TANGENT_DIST = 8\n",
      "    CAP_ANDROID = 1000\n",
      "    CAP_ANY = 0\n",
      "    CAP_ARAVIS = 2100\n",
      "    CAP_AVFOUNDATION = 1200\n",
      "    CAP_CMU1394 = 300\n",
      "    CAP_DC1394 = 300\n",
      "    CAP_DSHOW = 700\n",
      "    CAP_FFMPEG = 1900\n",
      "    CAP_FIREWARE = 300\n",
      "    CAP_FIREWIRE = 300\n",
      "    CAP_GIGANETIX = 1300\n",
      "    CAP_GPHOTO2 = 1700\n",
      "    CAP_GSTREAMER = 1800\n",
      "    CAP_IEEE1394 = 300\n",
      "    CAP_IMAGES = 2000\n",
      "    CAP_INTELPERC = 1500\n",
      "    CAP_INTELPERC_DEPTH_GENERATOR = 536870912\n",
      "    CAP_INTELPERC_DEPTH_MAP = 0\n",
      "    CAP_INTELPERC_GENERATORS_MASK = 939524096\n",
      "    CAP_INTELPERC_IMAGE = 3\n",
      "    CAP_INTELPERC_IMAGE_GENERATOR = 268435456\n",
      "    CAP_INTELPERC_IR_GENERATOR = 134217728\n",
      "    CAP_INTELPERC_IR_MAP = 2\n",
      "    CAP_INTELPERC_UVDEPTH_MAP = 1\n",
      "    CAP_INTEL_MFX = 2300\n",
      "    CAP_MSMF = 1400\n",
      "    CAP_OPENCV_MJPEG = 2200\n",
      "    CAP_OPENNI = 900\n",
      "    CAP_OPENNI2 = 1600\n",
      "    CAP_OPENNI2_ASUS = 1610\n",
      "    CAP_OPENNI_ASUS = 910\n",
      "    CAP_OPENNI_BGR_IMAGE = 5\n",
      "    CAP_OPENNI_DEPTH_GENERATOR = -2147483648\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_BASELINE = -2147483546\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_FOCAL_LENGTH = -2147483545\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_PRESENT = -2147483539\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION = -2147483544\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION_ON = -2147483544\n",
      "    CAP_OPENNI_DEPTH_MAP = 0\n",
      "    CAP_OPENNI_DISPARITY_MAP = 2\n",
      "    CAP_OPENNI_DISPARITY_MAP_32F = 3\n",
      "    CAP_OPENNI_GENERATORS_MASK = -536870912\n",
      "    CAP_OPENNI_GRAY_IMAGE = 6\n",
      "    CAP_OPENNI_IMAGE_GENERATOR = 1073741824\n",
      "    CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE = 1073741924\n",
      "    CAP_OPENNI_IMAGE_GENERATOR_PRESENT = 1073741933\n",
      "    CAP_OPENNI_IR_GENERATOR = 536870912\n",
      "    CAP_OPENNI_IR_GENERATOR_PRESENT = 536871021\n",
      "    CAP_OPENNI_IR_IMAGE = 7\n",
      "    CAP_OPENNI_POINT_CLOUD_MAP = 1\n",
      "    CAP_OPENNI_QVGA_30HZ = 3\n",
      "    CAP_OPENNI_QVGA_60HZ = 4\n",
      "    CAP_OPENNI_SXGA_15HZ = 1\n",
      "    CAP_OPENNI_SXGA_30HZ = 2\n",
      "    CAP_OPENNI_VALID_DEPTH_MASK = 4\n",
      "    CAP_OPENNI_VGA_30HZ = 0\n",
      "    CAP_PROP_APERTURE = 17008\n",
      "    CAP_PROP_AUTOFOCUS = 39\n",
      "    CAP_PROP_AUTO_EXPOSURE = 21\n",
      "    CAP_PROP_AUTO_WB = 44\n",
      "    CAP_PROP_BACKEND = 42\n",
      "    CAP_PROP_BACKLIGHT = 32\n",
      "    CAP_PROP_BRIGHTNESS = 10\n",
      "    CAP_PROP_BUFFERSIZE = 38\n",
      "    CAP_PROP_CHANNEL = 43\n",
      "    CAP_PROP_CONTRAST = 11\n",
      "    CAP_PROP_CONVERT_RGB = 16\n",
      "    CAP_PROP_DC1394_MAX = 31\n",
      "    CAP_PROP_DC1394_MODE_AUTO = -2\n",
      "    CAP_PROP_DC1394_MODE_MANUAL = -3\n",
      "    CAP_PROP_DC1394_MODE_ONE_PUSH_AUTO = -1\n",
      "    CAP_PROP_DC1394_OFF = -4\n",
      "    CAP_PROP_EXPOSURE = 15\n",
      "    CAP_PROP_EXPOSUREPROGRAM = 17009\n",
      "    CAP_PROP_FOCUS = 28\n",
      "    CAP_PROP_FORMAT = 8\n",
      "    CAP_PROP_FOURCC = 6\n",
      "    CAP_PROP_FPS = 5\n",
      "    CAP_PROP_FRAME_COUNT = 7\n",
      "    CAP_PROP_FRAME_HEIGHT = 4\n",
      "    CAP_PROP_FRAME_WIDTH = 3\n",
      "    CAP_PROP_GAIN = 14\n",
      "    CAP_PROP_GAMMA = 22\n",
      "    CAP_PROP_GIGA_FRAME_HEIGH_MAX = 10004\n",
      "    CAP_PROP_GIGA_FRAME_OFFSET_X = 10001\n",
      "    CAP_PROP_GIGA_FRAME_OFFSET_Y = 10002\n",
      "    CAP_PROP_GIGA_FRAME_SENS_HEIGH = 10006\n",
      "    CAP_PROP_GIGA_FRAME_SENS_WIDTH = 10005\n",
      "    CAP_PROP_GIGA_FRAME_WIDTH_MAX = 10003\n",
      "    CAP_PROP_GPHOTO2_COLLECT_MSGS = 17005\n",
      "    CAP_PROP_GPHOTO2_FLUSH_MSGS = 17006\n",
      "    CAP_PROP_GPHOTO2_PREVIEW = 17001\n",
      "    CAP_PROP_GPHOTO2_RELOAD_CONFIG = 17003\n",
      "    CAP_PROP_GPHOTO2_RELOAD_ON_CHANGE = 17004\n",
      "    CAP_PROP_GPHOTO2_WIDGET_ENUMERATE = 17002\n",
      "    CAP_PROP_GSTREAMER_QUEUE_LENGTH = 200\n",
      "    CAP_PROP_GUID = 29\n",
      "    CAP_PROP_HUE = 13\n",
      "    CAP_PROP_IMAGES_BASE = 18000\n",
      "    CAP_PROP_IMAGES_LAST = 19000\n",
      "    CAP_PROP_INTELPERC_DEPTH_CONFIDENCE_THRESHOLD = 11005\n",
      "    CAP_PROP_INTELPERC_DEPTH_FOCAL_LENGTH_HORZ = 11006\n",
      "    CAP_PROP_INTELPERC_DEPTH_FOCAL_LENGTH_VERT = 11007\n",
      "    CAP_PROP_INTELPERC_DEPTH_LOW_CONFIDENCE_VALUE = 11003\n",
      "    CAP_PROP_INTELPERC_DEPTH_SATURATION_VALUE = 11004\n",
      "    CAP_PROP_INTELPERC_PROFILE_COUNT = 11001\n",
      "    CAP_PROP_INTELPERC_PROFILE_IDX = 11002\n",
      "    CAP_PROP_IOS_DEVICE_EXPOSURE = 9002\n",
      "    CAP_PROP_IOS_DEVICE_FLASH = 9003\n",
      "    CAP_PROP_IOS_DEVICE_FOCUS = 9001\n",
      "    CAP_PROP_IOS_DEVICE_TORCH = 9005\n",
      "    CAP_PROP_IOS_DEVICE_WHITEBALANCE = 9004\n",
      "    CAP_PROP_IRIS = 36\n",
      "    CAP_PROP_ISO_SPEED = 30\n",
      "    CAP_PROP_MODE = 9\n",
      "    CAP_PROP_MONOCHROME = 19\n",
      "    CAP_PROP_OPENNI2_MIRROR = 111\n",
      "    CAP_PROP_OPENNI2_SYNC = 110\n",
      "    CAP_PROP_OPENNI_APPROX_FRAME_SYNC = 105\n",
      "    CAP_PROP_OPENNI_BASELINE = 102\n",
      "    CAP_PROP_OPENNI_CIRCLE_BUFFER = 107\n",
      "    CAP_PROP_OPENNI_FOCAL_LENGTH = 103\n",
      "    CAP_PROP_OPENNI_FRAME_MAX_DEPTH = 101\n",
      "    CAP_PROP_OPENNI_GENERATOR_PRESENT = 109\n",
      "    CAP_PROP_OPENNI_MAX_BUFFER_SIZE = 106\n",
      "    CAP_PROP_OPENNI_MAX_TIME_DURATION = 108\n",
      "    CAP_PROP_OPENNI_OUTPUT_MODE = 100\n",
      "    CAP_PROP_OPENNI_REGISTRATION = 104\n",
      "    CAP_PROP_OPENNI_REGISTRATION_ON = 104\n",
      "    CAP_PROP_PAN = 33\n",
      "    CAP_PROP_POS_AVI_RATIO = 2\n",
      "    CAP_PROP_POS_FRAMES = 1\n",
      "    CAP_PROP_POS_MSEC = 0\n",
      "    CAP_PROP_PVAPI_BINNINGX = 304\n",
      "    CAP_PROP_PVAPI_BINNINGY = 305\n",
      "    CAP_PROP_PVAPI_DECIMATIONHORIZONTAL = 302\n",
      "    CAP_PROP_PVAPI_DECIMATIONVERTICAL = 303\n",
      "    CAP_PROP_PVAPI_FRAMESTARTTRIGGERMODE = 301\n",
      "    CAP_PROP_PVAPI_MULTICASTIP = 300\n",
      "    CAP_PROP_PVAPI_PIXELFORMAT = 306\n",
      "    CAP_PROP_RECTIFICATION = 18\n",
      "    CAP_PROP_ROLL = 35\n",
      "    CAP_PROP_SAR_DEN = 41\n",
      "    CAP_PROP_SAR_NUM = 40\n",
      "    CAP_PROP_SATURATION = 12\n",
      "    CAP_PROP_SETTINGS = 37\n",
      "    CAP_PROP_SHARPNESS = 20\n",
      "    CAP_PROP_SPEED = 17007\n",
      "    CAP_PROP_TEMPERATURE = 23\n",
      "    CAP_PROP_TILT = 34\n",
      "    CAP_PROP_TRIGGER = 24\n",
      "    CAP_PROP_TRIGGER_DELAY = 25\n",
      "    CAP_PROP_VIEWFINDER = 17010\n",
      "    CAP_PROP_WB_TEMPERATURE = 45\n",
      "    CAP_PROP_WHITE_BALANCE_BLUE_U = 17\n",
      "    CAP_PROP_WHITE_BALANCE_RED_V = 26\n",
      "    CAP_PROP_XI_ACQ_BUFFER_SIZE = 548\n",
      "    CAP_PROP_XI_ACQ_BUFFER_SIZE_UNIT = 549\n",
      "    CAP_PROP_XI_ACQ_FRAME_BURST_COUNT = 499\n",
      "    CAP_PROP_XI_ACQ_TIMING_MODE = 538\n",
      "    CAP_PROP_XI_ACQ_TRANSPORT_BUFFER_COMMIT = 552\n",
      "    CAP_PROP_XI_ACQ_TRANSPORT_BUFFER_SIZE = 550\n",
      "    CAP_PROP_XI_AEAG = 415\n",
      "    CAP_PROP_XI_AEAG_LEVEL = 419\n",
      "    CAP_PROP_XI_AEAG_ROI_HEIGHT = 442\n",
      "    CAP_PROP_XI_AEAG_ROI_OFFSET_X = 439\n",
      "    CAP_PROP_XI_AEAG_ROI_OFFSET_Y = 440\n",
      "    CAP_PROP_XI_AEAG_ROI_WIDTH = 441\n",
      "    CAP_PROP_XI_AE_MAX_LIMIT = 417\n",
      "    CAP_PROP_XI_AG_MAX_LIMIT = 418\n",
      "    CAP_PROP_XI_APPLY_CMS = 471\n",
      "    CAP_PROP_XI_AUTO_BANDWIDTH_CALCULATION = 573\n",
      "    CAP_PROP_XI_AUTO_WB = 414\n",
      "    CAP_PROP_XI_AVAILABLE_BANDWIDTH = 539\n",
      "    CAP_PROP_XI_BINNING_HORIZONTAL = 429\n",
      "    CAP_PROP_XI_BINNING_PATTERN = 430\n",
      "    CAP_PROP_XI_BINNING_SELECTOR = 427\n",
      "    CAP_PROP_XI_BINNING_VERTICAL = 428\n",
      "    CAP_PROP_XI_BPC = 445\n",
      "    CAP_PROP_XI_BUFFERS_QUEUE_SIZE = 551\n",
      "    CAP_PROP_XI_BUFFER_POLICY = 540\n",
      "    CAP_PROP_XI_CC_MATRIX_00 = 479\n",
      "    CAP_PROP_XI_CC_MATRIX_01 = 480\n",
      "    CAP_PROP_XI_CC_MATRIX_02 = 481\n",
      "    CAP_PROP_XI_CC_MATRIX_03 = 482\n",
      "    CAP_PROP_XI_CC_MATRIX_10 = 483\n",
      "    CAP_PROP_XI_CC_MATRIX_11 = 484\n",
      "    CAP_PROP_XI_CC_MATRIX_12 = 485\n",
      "    CAP_PROP_XI_CC_MATRIX_13 = 486\n",
      "    CAP_PROP_XI_CC_MATRIX_20 = 487\n",
      "    CAP_PROP_XI_CC_MATRIX_21 = 488\n",
      "    CAP_PROP_XI_CC_MATRIX_22 = 489\n",
      "    CAP_PROP_XI_CC_MATRIX_23 = 490\n",
      "    CAP_PROP_XI_CC_MATRIX_30 = 491\n",
      "    CAP_PROP_XI_CC_MATRIX_31 = 492\n",
      "    CAP_PROP_XI_CC_MATRIX_32 = 493\n",
      "    CAP_PROP_XI_CC_MATRIX_33 = 494\n",
      "    CAP_PROP_XI_CHIP_TEMP = 468\n",
      "    CAP_PROP_XI_CMS = 470\n",
      "    CAP_PROP_XI_COLOR_FILTER_ARRAY = 475\n",
      "    CAP_PROP_XI_COLUMN_FPN_CORRECTION = 555\n",
      "    CAP_PROP_XI_COOLING = 466\n",
      "    CAP_PROP_XI_COUNTER_SELECTOR = 536\n",
      "    CAP_PROP_XI_COUNTER_VALUE = 537\n",
      "    CAP_PROP_XI_DATA_FORMAT = 401\n",
      "    CAP_PROP_XI_DEBOUNCE_EN = 507\n",
      "    CAP_PROP_XI_DEBOUNCE_POL = 510\n",
      "    CAP_PROP_XI_DEBOUNCE_T0 = 508\n",
      "    CAP_PROP_XI_DEBOUNCE_T1 = 509\n",
      "    CAP_PROP_XI_DEBUG_LEVEL = 572\n",
      "    CAP_PROP_XI_DECIMATION_HORIZONTAL = 433\n",
      "    CAP_PROP_XI_DECIMATION_PATTERN = 434\n",
      "    CAP_PROP_XI_DECIMATION_SELECTOR = 431\n",
      "    CAP_PROP_XI_DECIMATION_VERTICAL = 432\n",
      "    CAP_PROP_XI_DEFAULT_CC_MATRIX = 495\n",
      "    CAP_PROP_XI_DEVICE_MODEL_ID = 521\n",
      "    CAP_PROP_XI_DEVICE_RESET = 554\n",
      "    CAP_PROP_XI_DEVICE_SN = 522\n",
      "    CAP_PROP_XI_DOWNSAMPLING = 400\n",
      "    CAP_PROP_XI_DOWNSAMPLING_TYPE = 426\n",
      "    CAP_PROP_XI_EXPOSURE = 421\n",
      "    CAP_PROP_XI_EXPOSURE_BURST_COUNT = 422\n",
      "    CAP_PROP_XI_EXP_PRIORITY = 416\n",
      "    CAP_PROP_XI_FFS_ACCESS_KEY = 583\n",
      "    CAP_PROP_XI_FFS_FILE_ID = 594\n",
      "    CAP_PROP_XI_FFS_FILE_SIZE = 580\n",
      "    CAP_PROP_XI_FRAMERATE = 535\n",
      "    CAP_PROP_XI_FREE_FFS_SIZE = 581\n",
      "    CAP_PROP_XI_GAIN = 424\n",
      "    CAP_PROP_XI_GAIN_SELECTOR = 423\n",
      "    CAP_PROP_XI_GAMMAC = 477\n",
      "    CAP_PROP_XI_GAMMAY = 476\n",
      "    CAP_PROP_XI_GPI_LEVEL = 408\n",
      "    CAP_PROP_XI_GPI_MODE = 407\n",
      "    CAP_PROP_XI_GPI_SELECTOR = 406\n",
      "    CAP_PROP_XI_GPO_MODE = 410\n",
      "    CAP_PROP_XI_GPO_SELECTOR = 409\n",
      "    CAP_PROP_XI_HDR = 559\n",
      "    CAP_PROP_XI_HDR_KNEEPOINT_COUNT = 560\n",
      "    CAP_PROP_XI_HDR_T1 = 561\n",
      "    CAP_PROP_XI_HDR_T2 = 562\n",
      "    CAP_PROP_XI_HEIGHT = 452\n",
      "    CAP_PROP_XI_HOUS_BACK_SIDE_TEMP = 590\n",
      "    CAP_PROP_XI_HOUS_TEMP = 469\n",
      "    CAP_PROP_XI_HW_REVISION = 571\n",
      "    CAP_PROP_XI_IMAGE_BLACK_LEVEL = 565\n",
      "    CAP_PROP_XI_IMAGE_DATA_BIT_DEPTH = 462\n",
      "    CAP_PROP_XI_IMAGE_DATA_FORMAT = 435\n",
      "    CAP_PROP_XI_IMAGE_DATA_FORMAT_RGB32_ALPHA = 529\n",
      "    CAP_PROP_XI_IMAGE_IS_COLOR = 474\n",
      "    CAP_PROP_XI_IMAGE_PAYLOAD_SIZE = 530\n",
      "    CAP_PROP_XI_IS_COOLED = 465\n",
      "    CAP_PROP_XI_IS_DEVICE_EXIST = 547\n",
      "    CAP_PROP_XI_KNEEPOINT1 = 563\n",
      "    CAP_PROP_XI_KNEEPOINT2 = 564\n",
      "    CAP_PROP_XI_LED_MODE = 412\n",
      "    CAP_PROP_XI_LED_SELECTOR = 411\n",
      "    CAP_PROP_XI_LENS_APERTURE_VALUE = 512\n",
      "    CAP_PROP_XI_LENS_FEATURE = 518\n",
      "    CAP_PROP_XI_LENS_FEATURE_SELECTOR = 517\n",
      "    CAP_PROP_XI_LENS_FOCAL_LENGTH = 516\n",
      "    CAP_PROP_XI_LENS_FOCUS_DISTANCE = 515\n",
      "    CAP_PROP_XI_LENS_FOCUS_MOVE = 514\n",
      "    CAP_PROP_XI_LENS_FOCUS_MOVEMENT_VALUE = 513\n",
      "    CAP_PROP_XI_LENS_MODE = 511\n",
      "    CAP_PROP_XI_LIMIT_BANDWIDTH = 459\n",
      "    CAP_PROP_XI_LUT_EN = 541\n",
      "    CAP_PROP_XI_LUT_INDEX = 542\n",
      "    CAP_PROP_XI_LUT_VALUE = 543\n",
      "    CAP_PROP_XI_MANUAL_WB = 413\n",
      "    CAP_PROP_XI_OFFSET_X = 402\n",
      "    CAP_PROP_XI_OFFSET_Y = 403\n",
      "    CAP_PROP_XI_OUTPUT_DATA_BIT_DEPTH = 461\n",
      "    CAP_PROP_XI_OUTPUT_DATA_PACKING = 463\n",
      "    CAP_PROP_XI_OUTPUT_DATA_PACKING_TYPE = 464\n",
      "    CAP_PROP_XI_RECENT_FRAME = 553\n",
      "    CAP_PROP_XI_REGION_MODE = 595\n",
      "    CAP_PROP_XI_REGION_SELECTOR = 589\n",
      "    CAP_PROP_XI_ROW_FPN_CORRECTION = 591\n",
      "    CAP_PROP_XI_SENSOR_BOARD_TEMP = 596\n",
      "    CAP_PROP_XI_SENSOR_CLOCK_FREQ_HZ = 532\n",
      "    CAP_PROP_XI_SENSOR_CLOCK_FREQ_INDEX = 533\n",
      "    CAP_PROP_XI_SENSOR_DATA_BIT_DEPTH = 460\n",
      "    CAP_PROP_XI_SENSOR_FEATURE_SELECTOR = 585\n",
      "    CAP_PROP_XI_SENSOR_FEATURE_VALUE = 586\n",
      "    CAP_PROP_XI_SENSOR_MODE = 558\n",
      "    CAP_PROP_XI_SENSOR_OUTPUT_CHANNEL_COUNT = 534\n",
      "    CAP_PROP_XI_SENSOR_TAPS = 437\n",
      "    CAP_PROP_XI_SHARPNESS = 478\n",
      "    CAP_PROP_XI_SHUTTER_TYPE = 436\n",
      "    CAP_PROP_XI_TARGET_TEMP = 467\n",
      "    CAP_PROP_XI_TEST_PATTERN = 588\n",
      "    CAP_PROP_XI_TEST_PATTERN_GENERATOR_SELECTOR = 587\n",
      "    CAP_PROP_XI_TIMEOUT = 420\n",
      "    CAP_PROP_XI_TRANSPORT_PIXEL_FORMAT = 531\n",
      "    CAP_PROP_XI_TRG_DELAY = 544\n",
      "    CAP_PROP_XI_TRG_SELECTOR = 498\n",
      "    CAP_PROP_XI_TRG_SOFTWARE = 405\n",
      "    CAP_PROP_XI_TRG_SOURCE = 404\n",
      "    CAP_PROP_XI_TS_RST_MODE = 545\n",
      "    CAP_PROP_XI_TS_RST_SOURCE = 546\n",
      "    CAP_PROP_XI_USED_FFS_SIZE = 582\n",
      "    CAP_PROP_XI_WB_KB = 450\n",
      "    CAP_PROP_XI_WB_KG = 449\n",
      "    CAP_PROP_XI_WB_KR = 448\n",
      "    CAP_PROP_XI_WIDTH = 451\n",
      "    CAP_PROP_ZOOM = 27\n",
      "    CAP_PVAPI = 800\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF16 = 8\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF4 = 2\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF8 = 4\n",
      "    CAP_PVAPI_DECIMATION_OFF = 1\n",
      "    CAP_PVAPI_FSTRIGMODE_FIXEDRATE = 3\n",
      "    CAP_PVAPI_FSTRIGMODE_FREERUN = 0\n",
      "    CAP_PVAPI_FSTRIGMODE_SOFTWARE = 4\n",
      "    CAP_PVAPI_FSTRIGMODE_SYNCIN1 = 1\n",
      "    CAP_PVAPI_FSTRIGMODE_SYNCIN2 = 2\n",
      "    CAP_PVAPI_PIXELFORMAT_BAYER16 = 4\n",
      "    CAP_PVAPI_PIXELFORMAT_BAYER8 = 3\n",
      "    CAP_PVAPI_PIXELFORMAT_BGR24 = 6\n",
      "    CAP_PVAPI_PIXELFORMAT_BGRA32 = 8\n",
      "    CAP_PVAPI_PIXELFORMAT_MONO16 = 2\n",
      "    CAP_PVAPI_PIXELFORMAT_MONO8 = 1\n",
      "    CAP_PVAPI_PIXELFORMAT_RGB24 = 5\n",
      "    CAP_PVAPI_PIXELFORMAT_RGBA32 = 7\n",
      "    CAP_QT = 500\n",
      "    CAP_REALSENSE = 1500\n",
      "    CAP_UNICAP = 600\n",
      "    CAP_V4L = 200\n",
      "    CAP_V4L2 = 200\n",
      "    CAP_VFW = 200\n",
      "    CAP_WINRT = 1410\n",
      "    CAP_XIAPI = 1100\n",
      "    CAP_XINE = 2400\n",
      "    CASCADE_DO_CANNY_PRUNING = 1\n",
      "    CASCADE_DO_ROUGH_SEARCH = 8\n",
      "    CASCADE_FIND_BIGGEST_OBJECT = 4\n",
      "    CASCADE_SCALE_IMAGE = 2\n",
      "    CCL_DEFAULT = -1\n",
      "    CCL_GRANA = 1\n",
      "    CCL_WU = 0\n",
      "    CC_STAT_AREA = 4\n",
      "    CC_STAT_HEIGHT = 3\n",
      "    CC_STAT_LEFT = 0\n",
      "    CC_STAT_MAX = 5\n",
      "    CC_STAT_TOP = 1\n",
      "    CC_STAT_WIDTH = 2\n",
      "    CHAIN_APPROX_NONE = 1\n",
      "    CHAIN_APPROX_SIMPLE = 2\n",
      "    CHAIN_APPROX_TC89_KCOS = 4\n",
      "    CHAIN_APPROX_TC89_L1 = 3\n",
      "    CIRCLES_GRID_FINDER_PARAMETERS_ASYMMETRIC_GRID = 1\n",
      "    CIRCLES_GRID_FINDER_PARAMETERS_SYMMETRIC_GRID = 0\n",
      "    CMP_EQ = 0\n",
      "    CMP_GE = 2\n",
      "    CMP_GT = 1\n",
      "    CMP_LE = 4\n",
      "    CMP_LT = 3\n",
      "    CMP_NE = 5\n",
      "    COLORMAP_AUTUMN = 0\n",
      "    COLORMAP_BONE = 1\n",
      "    COLORMAP_CIVIDIS = 17\n",
      "    COLORMAP_COOL = 8\n",
      "    COLORMAP_HOT = 11\n",
      "    COLORMAP_HSV = 9\n",
      "    COLORMAP_INFERNO = 14\n",
      "    COLORMAP_JET = 2\n",
      "    COLORMAP_MAGMA = 13\n",
      "    COLORMAP_OCEAN = 5\n",
      "    COLORMAP_PARULA = 12\n",
      "    COLORMAP_PINK = 10\n",
      "    COLORMAP_PLASMA = 15\n",
      "    COLORMAP_RAINBOW = 4\n",
      "    COLORMAP_SPRING = 7\n",
      "    COLORMAP_SUMMER = 6\n",
      "    COLORMAP_TWILIGHT = 18\n",
      "    COLORMAP_TWILIGHT_SHIFTED = 19\n",
      "    COLORMAP_VIRIDIS = 16\n",
      "    COLORMAP_WINTER = 3\n",
      "    COLOR_BAYER_BG2BGR = 46\n",
      "    COLOR_BAYER_BG2BGRA = 139\n",
      "    COLOR_BAYER_BG2BGR_EA = 135\n",
      "    COLOR_BAYER_BG2BGR_VNG = 62\n",
      "    COLOR_BAYER_BG2GRAY = 86\n",
      "    COLOR_BAYER_BG2RGB = 48\n",
      "    COLOR_BAYER_BG2RGBA = 141\n",
      "    COLOR_BAYER_BG2RGB_EA = 137\n",
      "    COLOR_BAYER_BG2RGB_VNG = 64\n",
      "    COLOR_BAYER_GB2BGR = 47\n",
      "    COLOR_BAYER_GB2BGRA = 140\n",
      "    COLOR_BAYER_GB2BGR_EA = 136\n",
      "    COLOR_BAYER_GB2BGR_VNG = 63\n",
      "    COLOR_BAYER_GB2GRAY = 87\n",
      "    COLOR_BAYER_GB2RGB = 49\n",
      "    COLOR_BAYER_GB2RGBA = 142\n",
      "    COLOR_BAYER_GB2RGB_EA = 138\n",
      "    COLOR_BAYER_GB2RGB_VNG = 65\n",
      "    COLOR_BAYER_GR2BGR = 49\n",
      "    COLOR_BAYER_GR2BGRA = 142\n",
      "    COLOR_BAYER_GR2BGR_EA = 138\n",
      "    COLOR_BAYER_GR2BGR_VNG = 65\n",
      "    COLOR_BAYER_GR2GRAY = 89\n",
      "    COLOR_BAYER_GR2RGB = 47\n",
      "    COLOR_BAYER_GR2RGBA = 140\n",
      "    COLOR_BAYER_GR2RGB_EA = 136\n",
      "    COLOR_BAYER_GR2RGB_VNG = 63\n",
      "    COLOR_BAYER_RG2BGR = 48\n",
      "    COLOR_BAYER_RG2BGRA = 141\n",
      "    COLOR_BAYER_RG2BGR_EA = 137\n",
      "    COLOR_BAYER_RG2BGR_VNG = 64\n",
      "    COLOR_BAYER_RG2GRAY = 88\n",
      "    COLOR_BAYER_RG2RGB = 46\n",
      "    COLOR_BAYER_RG2RGBA = 139\n",
      "    COLOR_BAYER_RG2RGB_EA = 135\n",
      "    COLOR_BAYER_RG2RGB_VNG = 62\n",
      "    COLOR_BGR2BGR555 = 22\n",
      "    COLOR_BGR2BGR565 = 12\n",
      "    COLOR_BGR2BGRA = 0\n",
      "    COLOR_BGR2GRAY = 6\n",
      "    COLOR_BGR2HLS = 52\n",
      "    COLOR_BGR2HLS_FULL = 68\n",
      "    COLOR_BGR2HSV = 40\n",
      "    COLOR_BGR2HSV_FULL = 66\n",
      "    COLOR_BGR2LAB = 44\n",
      "    COLOR_BGR2LUV = 50\n",
      "    COLOR_BGR2Lab = 44\n",
      "    COLOR_BGR2Luv = 50\n",
      "    COLOR_BGR2RGB = 4\n",
      "    COLOR_BGR2RGBA = 2\n",
      "    COLOR_BGR2XYZ = 32\n",
      "    COLOR_BGR2YCR_CB = 36\n",
      "    COLOR_BGR2YCrCb = 36\n",
      "    COLOR_BGR2YUV = 82\n",
      "    COLOR_BGR2YUV_I420 = 128\n",
      "    COLOR_BGR2YUV_IYUV = 128\n",
      "    COLOR_BGR2YUV_YV12 = 132\n",
      "    COLOR_BGR5552BGR = 24\n",
      "    COLOR_BGR5552BGRA = 28\n",
      "    COLOR_BGR5552GRAY = 31\n",
      "    COLOR_BGR5552RGB = 25\n",
      "    COLOR_BGR5552RGBA = 29\n",
      "    COLOR_BGR5652BGR = 14\n",
      "    COLOR_BGR5652BGRA = 18\n",
      "    COLOR_BGR5652GRAY = 21\n",
      "    COLOR_BGR5652RGB = 15\n",
      "    COLOR_BGR5652RGBA = 19\n",
      "    COLOR_BGRA2BGR = 1\n",
      "    COLOR_BGRA2BGR555 = 26\n",
      "    COLOR_BGRA2BGR565 = 16\n",
      "    COLOR_BGRA2GRAY = 10\n",
      "    COLOR_BGRA2RGB = 3\n",
      "    COLOR_BGRA2RGBA = 5\n",
      "    COLOR_BGRA2YUV_I420 = 130\n",
      "    COLOR_BGRA2YUV_IYUV = 130\n",
      "    COLOR_BGRA2YUV_YV12 = 134\n",
      "    COLOR_BayerBG2BGR = 46\n",
      "    COLOR_BayerBG2BGRA = 139\n",
      "    COLOR_BayerBG2BGR_EA = 135\n",
      "    COLOR_BayerBG2BGR_VNG = 62\n",
      "    COLOR_BayerBG2GRAY = 86\n",
      "    COLOR_BayerBG2RGB = 48\n",
      "    COLOR_BayerBG2RGBA = 141\n",
      "    COLOR_BayerBG2RGB_EA = 137\n",
      "    COLOR_BayerBG2RGB_VNG = 64\n",
      "    COLOR_BayerGB2BGR = 47\n",
      "    COLOR_BayerGB2BGRA = 140\n",
      "    COLOR_BayerGB2BGR_EA = 136\n",
      "    COLOR_BayerGB2BGR_VNG = 63\n",
      "    COLOR_BayerGB2GRAY = 87\n",
      "    COLOR_BayerGB2RGB = 49\n",
      "    COLOR_BayerGB2RGBA = 142\n",
      "    COLOR_BayerGB2RGB_EA = 138\n",
      "    COLOR_BayerGB2RGB_VNG = 65\n",
      "    COLOR_BayerGR2BGR = 49\n",
      "    COLOR_BayerGR2BGRA = 142\n",
      "    COLOR_BayerGR2BGR_EA = 138\n",
      "    COLOR_BayerGR2BGR_VNG = 65\n",
      "    COLOR_BayerGR2GRAY = 89\n",
      "    COLOR_BayerGR2RGB = 47\n",
      "    COLOR_BayerGR2RGBA = 140\n",
      "    COLOR_BayerGR2RGB_EA = 136\n",
      "    COLOR_BayerGR2RGB_VNG = 63\n",
      "    COLOR_BayerRG2BGR = 48\n",
      "    COLOR_BayerRG2BGRA = 141\n",
      "    COLOR_BayerRG2BGR_EA = 137\n",
      "    COLOR_BayerRG2BGR_VNG = 64\n",
      "    COLOR_BayerRG2GRAY = 88\n",
      "    COLOR_BayerRG2RGB = 46\n",
      "    COLOR_BayerRG2RGBA = 139\n",
      "    COLOR_BayerRG2RGB_EA = 135\n",
      "    COLOR_BayerRG2RGB_VNG = 62\n",
      "    COLOR_COLORCVT_MAX = 143\n",
      "    COLOR_GRAY2BGR = 8\n",
      "    COLOR_GRAY2BGR555 = 30\n",
      "    COLOR_GRAY2BGR565 = 20\n",
      "    COLOR_GRAY2BGRA = 9\n",
      "    COLOR_GRAY2RGB = 8\n",
      "    COLOR_GRAY2RGBA = 9\n",
      "    COLOR_HLS2BGR = 60\n",
      "    COLOR_HLS2BGR_FULL = 72\n",
      "    COLOR_HLS2RGB = 61\n",
      "    COLOR_HLS2RGB_FULL = 73\n",
      "    COLOR_HSV2BGR = 54\n",
      "    COLOR_HSV2BGR_FULL = 70\n",
      "    COLOR_HSV2RGB = 55\n",
      "    COLOR_HSV2RGB_FULL = 71\n",
      "    COLOR_LAB2BGR = 56\n",
      "    COLOR_LAB2LBGR = 78\n",
      "    COLOR_LAB2LRGB = 79\n",
      "    COLOR_LAB2RGB = 57\n",
      "    COLOR_LBGR2LAB = 74\n",
      "    COLOR_LBGR2LUV = 76\n",
      "    COLOR_LBGR2Lab = 74\n",
      "    COLOR_LBGR2Luv = 76\n",
      "    COLOR_LRGB2LAB = 75\n",
      "    COLOR_LRGB2LUV = 77\n",
      "    COLOR_LRGB2Lab = 75\n",
      "    COLOR_LRGB2Luv = 77\n",
      "    COLOR_LUV2BGR = 58\n",
      "    COLOR_LUV2LBGR = 80\n",
      "    COLOR_LUV2LRGB = 81\n",
      "    COLOR_LUV2RGB = 59\n",
      "    COLOR_Lab2BGR = 56\n",
      "    COLOR_Lab2LBGR = 78\n",
      "    COLOR_Lab2LRGB = 79\n",
      "    COLOR_Lab2RGB = 57\n",
      "    COLOR_Luv2BGR = 58\n",
      "    COLOR_Luv2LBGR = 80\n",
      "    COLOR_Luv2LRGB = 81\n",
      "    COLOR_Luv2RGB = 59\n",
      "    COLOR_M_RGBA2RGBA = 126\n",
      "    COLOR_RGB2BGR = 4\n",
      "    COLOR_RGB2BGR555 = 23\n",
      "    COLOR_RGB2BGR565 = 13\n",
      "    COLOR_RGB2BGRA = 2\n",
      "    COLOR_RGB2GRAY = 7\n",
      "    COLOR_RGB2HLS = 53\n",
      "    COLOR_RGB2HLS_FULL = 69\n",
      "    COLOR_RGB2HSV = 41\n",
      "    COLOR_RGB2HSV_FULL = 67\n",
      "    COLOR_RGB2LAB = 45\n",
      "    COLOR_RGB2LUV = 51\n",
      "    COLOR_RGB2Lab = 45\n",
      "    COLOR_RGB2Luv = 51\n",
      "    COLOR_RGB2RGBA = 0\n",
      "    COLOR_RGB2XYZ = 33\n",
      "    COLOR_RGB2YCR_CB = 37\n",
      "    COLOR_RGB2YCrCb = 37\n",
      "    COLOR_RGB2YUV = 83\n",
      "    COLOR_RGB2YUV_I420 = 127\n",
      "    COLOR_RGB2YUV_IYUV = 127\n",
      "    COLOR_RGB2YUV_YV12 = 131\n",
      "    COLOR_RGBA2BGR = 3\n",
      "    COLOR_RGBA2BGR555 = 27\n",
      "    COLOR_RGBA2BGR565 = 17\n",
      "    COLOR_RGBA2BGRA = 5\n",
      "    COLOR_RGBA2GRAY = 11\n",
      "    COLOR_RGBA2M_RGBA = 125\n",
      "    COLOR_RGBA2RGB = 1\n",
      "    COLOR_RGBA2YUV_I420 = 129\n",
      "    COLOR_RGBA2YUV_IYUV = 129\n",
      "    COLOR_RGBA2YUV_YV12 = 133\n",
      "    COLOR_RGBA2mRGBA = 125\n",
      "    COLOR_XYZ2BGR = 34\n",
      "    COLOR_XYZ2RGB = 35\n",
      "    COLOR_YCR_CB2BGR = 38\n",
      "    COLOR_YCR_CB2RGB = 39\n",
      "    COLOR_YCrCb2BGR = 38\n",
      "    COLOR_YCrCb2RGB = 39\n",
      "    COLOR_YUV2BGR = 84\n",
      "    COLOR_YUV2BGRA_I420 = 105\n",
      "    COLOR_YUV2BGRA_IYUV = 105\n",
      "    COLOR_YUV2BGRA_NV12 = 95\n",
      "    COLOR_YUV2BGRA_NV21 = 97\n",
      "    COLOR_YUV2BGRA_UYNV = 112\n",
      "    COLOR_YUV2BGRA_UYVY = 112\n",
      "    COLOR_YUV2BGRA_Y422 = 112\n",
      "    COLOR_YUV2BGRA_YUNV = 120\n",
      "    COLOR_YUV2BGRA_YUY2 = 120\n",
      "    COLOR_YUV2BGRA_YUYV = 120\n",
      "    COLOR_YUV2BGRA_YV12 = 103\n",
      "    COLOR_YUV2BGRA_YVYU = 122\n",
      "    COLOR_YUV2BGR_I420 = 101\n",
      "    COLOR_YUV2BGR_IYUV = 101\n",
      "    COLOR_YUV2BGR_NV12 = 91\n",
      "    COLOR_YUV2BGR_NV21 = 93\n",
      "    COLOR_YUV2BGR_UYNV = 108\n",
      "    COLOR_YUV2BGR_UYVY = 108\n",
      "    COLOR_YUV2BGR_Y422 = 108\n",
      "    COLOR_YUV2BGR_YUNV = 116\n",
      "    COLOR_YUV2BGR_YUY2 = 116\n",
      "    COLOR_YUV2BGR_YUYV = 116\n",
      "    COLOR_YUV2BGR_YV12 = 99\n",
      "    COLOR_YUV2BGR_YVYU = 118\n",
      "    COLOR_YUV2GRAY_420 = 106\n",
      "    COLOR_YUV2GRAY_I420 = 106\n",
      "    COLOR_YUV2GRAY_IYUV = 106\n",
      "    COLOR_YUV2GRAY_NV12 = 106\n",
      "    COLOR_YUV2GRAY_NV21 = 106\n",
      "    COLOR_YUV2GRAY_UYNV = 123\n",
      "    COLOR_YUV2GRAY_UYVY = 123\n",
      "    COLOR_YUV2GRAY_Y422 = 123\n",
      "    COLOR_YUV2GRAY_YUNV = 124\n",
      "    COLOR_YUV2GRAY_YUY2 = 124\n",
      "    COLOR_YUV2GRAY_YUYV = 124\n",
      "    COLOR_YUV2GRAY_YV12 = 106\n",
      "    COLOR_YUV2GRAY_YVYU = 124\n",
      "    COLOR_YUV2RGB = 85\n",
      "    COLOR_YUV2RGBA_I420 = 104\n",
      "    COLOR_YUV2RGBA_IYUV = 104\n",
      "    COLOR_YUV2RGBA_NV12 = 94\n",
      "    COLOR_YUV2RGBA_NV21 = 96\n",
      "    COLOR_YUV2RGBA_UYNV = 111\n",
      "    COLOR_YUV2RGBA_UYVY = 111\n",
      "    COLOR_YUV2RGBA_Y422 = 111\n",
      "    COLOR_YUV2RGBA_YUNV = 119\n",
      "    COLOR_YUV2RGBA_YUY2 = 119\n",
      "    COLOR_YUV2RGBA_YUYV = 119\n",
      "    COLOR_YUV2RGBA_YV12 = 102\n",
      "    COLOR_YUV2RGBA_YVYU = 121\n",
      "    COLOR_YUV2RGB_I420 = 100\n",
      "    COLOR_YUV2RGB_IYUV = 100\n",
      "    COLOR_YUV2RGB_NV12 = 90\n",
      "    COLOR_YUV2RGB_NV21 = 92\n",
      "    COLOR_YUV2RGB_UYNV = 107\n",
      "    COLOR_YUV2RGB_UYVY = 107\n",
      "    COLOR_YUV2RGB_Y422 = 107\n",
      "    COLOR_YUV2RGB_YUNV = 115\n",
      "    COLOR_YUV2RGB_YUY2 = 115\n",
      "    COLOR_YUV2RGB_YUYV = 115\n",
      "    COLOR_YUV2RGB_YV12 = 98\n",
      "    COLOR_YUV2RGB_YVYU = 117\n",
      "    COLOR_YUV420P2BGR = 99\n",
      "    COLOR_YUV420P2BGRA = 103\n",
      "    COLOR_YUV420P2GRAY = 106\n",
      "    COLOR_YUV420P2RGB = 98\n",
      "    COLOR_YUV420P2RGBA = 102\n",
      "    COLOR_YUV420SP2BGR = 93\n",
      "    COLOR_YUV420SP2BGRA = 97\n",
      "    COLOR_YUV420SP2GRAY = 106\n",
      "    COLOR_YUV420SP2RGB = 92\n",
      "    COLOR_YUV420SP2RGBA = 96\n",
      "    COLOR_YUV420p2BGR = 99\n",
      "    COLOR_YUV420p2BGRA = 103\n",
      "    COLOR_YUV420p2GRAY = 106\n",
      "    COLOR_YUV420p2RGB = 98\n",
      "    COLOR_YUV420p2RGBA = 102\n",
      "    COLOR_YUV420sp2BGR = 93\n",
      "    COLOR_YUV420sp2BGRA = 97\n",
      "    COLOR_YUV420sp2GRAY = 106\n",
      "    COLOR_YUV420sp2RGB = 92\n",
      "    COLOR_YUV420sp2RGBA = 96\n",
      "    COLOR_mRGBA2RGBA = 126\n",
      "    CONTOURS_MATCH_I1 = 1\n",
      "    CONTOURS_MATCH_I2 = 2\n",
      "    CONTOURS_MATCH_I3 = 3\n",
      "    COVAR_COLS = 16\n",
      "    COVAR_NORMAL = 1\n",
      "    COVAR_ROWS = 8\n",
      "    COVAR_SCALE = 4\n",
      "    COVAR_SCRAMBLED = 0\n",
      "    COVAR_USE_AVG = 2\n",
      "    CV_16S = 3\n",
      "    CV_16SC1 = 3\n",
      "    CV_16SC2 = 11\n",
      "    CV_16SC3 = 19\n",
      "    CV_16SC4 = 27\n",
      "    CV_16U = 2\n",
      "    CV_16UC1 = 2\n",
      "    CV_16UC2 = 10\n",
      "    CV_16UC3 = 18\n",
      "    CV_16UC4 = 26\n",
      "    CV_32F = 5\n",
      "    CV_32FC1 = 5\n",
      "    CV_32FC2 = 13\n",
      "    CV_32FC3 = 21\n",
      "    CV_32FC4 = 29\n",
      "    CV_32S = 4\n",
      "    CV_32SC1 = 4\n",
      "    CV_32SC2 = 12\n",
      "    CV_32SC3 = 20\n",
      "    CV_32SC4 = 28\n",
      "    CV_64F = 6\n",
      "    CV_64FC1 = 6\n",
      "    CV_64FC2 = 14\n",
      "    CV_64FC3 = 22\n",
      "    CV_64FC4 = 30\n",
      "    CV_8S = 1\n",
      "    CV_8SC1 = 1\n",
      "    CV_8SC2 = 9\n",
      "    CV_8SC3 = 17\n",
      "    CV_8SC4 = 25\n",
      "    CV_8U = 0\n",
      "    CV_8UC1 = 0\n",
      "    CV_8UC2 = 8\n",
      "    CV_8UC3 = 16\n",
      "    CV_8UC4 = 24\n",
      "    CirclesGridFinderParameters_ASYMMETRIC_GRID = 1\n",
      "    CirclesGridFinderParameters_SYMMETRIC_GRID = 0\n",
      "    DCT_INVERSE = 1\n",
      "    DCT_ROWS = 4\n",
      "    DECOMP_CHOLESKY = 3\n",
      "    DECOMP_EIG = 2\n",
      "    DECOMP_LU = 0\n",
      "    DECOMP_NORMAL = 16\n",
      "    DECOMP_QR = 4\n",
      "    DECOMP_SVD = 1\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE = 2\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING = 4\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMINGLUT = 5\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_L1 = 3\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_SL2 = 6\n",
      "    DESCRIPTOR_MATCHER_FLANNBASED = 1\n",
      "    DFT_COMPLEX_INPUT = 64\n",
      "    DFT_COMPLEX_OUTPUT = 16\n",
      "    DFT_INVERSE = 1\n",
      "    DFT_REAL_OUTPUT = 32\n",
      "    DFT_ROWS = 4\n",
      "    DFT_SCALE = 2\n",
      "    DISOPTICAL_FLOW_PRESET_FAST = 1\n",
      "    DISOPTICAL_FLOW_PRESET_MEDIUM = 2\n",
      "    DISOPTICAL_FLOW_PRESET_ULTRAFAST = 0\n",
      "    DISOpticalFlow_PRESET_FAST = 1\n",
      "    DISOpticalFlow_PRESET_MEDIUM = 2\n",
      "    DISOpticalFlow_PRESET_ULTRAFAST = 0\n",
      "    DIST_C = 3\n",
      "    DIST_FAIR = 5\n",
      "    DIST_HUBER = 7\n",
      "    DIST_L1 = 1\n",
      "    DIST_L12 = 4\n",
      "    DIST_L2 = 2\n",
      "    DIST_LABEL_CCOMP = 0\n",
      "    DIST_LABEL_PIXEL = 1\n",
      "    DIST_MASK_3 = 3\n",
      "    DIST_MASK_5 = 5\n",
      "    DIST_MASK_PRECISE = 0\n",
      "    DIST_USER = -1\n",
      "    DIST_WELSCH = 6\n",
      "    DRAW_MATCHES_FLAGS_DEFAULT = 0\n",
      "    DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG = 1\n",
      "    DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS = 4\n",
      "    DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS = 2\n",
      "    DescriptorMatcher_BRUTEFORCE = 2\n",
      "    DescriptorMatcher_BRUTEFORCE_HAMMING = 4\n",
      "    DescriptorMatcher_BRUTEFORCE_HAMMINGLUT = 5\n",
      "    DescriptorMatcher_BRUTEFORCE_L1 = 3\n",
      "    DescriptorMatcher_BRUTEFORCE_SL2 = 6\n",
      "    DescriptorMatcher_FLANNBASED = 1\n",
      "    DrawMatchesFlags_DEFAULT = 0\n",
      "    DrawMatchesFlags_DRAW_OVER_OUTIMG = 1\n",
      "    DrawMatchesFlags_DRAW_RICH_KEYPOINTS = 4\n",
      "    DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS = 2\n",
      "    EVENT_FLAG_ALTKEY = 32\n",
      "    EVENT_FLAG_CTRLKEY = 8\n",
      "    EVENT_FLAG_LBUTTON = 1\n",
      "    EVENT_FLAG_MBUTTON = 4\n",
      "    EVENT_FLAG_RBUTTON = 2\n",
      "    EVENT_FLAG_SHIFTKEY = 16\n",
      "    EVENT_LBUTTONDBLCLK = 7\n",
      "    EVENT_LBUTTONDOWN = 1\n",
      "    EVENT_LBUTTONUP = 4\n",
      "    EVENT_MBUTTONDBLCLK = 9\n",
      "    EVENT_MBUTTONDOWN = 3\n",
      "    EVENT_MBUTTONUP = 6\n",
      "    EVENT_MOUSEHWHEEL = 11\n",
      "    EVENT_MOUSEMOVE = 0\n",
      "    EVENT_MOUSEWHEEL = 10\n",
      "    EVENT_RBUTTONDBLCLK = 8\n",
      "    EVENT_RBUTTONDOWN = 2\n",
      "    EVENT_RBUTTONUP = 5\n",
      "    FAST_FEATURE_DETECTOR_FAST_N = 10002\n",
      "    FAST_FEATURE_DETECTOR_NONMAX_SUPPRESSION = 10001\n",
      "    FAST_FEATURE_DETECTOR_THRESHOLD = 10000\n",
      "    FAST_FEATURE_DETECTOR_TYPE_5_8 = 0\n",
      "    FAST_FEATURE_DETECTOR_TYPE_7_12 = 1\n",
      "    FAST_FEATURE_DETECTOR_TYPE_9_16 = 2\n",
      "    FILE_NODE_EMPTY = 16\n",
      "    FILE_NODE_FLOAT = 2\n",
      "    FILE_NODE_FLOW = 8\n",
      "    FILE_NODE_INT = 1\n",
      "    FILE_NODE_MAP = 5\n",
      "    FILE_NODE_NAMED = 32\n",
      "    FILE_NODE_NONE = 0\n",
      "    FILE_NODE_REAL = 2\n",
      "    FILE_NODE_SEQ = 4\n",
      "    FILE_NODE_STR = 3\n",
      "    FILE_NODE_STRING = 3\n",
      "    FILE_NODE_TYPE_MASK = 7\n",
      "    FILE_NODE_UNIFORM = 8\n",
      "    FILE_STORAGE_APPEND = 2\n",
      "    FILE_STORAGE_BASE64 = 64\n",
      "    FILE_STORAGE_FORMAT_AUTO = 0\n",
      "    FILE_STORAGE_FORMAT_JSON = 24\n",
      "    FILE_STORAGE_FORMAT_MASK = 56\n",
      "    FILE_STORAGE_FORMAT_XML = 8\n",
      "    FILE_STORAGE_FORMAT_YAML = 16\n",
      "    FILE_STORAGE_INSIDE_MAP = 4\n",
      "    FILE_STORAGE_MEMORY = 4\n",
      "    FILE_STORAGE_NAME_EXPECTED = 2\n",
      "    FILE_STORAGE_READ = 0\n",
      "    FILE_STORAGE_UNDEFINED = 0\n",
      "    FILE_STORAGE_VALUE_EXPECTED = 1\n",
      "    FILE_STORAGE_WRITE = 1\n",
      "    FILE_STORAGE_WRITE_BASE64 = 65\n",
      "    FILLED = -1\n",
      "    FILTER_SCHARR = -1\n",
      "    FLOODFILL_FIXED_RANGE = 65536\n",
      "    FLOODFILL_MASK_ONLY = 131072\n",
      "    FM_7POINT = 1\n",
      "    FM_8POINT = 2\n",
      "    FM_LMEDS = 4\n",
      "    FM_RANSAC = 8\n",
      "    FONT_HERSHEY_COMPLEX = 3\n",
      "    FONT_HERSHEY_COMPLEX_SMALL = 5\n",
      "    FONT_HERSHEY_DUPLEX = 2\n",
      "    FONT_HERSHEY_PLAIN = 1\n",
      "    FONT_HERSHEY_SCRIPT_COMPLEX = 7\n",
      "    FONT_HERSHEY_SCRIPT_SIMPLEX = 6\n",
      "    FONT_HERSHEY_SIMPLEX = 0\n",
      "    FONT_HERSHEY_TRIPLEX = 4\n",
      "    FONT_ITALIC = 16\n",
      "    FORMATTER_FMT_C = 5\n",
      "    FORMATTER_FMT_CSV = 2\n",
      "    FORMATTER_FMT_DEFAULT = 0\n",
      "    FORMATTER_FMT_MATLAB = 1\n",
      "    FORMATTER_FMT_NUMPY = 4\n",
      "    FORMATTER_FMT_PYTHON = 3\n",
      "    FastFeatureDetector_FAST_N = 10002\n",
      "    FastFeatureDetector_NONMAX_SUPPRESSION = 10001\n",
      "    FastFeatureDetector_THRESHOLD = 10000\n",
      "    FastFeatureDetector_TYPE_5_8 = 0\n",
      "    FastFeatureDetector_TYPE_7_12 = 1\n",
      "    FastFeatureDetector_TYPE_9_16 = 2\n",
      "    FileNode_EMPTY = 16\n",
      "    FileNode_FLOAT = 2\n",
      "    FileNode_FLOW = 8\n",
      "    FileNode_INT = 1\n",
      "    FileNode_MAP = 5\n",
      "    FileNode_NAMED = 32\n",
      "    FileNode_NONE = 0\n",
      "    FileNode_REAL = 2\n",
      "    FileNode_SEQ = 4\n",
      "    FileNode_STR = 3\n",
      "    FileNode_STRING = 3\n",
      "    FileNode_TYPE_MASK = 7\n",
      "    FileNode_UNIFORM = 8\n",
      "    FileStorage_APPEND = 2\n",
      "    FileStorage_BASE64 = 64\n",
      "    FileStorage_FORMAT_AUTO = 0\n",
      "    FileStorage_FORMAT_JSON = 24\n",
      "    FileStorage_FORMAT_MASK = 56\n",
      "    FileStorage_FORMAT_XML = 8\n",
      "    FileStorage_FORMAT_YAML = 16\n",
      "    FileStorage_INSIDE_MAP = 4\n",
      "    FileStorage_MEMORY = 4\n",
      "    FileStorage_NAME_EXPECTED = 2\n",
      "    FileStorage_READ = 0\n",
      "    FileStorage_UNDEFINED = 0\n",
      "    FileStorage_VALUE_EXPECTED = 1\n",
      "    FileStorage_WRITE = 1\n",
      "    FileStorage_WRITE_BASE64 = 65\n",
      "    Formatter_FMT_C = 5\n",
      "    Formatter_FMT_CSV = 2\n",
      "    Formatter_FMT_DEFAULT = 0\n",
      "    Formatter_FMT_MATLAB = 1\n",
      "    Formatter_FMT_NUMPY = 4\n",
      "    Formatter_FMT_PYTHON = 3\n",
      "    GC_BGD = 0\n",
      "    GC_EVAL = 2\n",
      "    GC_EVAL_FREEZE_MODEL = 3\n",
      "    GC_FGD = 1\n",
      "    GC_INIT_WITH_MASK = 1\n",
      "    GC_INIT_WITH_RECT = 0\n",
      "    GC_PR_BGD = 2\n",
      "    GC_PR_FGD = 3\n",
      "    GEMM_1_T = 1\n",
      "    GEMM_2_T = 2\n",
      "    GEMM_3_T = 4\n",
      "    HISTCMP_BHATTACHARYYA = 3\n",
      "    HISTCMP_CHISQR = 1\n",
      "    HISTCMP_CHISQR_ALT = 4\n",
      "    HISTCMP_CORREL = 0\n",
      "    HISTCMP_HELLINGER = 3\n",
      "    HISTCMP_INTERSECT = 2\n",
      "    HISTCMP_KL_DIV = 5\n",
      "    HOGDESCRIPTOR_DEFAULT_NLEVELS = 64\n",
      "    HOGDESCRIPTOR_DESCR_FORMAT_COL_BY_COL = 0\n",
      "    HOGDESCRIPTOR_DESCR_FORMAT_ROW_BY_ROW = 1\n",
      "    HOGDESCRIPTOR_L2HYS = 0\n",
      "    HOGDescriptor_DEFAULT_NLEVELS = 64\n",
      "    HOGDescriptor_DESCR_FORMAT_COL_BY_COL = 0\n",
      "    HOGDescriptor_DESCR_FORMAT_ROW_BY_ROW = 1\n",
      "    HOGDescriptor_L2Hys = 0\n",
      "    HOUGH_GRADIENT = 3\n",
      "    HOUGH_MULTI_SCALE = 2\n",
      "    HOUGH_PROBABILISTIC = 1\n",
      "    HOUGH_STANDARD = 0\n",
      "    IMREAD_ANYCOLOR = 4\n",
      "    IMREAD_ANYDEPTH = 2\n",
      "    IMREAD_COLOR = 1\n",
      "    IMREAD_GRAYSCALE = 0\n",
      "    IMREAD_IGNORE_ORIENTATION = 128\n",
      "    IMREAD_LOAD_GDAL = 8\n",
      "    IMREAD_REDUCED_COLOR_2 = 17\n",
      "    IMREAD_REDUCED_COLOR_4 = 33\n",
      "    IMREAD_REDUCED_COLOR_8 = 65\n",
      "    IMREAD_REDUCED_GRAYSCALE_2 = 16\n",
      "    IMREAD_REDUCED_GRAYSCALE_4 = 32\n",
      "    IMREAD_REDUCED_GRAYSCALE_8 = 64\n",
      "    IMREAD_UNCHANGED = -1\n",
      "    IMWRITE_EXR_TYPE = 48\n",
      "    IMWRITE_EXR_TYPE_FLOAT = 2\n",
      "    IMWRITE_EXR_TYPE_HALF = 1\n",
      "    IMWRITE_JPEG2000_COMPRESSION_X1000 = 272\n",
      "    IMWRITE_JPEG_CHROMA_QUALITY = 6\n",
      "    IMWRITE_JPEG_LUMA_QUALITY = 5\n",
      "    IMWRITE_JPEG_OPTIMIZE = 3\n",
      "    IMWRITE_JPEG_PROGRESSIVE = 2\n",
      "    IMWRITE_JPEG_QUALITY = 1\n",
      "    IMWRITE_JPEG_RST_INTERVAL = 4\n",
      "    IMWRITE_PAM_FORMAT_BLACKANDWHITE = 1\n",
      "    IMWRITE_PAM_FORMAT_GRAYSCALE = 2\n",
      "    IMWRITE_PAM_FORMAT_GRAYSCALE_ALPHA = 3\n",
      "    IMWRITE_PAM_FORMAT_NULL = 0\n",
      "    IMWRITE_PAM_FORMAT_RGB = 4\n",
      "    IMWRITE_PAM_FORMAT_RGB_ALPHA = 5\n",
      "    IMWRITE_PAM_TUPLETYPE = 128\n",
      "    IMWRITE_PNG_BILEVEL = 18\n",
      "    IMWRITE_PNG_COMPRESSION = 16\n",
      "    IMWRITE_PNG_STRATEGY = 17\n",
      "    IMWRITE_PNG_STRATEGY_DEFAULT = 0\n",
      "    IMWRITE_PNG_STRATEGY_FILTERED = 1\n",
      "    IMWRITE_PNG_STRATEGY_FIXED = 4\n",
      "    IMWRITE_PNG_STRATEGY_HUFFMAN_ONLY = 2\n",
      "    IMWRITE_PNG_STRATEGY_RLE = 3\n",
      "    IMWRITE_PXM_BINARY = 32\n",
      "    IMWRITE_TIFF_COMPRESSION = 259\n",
      "    IMWRITE_TIFF_RESUNIT = 256\n",
      "    IMWRITE_TIFF_XDPI = 257\n",
      "    IMWRITE_TIFF_YDPI = 258\n",
      "    IMWRITE_WEBP_QUALITY = 64\n",
      "    INPAINT_NS = 0\n",
      "    INPAINT_TELEA = 1\n",
      "    INTERSECT_FULL = 2\n",
      "    INTERSECT_NONE = 0\n",
      "    INTERSECT_PARTIAL = 1\n",
      "    INTER_AREA = 3\n",
      "    INTER_BITS = 5\n",
      "    INTER_BITS2 = 10\n",
      "    INTER_CUBIC = 2\n",
      "    INTER_LANCZOS4 = 4\n",
      "    INTER_LINEAR = 1\n",
      "    INTER_LINEAR_EXACT = 5\n",
      "    INTER_MAX = 7\n",
      "    INTER_NEAREST = 0\n",
      "    INTER_TAB_SIZE = 32\n",
      "    INTER_TAB_SIZE2 = 1024\n",
      "    KAZE_DIFF_CHARBONNIER = 3\n",
      "    KAZE_DIFF_PM_G1 = 0\n",
      "    KAZE_DIFF_PM_G2 = 1\n",
      "    KAZE_DIFF_WEICKERT = 2\n",
      "    KMEANS_PP_CENTERS = 2\n",
      "    KMEANS_RANDOM_CENTERS = 0\n",
      "    KMEANS_USE_INITIAL_LABELS = 1\n",
      "    LDR_SIZE = 256\n",
      "    LINE_4 = 4\n",
      "    LINE_8 = 8\n",
      "    LINE_AA = 16\n",
      "    LMEDS = 4\n",
      "    LSD_REFINE_ADV = 2\n",
      "    LSD_REFINE_NONE = 0\n",
      "    LSD_REFINE_STD = 1\n",
      "    MARKER_CROSS = 0\n",
      "    MARKER_DIAMOND = 3\n",
      "    MARKER_SQUARE = 4\n",
      "    MARKER_STAR = 2\n",
      "    MARKER_TILTED_CROSS = 1\n",
      "    MARKER_TRIANGLE_DOWN = 6\n",
      "    MARKER_TRIANGLE_UP = 5\n",
      "    MAT_AUTO_STEP = 0\n",
      "    MAT_CONTINUOUS_FLAG = 16384\n",
      "    MAT_DEPTH_MASK = 7\n",
      "    MAT_MAGIC_MASK = -65536\n",
      "    MAT_MAGIC_VAL = 1124007936\n",
      "    MAT_SUBMATRIX_FLAG = 32768\n",
      "    MAT_TYPE_MASK = 4095\n",
      "    MIXED_CLONE = 2\n",
      "    MONOCHROME_TRANSFER = 3\n",
      "    MORPH_BLACKHAT = 6\n",
      "    MORPH_CLOSE = 3\n",
      "    MORPH_CROSS = 1\n",
      "    MORPH_DILATE = 1\n",
      "    MORPH_ELLIPSE = 2\n",
      "    MORPH_ERODE = 0\n",
      "    MORPH_GRADIENT = 4\n",
      "    MORPH_HITMISS = 7\n",
      "    MORPH_OPEN = 2\n",
      "    MORPH_RECT = 0\n",
      "    MORPH_TOPHAT = 5\n",
      "    MOTION_AFFINE = 2\n",
      "    MOTION_EUCLIDEAN = 1\n",
      "    MOTION_HOMOGRAPHY = 3\n",
      "    MOTION_TRANSLATION = 0\n",
      "    Mat_AUTO_STEP = 0\n",
      "    Mat_CONTINUOUS_FLAG = 16384\n",
      "    Mat_DEPTH_MASK = 7\n",
      "    Mat_MAGIC_MASK = -65536\n",
      "    Mat_MAGIC_VAL = 1124007936\n",
      "    Mat_SUBMATRIX_FLAG = 32768\n",
      "    Mat_TYPE_MASK = 4095\n",
      "    NORMAL_CLONE = 1\n",
      "    NORMCONV_FILTER = 2\n",
      "    NORM_HAMMING = 6\n",
      "    NORM_HAMMING2 = 7\n",
      "    NORM_INF = 1\n",
      "    NORM_L1 = 2\n",
      "    NORM_L2 = 4\n",
      "    NORM_L2SQR = 5\n",
      "    NORM_MINMAX = 32\n",
      "    NORM_RELATIVE = 8\n",
      "    NORM_TYPE_MASK = 7\n",
      "    OPTFLOW_FARNEBACK_GAUSSIAN = 256\n",
      "    OPTFLOW_LK_GET_MIN_EIGENVALS = 8\n",
      "    OPTFLOW_USE_INITIAL_FLOW = 4\n",
      "    ORB_FAST_SCORE = 1\n",
      "    ORB_HARRIS_SCORE = 0\n",
      "    PARAM_ALGORITHM = 6\n",
      "    PARAM_BOOLEAN = 1\n",
      "    PARAM_FLOAT = 7\n",
      "    PARAM_INT = 0\n",
      "    PARAM_MAT = 4\n",
      "    PARAM_MAT_VECTOR = 5\n",
      "    PARAM_REAL = 2\n",
      "    PARAM_SCALAR = 12\n",
      "    PARAM_STRING = 3\n",
      "    PARAM_UCHAR = 11\n",
      "    PARAM_UINT64 = 9\n",
      "    PARAM_UNSIGNED_INT = 8\n",
      "    PCA_DATA_AS_COL = 1\n",
      "    PCA_DATA_AS_ROW = 0\n",
      "    PCA_USE_AVG = 2\n",
      "    PROJ_SPHERICAL_EQRECT = 1\n",
      "    PROJ_SPHERICAL_ORTHO = 0\n",
      "    Param_ALGORITHM = 6\n",
      "    Param_BOOLEAN = 1\n",
      "    Param_FLOAT = 7\n",
      "    Param_INT = 0\n",
      "    Param_MAT = 4\n",
      "    Param_MAT_VECTOR = 5\n",
      "    Param_REAL = 2\n",
      "    Param_SCALAR = 12\n",
      "    Param_STRING = 3\n",
      "    Param_UCHAR = 11\n",
      "    Param_UINT64 = 9\n",
      "    Param_UNSIGNED_INT = 8\n",
      "    QT_CHECKBOX = 1\n",
      "    QT_FONT_BLACK = 87\n",
      "    QT_FONT_BOLD = 75\n",
      "    QT_FONT_DEMIBOLD = 63\n",
      "    QT_FONT_LIGHT = 25\n",
      "    QT_FONT_NORMAL = 50\n",
      "    QT_NEW_BUTTONBAR = 1024\n",
      "    QT_PUSH_BUTTON = 0\n",
      "    QT_RADIOBOX = 2\n",
      "    QT_STYLE_ITALIC = 1\n",
      "    QT_STYLE_NORMAL = 0\n",
      "    QT_STYLE_OBLIQUE = 2\n",
      "    RANSAC = 8\n",
      "    RECURS_FILTER = 1\n",
      "    REDUCE_AVG = 1\n",
      "    REDUCE_MAX = 2\n",
      "    REDUCE_MIN = 3\n",
      "    REDUCE_SUM = 0\n",
      "    RETR_CCOMP = 2\n",
      "    RETR_EXTERNAL = 0\n",
      "    RETR_FLOODFILL = 4\n",
      "    RETR_LIST = 1\n",
      "    RETR_TREE = 3\n",
      "    RHO = 16\n",
      "    RNG_NORMAL = 1\n",
      "    RNG_UNIFORM = 0\n",
      "    ROTATE_180 = 1\n",
      "    ROTATE_90_CLOCKWISE = 0\n",
      "    ROTATE_90_COUNTERCLOCKWISE = 2\n",
      "    SOLVELP_MULTI = 1\n",
      "    SOLVELP_SINGLE = 0\n",
      "    SOLVELP_UNBOUNDED = -2\n",
      "    SOLVELP_UNFEASIBLE = -1\n",
      "    SOLVEPNP_AP3P = 5\n",
      "    SOLVEPNP_DLS = 3\n",
      "    SOLVEPNP_EPNP = 1\n",
      "    SOLVEPNP_ITERATIVE = 0\n",
      "    SOLVEPNP_MAX_COUNT = 6\n",
      "    SOLVEPNP_P3P = 2\n",
      "    SOLVEPNP_UPNP = 4\n",
      "    SORT_ASCENDING = 0\n",
      "    SORT_DESCENDING = 16\n",
      "    SORT_EVERY_COLUMN = 1\n",
      "    SORT_EVERY_ROW = 0\n",
      "    SPARSE_MAT_HASH_BIT = -2147483648\n",
      "    SPARSE_MAT_HASH_SCALE = 1540483477\n",
      "    SPARSE_MAT_MAGIC_VAL = 1123876864\n",
      "    SPARSE_MAT_MAX_DIM = 32\n",
      "    STEREO_BM_PREFILTER_NORMALIZED_RESPONSE = 0\n",
      "    STEREO_BM_PREFILTER_XSOBEL = 1\n",
      "    STEREO_MATCHER_DISP_SCALE = 16\n",
      "    STEREO_MATCHER_DISP_SHIFT = 4\n",
      "    STEREO_SGBM_MODE_HH = 1\n",
      "    STEREO_SGBM_MODE_HH4 = 3\n",
      "    STEREO_SGBM_MODE_SGBM = 0\n",
      "    STEREO_SGBM_MODE_SGBM_3WAY = 2\n",
      "    STITCHER_ERR_CAMERA_PARAMS_ADJUST_FAIL = 3\n",
      "    STITCHER_ERR_HOMOGRAPHY_EST_FAIL = 2\n",
      "    STITCHER_ERR_NEED_MORE_IMGS = 1\n",
      "    STITCHER_OK = 0\n",
      "    STITCHER_PANORAMA = 0\n",
      "    STITCHER_SCANS = 1\n",
      "    SUBDIV2D_NEXT_AROUND_DST = 34\n",
      "    SUBDIV2D_NEXT_AROUND_LEFT = 19\n",
      "    SUBDIV2D_NEXT_AROUND_ORG = 0\n",
      "    SUBDIV2D_NEXT_AROUND_RIGHT = 49\n",
      "    SUBDIV2D_PREV_AROUND_DST = 51\n",
      "    SUBDIV2D_PREV_AROUND_LEFT = 32\n",
      "    SUBDIV2D_PREV_AROUND_ORG = 17\n",
      "    SUBDIV2D_PREV_AROUND_RIGHT = 2\n",
      "    SUBDIV2D_PTLOC_ERROR = -2\n",
      "    SUBDIV2D_PTLOC_INSIDE = 0\n",
      "    SUBDIV2D_PTLOC_ON_EDGE = 2\n",
      "    SUBDIV2D_PTLOC_OUTSIDE_RECT = -1\n",
      "    SUBDIV2D_PTLOC_VERTEX = 1\n",
      "    SVD_FULL_UV = 4\n",
      "    SVD_MODIFY_A = 1\n",
      "    SVD_NO_UV = 2\n",
      "    SparseMat_HASH_BIT = -2147483648\n",
      "    SparseMat_HASH_SCALE = 1540483477\n",
      "    SparseMat_MAGIC_VAL = 1123876864\n",
      "    SparseMat_MAX_DIM = 32\n",
      "    StereoBM_PREFILTER_NORMALIZED_RESPONSE = 0\n",
      "    StereoBM_PREFILTER_XSOBEL = 1\n",
      "    StereoMatcher_DISP_SCALE = 16\n",
      "    StereoMatcher_DISP_SHIFT = 4\n",
      "    StereoSGBM_MODE_HH = 1\n",
      "    StereoSGBM_MODE_HH4 = 3\n",
      "    StereoSGBM_MODE_SGBM = 0\n",
      "    StereoSGBM_MODE_SGBM_3WAY = 2\n",
      "    Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL = 3\n",
      "    Stitcher_ERR_HOMOGRAPHY_EST_FAIL = 2\n",
      "    Stitcher_ERR_NEED_MORE_IMGS = 1\n",
      "    Stitcher_OK = 0\n",
      "    Stitcher_PANORAMA = 0\n",
      "    Stitcher_SCANS = 1\n",
      "    Subdiv2D_NEXT_AROUND_DST = 34\n",
      "    Subdiv2D_NEXT_AROUND_LEFT = 19\n",
      "    Subdiv2D_NEXT_AROUND_ORG = 0\n",
      "    Subdiv2D_NEXT_AROUND_RIGHT = 49\n",
      "    Subdiv2D_PREV_AROUND_DST = 51\n",
      "    Subdiv2D_PREV_AROUND_LEFT = 32\n",
      "    Subdiv2D_PREV_AROUND_ORG = 17\n",
      "    Subdiv2D_PREV_AROUND_RIGHT = 2\n",
      "    Subdiv2D_PTLOC_ERROR = -2\n",
      "    Subdiv2D_PTLOC_INSIDE = 0\n",
      "    Subdiv2D_PTLOC_ON_EDGE = 2\n",
      "    Subdiv2D_PTLOC_OUTSIDE_RECT = -1\n",
      "    Subdiv2D_PTLOC_VERTEX = 1\n",
      "    TERM_CRITERIA_COUNT = 1\n",
      "    TERM_CRITERIA_EPS = 2\n",
      "    TERM_CRITERIA_MAX_ITER = 1\n",
      "    THRESH_BINARY = 0\n",
      "    THRESH_BINARY_INV = 1\n",
      "    THRESH_MASK = 7\n",
      "    THRESH_OTSU = 8\n",
      "    THRESH_TOZERO = 3\n",
      "    THRESH_TOZERO_INV = 4\n",
      "    THRESH_TRIANGLE = 16\n",
      "    THRESH_TRUNC = 2\n",
      "    TM_CCOEFF = 4\n",
      "    TM_CCOEFF_NORMED = 5\n",
      "    TM_CCORR = 2\n",
      "    TM_CCORR_NORMED = 3\n",
      "    TM_SQDIFF = 0\n",
      "    TM_SQDIFF_NORMED = 1\n",
      "    TermCriteria_COUNT = 1\n",
      "    TermCriteria_EPS = 2\n",
      "    TermCriteria_MAX_ITER = 1\n",
      "    UMAT_AUTO_STEP = 0\n",
      "    UMAT_CONTINUOUS_FLAG = 16384\n",
      "    UMAT_DATA_ASYNC_CLEANUP = 128\n",
      "    UMAT_DATA_COPY_ON_MAP = 1\n",
      "    UMAT_DATA_DEVICE_COPY_OBSOLETE = 4\n",
      "    UMAT_DATA_DEVICE_MEM_MAPPED = 64\n",
      "    UMAT_DATA_HOST_COPY_OBSOLETE = 2\n",
      "    UMAT_DATA_TEMP_COPIED_UMAT = 24\n",
      "    UMAT_DATA_TEMP_UMAT = 8\n",
      "    UMAT_DATA_USER_ALLOCATED = 32\n",
      "    UMAT_DEPTH_MASK = 7\n",
      "    UMAT_MAGIC_MASK = -65536\n",
      "    UMAT_MAGIC_VAL = 1124007936\n",
      "    UMAT_SUBMATRIX_FLAG = 32768\n",
      "    UMAT_TYPE_MASK = 4095\n",
      "    UMatData_ASYNC_CLEANUP = 128\n",
      "    UMatData_COPY_ON_MAP = 1\n",
      "    UMatData_DEVICE_COPY_OBSOLETE = 4\n",
      "    UMatData_DEVICE_MEM_MAPPED = 64\n",
      "    UMatData_HOST_COPY_OBSOLETE = 2\n",
      "    UMatData_TEMP_COPIED_UMAT = 24\n",
      "    UMatData_TEMP_UMAT = 8\n",
      "    UMatData_USER_ALLOCATED = 32\n",
      "    UMat_AUTO_STEP = 0\n",
      "    UMat_CONTINUOUS_FLAG = 16384\n",
      "    UMat_DEPTH_MASK = 7\n",
      "    UMat_MAGIC_MASK = -65536\n",
      "    UMat_MAGIC_VAL = 1124007936\n",
      "    UMat_SUBMATRIX_FLAG = 32768\n",
      "    UMat_TYPE_MASK = 4095\n",
      "    USAGE_ALLOCATE_DEVICE_MEMORY = 2\n",
      "    USAGE_ALLOCATE_HOST_MEMORY = 1\n",
      "    USAGE_ALLOCATE_SHARED_MEMORY = 4\n",
      "    USAGE_DEFAULT = 0\n",
      "    VIDEOWRITER_PROP_FRAMEBYTES = 2\n",
      "    VIDEOWRITER_PROP_NSTRIPES = 3\n",
      "    VIDEOWRITER_PROP_QUALITY = 1\n",
      "    WARP_FILL_OUTLIERS = 8\n",
      "    WARP_INVERSE_MAP = 16\n",
      "    WARP_POLAR_LINEAR = 0\n",
      "    WARP_POLAR_LOG = 256\n",
      "    WINDOW_AUTOSIZE = 1\n",
      "    WINDOW_FREERATIO = 256\n",
      "    WINDOW_FULLSCREEN = 1\n",
      "    WINDOW_GUI_EXPANDED = 0\n",
      "    WINDOW_GUI_NORMAL = 16\n",
      "    WINDOW_KEEPRATIO = 0\n",
      "    WINDOW_NORMAL = 0\n",
      "    WINDOW_OPENGL = 4096\n",
      "    WND_PROP_ASPECT_RATIO = 2\n",
      "    WND_PROP_AUTOSIZE = 1\n",
      "    WND_PROP_FULLSCREEN = 0\n",
      "    WND_PROP_OPENGL = 3\n",
      "    WND_PROP_VISIBLE = 4\n",
      "    haarcascades = r'C:\\Users\\LUBNA\\Anaconda3\\lib\\site-packages\\cv2\\data\\'\n",
      "\n",
      "VERSION\n",
      "    4.1.0\n",
      "\n",
      "FILE\n",
      "    c:\\users\\lubna\\anaconda3\\lib\\site-packages\\cv2\\cv2.cp37-win_amd64.pyd\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
